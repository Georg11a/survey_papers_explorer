venue,title,authors,abstract,year,link,doi,pages,rank,peer_reviewed,area,gpt_confidence,gpt_note,file,original,type,publisher,acronym
AAAI Conference on Artificial Intelligence,“Reverse Gerrymandering”: Manipulation in Multi-Group Decision Making,Omer Lev;Yoad Lewenberg,"District-based manipulation, or gerrymandering, is usually taken to refer to agents who are in fixed location, and an external division is imposed upon them. However, in many real-world setting, there is an external, fixed division – an organizational chart of a company, or markets for a particular product. In these cases, agents may wish to move around( “reverse gerrymandering”) , as each of them tries to maximize their influence across the company’s subunits, or resources are “working” to be allocated to areas where they will be most needed. In this paper we explore an iterative dynamic in this setting, finding that allowing this decentralized system results, in some particular cases, in a stable equilibrium, though in general, the setting may end up in a cycle. We further examine how this decentralized process affects the social welfare of the system.",2019,https://ojs.aaai.org/index.php/AAAI/article/view/4037,10.1609/aaai.v33i01.33012069,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Game Theory and Economic Paradigms,AAAI,NA
AAAI Conference on Artificial Intelligence,3D-STMN: Dependency-Driven Superpoint-Text Matching Network for End-to-End 3D Referring Expression Segmentation,Changli Wu;Yiwei Ma;Qi Chen;Haowei Wang;Gen Luo;Jiayi Ji;Xiaoshuai Sun,"In 3D Referring Expression Segmentation( 3D-RES) , the earlier approach adopts a two-stage paradigm, extracting segmentation proposals and then matching them with referring expressions. However, this conventional paradigm encounters significant challenges, most notably in terms of the generation of lackluster initial proposals and a pronounced deceleration in inference speed. Recognizing these limitations, we introduce an innovative end-to-end Superpoint-Text Matching Network( 3D-STMN) that is enriched by dependency-driven insights. One of the keystones of our model is the Superpoint-Text Matching( STM) mechanism. Unlike traditional methods that navigate through instance proposals, STM directly correlates linguistic indications with their respective superpoints, clusters of semantically related points. This architectural decision empowers our model to efficiently harness cross-modal semantic relationships, primarily leveraging densely annotated superpoint-text pairs, as opposed to the more sparse instance-text pairs. In pursuit of enhancing the role of text in guiding the segmentation process, we further incorporate the Dependency-Driven Interaction( DDI) module to deepen the networks semantic comprehension of referring expressions. Using the dependency trees as a beacon, this module discerns the intricate relationships between primary terms and their associated descriptors in expressions, thereby elevating both the localization and segmentation capacities. Comprehensive experiments on the ScanRefer benchmark reveal that our model not only sets new performance standards, registering an mIoU gain of 11. 7 points but also achieves a staggering enhancement in inference speed, surpassing traditional methods by 95. 7 times. The code and models are available at https://github. com/sosppxo/3D-STMN.",2024,https://ojs.aaai.org/index.php/AAAI/article/view/28408,10.1609/aaai.v38i6.28408,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Computer Vision V,AAAI,NA
AAAI Conference on Artificial Intelligence,A Bayesian Spatial Model to Correct Under-Reporting in Urban Crowdsourcing,Gabriel Agostini;Emma Pierson;Nikhil Garg,"Decision-makers often observe the occurrence of events through a reporting process. City governments, for example, rely on resident reports to find and then resolve urban infrastructural problems such as fallen street trees, flooded basements, or rat infestations. Without additional assumptions, there is no way to distinguish events that occur but are not reported from events that truly did not occur--a fundamental problem in settings with positive-unlabeled data. Because disparities in reporting rates correlate with resident demographics, addressing incidents only on the basis of reports leads to systematic neglect in neighborhoods that are less likely to report events. We show how to overcome this challenge by leveraging the fact that events are spatially correlated. Our framework uses a Bayesian spatial latent variable model to infer event occurrence probabilities and applies it to storm-induced flooding reports in New York City, further pooling results across multiple storms. We show that a model accounting for under-reporting and spatial correlation predicts future reports more accurately than other models, and further induces a more equitable set of inspections: its allocations better reflect the population and provide equitable service to non-white, less traditionally educated, and lower-income residents. This finding reflects heterogeneous reporting behavior learned by the model: reporting rates are higher in Census tracts with higher populations, proportions of white residents, and proportions of owner-occupied households. Our work lays the groundwork for more equitable proactive government services, even with disparate reporting behavior.",2024,https://ojs.aaai.org/index.php/AAAI/article/view/30190,10.1609/aaai.v38i20.30190,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on AI for Social Impact Track,AAAI,NA
AAAI Conference on Artificial Intelligence,A BTP-Based Family of Variable Elimination Rules for Binary CSPs,Achref El Mouelhi,"The study of broken-triangles is becoming increasingly ambitious, by both solving constraint satisfaction problems( CSPs) in polynomial time and reducing search space size through value merging or variable elimination. Considerable progress has been made in extending this important concept, such as dual broken-triangle and weakly broken-triangle, in order to maximize the number of captured tractable CSP instances and/or the number of merged values. Specifically, m-wBTP allows to merge more values than BTP. k-BTP, WBTP and m-BTP permit to capture more tractable instances than BTP. Here, we introduce a new weaker form of BTP, which will be called m-fBTP for flexible broken-triangle property. m-fBTP allows on the one hand to eliminate more variables than BTP while preserving satisfiability and on the other to define new bigger tractable class for which arc consistency is a decision procedure. Likewise, m-fBTP permits to merge more values than BTP but less than m-wBTP.",2017,https://ojs.aaai.org/index.php/AAAI/article/view/11126,10.1609/aaai.v31i1.11126,NA,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,Main Track: Search and Constraint Satisfaction,AAAI,NA
AAAI Conference on Artificial Intelligence,A Case Study of the Shortcut Effects in Visual Commonsense Reasoning,Keren Ye;Adriana Kovashka,"Visual reasoning and question-answering have gathered attention in recent years. Many datasets and evaluation protocols have been proposed; some have been shown to contain bias that allows models to ``cheat without performing true, generalizable reasoning. A well-known bias is dependence on language priors( frequency of answers) resulting in the model not looking at the image. We discover a new type of bias in the Visual Commonsense Reasoning( VCR) dataset. In particular we show that most state-of-the-art models exploit co-occurring text between input( question) and output( answer options) , and rely on only a few pieces of information in the candidate options, to make a decision. Unfortunately, relying on such superficial evidence causes models to be very fragile. To measure fragility, we propose two ways to modify the validation data, in which a few words in the answer choices are modified without significant changes in meaning. We find such insignificant changes cause models performance to degrade significantly. To resolve the issue, we propose a curriculum-based masking approach, as a mechanism to perform more robust training. Our method improves the baseline by requiring it to pay attention to the answers as a whole, and is more effective than prior masking strategies.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/16428,10.1609/aaai.v35i4.16428,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Computer Vision III,AAAI,NA
AAAI Conference on Artificial Intelligence,A Complete Criterion for Value of Information in Soluble Influence Diagrams,Chris van Merwijk;Ryan Carey;Tom Everitt,"Influence diagrams have recently been used to analyse the safety and fairness properties of AI systems. A key building block for this analysis is a graphical criterion for value of information( VoI). This paper establishes the first complete graphical criterion for VoI in influence diagrams with multiple decisions. Along the way, we establish two techniques for proving properties of multi-decision influence diagrams: ID homomorphisms are structure-preserving transformations of influence diagrams, while a Tree of Systems is a collection of paths that captures how information and control can flow in an influence diagram.",2022,https://ojs.aaai.org/index.php/AAAI/article/view/21242,10.1609/aaai.v36i9.21242,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Reasoning under Uncertainty,AAAI,NA
AAAI Conference on Artificial Intelligence,A Data-Driven Approach for Gin Rummy Hand Evaluation,Sang T. Truong;Todd W. Neller,"We develop a data-driven approach for hand strength evaluation in the game of Gin Rummy. Employing Convolutional Neural Networks, Monte Carlo simulation, and Bayesian reasoning, we compute both offensive and defensive scores of a game state. After only one training cycle, the model was able to make sophisticated and human-like decisions with a 55. 4% +/- 0. 8% win rate( 90% confidence level) against a Simple player.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/17843,10.1609/aaai.v35i17.17843,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,EAAI Symposium: Full Papers,AAAI,NA
AAAI Conference on Artificial Intelligence,A Deep Model With Local Surrogate Loss for General Cost-Sensitive Multi-Label Learning,Cheng-Yu Hsieh;Yi-An Lin;Hsuan-Tien Lin,"Multi-label learning is an important machine learning problem with a wide range of applications. The variety of criteria for satisfying different application needs calls for cost-sensitive algorithms, which can adapt to different criteria easily. Nevertheless, because of the sophisticated nature of the criteria for multi-label learning, cost-sensitive algorithms for general criteria are hard to design, and current cost-sensitive algorithms can at most deal with some special types of criteria. In this work, we propose a novel cost-sensitive multi-label learning model for any general criteria. Our key idea within the model is to iteratively estimate a surrogate loss that approximates the sophisticated criterion of interest near some local neighborhood, and use the estimate to decide a descent direction for optimization. The key idea is then coupled with deep learning to form our proposed model. Experimental results validate that our proposed model is superior to existing cost-sensitive algorithms and existing deep learning models across different criteria.",2018,https://ojs.aaai.org/index.php/AAAI/article/view/11816,10.1609/aaai.v32i1.11816,NA,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Machine Learning,AAAI,NA
AAAI Conference on Artificial Intelligence,A Deep Reinforcement Learning Framework for Rebalancing Dockless Bike Sharing Systems,Ling Pan;Qingpeng Cai;Zhixuan Fang;Pingzhong Tang;Longbo Huang,"Bike sharing provides an environment-friendly way for traveling and is booming all over the world. Yet, due to the high similarity of user travel patterns, the bike imbalance problem constantly occurs, especially for dockless bike sharing systems, causing significant impact on service quality and company revenue. Thus, it has become a critical task for bike sharing operators to resolve such imbalance efficiently. In this paper, we propose a novel deep reinforcement learning framework for incentivizing users to rebalance such systems. We model the problem as a Markov decision process and take both spatial and temporal features into consideration. We develop a novel deep reinforcement learning algorithm called Hierarchical Reinforcement Pricing( HRP) , which builds upon the Deep Deterministic Policy Gradient algorithm. Different from existing methods that often ignore spatial information and rely heavily on accurate prediction, HRP captures both spatial and temporal dependencies using a divide-and-conquer structure with an embedded localized module. We conduct extensive experiments to evaluate HRP, based on a dataset from Mobike, a major Chinese dockless bike sharing company. Results show that HRP performs close to the 24-timeslot look-ahead optimization, and outperforms state-of-the-art methods in both service level and bike distribution. It also transfers well when applied to unseen areas.",2019,https://ojs.aaai.org/index.php/AAAI/article/view/3940,10.1609/aaai.v33i01.33011393,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Computational Sustainability,AAAI,NA
AAAI Conference on Artificial Intelligence,A Deep Sequential Model for Discourse Parsing on Multi-Party Dialogues,Zhouxing Shi;Minlie Huang,"Discourse structures are beneficial for various NLP tasks such as dialogue understanding, question answering, sentiment analysis, and so on. This paper presents a deep sequential model for parsing discourse dependency structures of multi-party dialogues. The proposed model aims to construct a discourse dependency tree by predicting dependency relations and constructing the discourse structure jointly and alternately. It makes a sequential scan of the Elementary DiscourseUnits( EDUs) 1 in a dialogue. For each EDU, the model decides to which previous EDU the current one should link and what the corresponding relation type is. The predicted link and relation type are then used to build the discourse structure incrementally with a structured encoder. During link prediction and relation classification, the model utilizes not only local information that represents the concerned EDUs, but also global information that encodes the EDU sequence and the discourse structure that is already built at the current step. Experiments show that the proposed model outperforms all the state-of-the-art baselines.",2019,https://ojs.aaai.org/index.php/AAAI/article/view/4680,10.1609/aaai.v33i01.33017007,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Natural Language Processing,AAAI,NA
AAAI Conference on Artificial Intelligence,A Deterministic Neural Network Approach to Playing Gin Rummy,Viet Dung Nguyen;Dung Doan;Todd W. Neller,"This paper describes a deterministic approach to building a fixed-strategy gin rummy player. In the paper, we develop and evaluate both heuristic and neural network models for informing draw, discard, and knock decisions in the game. In this empirical study, we test performance of the models through competitive game play, show which best inform strategy, and demonstrate statistical significance of the improvement over a simple strategy. Through this empirical study, we indicate features that we expect to be helpful in future improvements to Gin Rummy play.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/17840,10.1609/aaai.v35i17.17840,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,EAAI Symposium: Full Papers,AAAI,NA
AAAI Conference on Artificial Intelligence,A Distillation Approach to Data Efficient Individual Treatment Effect Estimation,Maggie Makar;Adith Swaminathan;Emre Kıcıman,"The potential for using machine learning algorithms as a tool for suggesting optimal interventions has fueled significant interest in developing methods for estimating heterogeneous or individual treatment effects( ITEs) from observational data. While several methods for estimating ITEs have been recently suggested, these methods assume no constraints on the availability of data at the time of deployment or test time. This assumption is unrealistic in settings where data acquisition is a significant part of the analysis pipeline, meaning data about a test case has to be collected in order to predict the ITE. In this work, we present Data Efficient Individual Treatment Effect Estimation( DEITEE) , a method which exploits the idea that adjusting for confounding, and hence collecting information about confounders, is not necessary at test time. DEITEE allows the development of rich models that exploit all variables at train time but identifies a minimal set of variables required to estimate the ITE at test time. Using 77 semi-synthetic datasets with varying data generating processes, we show that DEITEE achieves significant reductions in the number of variables required at test time with little to no loss in accuracy. Using real data, we demonstrate the utility of our approach in helping soon-to-be mothers make planning and lifestyle decisions that will impact newborn health.",2019,https://ojs.aaai.org/index.php/AAAI/article/view/4375,10.1609/aaai.v33i01.33014544,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Machine Learning,AAAI,NA
AAAI Conference on Artificial Intelligence,A Dynamic Rationalization of Distance Rationalizability,Craig Boutilier;Ariel Procaccia,"Distance rationalizability is an intuitive paradigm for developing and studying voting rules: given a notion of consensus and a distance function on preference profiles, a rationalizable voting rule selects an alternative that is closest to being a consensus winner. Despite its appeal, distance rationalizability faces the challenge of connecting the chosen distance measure and consensus notion to an operational measure of social desirability. We tackle this issue via the decision-theoretic framework of dynamic social choice, in which a social choice Markov decision process( MDP) models the dynamics of voter preferences in response to winner selection. We show that, for a prominent class of distance functions, one can construct a social choice MDP, with natural preference dynamics and rewards, such that a voting rule is( votewise) rationalizable with respect to the unanimity consensus for a given distance function iff it is a( deterministic) optimal policy in the MDP. This provides an alternative rationale for distance rationalizability, demonstrating the equivalence of rationalizable voting rules in a static sense and winner selection to maximize societal utility in a dynamic process.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/8240,10.1609/aaai.v26i1.8240,7,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Multiagent Systems,AAAI,NA
AAAI Conference on Artificial Intelligence,A Fair Incentive Scheme for Community Health Workers,Avinandan Bose;Tracey Li;Arunesh Sinha;Tien Mai,"Community health workers( CHWs) play a crucial role in the last mile delivery of essential health services to underserved populations in low-income countries. Many nongovernmental organizations( NGOs) provide training and support to enable CHWs to deliver health services to their communities, with no charge to the recipients of the services. This includes monetary compensation for the work that CHWs perform, which is broken down into a series of well defined tasks. In this work, we partner with a NGO D-Tree International to design a fair monetary compensation scheme for tasks performed by CHWs in the semi-autonomous region of Zanzibar in Tanzania, Africa. In consultation with stakeholders, we interpret fairness as the equal opportunity to earn, which means that each CHW has the opportunity to earn roughly the same total payment over a given T month period, if the CHW reacts to the incentive scheme almost rationally. We model this problem as a reward design problem for a Markov Decision Process( MDP) formulation for the CHWs’ earning. There is a need for the mechanism to be simple so that it is understood by the CHWs, thus, we explore linear and piecewise linear rewards in the CHWs’ measured units of work. We solve this design problem via a novel policy-reward gradient result. Our experiments using two real world parameters from the ground provide evidence of reasonable incentive output by our scheme.",2023,https://ojs.aaai.org/index.php/AAAI/article/view/26653,10.1609/aaai.v37i12.26653,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Special Track on AI for Social Impact,AAAI,NA
AAAI Conference on Artificial Intelligence,A General Search-Based Framework for Generating Textual Counterfactual Explanations,Daniel Gilo;Shaul Markovitch,"One of the prominent methods for explaining the decision of a machine-learning classifier is by a counterfactual example. Most current algorithms for generating such examples in the textual domain are based on generative language models. Generative models, however, are trained to minimize a specific loss function in order to fulfill certain requirements for the generated texts. Any change in the requirements may necessitate costly retraining, thus potentially limiting their applicability. In this paper, we present a general search-based framework for generating counterfactual explanations in the textual domain. Our framework is model-agnostic, domain-agnostic, anytime, and does not require retraining in order to adapt to changes in the user requirements. We model the task as a search problem in a space where the initial state is the classified text, and the goal state is a text in a given target class. Our framework includes domain-independent modification operators, but can also exploit domain-specific knowledge through specialized operators. The search algorithm attempts to find a text from the target class with minimal user-specified distance from the original classified object.",2024,https://ojs.aaai.org/index.php/AAAI/article/view/29764,10.1609/aaai.v38i16.29764,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Natural Language Processing I,AAAI,NA
AAAI Conference on Artificial Intelligence,A General Theoretical Framework for Learning Smallest Interpretable Models,Sebastian Ordyniak;Giacomo Paesani;Mateusz Rychlicki;Stefan Szeider,"We develop a general algorithmic framework that allows us to obtain fixed-parameter tractability for computing smallest symbolic models that represent given data. Our framework applies to all ML model types that admit a certain extension property. By showing this extension property for decision trees, decision sets, decision lists, and binary decision diagrams, we obtain that minimizing these fundamental model types is fixed-parameter tractable. Our framework even applies to ensembles, which combine individual models by majority decision.",2024,https://ojs.aaai.org/index.php/AAAI/article/view/28937,10.1609/aaai.v38i9.28937,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Knowledge Representation and Reasoning,AAAI,NA
AAAI Conference on Artificial Intelligence,A Highly-Parameterized Ensemble to Play Gin Rummy,Masayuki Nagai;Kavya Shrivastava;Kien Ta;Steven Bogaerts;Chad Byers,"This paper describes the design and training of a computer Gin Rummy player. The system includes three main components to make decisions about drawing cards, discarding, and ending the game, with numerous parameters controlling behavior. In particular, an ensemble approach is explored in the discard decision. Finally, three sets of parameter tuning and performance experiments are analyzed.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/17839,10.1609/aaai.v35i17.17839,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,EAAI Symposium: Full Papers,AAAI,NA
AAAI Conference on Artificial Intelligence,A Lyapunov-Based Methodology for Constrained Optimization with Bandit Feedback,Semih Cayci;Yilin Zheng;Atilla Eryilmaz,"In a wide variety of applications including online advertising, contractual hiring, and wireless scheduling, the controller is constrained by a stringent budget constraint on the available resources, which are consumed in a random amount by each action, and a stochastic feasibility constraint that may impose important operational limitations on decision-making. In this work, we consider a general model to address such problems, where each action returns a random reward, cost, and penalty from an unknown joint distribution, and the decision-maker aims to maximize the total reward under a budget constraint B on the total cost and a stochastic constraint on the time-average penalty. We propose a novel low-complexity algorithm based on Lyapunov optimization methodology, named LyOn, and prove that for K arms it achieves square root of KBlog( B) regret and zero constraint-violation when B is sufficiently large. The low computational cost and sharp performance bounds of LyOn suggest that Lyapunov-based algorithm design methodology can be effective in solving constrained bandit optimization problems.",2022,https://ojs.aaai.org/index.php/AAAI/article/view/20285,10.1609/aaai.v36i4.20285,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Constraint Satisfaction and Optimization,AAAI,NA
AAAI Conference on Artificial Intelligence,A Machine Learning Approach to Identify Houses with High Lead Tap Water Concentrations,Seyedsaeed Hajiseyedjavadi;Michael Blackhurst;Hassan A Karimi,"Over a century separates initial lead service lateral installations from the federal regulation of lead in drinking water. As such, municipalities often do not have adequate information describing installations of lead plumbing. Municipalities thus face challenges such as reducing exposure to lead in drinking water, spreading scarce resources for gathering information, adopting short-term protection measures( e. g. , providing filters) , and developing longer-term prevention strategies( e. g. , replacing lead laterals). Given the spatial and temporal patterns to properties, machine learning is seen as a useful tool to reduce uncertainty in decision making by authorities when addressing lead in water. The Pittsburgh Water and Sewer Authority( PWSA) is currently addressing these challenges in Pittsburgh and this paper describes the development and application of a model predicting high tap water concentrations( > 15 ppb) for PWSA customers. The model was developed using spatial cross validation to support PWSA’s interest in applying predictions in areas without training data. The model’s AUROC is 71. 6% and primarily relies on publicly available property tax assessment data and indicators of lateral material collected by PWSA as they meet regulatory requirements.",2020,https://ojs.aaai.org/index.php/AAAI/article/view/7040,10.1609/aaai.v34i08.7040,6,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,IAAI Technical Track: Emerging Papers,AAAI,NA
AAAI Conference on Artificial Intelligence,A Machine Learning Method for EV Range Prediction with Updates on Route Information and Traffic Conditions,Dohee Kim;Hong Gi Shim;Jeong Soo Eo,"Drivers anxiety about the remaining driving range of electric vehicles( EVs) has been quite improved by mounting a high-capacity battery pack. However, when EVs need to be charged, the drivers still feel uncomfortable if inaccurate range prediction is provided because the inaccuracy makes it difficult to decide when and where to charge EV. In this paper, to mitigate the EV range anxiety, a new machine learning( ML) method to enhance range prediction accuracy is proposed in a practical way. For continuously obtaining the recent traffic conditions ahead, input features indicating the near-future vehicle dynamics are connected to a long short-term memory( LSTM) network, which can consecutively utilize a relation of neighboring data, and then the output features of the LSTM network with another input features consisting of energy-related vehicle system states become another input layer for deep learning network( DNN). The proposed LSTM-DNN mixture model is trained by exploiting the driving data of about 160, 000 km and the following test performance shows that the model retains the range prediction accuracy of 2 ~ 3 km in a time window of 40 min. The test results indicate that the LSTM-DNN range prediction model is able to make a far-sighted range prediction while considering varying map and traffic information to a destination.",2022,https://ojs.aaai.org/index.php/AAAI/article/view/21525,10.1609/aaai.v36i11.21525,7,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,IAAI Technical Track on Emerging Applications of AI,AAAI,NA
AAAI Conference on Artificial Intelligence,A Model for Estimating the Economic Costs of Computer Vision Systems That Use Deep Learning,Neil Thompson;Martin Fleming;Benny J. Tang;Anna M. Pastwa;Nicholas Borge;Brian C. Goehring;Subhro Das,"Deep learning, the most important subfield of machine learning and artificial intelligence( AI) over the last decade, is considered one of the fundamental technologies underpinning the Fourth Industrial Revolution. But despite its record-breaking history, deep learning’s enormous appetite for compute and data means that sometimes it can be too costly to practically use. In this paper, we connect technical insights from deep learning scaling laws and transfer learning with the economics of IT to propose a framework for estimating the cost of deep learning computer vision systems to achieve a desired level of accuracy. Our tool can be of practical use to AI practitioners in industry or academia to guide investment decisions.",2024,https://ojs.aaai.org/index.php/AAAI/article/view/30343,10.1609/aaai.v38i21.30343,7,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,IAAI Technical Track on Deployed Innovative Tools for Enabling AI Applications,AAAI,NA
AAAI Conference on Artificial Intelligence,A New Bounding Scheme for Influence Diagrams,Radu Marinescu;Junkyu Lee;Rina Dechter,"Influence diagrams provide a modeling and inference framework for sequential decision problems, representing the probabilistic knowledge by a Bayesian network and the preferences of an agent by utility functions over the random variables and decision variables. Computing the maximum expected utility( MEU) and the optimizing policy is exponential in the constrained induced width and therefore is notoriously difficult for larger models. In this paper, we develop a new bounding scheme for MEU that applies partitioning based approximations on top of the decomposition scheme called a multi-operator cluster DAG for influence diagrams that is more sensitive to the underlying structure of the model than the classical join-tree decomposition of influence diagrams. Our bounding scheme utilizes a cost-shifting mechanism to tighten the bound further. We demonstrate the effectiveness of the proposed scheme on various hard benchmarks.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/17443,10.1609/aaai.v35i13.17443,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Reasoning under Uncertainty,AAAI,NA
AAAI Conference on Artificial Intelligence,A New Ensemble Adversarial Attack Powered by Long-Term Gradient Memories,Zhaohui Che;Ali Borji;Guangtao Zhai;Suiyi Ling;Jing Li;Patrick Le Callet,"Deep neural networks are vulnerable to adversarial attacks. More importantly, some adversarial examples crafted against an ensemble of pre-trained source models can transfer to other new target models, thus pose a security threat to black-box applications( when the attackers have no access to the target models). Despite adopting diverse architectures and parameters, source and target models often share similar decision boundaries. Therefore, if an adversary is capable of fooling several source models concurrently, it can potentially capture intrinsic transferable adversarial information that may allow it to fool a broad class of other black-box target models. Current ensemble attacks, however, only consider a limited number of source models to craft an adversary, and obtain poor transferability. In this paper, we propose a novel black-box attack, dubbed Serial-Mini-Batch-Ensemble-Attack( SMBEA). SMBEA divides a large number of pre-trained source models into several mini-batches. For each single batch, we design 3 new ensemble strategies to improve the intra-batch transferability. Besides, we propose a new algorithm that recursively accumulates the “long-term” gradient memories of the previous batch to the following batch. This way, the learned adversarial information can be preserved and the inter-batch transferability can be improved. Experiments indicate that our method outperforms state-of-the-art ensemble attacks over multiple pixel-to-pixel vision tasks including image translation and salient region prediction. Our method successfully fools two online black-box saliency prediction systems including DeepGaze-II( Kummerer 2017) and SALICON( Huang et al. 2017). Finally, we also contribute a new repository to promote the research on adversarial attack and defense over pixel-to-pixel tasks: https://github. com/CZHQuality/AAA-Pix2pix.",2020,https://ojs.aaai.org/index.php/AAAI/article/view/5743,10.1609/aaai.v34i04.5743,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Machine Learning,AAAI,NA
AAAI Conference on Artificial Intelligence,A Novel Visual Interpretability for Deep Neural Networks by Optimizing Activation Maps with Perturbation,Qinglong Zhang;Lu Rao;Yubin Yang,"Interpretability has been regarded as an essential component for deploying deep neural networks, in which the saliency-based method is one of the most prevailing interpretable approaches since it can generate individually intuitive heatmaps that highlight parts of the input image that are most important to the decision of the deep networks on a particular classification target. However, heatmaps generated by existing methods either contain little information to represent objects( perturbation-based methods) or cannot effectively locate multi-class objects( activation-based approaches). To address this issue, a two-stage framework for visualizing the interpretability of deep neural networks, called Activation Optimized with Perturbation( AOP) , is designed to optimize activation maps generated by general activation-based methods with the help of perturbation-based methods. Finally, in order to obtain better explanations for different types of images, we further present an instance of the AOP framework, Smooth Integrated Gradient-based Class Activation Map( SIGCAM) , which proposes a weighted GradCAM by applying the feature map as weight coefficients and employs I-GOS to optimize the base-mask generated by weighted GradCAM. Experimental results on common-used benchmarks, including deletion and insertion tests on ImageNet-1k, and pointing game tests on COCO2017, show that the proposed AOP and SIGCAM outperform the current state-of-the-art methods significantly by generating higher quality image-based saliency maps.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/16450,10.1609/aaai.v35i4.16450,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Computer Vision III,AAAI,NA
AAAI Conference on Artificial Intelligence,A PAC Framework for Aggregating Agents’ Judgments,Hanrui Zhang;Vincent Conitzer,"Specifying the objective function that an AI system should pursue can be challenging. Especially when the decisions to be made by the system have a moral component, input from multiple stakeholders is often required. We consider approaches that query them about their judgments in individual examples, and then aggregate these judgments into a general policy. We propose a formal learning-theoretic framework for this setting. We then give general results on how to translate classical results from PAC learning into results in our framework. Subsequently, we show that in some settings, better results can be obtained by working directly in our framework. Finally, we discuss how our model can be extended in a variety of ways for future research.",2019,https://ojs.aaai.org/index.php/AAAI/article/view/4059,10.1609/aaai.v33i01.33012237,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Game Theory and Economic Paradigms,AAAI,NA
AAAI Conference on Artificial Intelligence,A PAC Learning Algorithm for LTL and Omega-Regular Objectives in MDPs,Mateo Perez;Fabio Somenzi;Ashutosh Trivedi,"Linear temporal logic( LTL) and omega-regular objectives---a superset of LTL---have seen recent use as a way to express non-Markovian objectives in reinforcement learning. We introduce a model-based probably approximately correct( PAC) learning algorithm for omega-regular objectives in Markov decision processes( MDPs). As part of the development of our algorithm, we introduce the epsilon-recurrence time: a measure of the speed at which a policy converges to the satisfaction of the omega-regular objective in the limit. We prove that our algorithm only requires a polynomial number of samples in the relevant parameters, and perform experiments which confirm our theory.",2024,https://ojs.aaai.org/index.php/AAAI/article/view/30148,10.1609/aaai.v38i19.30148,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,"AAAI Technical Track on Safe, Robust and Responsible AI Track",AAAI,NA
AAAI Conference on Artificial Intelligence,A Pair-Approximation Method for Modelling the Dynamics of Multi-Agent Stochastic Games,Chen Chu;Zheng Yuan;Shuyue Hu;Chunjiang Mu;Zhen Wang,"Developing a dynamical model for learning in games has attracted much recent interest. In stochastic games, agents need to make decisions in multiple states, and transitions between states, in turn, influence the dynamics of strategies. While previous works typically focus either on 2-agent stochastic games or on normal form games under an infinite-agent setting, we aim at formally modelling the learning dynamics in stochastic games under the infinite-agent setting. With a novel use of pair-approximation method, we develop a formal model for myopic Q-learning in stochastic games with symmetric state transition. We verify the descriptive power of our model( a partial differential equation) across various games through comparisons with agent-based simulation results. Based on our proposed model, we can gain qualitative and quantitative insights into the influence of transition probabilities on the dynamics of strategies. In particular, we illustrate that a careful design of transition probabilities can help players overcome the social dilemmas and promote cooperation, even if agents are myopic learners.",2023,https://ojs.aaai.org/index.php/AAAI/article/view/25691,10.1609/aaai.v37i5.25691,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Game Theory and Economic Paradigms,AAAI,NA
AAAI Conference on Artificial Intelligence,A POMDP Formulation of Proactive Learning,Kyle Wray;Shlomo Zilberstein,"We cast the Proactive Learning( PAL) problem—Active Learning( AL) with multiple reluctant, fallible, cost-varying oracles—as a Partially Observable Markov Decision Process( POMDP). The agent selects an oracle at each time step to label a data point, while it maintains a belief over the true underlying correctness of its current dataset’s labels. The goal is to minimize labeling costs while considering the value of obtaining correct labels, thus maximizing final resultant classifier accuracy. We prove three properties that show our particular formulation leads to a structured and bounded-size set of belief points, enabling strong performance of point-based methods to solve the POMDP. Our method is compared with the original three algorithms proposed by Donmez and Carbonell and a simple baseline. We demonstrate that our approach matches or improves upon the original approach within five different oracle scenarios, each on two datasets. Finally, our algorithm provides a general, well-defined mathematical foundation to build upon.",2016,https://ojs.aaai.org/index.php/AAAI/article/view/10400,10.1609/aaai.v30i1.10400,NA,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,Technical Papers: Planning and Scheduling,AAAI,NA
AAAI Conference on Artificial Intelligence,A Primal-Dual Online Algorithm for Online Matching Problem in Dynamic Environments,Yu-Hang Zhou;Peng Hu;Chen Liang;Huan Xu;Guangda Huzhang;Yinfu Feng;Qing Da;Xinshang Wang;An-Xiang Zeng,"Recently, the online matching problem has attracted much attention due to its wide application on real-world decision-making scenarios. In stationary environments, by adopting the stochastic user arrival model, existing methods are proposed to learn dual optimal prices and are shown to achieve a fast regret bound. However, the stochastic model is no longer a proper assumption when the environment is changing, leading to an optimistic method that may suffer poor performance. In this paper, we study the online matching problem in dynamic environments in which the dual optimal prices are allowed to vary over time. We bound the dynamic regret of online matching problem by the sum of two quantities, including a regret of online max-min problem and a dynamic regret of online convex optimization( OCO) problem. Then we propose a novel online approach named Primal-Dual Online Algorithm( PDOA) to minimize both quantities. In particular, PDOA adopts the primal-dual framework by optimizing dual prices with the online gradient descent( OGD) algorithm to eliminate the online max-min problems regret. Moreover, it maintains a set of OGD experts and combines them via an expert-tracking algorithm, which gives a sublinear dynamic regret bound for the OCO problem. We show that PDOA achieves an O( K sqrt{T( 1+P_T) }) dynamic regret where K is the number of resources, T is the number of iterations and P_T is the path-length of any potential dual price sequence that reflects the dynamic environment. Finally, experiments on real applications exhibit the superiority of our approach.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/17331,10.1609/aaai.v35i12.17331,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Machine Learning V,AAAI,NA
AAAI Conference on Artificial Intelligence,A Provably-Efficient Model-Free Algorithm for Infinite-Horizon Average-Reward Constrained Markov Decision Processes,Honghao Wei;Xin Liu;Lei Ying,"This paper presents a model-free reinforcement learning( RL) algorithm for infinite-horizon average-reward Constrained Markov Decision Processes( CMDPs). Considering a learning horizon K, which is sufficiently large, the proposed algorithm achieves sublinear regret and zero constraint violation. The bounds depend on the number of states S, the number of actions A, and two constants which are independent of the learning horizon K.",2022,https://ojs.aaai.org/index.php/AAAI/article/view/20302,10.1609/aaai.v36i4.20302,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Constraint Satisfaction and Optimization,AAAI,NA
AAAI Conference on Artificial Intelligence,A PSPACE Subclass of Dependency Quantified Boolean Formulas and Its Effective Solving,Christoph Scholl;Jie-Hong Roland Jiang;Ralf Wimmer;Aile Ge-Ernst,"Dependency quantified Boolean formulas( DQBFs) are a powerful formalism, which subsumes quantified Boolean formulas( QBFs) and allows an explicit specification of dependencies of existential variables on universal variables. This enables a succinct encoding of decision problems in the NEXPTIME complexity class. As solving general DQBFs is NEXPTIME complete, in contrast to the PSPACE completeness of QBF solving, characterizing DQBF subclasses of lower computational complexity allows their effective solving and is of practical importance. Recently a DQBF proof calculus based on a notion of fork extension, in addition to resolution and universal reduction, was proposed by Rabe in 2017. We show that this calculus is in fact incomplete for general DQBFs, but complete for a subclass of DQBFs, where any two existential variables have either identical or disjoint dependency sets over the universal variables. We further characterize this DQBF subclass to be ΣP3 complete in the polynomial time hierarchy. Essentially using fork extension, a DQBF in this subclass can be converted to an equisatisfiable 3QBF with only a linear increase in formula size. We exploit this conversion for effective solving of this DQBF subclass and point out its potential as a general strategy for DQBF quantifier localization. Experimental results show that the method outperforms state-of-the-art DQBF solvers on a number of benchmarks, including the 2018 DQBF evaluation benchmarks.",2019,https://ojs.aaai.org/index.php/AAAI/article/view/3973,10.1609/aaai.v33i01.33011584,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Constraint Satisfaction and Optimization,AAAI,NA
AAAI Conference on Artificial Intelligence,A Recurrent Model for Collective Entity Linking with Adaptive Features,Xiaoling Zhou;Yukai Miao;Wei Wang;Jianbin Qin,"The vast amount of web data enables us to build knowledge bases with unprecedented quality and coverage. Named Entity Disambiguation( NED) is an important task that automatically resolves ambiguous mentions in free text to correct target entries in the knowledge base. Traditional machine learning based methods for NED were outperformed and made obsolete by the state-of-the-art deep learning based models. However, deep learning models are more complex, requiring large amount of training data and lengthy training and parameter tuning time. In this paper, we revisit traditional machine learning techniques and propose a light-weight, tuneable and time-efficient method without using deep learning or deep learning generated features. We propose novel adaptive features that focus on extracting discriminative features to better model similarities between candidate entities and the mentions context. We learn a local ranking model based on traditional and the new adaptive features based on the learning-to-rank framework. While arriving at linking decisions individually via the local model, our method also takes into consideration the correlation between decisions by running multiple recurrent global models, which can be deemed as a learned local search method. Our method attains performances comparable to the state-of-the-art deep learning-based methods on NED benchmark datasets while being significantly faster to train.",2020,https://ojs.aaai.org/index.php/AAAI/article/view/5367,10.1609/aaai.v34i01.5367,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: AI and the Web,AAAI,NA
AAAI Conference on Artificial Intelligence,A Recursive Scenario Decomposition Algorithm for Combinatorial Multistage Stochastic Optimisation Problems,David Hemmi;Guido Tack;Mark Wallace,"Stochastic programming is concerned with decision making under uncertainty, seeking an optimal policy with respect to a set of possible future scenarios. This paper looks at multistage decision problems where the uncertainty is revealed over time. First, decisions are made with respect to all possible future scenarios. Secondly, after observing the random variables, a set of scenario specific decisions is taken. Our goal is to develop algorithms that can be used as a back-end solver for high-level modeling languages. In this paper we propose a scenario decomposition method to solve multistage stochastic combinatorial decision problems recursively. Our approach is applicable to general problem structures, utilizes standard solving technology and is highly parallelizable. We provide experimental results to show how it efficiently solves benchmarks with hundreds of scenarios.",2018,https://ojs.aaai.org/index.php/AAAI/article/view/11525,10.1609/aaai.v32i1.11525,NA,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Heuristic Search and Optimization,AAAI,NA
AAAI Conference on Artificial Intelligence,A Risk-Sensitive Approach to Policy Optimization,Jared Markowitz;Ryan W. Gardner;Ashley Llorens;Raman Arora;I-Jeng Wang,"Standard deep reinforcement learning( DRL) aims to maximize expected reward, considering collected experiences equally in formulating a policy. This differs from human decision-making, where gains and losses are valued differently and outlying outcomes are given increased consideration. It also fails to capitalize on opportunities to improve safety and/or performance through the incorporation of distributional context. Several approaches to distributional DRL have been investigated, with one popular strategy being to evaluate the projected distribution of returns for possible actions. We propose a more direct approach whereby risk-sensitive objectives, specified in terms of the cumulative distribution function( CDF) of the distribution of full-episode rewards, are optimized. This approach allows for outcomes to be weighed based on relative quality, can be used for both continuous and discrete action spaces, and may naturally be applied in both constrained and unconstrained settings. We show how to compute an asymptotically consistent estimate of the policy gradient for a broad class of risk-sensitive objectives via sampling, subsequently incorporating variance reduction and regularization measures to facilitate effective on-policy learning. We then demonstrate that the use of moderately pessimistic risk profiles, which emphasize scenarios where the agent performs poorly, leads to enhanced exploration and a continual focus on addressing deficiencies. We test the approach using different risk profiles in six OpenAI Safety Gym environments, comparing to state of the art on-policy methods. Without cost constraints, we find that pessimistic risk profiles can be used to reduce cost while improving total reward accumulation. With cost constraints, they are seen to provide higher positive rewards than risk-neutral approaches at the prescribed allowable cost.",2023,https://ojs.aaai.org/index.php/AAAI/article/view/26753,10.1609/aaai.v37i12.26753,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Special Track on Safe and Robust AI,AAAI,NA
AAAI Conference on Artificial Intelligence,A Sample-Efficient Algorithm for Episodic Finite-Horizon MDP with Constraints,Krishna C. Kalagarla;Rahul Jain;Pierluigi Nuzzo,"Constrained Markov decision processes( CMDPs) formalize sequential decision-making problems whose objective is to minimize a cost function while satisfying constraints on various cost functions. In this paper, we consider the setting of episodic fixed-horizon CMDPs. We propose an online algorithm which leverages the linear programming formulation of repeated optimistic planning for finite-horizon CMDP to provide a probably approximately correctness( PAC) guarantee on the number of episodes needed to ensure a near optimal policy, i. e. , with resulting objective value close to that of the optimal value and satisfying the constraints within low tolerance, with high probability. The number of episodes needed is shown to have linear dependence on the sizes of the state and action spaces and quadratic dependence on the time horizon and an upper bound on the number of possible successor states for a state-action pair. Therefore, if the upper bound on the number of possible successor states is much smaller than the size of the state space, the number of needed episodes becomes linear in the sizes of the state and action spaces and quadratic in the time horizon.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/16979,10.1609/aaai.v35i9.16979,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Machine Learning II,AAAI,NA
AAAI Conference on Artificial Intelligence,A Scalable Framework to Choose Sellers in E-Marketplaces Using POMDPs,Athirai Irissappane;Frans A. Oliehoek;Jie Zhang,"In multiagent e-marketplaces, buying agents need to select good sellers by querying other buyers( called advisors). Partially Observable Markov Decision Processes( POMDPs) have shown to be an effective framework for optimally selecting sellers by selectively querying advisors. However, current solution methods do not scale to hundreds or even tens of agents operating in the e-market. In this paper, we propose the Mixture of POMDP Experts( MOPE) technique, which exploits the inherent structure of trust-based domains, such as the seller selection problem in e-markets, by aggregating the solutions of smaller sub-POMDPs. We propose a number of variants of the MOPE approach that we analyze theoretically and empirically. Experiments show that MOPE can scale up to a hundred agents thereby leveraging the presence of more advisors to significantly improve buyer satisfaction.",2016,https://ojs.aaai.org/index.php/AAAI/article/view/9995,10.1609/aaai.v30i1.9995,NA,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,Technical Papers: AI and the Web,AAAI,NA
AAAI Conference on Artificial Intelligence,A Scalable Two Stage Approach to Computing Optimal Decision Sets,Alexey Ignatiev;Edward Lam;Peter J. Stuckey;Joao Marques-Silva,"Machine learning( ML) is ubiquitous in modern life. Since it is being deployed in technologies that affect our privacy and safety, it is often crucial to understand the reasoning behind its decisions, warranting the need for explainable AI. Rule-based models, such as decision trees, decision lists, and decision sets, are conventionally deemed to be the most interpretable. Recent work uses propositional satisfiability( SAT) solving( and its optimization variants) to generate minimum-size decision sets. Motivated by limited practical scalability of these earlier methods, this paper proposes a novel approach to learn minimum-size decision sets by enumerating individual rules of the target decision set independently of each other, and then solving a set cover problem to select a subset of rules. The approach makes use of modern maximum satisfiability and integer linear programming technologies. Experiments on a wide range of publicly available datasets demonstrate the advantage of the new approach over the state of the art in SAT-based decision set learning.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/16498,10.1609/aaai.v35i5.16498,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Constraint Satisfaction and Optimization,AAAI,NA
AAAI Conference on Artificial Intelligence,A Semi-parametric Model for Decision Making in High-Dimensional Sensory Discrimination Tasks,Stephen Keeley;Benjamin Letham;Craig Sanders;Chase Tymms;Michael Shvartsman,"Psychometric functions typically characterize binary sensory decisions along a single stimulus dimension. However, real-life sensory tasks vary along a greater variety of dimensions( e. g. color, contrast and luminance for visual stimuli). Approaches to characterizing high-dimensional sensory spaces either require strong parametric assumptions about these additional contextual dimensions, or fail to leverage known properties of classical psychometric curves. We overcome both limitations by introducing a semi-parametric model of sensory discrimination that applies traditional psychophysical models along a stimulus intensity dimension, but puts Gaussian process( GP) priors on the parameters of these models with respect to the remaining dimensions. By combining the flexibility of the GP with the deep literature on parametric psychophysics, our semi-parametric models achieve good performance with much less data than baselines on both synthetic and real-world, high-dimensional psychophysics datasets. We additionally show strong performance in a Bayesian active learning setting, and present a novel active learning paradigm for the semi-parametric model.",2023,https://ojs.aaai.org/index.php/AAAI/article/view/25074,10.1609/aaai.v37i1.25074,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Cognitive Modeling & Cognitive Systems,AAAI,NA
AAAI Conference on Artificial Intelligence,A Sequential Decision Approach to Ordinal Preferences in Recommender Systems,Truyen Tran;Dinh Phung;Svetha Venkatesh,"We propose a novel sequential decision approach to modeling ordinal ratings in collaborative filtering problems. The rating process is assumed to start from the lowest level, evaluates against the latent utility at the corresponding level and moves up until a suitable ordinal level is found. Crucial to this generative process is the underlying utility random variables that govern the generation of ratings and their modelling choices. To this end, we make a novel use of the generalised extreme value distributions, which is found to be particularly suitable for our modeling tasks and at the same time, facilitate our inference and learning procedure. The proposed approach is flexible to incorporate features from both the user and the item. We evaluate the proposed framework on three well-known datasets: MovieLens, Dating Agency and Netflix. In all cases, it is demonstrated that the proposed work is competitive against state-of-the-art collaborative filtering methods.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/8201,10.1609/aaai.v26i1.8201,7,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,Knowledge-Based Information Systems,AAAI,NA
AAAI Conference on Artificial Intelligence,A Sequentially Fair Mechanism for Multiple Sensitive Attributes,Francois Hu;Philipp Ratz;Arthur Charpentier,"In the standard use case of Algorithmic Fairness, the goal is to eliminate the relationship between a sensitive variable and a corresponding score. Throughout recent years, the scientific community has developed a host of definitions and tools to solve this task, which work well in many practical applications. However, the applicability and effectivity of these tools and definitions becomes less straightfoward in the case of multiple sensitive attributes. To tackle this issue, we propose a sequential framework, which allows to progressively achieve fairness across a set of sensitive features. We accomplish this by leveraging multi-marginal Wasserstein barycenters, which extends the standard notion of Strong Demographic Parity to the case with multiple sensitive characteristics. This method also provides a closed-form solution for the optimal, sequentially fair predictor, permitting a clear interpretation of inter-sensitive feature correlations. Our approach seamlessly extends to approximate fairness, enveloping a framework accommodating the trade-off between risk and unfairness. This extension permits a targeted prioritization of fairness improvements for a specific attribute within a set of sensitive attributes, allowing for a case specific adaptation. A data-driven estimation procedure for the derived solution is developed, and comprehensive numerical experiments are conducted on both synthetic and real datasets. Our empirical findings decisively underscore the practical efficacy of our post-processing approach in fostering fair decision-making.",2024,https://ojs.aaai.org/index.php/AAAI/article/view/29143,10.1609/aaai.v38i11.29143,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Machine Learning II,AAAI,NA
AAAI Conference on Artificial Intelligence,A Sharp Leap from Quantified Boolean Formula to Stochastic Boolean Satisfiability Solving,Pei-Wei Chen;Yu-Ching Huang;Jie-Hong R. Jiang,"Stochastic Boolean Satisfiability( SSAT) is a powerful representation for the concise encoding of quantified decision problems with uncertainty. While it shares commonalities with quantified Boolean formula( QBF) satisfiability and has the same PSPACE-complete complexity, SSAT solving tends to be more challenging as it involves expensive model counting, a. k. a. Sharp-SAT. To date, SSAT solvers, especially those imposing no restrictions on quantification levels, remain much lacking. In this paper, we present a new SSAT solver based on the framework of clause selection and cube distribution previously proposed for QBF solving. With model counting integrated and learning techniques strengthened, our solver is general and effective. Experimental results demonstrate the overall superiority of the proposed algorithm in both solving performance and memory usage compared to the state-of-the-art solvers on a number of benchmark formulas.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/16486,10.1609/aaai.v35i5.16486,10,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Constraint Satisfaction and Optimization,AAAI,NA
AAAI Conference on Artificial Intelligence,A Simulation-Based Evaluation Framework for Interactive AI Systems and Its Application,Maeda F. Hanafi;Yannis Katsis;Martín Santillán Cooper;Yunyao Li,"Interactive AI( IAI) systems are increasingly popular as the human-centered AI design paradigm is gaining strong traction. However, evaluating IAI systems, a key step in building such systems, is particularly challenging, as their output highly depends on the performed user actions. Developers often have to rely on limited and mostly qualitative data from ad-hoc user testing to assess and improve their systems. In this paper, we present InteractEva; a systematic evaluation framework for IAI systems. We also describe how we have applied InteractEva to evaluate a commercial IAI system, leading to both quality improvements and better data-driven design decisions.",2022,https://ojs.aaai.org/index.php/AAAI/article/view/21541,10.1609/aaai.v36i11.21541,7,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,IAAI Technical Track on Innovative Tools for Enabling AI Application,AAAI,NA
AAAI Conference on Artificial Intelligence,A Submodular Optimization Approach to Accountable Loan Approval,Kyungsik Lee;Hana Yoo;Sumin Shin;Wooyoung Kim;Yeonung Baek;Hyunjin Kang;Jaehyun Kim;Kee-Eung Kim,"In the field of finance, the underwriting process is an essential step in evaluating every loan application. During this stage, the borrowers creditworthiness and ability to repay the loan are assessed to ultimately decide whether to approve the loan application. One of the core components of underwriting is credit scoring, in which the probability of default is estimated. As such, there has been significant progress in enhancing the predictive accuracy of credit scoring models through the use of machine learning, but there still exists a need to ultimately construct an approval rule that takes into consideration additional criteria beyond the score itself. This construction process is traditionally done manually to ensure that the approval rule remains interpretable to humans. In this paper, we outline an automated system for optimizing a rule-based system for approving loan applications, which has been deployed at Hyundai Capital Services( HCS). The main challenge lay in creating a high-quality rule base that is simultaneously simple enough to be interpretable by risk analysts as well as customers, since the approval decision should be accountable. We addressed this challenge through principled submodular optimization. The deployment of our system has led to a 14% annual growth in the volume of loan services at HCS, while maintaining the target bad rate, and has resulted in the approval of customers who might have otherwise been rejected.",2024,https://ojs.aaai.org/index.php/AAAI/article/view/30310,10.1609/aaai.v38i21.30310,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,IAAI Technical Track on Deployed Highly Innovative Applications of AI,AAAI,NA
AAAI Conference on Artificial Intelligence,A Surprisingly Simple Continuous-Action POMDP Solver: Lazy Cross-Entropy Search Over Policy Trees,Marcus Hoerger;Hanna Kurniawati;Dirk Kroese;Nan Ye,"The Partially Observable Markov Decision Process( POMDP) provides a principled framework for decision making in stochastic partially observable environments. However, computing good solutions for problems with continuous action spaces remains challenging. To ease this challenge, we propose a simple online POMDP solver, called Lazy Cross-Entropy Search Over Policy Trees( LCEOPT). At each planning step, our method uses a novel lazy Cross-Entropy method to search the space of policy trees, which provide a simple policy representation. Specifically, we maintain a distribution on promising finite-horizon policy trees. The distribution is iteratively updated by sampling policies, evaluating them via Monte Carlo simulation, and refitting them to the top-performing ones. Our method is lazy in the sense that it exploits the policy tree representation to avoid redundant computations in policy sampling, evaluation, and distribution update. This leads to computational savings of up to two orders of magnitude. Our LCEOPT is surprisingly simple as compared to existing state-of-the-art methods, yet empirically outperforms them on several continuous-action POMDP problems, particularly for problems with higher-dimensional action spaces.",2024,https://ojs.aaai.org/index.php/AAAI/article/view/29992,10.1609/aaai.v38i18.29992,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,"AAAI Technical Track on Planning, Routing, and Scheduling",AAAI,NA
AAAI Conference on Artificial Intelligence,A Symbolic SAT-Based Algorithm for Almost-Sure Reachability with Small Strategies in POMDPs,Krishnendu Chatterjee;Martin Chmelík;Jessica Davies,"POMDPs are standard models for probabilistic planning problems, where an agent interacts with an uncertain environment. We study the problem of almost-sure reachability, where given a set of target states, the question is to decide whether there is a policy to ensure that the target set is reached with probability 1( almost-surely). While in general the problem is EXPTIME-complete, in many practical cases policies with a small amount of memory suffice. Moreover, the existing solution to the problem is explicit, which first requires to construct explicitly an exponential reduction to a belief-support MDP. In this work, we first study the existence of observation-stationary strategies, which is NP-complete, and then small-memory strategies. We present a symbolic algorithm by an efficient encoding to SAT and using a SAT solver for the problem. We report experimental results demonstrating the scalability of our symbolic( SAT-based) approach.",2016,https://ojs.aaai.org/index.php/AAAI/article/view/10422,10.1609/aaai.v30i1.10422,NA,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,Technical Papers: Reasoning under Uncertainty,AAAI,NA
AAAI Conference on Artificial Intelligence,A System for Medical Information Extraction and Verification from Unstructured Text,Damir Juric;Giorgos Stoilos;Andre Melo;Jonathan Moore;Mohammad Khodadadi,"A wealth of medical knowledge has been encoded in terminologies like SNOMED CT, NCI, FMA, and more. However, these resources are usually lacking information like relations between diseases, symptoms, and risk factors preventing their use in diagnostic or other decision making applications. In this paper we present a pipeline for extracting such information from unstructured text and enriching medical knowledge bases. Our approach uses Semantic Role Labelling and is unsupervised. We show how we dealt with several deficiencies of SRL-based extraction, like copula verbs, relations expressed through nouns, and assigning scores to extracted triples. The system have so far extracted about 120K relations and in-house doctors verified about 5k relationships. We compared the output of the system with a manually constructed network of diseases, symptoms and risk factors build by doctors in the course of a year. Our results show that our pipeline extracts good quality and precise relations and speeds up the knowledge acquisition process considerably.",2020,https://ojs.aaai.org/index.php/AAAI/article/view/7042,10.1609/aaai.v34i08.7042,6,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,IAAI Technical Track: Emerging Papers,AAAI,NA
AAAI Conference on Artificial Intelligence,A Unified Knowledge Transfer Network for Generalized Category Discovery,Wenkai Shi;Wenbin An;Feng Tian;Yan Chen;Yaqiang Wu;Qianying Wang;Ping Chen,"Generalized Category Discovery( GCD) aims to recognize both known and novel categories in an unlabeled dataset by leveraging another labeled dataset with only known categories. Without considering knowledge transfer from known to novel categories, current methods usually perform poorly on novel categories due to the lack of corresponding supervision. To mitigate this issue, we propose a unified Knowledge Transfer Network( KTN) , which solves two obstacles to knowledge transfer in GCD. First, the mixture of known and novel categories in unlabeled data makes it difficult to identify transfer candidates( i. e. , samples with novel categories). For this, we propose an entropy-based method that leverages knowledge in the pre-trained classifier to differentiate known and novel categories without requiring extra data or parameters. Second, the lack of prior knowledge of novel categories presents challenges in quantifying semantic relationships between categories to decide the transfer weights. For this, we model different categories with prototypes and treat their similarities as transfer weights to measure the semantic similarities between categories. On the basis of two treatments, we transfer knowledge from known to novel categories by conducting pre-adjustment of logits and post-adjustment of labels for transfer candidates based on the transfer weights between different categories. With the weighted adjustment, KTN can generate more accurate pseudo-labels for unlabeled data, which helps to learn more discriminative features and boost model performance on novel categories. Extensive experiments show that our method outperforms state-of-the-art models on all evaluation metrics across multiple benchmark datasets. Furthermore, different from previous clustering-based methods that can only work offline with abundant data, KTN can be deployed online conveniently with faster inference speed. Code and data are available at https://github. com/yibai-shi/KTN.",2024,https://ojs.aaai.org/index.php/AAAI/article/view/29862,10.1609/aaai.v38i17.29862,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Natural Language Processing II,AAAI,NA
AAAI Conference on Artificial Intelligence,A Unified Taylor Framework for Revisiting Attribution Methods,Huiqi Deng;Na Zou;Mengnan Du;Weifu Chen;Guocan Feng;Xia Hu,"Attribution methods have been developed to understand the decision making process of machine learning models, especially deep neural networks, by assigning importance scores to individual features. Existing attribution methods often built upon empirical intuitions and heuristics. There still lacks a general and theoretical framework that not only can unify these attribution methods, but also theoretically reveal their rationales, fidelity, and limitations. To bridge the gap, in this paper, we propose a Taylor attribution framework and reformulate seven mainstream attribution methods into the framework. Based on reformulations, we analyze the attribution methods in terms of rationale, fidelity, and limitation. Moreover, We establish three principles for a good attribution in the Taylor attribution framework, i. e. , low approximation error, correct contribution assignment, and unbiased baseline selection. Finally, we empirically validate the Taylor reformulations, and reveal a positive correlation between the attribution performance and the number of principles followed by the attribution method via benchmarking on real-world datasets.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/17365,10.1609/aaai.v35i13.17365,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Philosophy and Ethics of AI,AAAI,NA
AAAI Conference on Artificial Intelligence,A Universal 2-state n-action Adaptive Management Solver,Luz Valerie Pascal;Marianne Akian;Sam Nicol;Iadine Chades,"In poor data and urgent decision-making applications, managers need to make decisions without complete knowledge of the system dynamics. In biodiversity conservation, adaptive management( AM) is the principal tool for decision-making under uncertainty. AM can be solved using simplified Mixed Observable Markov Decision Processes called hidden model MDPs( hmMDPs) when the unknown dynamics are assumed stationary. hmMDPs provide optimal policies to AM problems by augmenting the MDP state space with an unobservable state variable representing a finite set of predefined models. A drawback in formalising an AM problem is that experts are often solicited to provide this predefined set of models by specifying the transition matrices. Expert elicitation is a challenging and time-consuming process that is prone to biases, and a key assumption of hmMDPs is that the true transition matrix will be included in the candidate model set. We propose an original approach to build a hmMDP with a universal set of predefined models that is capable of solving any 2-state n-action AM problem. Our approach uses properties of the transition matrices to build the model set and is independent of expert input, removing the potential for expert error in the optimal solution. We provide analytical formulations to derive the minimum set of models to include into an hmMDP to solve any AM problems with 2 states and n actions. We assess our universal AM algorithm on two species conservation case studies from Australia and randomly generated problems.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/17747,10.1609/aaai.v35i17.17747,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Special Track on AI for Social Impact,AAAI,NA
AAAI Conference on Artificial Intelligence,A User-Adaptive Layer Selection Framework for Very Deep Sequential Recommender Models,Lei Chen;Fajie Yuan;Jiaxi Yang;Xiang Ao;Chengming Li;Min Yang,"Sequential recommender systems( SRS) have become a research hotspot in recent studies. Because of the requirement in capturing users dynamic interests, sequential neural network based recommender models often need to be stacked with more hidden layers( e. g. , up to 100 layers) compared with standard collaborative filtering methods. However, the high network latency has become the main obstacle when deploying very deep recommender models into a production environment. In this paper, we argue that the typical prediction framework that treats all users equally during the inference phase is inefficient in running time, as well as sub-optimal in accuracy. To resolve such an issue, we present SkipRec, an adaptive inference framework by learning to skip inactive hidden layers on a per-user basis. Specifically, we devise a policy network to automatically determine which layers should be retained and which layers are allowed to be skipped, so as to achieve user-specific decisions. To derive the optimal skipping policy, we propose using gumbel softmax and reinforcement learning to solve the non-differentiable problem during backpropagation. We perform extensive experiments on three real-world recommendation datasets, and demonstrate that SkipRec attains comparable or better accuracy with much less inference time.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/16518,10.1609/aaai.v35i5.16518,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Data Mining and Knowledge Management,AAAI,NA
AAAI Conference on Artificial Intelligence,A Variational Perturbative Approach to Planning in Graph-Based Markov Decision Processes,Dominik Linzner;Heinz Koeppl,"Coordinating multiple interacting agents to achieve a common goal is a difficult task with huge applicability. This problem remains hard to solve, even when limiting interactions to be mediated via a static interaction-graph. We present a novel approximate solution method for multi-agent Markov decision problems on graphs, based on variational perturbation theory. We adopt the strategy of planning via inference, which has been explored in various prior works. We employ a non-trivial extension of a novel high-order variational method that allows for approximate inference in large networks and has been shown to surpass the accuracy of existing variational methods. To compare our method to two state-of-the-art methods for multi-agent planning on graphs, we apply the method different standard GMDP problems. We show that in cases, where the goal is encoded as a non-local cost function, our method performs well, while state-of-the-art methods approach the performance of random guess. In a final experiment, we demonstrate that our method brings significant improvement for synchronization tasks.",2020,https://ojs.aaai.org/index.php/AAAI/article/view/6210,10.1609/aaai.v34i05.6210,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Multiagent Systems,AAAI,NA
AAAI Conference on Artificial Intelligence,A Voting-Based System for Ethical Decision Making,Ritesh Noothigattu;Snehalkumar Gaikwad;Edmond Awad;Sohan Dsouza;Iyad Rahwan;Pradeep Ravikumar;Ariel Procaccia,"We present a general approach to automating ethical decisions, drawing on machine learning and computational social choice. In a nutshell, we propose to learn a model of societal preferences, and, when faced with a specific ethical dilemma at runtime, efficiently aggregate those preferences to identify a desirable choice. We provide a concrete algorithm that instantiates our approach; some of its crucial steps are informed by a new theory of swap-dominance efficient voting rules. Finally, we implement and evaluate a system for ethical decision making in the autonomous vehicle domain, using preference data collected from 1. 3 million people through the Moral Machine website.",2018,https://ojs.aaai.org/index.php/AAAI/article/view/11512,10.1609/aaai.v32i1.11512,NA,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Human-Computation and Crowd Sourcing,AAAI,NA
AAAI Conference on Artificial Intelligence,Abduction-Based Explanations for Machine Learning Models,Alexey Ignatiev;Nina Narodytska;Joao Marques-Silva,"The growing range of applications of Machine Learning( ML) in a multitude of settings motivates the ability of computing small explanations for predictions made. Small explanations are generally accepted as easier for human decision makers to understand. Most earlier work on computing explanations is based on heuristic approaches, providing no guarantees of quality, in terms of how close such solutions are from cardinalityor subset-minimal explanations. This paper develops a constraint-agnostic solution for computing explanations for any ML model. The proposed solution exploits abductive reasoning, and imposes the requirement that the ML model can be represented as sets of constraints using some target constraint reasoning system for which the decision problem can be answered with some oracle. The experimental results, obtained on well-known datasets, validate the scalability of the proposed approach as well as the quality of the computed solutions.",2019,https://ojs.aaai.org/index.php/AAAI/article/view/3964,10.1609/aaai.v33i01.33011511,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Constraint Satisfaction and Optimization,AAAI,NA
AAAI Conference on Artificial Intelligence,Abstract Interpretation of Decision Tree Ensemble Classifiers,Francesco Ranzato;Marco Zanella,"We study the problem of formally and automatically verifying robustness properties of decision tree ensemble classifiers such as random forests and gradient boosted decision tree models. A recent stream of works showed how abstract interpretation, which is ubiquitously used in static program analysis, can be successfully deployed to formally verify( deep) neural networks. In this work we push forward this line of research by designing a general and principled abstract interpretation-based framework for the formal verification of robustness and stability properties of decision tree ensemble models. Our abstract interpretation-based method may induce complete robustness checks of standard adversarial perturbations and output concrete adversarial attacks. We implemented our abstract verification technique in a tool called silva, which leverages an abstract domain of not necessarily closed real hyperrectangles and is instantiated to verify random forests and gradient boosted decision trees. Our experimental evaluation on the MNIST dataset shows that silva provides a precise and efficient tool which advances the current state of the art in tree ensembles verification.",2020,https://ojs.aaai.org/index.php/AAAI/article/view/5998,10.1609/aaai.v34i04.5998,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Machine Learning,AAAI,NA
AAAI Conference on Artificial Intelligence,Accelerated Vector Pruning for Optimal POMDP Solvers,Erwin Walraven;Matthijs Spaan,"Partially Observable Markov Decision Processes( POMDPs) are powerful models for planning under uncertainty in partially observable domains. However, computing optimal solutions for POMDPs is challenging because of the high computational requirements of POMDP solution algorithms. Several algorithms use a subroutine to prune dominated vectors in value functions, which requires a large number of linear programs( LPs) to be solved and it represents a large part of the total running time. In this paper we show how the LPs in POMDP pruning subroutines can be decomposed using a Benders decomposition. The resulting algorithm incrementally adds LP constraints and uses only a small fraction of the constraints. Our algorithm significantly improves the performance of existing pruning methods and the commonly used incremental pruning algorithm. Our new variant of incremental pruning is the fastest optimal pruning-based POMDP algorithm.",2017,https://ojs.aaai.org/index.php/AAAI/article/view/11032,10.1609/aaai.v31i1.11032,NA,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,Main Track: Planning and Scheduling,AAAI,NA
AAAI Conference on Artificial Intelligence,Accelerating Adversarially Robust Model Selection for Deep Neural Networks via Racing,Matthias König;Holger H. Hoos;Jan N. van Rijn,"Recent research has introduced several approaches to formally verify the robustness of neural network models against perturbations in their inputs, such as the ones that occur in adversarial attacks. At the same time, this particular verification task is known to be computationally challenging. More specifically, assessing the robustness of a neural network against input perturbations can easily take several hours of compute time per input vector, even when using state-of-the-art verification approaches. In light of this, it becomes challenging to select from a given set of neural network models the one that is best in terms of robust accuracy, i. e. , the fraction of instances for which the model is known to be robust against adversarial perturbations, especially when given limited computing resources. To tackle this problem, we propose a racing method specifically adapted to the domain of robustness verification. This racing method utilises Delta-values, which can be seen as an efficiently computable proxy for the distance of a given input to a neural network model to the decision boundary. We present statistical evidence indicating significant differences in the empirical cumulative distribution between robust and non-robust inputs as a function of Delta-values. Using this information, we show that it is possible to reliably expose vulnerabilities in the model with relatively few input iterations. Overall, when applied to selecting the most robust network from sets of 31 MNIST and 27 CIFAR-10 networks, our proposed method achieves speedups of a factor of 108 and 42, respectively, in terms of cumulative running time compared to standard local robustness verification on the complete testing sets.",2024,https://ojs.aaai.org/index.php/AAAI/article/view/30121,10.1609/aaai.v38i19.30121,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,"AAAI Technical Track on Safe, Robust and Responsible AI Track",AAAI,NA
AAAI Conference on Artificial Intelligence,Accelerating Ranking in E-Commerce Search Engines through Contextual Factor Selection,Anxiang Zeng;Han Yu;Qing Da;Yusen Zhan;Chunyan Miao,"In large-scale search systems, the quality of the ranking results is continually improved with the introduction of more factors from complex procedures. Meanwhile, the increase in factors demands more computation resources and increases system response latency. It has been observed that, under some certain context a search instance may require only a small set of useful factors instead of all factors in order to return high quality results. Therefore, removing ineffective factors accordingly can significantly improve system efficiency. In this paper, we report our experience incorporating our Contextual Factor Selection( CFS) approach into the Taobao e-commerce platform to optimize the selection of factors based on the context of each search query in order to simultaneously achieve high quality search results while significantly reducing latency time. This problem is treated as a combinatorial optimization problem which can be tackled through a sequential decision-making procedure. The problem can be efficiently solved by CFS through a deep reinforcement learning method with reward shaping to address the problems of reward signal scarcity and wide reward signal distribution in real-world search engines. Through extensive off-line experiments based on data from the Taobao. com platform, CFS is shown to significantly outperform state-of-the-art approaches. Online deployment on Taobao. com demonstrated that CFS is able to reduce average search latency time by more than 40% compared to the previous approach with negligible reduction in search result quality. Under peak usage during the Singles Day Shopping Festival( November 11th) in 2017, CFS reduced peak load search latency time by 33% compared to the previous approach, helping Taobao. com achieve 40% higher revenue than the same period during 2016. Corrigendum The spelling of coauthor Yusen Zan in the paper Accelerating Ranking in E-Commerce Search Engines through Contextual Factor Selection has been changed from Zan to Zhan. The original spelling was a typographical error.",2020,https://ojs.aaai.org/index.php/AAAI/article/view/7026,10.1609/aaai.v34i08.7026,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,IAAI Technical Track: Deployed Papers,AAAI,NA
AAAI Conference on Artificial Intelligence,ACE: Cooperative Multi-Agent Q-learning with Bidirectional Action-Dependency,Chuming Li;Jie Liu;Yinmin Zhang;Yuhong Wei;Yazhe Niu;Yaodong Yang;Yu Liu;Wanli Ouyang,"Multi-agent reinforcement learning( MARL) suffers from the non-stationarity problem, which is the ever-changing targets at every iteration when multiple agents update their policies at the same time. Starting from first principle, in this paper, we manage to solve the non-stationarity problem by proposing bidirectional action-dependent Q-learning( ACE). Central to the development of ACE is the sequential decision making process wherein only one agent is allowed to take action at one time. Within this process, each agent maximizes its value function given the actions taken by the preceding agents at the inference stage. In the learning phase, each agent minimizes the TD error that is dependent on how the subsequent agents have reacted to their chosen action. Given the design of bidirectional dependency, ACE effectively turns a multi-agent MDP into a single-agent MDP. We implement the ACE framework by identifying the proper network representation to formulate the action dependency, so that the sequential decision process is computed implicitly in one forward pass. To validate ACE, we compare it with strong baselines on two MARL benchmarks. Empirical experiments demonstrate that ACE outperforms the state-of-the-art algorithms on Google Research Football and StarCraft Multi-Agent Challenge by a large margin. In particular, on SMAC tasks, ACE achieves 100% success rate on almost all the hard and super hard maps. We further study extensive research problems regarding ACE, including extension, generalization and practicability.",2023,https://ojs.aaai.org/index.php/AAAI/article/view/26028,10.1609/aaai.v37i7.26028,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Machine Learning II,AAAI,NA
AAAI Conference on Artificial Intelligence,Achieving Counterfactual Fairness for Causal Bandit,Wen Huang;Lu Zhang;Xintao Wu,"In online recommendation, customers arrive in a sequential and stochastic manner from an underlying distribution and the online decision model recommends a chosen item for each arriving individual based on some strategy. We study how to recommend an item at each step to maximize the expected reward while achieving user-side fairness for customers, i. e. , customers who share similar profiles will receive a similar reward regardless of their sensitive attributes and items being recommended. By incorporating causal inference into bandits and adopting soft intervention to model the arm selection strategy, we first propose the d-separation based UCB algorithm( D-UCB) to explore the utilization of the d-separation set in reducing the amount of exploration needed to achieve low cumulative regret. Based on that, we then propose the fair causal bandit( F-UCB) for achieving the counterfactual individual fairness. Both theoretical analysis and empirical evaluation demonstrate effectiveness of our algorithms.",2022,https://ojs.aaai.org/index.php/AAAI/article/view/20653,10.1609/aaai.v36i6.20653,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Machine Learning I,AAAI,NA
AAAI Conference on Artificial Intelligence,Achieving Long-Term Fairness in Sequential Decision Making,Yaowei Hu;Lu Zhang,"In this paper, we propose a framework for achieving long-term fair sequential decision making. By conducting both the hard and soft interventions, we propose to take path-specific effects on the time-lagged causal graph as a quantitative tool for measuring long-term fairness. The problem of fair sequential decision making is then formulated as a constrained optimization problem with the utility as the objective and the long-term and short-term fairness as constraints. We show that such an optimization problem can be converted to a performative risk optimization. Finally, repeated risk minimization( RRM) is used for model training, and the convergence of RRM is theoretically analyzed. The empirical evaluation shows the effectiveness of the proposed algorithm on synthetic and semi-synthetic temporal datasets.",2022,https://ojs.aaai.org/index.php/AAAI/article/view/21188,10.1609/aaai.v36i9.21188,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Philosophy and Ethics of AI,AAAI,NA
AAAI Conference on Artificial Intelligence,Achieving Zero Constraint Violation for Constrained Reinforcement Learning via Conservative Natural Policy Gradient Primal-Dual Algorithm,Qinbo Bai;Amrit Singh Bedi;Vaneet Aggarwal,"We consider the problem of constrained Markov decision process( CMDP) in continuous state actions spaces where the goal is to maximize the expected cumulative reward subject to some constraints. We propose a novel Conservative Natural Policy Gradient Primal Dual Algorithm( CNPGPD) to achieve zero constraint violation while achieving state of the art convergence results for the objective value function. For general policy parametrization, we prove convergence of value function to global optimal upto an approximation error due to restricted policy class. We improve the sample complexity of existing constrained NPGPD algorithm. To the best of our knowledge, this is the first work to establish zero constraint violation with Natural policy gradient style algorithms for infinite horizon discounted CMDPs. We demonstrate the merits of proposed algorithm via experimental evaluations.",2023,https://ojs.aaai.org/index.php/AAAI/article/view/25826,10.1609/aaai.v37i6.25826,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Machine Learning I,AAAI,NA
AAAI Conference on Artificial Intelligence,Achieving Zero Constraint Violation for Constrained Reinforcement Learning via Primal-Dual Approach,Qinbo Bai;Amrit Singh Bedi;Mridul Agarwal;Alec Koppel;Vaneet Aggarwal,"Reinforcement learning is widely used in applications where one needs to perform sequential decisions while interacting with the environment. The problem becomes more challenging when the decision requirement includes satisfying some safety constraints. The problem is mathematically formulated as constrained Markov decision process( CMDP). In the literature, various algorithms are available to solve CMDP problems in a model-free manner to achieve epsilon-optimal cumulative reward with epsilon feasible policies. An epsilon-feasible policy implies that it suffers from constraint violation. An important question here is whether we can achieve epsilon-optimal cumulative reward with zero constraint violations or not. To achieve that, we advocate the use of a randomized primal-dual approach to solve the CMDP problems and propose a conservative stochastic primal-dual algorithm( CSPDA) which is shown to exhibit O( 1/epsilon^2) sample complexity to achieve epsilon-optimal cumulative reward with zero constraint violations. In the prior works, the best available sample complexity for the epsilon-optimal policy with zero constraint violation is O( 1/epsilon^5). Hence, the proposed algorithm provides a significant improvement compared to the state of the art.",2022,https://ojs.aaai.org/index.php/AAAI/article/view/20281,10.1609/aaai.v36i4.20281,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Constraint Satisfaction and Optimization,AAAI,NA
AAAI Conference on Artificial Intelligence,ACT: Empowering Decision Transformer with Dynamic Programming via Advantage Conditioning,Chen-Xiao Gao;Chenyang Wu;Mingjun Cao;Rui Kong;Zongzhang Zhang;Yang Yu,"Decision Transformer( DT) , which employs expressive sequence modeling techniques to perform action generation, has emerged as a promising approach to offline policy optimization. However, DT generates actions conditioned on a desired future return, which is known to bear some weaknesses such as the susceptibility to environmental stochasticity. To overcome DTs weaknesses, we propose to empower DT with dynamic programming. Our method comprises three steps. First, we employ in-sample value iteration to obtain approximated value functions, which involves dynamic programming over the MDP structure. Second, we evaluate action quality in context with estimated advantages. We introduce two types of advantage estimators, IAE and GAE, which are suitable for different tasks. Third, we train an Advantage-Conditioned Transformer( ACT) to generate actions conditioned on the estimated advantages. Finally, during testing, ACT generates actions conditioned on a desired advantage. Our evaluation results validate that, by leveraging the power of dynamic programming, ACT demonstrates effective trajectory stitching and robust action generation in spite of the environmental stochasticity, outperforming baseline methods across various benchmarks. Additionally, we conduct an in-depth analysis of ACTs various design choices through ablation studies. Our code is available at https://github. com/LAMDA-RL/ACT.",2024,https://ojs.aaai.org/index.php/AAAI/article/view/29101,10.1609/aaai.v38i11.29101,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Machine Learning II,AAAI,NA
AAAI Conference on Artificial Intelligence,Acting and Planning Using Operational Models,Sunandita Patra;Malik Ghallab;Dana Nau;Paolo Traverso,"The most common representation formalisms for planning are descriptive models. They abstractly describe what the actions do and are tailored for efficiently computing the next state( s) in a state transition system. But acting requires operational models that describe how to do things, with rich control structures for closed-loop online decision-making. Using descriptive representations for planning and operational representations for acting can lead to problems with developing and verifying consistency of the different models. We define and implement an integrated acting-and-planning system in which both planning and acting use the same operational models, which are written in a general-purpose hierarchical task-oriented language offering rich control structures. The acting component is inspired by the well-known PRS system, except that instead of being purely reactive, it can get advice from the planner. Our planning algorithm, RAEplan, plans by doing Monte Carlo rollout simulations of the actor’s operational models. Our experiments show significant benefits in the efficiency of the acting and planning system.",2019,https://ojs.aaai.org/index.php/AAAI/article/view/4764,10.1609/aaai.v33i01.33017691,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,"AAAI Technical Track: Planning, Routing, and Scheduling",AAAI,NA
AAAI Conference on Artificial Intelligence,Action Branching Architectures for Deep Reinforcement Learning,Arash Tavakoli;Fabio Pardo;Petar Kormushev,"Discrete-action algorithms have been central to numerous recent successes of deep reinforcement learning. However, applying these algorithms to high-dimensional action tasks requires tackling the combinatorial increase of the number of possible actions with the number of action dimensions. This problem is further exacerbated for continuous-action tasks that require fine control of actions via discretization. In this paper, we propose a novel neural architecture featuring a shared decision module followed by several network branches, one for each action dimension. This approach achieves a linear increase of the number of network outputs with the number of degrees of freedom by allowing a level of independence for each individual action dimension. To illustrate the approach, we present a novel agent, called Branching Dueling Q-Network( BDQ) , as a branching variant of the Dueling Double Deep Q-Network( Dueling DDQN). We evaluate the performance of our agent on a set of challenging continuous control tasks. The empirical results show that the proposed agent scales gracefully to environments with increasing action dimensionality and indicate the significance of the shared decision module in coordination of the distributed action branches. Furthermore, we show that the proposed agent performs competitively against a state-of-the-art continuous control algorithm, Deep Deterministic Policy Gradient( DDPG).",2018,https://ojs.aaai.org/index.php/AAAI/article/view/11798,10.1609/aaai.v32i1.11798,NA,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Machine Learning,AAAI,NA
AAAI Conference on Artificial Intelligence,Action Candidate Based Clipped Double Q-learning for Discrete and Continuous Action Tasks,Haobo Jiang;Jin Xie;Jian Yang,"Double Q-learning is a popular reinforcement learning algorithm in Markov decision process( MDP) problems. Clipped Double Q-learning, as an effective variant of Double Q-learning, employs the clipped double estimator to approximate the maximum expected action value. Due to the underestimation bias of the clipped double estimator, performance of clipped Double Q-learning may be degraded in some stochastic environments. In this paper, in order to reduce the underestimation bias, we propose an action candidate based clipped double estimator for Double Q-learning. Specifically, we first select a set of elite action candidates with the high action values from one set of estimators. Then, among these candidates, we choose the highest valued action from the other set of estimators. Finally, we use the maximum value in the second set of estimators to clip the action value of the chosen action in the first set of estimators and the clipped value is used for approximating the maximum expected action value. Theoretically, the underestimation bias in our clipped Double Q-learning decays monotonically as the number of the action candidates decreases. Moreover, the number of action candidates controls the trade-off between the overestimation and underestimation biases. In addition, we also extend our clipped Double Q-learning to continuous action tasks via approximating the elite continuous action candidates. We empirically verify that our algorithm can more accurately estimate the maximum expected action value on some toy environments and yield good performance on several benchmark problems.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/16973,10.1609/aaai.v35i9.16973,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Machine Learning II,AAAI,NA
AAAI Conference on Artificial Intelligence,Actionable Ethics through Neural Learning,Daniele Rossini;Danilo Croce;Sara Mancini;Massimo Pellegrino;Roberto Basili,"While AI is going to produce a great impact on society, its alignment with human values and expectations is an essential step towards a correct harnessing of AI potentials for good. There is a corresponding growing need for mature and established technical standards to enable the assessment of an AI application as the evaluation of its graded adherence to formalized ethics. This is clearly dependent on methods to inject ethical awareness at all stages of an AI application development and use. For this reason we introduce the notion of Embedding Principles of ethics by Design( EPbD) as a comprehensive inductive framework. Although extending generic AI applications, it mainly aims at learning the ethical behaviour through numerical optimization, i. e. deep neural models. The core idea is to support ethics by integrating automated reasoning over formal knowledge and induction from ethically enriched training data. A deep neural network is proposed here to model both the functional as well as the ethical conditions characterizing a target decision. In this way, the discovery of latent ethical knowledge is enabled and made available to the learning process. The application of the above framework to a banking application, i. e. AI-driven Digital Lending, is used to show how accurate classification can be achieved without neglecting the ethical dimension. Results over existing datasets demonstrate that the ethical compliance of the sources can be used to output models able to optimally fine tune the balance between business and ethical accuracy.",2020,https://ojs.aaai.org/index.php/AAAI/article/view/6005,10.1609/aaai.v34i04.6005,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Machine Learning,AAAI,NA
AAAI Conference on Artificial Intelligence,Actional Atomic-Concept Learning for Demystifying Vision-Language Navigation,Bingqian Lin;Yi Zhu;Xiaodan Liang;Liang Lin;Jianzhuang Liu,"Vision-Language Navigation( VLN) is a challenging task which requires an agent to align complex visual observations to language instructions to reach the goal position. Most existing VLN agents directly learn to align the raw directional features and visual features trained using one-hot labels to linguistic instruction features. However, the big semantic gap among these multi-modal inputs makes the alignment difficult and therefore limits the navigation performance. In this paper, we propose Actional Atomic-Concept Learning( AACL) , which maps visual observations to actional atomic concepts for facilitating the alignment. Specifically, an actional atomic concept is a natural language phrase containing an atomic action and an object, e. g. , ``go up stairs. These actional atomic concepts, which serve as the bridge between observations and instructions, can effectively mitigate the semantic gap and simplify the alignment. AACL contains three core components: 1) a concept mapping module to map the observations to the actional atomic concept representations through the VLN environment and the recently proposed Contrastive Language-Image Pretraining( CLIP) model, 2) a concept refining adapter to encourage more instruction-oriented object concept extraction by re-ranking the predicted object concepts by CLIP, and 3) an observation co-embedding module which utilizes concept representations to regularize the observation representations. Our AACL establishes new state-of-the-art results on both fine-grained( R2R) and high-level( REVERIE and R2R-Last) VLN benchmarks. Moreover, the visualization shows that AACL significantly improves the interpretability in action decision. Code will be available at https://gitee. com/mindspore/models/tree/master/research/cv/VLN-AACL.",2023,https://ojs.aaai.org/index.php/AAAI/article/view/25243,10.1609/aaai.v37i2.25243,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Computer Vision II,AAAI,NA
AAAI Conference on Artificial Intelligence,Active Preference Learning Based on Generalized Gini Functions: Application to the Multiagent Knapsack Problem,Nadjet Bourdache;Patrice Perny,We consider the problem of actively eliciting preferences from a Decision Maker supervising a collective decision process in the context of fair multiagent combinatorial optimization. Individual preferences are supposed to be known and represented by linear utility functions defined on a combinatorial domain and the social utility is defined as a generalized Gini Social evaluation Function( GSF) for the sake of fairness. The GSF is a non-linear aggregation function parameterized by weighting coefficients which allow a fine control of the equity requirement in the aggregation of individual utilities. The paper focuses on the elicitation of these weights by active learning in the context of the fair multiagent knapsack problem. We introduce and compare several incremental decision procedures interleaving an adaptive preference elicitation procedure with a combinatorial optimization algorithm to determine a GSF-optimal solution. We establish an upper bound on the number of queries and provide numerical tests to show the efficiency of the proposed approach.,2019,https://ojs.aaai.org/index.php/AAAI/article/view/4770,10.1609/aaai.v33i01.33017741,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Reasoning under Uncertainty,AAAI,NA
AAAI Conference on Artificial Intelligence,Actor Critic Deep Reinforcement Learning for Neural Malware Control,Yu Wang;Jack Stokes;Mady Marinescu,"In addition to using signatures, antimalware products also detect malicious attacks by evaluating unknown files in an emulated environment, i. e. sandbox, prior to execution on a computers native operating system. During emulation, a file cannot be scanned indefinitely, and antimalware engines often set the number of instructions to be executed based on a set of heuristics. These heuristics only make the decision of when to halt emulation using partial information leading to the execution of the file for either too many or too few instructions. Also this method is vulnerable if the attackers learn this set of heuristics. Recent research uses a deep reinforcement learning( DRL) model employing a Deep Q-Network( DQN) to learn when to halt the emulation of a file. In this paper, we propose a new DRL-based system which instead employs a modified actor critic( AC) framework for the emulation halting task. This AC model dynamically predicts the best time to halt the files execution based on a sequence of system API calls. Compared to the earlier models, the new model is capable of handling adversarial attacks by simulating their behaviors using the critic model. The new AC model demonstrates much better performance than both the DQN model and antimalware engines heuristics. In terms of execution speed( evaluated by the halting decision) , the new model halts the execution of unknown files by up to 2. 5% earlier than the DQN model and 93. 6% earlier than the heuristics. For the task of detecting malicious files, the proposed AC model increases the true positive rate by 9. 9% from 69. 5% to 76. 4% at a false positive rate of 1% compared to the DQN model, and by 83. 4% from 41. 2% to 76. 4% at a false positive rate of 1% compared to a recently proposed LSTM model.",2020,https://ojs.aaai.org/index.php/AAAI/article/view/5449,10.1609/aaai.v34i01.5449,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Applications,AAAI,NA
AAAI Conference on Artificial Intelligence,AdapSafe: Adaptive and Safe-Certified Deep Reinforcement Learning-Based Frequency Control for Carbon-Neutral Power Systems,Xu Wan;Mingyang Sun;Boli Chen;Zhongda Chu;Fei Teng,"With the increasing penetration of inverter-based renewable energy resources, deep reinforcement learning( DRL) has been proposed as one of the most promising solutions to realize real-time and autonomous control for future carbon-neutral power systems. In particular, DRL-based frequency control approaches have been extensively investigated to overcome the limitations of model-based approaches, such as the computational cost and scalability for large-scale systems. Nevertheless, the real-world implementation of DRLbased frequency control methods is facing the following fundamental challenges: 1) safety guarantee during the learning and decision-making processes; 2) adaptability against the dynamic system operating conditions. To this end, this is the first work that proposes an Adaptive and Safe-Certified DRL( AdapSafe) algorithm for frequency control to simultaneously address the aforementioned challenges. In particular, a novel self-tuning control barrier function is designed to actively compensate the unsafe frequency control strategies under variational safety constraints and thus achieve guaranteed safety. Furthermore, the concept of meta-reinforcement learning is integrated to significantly enhance its adaptiveness in non-stationary power system environments without sacrificing the safety cost. Experiments are conducted based on GB 2030 power system, and the results demonstrate that the proposed AdapSafe exhibits superior performance in terms of its guaranteed safety in both training and test phases, as well as its considerable adaptability against the dynamics changes of system parameters.",2023,https://ojs.aaai.org/index.php/AAAI/article/view/25660,10.1609/aaai.v37i4.25660,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Domain( s) of Application,AAAI,NA
AAAI Conference on Artificial Intelligence,Adapt to Environment Sudden Changes by Learning a Context Sensitive Policy,Fan-Ming Luo;Shengyi Jiang;Yang Yu;ZongZhang Zhang;Yi-Feng Zhang,"Dealing with real-world reinforcement learning( RL) tasks, we shall be aware that the environment may have sudden changes. We expect that a robust policy is able to handle such changes and adapt to the new environment rapidly. Context-based meta reinforcement learning aims at learning environment adaptable policies. These methods adopt a context encoder to perceive the environment on-the-fly, following which a contextual policy makes environment adaptive decisions according to the context. However, previous methods show lagged and unstable context extraction, which are hard to handle sudden changes well. This paper proposes an environment sensitive contextual policy learning( ESCP) approach, in order to improve both the sensitivity and the robustness of context encoding. ESCP is composed of three key components: variance minimization that forces a rapid and stable encoding of the environment context, relational matrix determinant maximization that avoids trivial solutions, and a history-truncated recurrent neural network model that avoids old memory interference. We use a grid-world task and 5 locomotion controlling tasks with changing parameters to empirically assess our algorithm. Experiment results show that in environments with both in-distribution and out-of-distribution parameter changes, ESCP can not only better recover the environment encoding, but also adapt more rapidly to the post-change environment( 10x faster in the grid-world) while the return performance is kept or improved, compared with state-of-the-art meta RL methods.",2022,https://ojs.aaai.org/index.php/AAAI/article/view/20730,10.1609/aaai.v36i7.20730,10,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Machine Learning II,AAAI,NA
AAAI Conference on Artificial Intelligence,Adaptable Regression Method for Ensemble Consensus Forecasting,John Williams;Peter Neilley;Joseph Koval;Jeff McDonald,"Accurate weather forecasts enhance sustainability by facilitating decision making across a broad range of endeavors including public safety, transportation, energy generation and management, retail logistics, emergency preparedness, and many others. This paper presents a method for combining multiple scalar forecasts to obtain deterministic predictions that are generally more accurate than any of the constituents. Exponentially-weighted forecast bias estimates and error covariance matrices are formed at observation sites, aggregated spatially and temporally, and used to formulate a constrained, regularized least squares regression problem that may be solved using quadratic programming. The model is re-trained when new observations arrive, updating the forecast bias estimates and consensus combination weights to adapt to weather regime and input forecast model changes. The algorithm is illustrated for 0-72 hour temperature forecasts at over 1200 sites in the contiguous U. S. based on a 22-member forecast ensemble, and its performance over multiple seasons is compared to a state-of-the-art ensemble-based forecasting system. In addition to weather forecasts, this approach to consensus may be useful for ensemble predictions of climate, wind energy, solar power, energy demand, and numerous other quantities.",2016,https://ojs.aaai.org/index.php/AAAI/article/view/9913,10.1609/aaai.v30i1.9913,NA,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,Special Track: Computational Sustainability,AAAI,NA
AAAI Conference on Artificial Intelligence,Adapting a Kidney Exchange Algorithm to Align With Human Values,Rachel Freedman;Jana Schaich Borg;Walter Sinnott-Armstrong;John Dickerson;Vincent Conitzer,"The efficient allocation of limited resources is a classical problem in economics and computer science. In kidney exchanges, a central market maker allocates living kidney donors to patients in need of an organ. Patients and donors in kidney exchanges are prioritized using ad-hoc weights decided on by committee and then fed into an allocation algorithm that determines who get what—and who does not. In this paper, we provide an end-to-end methodology for estimating weights of individual participant profiles in a kidney exchange. We first elicit from human subjects a list of patient attributes they consider acceptable for the purpose of prioritizing patients( e. g. , medical characteristics, lifestyle choices, and so on). Then, we ask subjects comparison queries between patient profiles and estimate weights in a principled way from their responses. We show how to use these weights in kidney exchange market clearing algorithms. We then evaluate the impact of the weights in simulations and find that the precise numerical values of the weights we computed matter little, other than the ordering of profiles that they imply. However, compared to not prioritizing patients at all, there is a significant effect, with certain classes of patients being( de) prioritized based on the human-elicited value judgments.",2018,https://ojs.aaai.org/index.php/AAAI/article/view/11505,10.1609/aaai.v32i1.11505,NA,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Humans and AI,AAAI,NA
AAAI Conference on Artificial Intelligence,Adapting to Concept Drift in Credit Card Transaction Data Streams Using Contextual Bandits and Decision Trees,Dennis Soemers;Tim Brys;Kurt Driessens;Mark Winands;Ann Nowé,"Credit card transactions predicted to be fraudulent by automated detection systems are typically handed over to human experts for verification. To limit costs, it is standard practice to select only the most suspicious transactions for investigation. We claim that a trade-off between exploration and exploitation is imperative to enable adaptation to changes in behavior( concept drift). Exploration consists of the selection and investigation of transactions with the purpose of improving predictive models, and exploitation consists of investigating transactions detected to be suspicious. Modeling the detection of fraudulent transactions as rewarding, we use an incremental Regression Tree learner to create clusters of transactions with similar expected rewards. This enables the use of a Contextual Multi-Armed Bandit( CMAB) algorithm to provide the exploration/exploitation trade-off. We introduce a novel variant of a CMAB algorithm that makes use of the structure of this tree, and use Semi-Supervised Learning to grow the tree using unlabeled data. The approach is evaluated on a real dataset and data generated by a simulator that adds concept drift by adapting the behavior of fraudsters to avoid detection. It outperforms frequently used offline models in terms of cumulative rewards, in particular in the presence of concept drift.",2018,https://ojs.aaai.org/index.php/AAAI/article/view/11411,10.1609/aaai.v32i1.11411,NA,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,IAAI18 - Emerging,AAAI,NA
AAAI Conference on Artificial Intelligence,Adaptive Energy Management for Self-Sustainable Wearables in Mobile Health,Dina Hussein;Ganapati Bhat;Janardhan Rao Doppa,"Wearable devices that integrate multiple sensors, processors, and communication technologies have the potential to transform mobile health for remote monitoring of health parameters. However, the small form factor of the wearable devices limits the battery size and operating lifetime. As a result, the devices require frequent recharging, which has limited their widespread adoption. Energy harvesting has emerged as an effective method towards sustainable operation of wearable devices. Unfortunately, energy harvesting alone is not sufficient to fulfill the energy requirements of wearable devices. This paper studies the novel problem of adaptive energy management towards the goal of self-sustainable wearables by using harvested energy to supplement the battery energy and to reduce manual recharging by users. To solve this problem, we propose a principled algorithm referred as AdaEM. There are two key ideas behind AdaEM. First, it uses machine learning( ML) methods to learn predictive models of user activity and energy usage patterns. These models allow us to estimate the potential of energy harvesting in a day as a function of the user activities. Second, it reasons about the uncertainty in predictions and estimations from the ML models to optimize the energy management decisions using a dynamic robust optimization( DyRO) formulation. We propose a light-weight solution for DyRO to meet the practical needs of deployment. We validate the AdaEM approach on a wearable device prototype consisting of solar and motion energy harvesting using real-world data of user activities. Experiments show that AdaEM achieves solutions that are within 5% of the optimal with less than 0. 005% execution time and energy overhead.",2022,https://ojs.aaai.org/index.php/AAAI/article/view/21451,10.1609/aaai.v36i11.21451,10,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Special Track on AI for Social Impact,AAAI,NA
AAAI Conference on Artificial Intelligence,Adaptive Pattern-Parameter Matching for Robust Pedestrian Detection,Mengyin Liu;Chao Zhu;Jun Wang;Xu-Cheng Yin,"Pedestrians with challenging patterns, e. g. small scale or heavy occlusion, appear frequently in practical applications like autonomous driving, which remains tremendous obstacle to higher robustness of detectors. Although plenty of previous works have been dedicated to these problems, properly matching patterns of pedestrian and parameters of detector, i. e. , constructing a detector with proper parameter sizes for certain pedestrian patterns of different complexity, has been seldom investigated intensively. Pedestrian instances are usually handled equally with the same amount of parameters, which in our opinion is inadequate for those with more difficult patterns and leads to unsatisfactory performance. Thus, we propose in this paper a novel detection approach via adaptive pattern-parameter matching. The input pedestrian patterns, especially the complex ones, are first disentangled into simpler patterns for detection head by Pattern Disentangling Module( PDM) with various receptive fields. Then, Gating Feature Filtering Module( GFFM) dynamically decides the spatial positions where the patterns are still not simple enough and need further disentanglement by the next-level PDM. Cooperating with these two key components, our approach can adaptively select the best matched parameter size for the input patterns according to their complexity. Moreover, to further explore the relationship between parameter sizes and their performance on the corresponding patterns, two parameter selection policies are designed: 1) extending parameter size to maximum, aiming at more difficult patterns for different occlusion types; 2) specializing parameter size by group division, aiming at complex patterns for scale variations. Extensive experiments on two popular benchmarks, Caltech and CityPersons, show that our proposed method achieves superior performance compared with other state-of-the-art methods on subsets of different scales and occlusion types.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/16313,10.1609/aaai.v35i3.16313,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Computer Vision II,AAAI,NA
AAAI Conference on Artificial Intelligence,Adaptive Quantitative Trading: An Imitative Deep Reinforcement Learning Approach,Yang Liu;Qi Liu;Hongke Zhao;Zhen Pan;Chuanren Liu,"In recent years, considerable efforts have been devoted to developing AI techniques for finance research and applications. For instance, AI techniques( e. g. , machine learning) can help traders in quantitative trading( QT) by automating two tasks: market condition recognition and trading strategies execution. However, existing methods in QT face challenges such as representing noisy high-frequent financial data and finding the balance between exploration and exploitation of the trading agent with AI techniques. To address the challenges, we propose an adaptive trading model, namely iRDPG, to automatically develop QT strategies by an intelligent trading agent. Our model is enhanced by deep reinforcement learning( DRL) and imitation learning techniques. Specifically, considering the noisy financial data, we formulate the QT process as a Partially Observable Markov Decision Process( POMDP). Also, we introduce imitation learning to leverage classical trading strategies useful to balance between exploration and exploitation. For better simulation, we train our trading agent in the real financial market using minute-frequent data. Experimental results demonstrate that our model can extract robust market features and be adaptive in different markets.",2020,https://ojs.aaai.org/index.php/AAAI/article/view/5587,10.1609/aaai.v34i02.5587,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Game Theory and Economic Paradigms,AAAI,NA
AAAI Conference on Artificial Intelligence,Adaptive Verifiable Training Using Pairwise Class Similarity,Shiqi Wang;Kevin Eykholt;Taesung Lee;Jiyong Jang;Ian Molloy,"Verifiable training has shown success in creating neural networks that are provably robust to a given amount of noise. However, despite only enforcing a single robustness criterion, its performance scales poorly with dataset complexity. On CIFAR10, a non-robust LeNet model has a 21. 63% error rate, while a model created using verifiable training and a L-infinity robustness criterion of 8/255, has an error rate of 57. 10%. Upon examination, we find that when labeling visually similar classes, the models error rate is as high as 61. 65%. Thus, we attribute the loss in performance to inter-class similarity. Classes that are similar( i. e. , close in the feature space) increase the difficulty of learning a robust model. While it may be desirable to train a model to be robust for a large robustness region, pairwise class similarities limit the potential gains. Furthermore, consideration must be made regarding the relative cost of mistaking one class for another. In security or safety critical tasks, similar classes are likely to belong to the same group, and thus are equally sensitive. In this work, we propose a new approach that utilizes inter-class similarity to improve the performance of verifiable training and create robust models with respect to multiple adversarial criteria. First, we cluster similar classes using agglomerate clustering and assign robustness criteria based on the degree of similarity between clusters. Next, we propose two methods to apply our approach:( 1) the Inter-Group Robustness Prioritization method, which uses a custom loss term to create a single model with multiple robustness guarantees and( 2) the neural decision tree method, which trains multiple sub-classifiers with different robustness guarantees and combines them in a decision tree architecture. Our experiments on Fashion-MNIST and CIFAR10 demonstrate that by prioritizing the robustness between the most dissimilar groups, we improve clean performance by up to 9. 63% and 30. 89% respectively. Furthermore, on CIFAR100, our approach reduces the clean error rate by 26. 32%.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/17223,10.1609/aaai.v35i11.17223,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Machine Learning IV,AAAI,NA
AAAI Conference on Artificial Intelligence,ADDMC: Weighted Model Counting with Algebraic Decision Diagrams,Jeffrey Dudek;Vu Phan;Moshe Vardi,"We present an algorithm to compute exact literal-weighted model counts of Boolean formulas in Conjunctive Normal Form. Our algorithm employs dynamic programming and uses Algebraic Decision Diagrams as the main data structure. We implement this technique in ADDMC, a new model counter. We empirically evaluate various heuristics that can be used with ADDMC. We then compare ADDMC to four state-of-the-art weighted model counters( Cachet, c2d, d4, and miniC2D) on 1914 standard model counting benchmarks and show that ADDMC significantly improves the virtual best solver.",2020,https://ojs.aaai.org/index.php/AAAI/article/view/5505,10.1609/aaai.v34i02.5505,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Constraint Satisfaction and Optimization,AAAI,NA
AAAI Conference on Artificial Intelligence,Addressing Action Oscillations through Learning Policy Inertia,Chen Chen;Hongyao Tang;Jianye Hao;Wulong Liu;Zhaopeng Meng,"Deep reinforcement learning( DRL) algorithms have been demonstrated to be effective on a wide range of challenging decision making and control tasks. However, these methods typically suffer from severe action oscillations in particular in discrete action setting, which means that agents select different actions within consecutive steps even though states only slightly differ. This issue is often neglected since we usually evaluate the quality of a policy using cumulative rewards only. Action oscillation strongly affects the user experience and even causes serious potential security menace especially in real-world domains with the main concern of safety, such as autonomous driving. In this paper, we introduce Policy Inertia Controller( PIC) which serves as a generic plug-in framework to off-the-shelf DRL algorithms, to enable adaptive balance between the optimality and smoothness in a formal way. We propose Nested Policy Iteration as a general training algorithm for PIC-augmented policy which ensures monotonically non-decreasing updates. Further, we derive a practical DRL algorithm, namely Nested Soft Actor-Critic. Experiments on a collection of autonomous driving tasks and several Atari games suggest that our approach demonstrates substantial oscillation reduction than a range of commonly adopted baselines with almost no performance degradation.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/16864,10.1609/aaai.v35i8.16864,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Machine Learning I,AAAI,NA
AAAI Conference on Artificial Intelligence,Adversarial Permutation Guided Node Representations for Link Prediction,Indradyumna Roy;Abir De;Soumen Chakrabarti,"After observing a snapshot of a social network, a link prediction( LP) algorithm identifies node pairs between which new edges will likely materialize in future. Most LP algorithms estimate a score for currently non-neighboring node pairs, and rank them by this score. Recent LP systems compute this score by comparing dense, low dimensional vector representations of nodes. Graph neural networks( GNNs) , in particular graph convolutional networks( GCNs) , are popular examples. For two nodes to be meaningfully compared, their embeddings should be indifferent to reordering of their neighbors. GNNs typically use simple, symmetric set aggregators to ensure this property, but this design decision has been shown to produce representations with limited expressive power. Sequence encoders are more expressive, but are permutation sensitive by design. Recent efforts to overcome this dilemma turn out to be unsatisfactory for LP tasks. In response, we propose PermGNN, which aggregates neighbor features using a recurrent, order-sensitive aggregator and directly minimizes an LP loss while it is `attacked by adversarial generator of neighbor permutations. PermGNN has superior expressive power compared to earlier GNNs. Next, we devise an optimization framework to map PermGNNs node embeddings to a suitable locality-sensitive hash, which speeds up reporting the top-K most likely edges for the LP task. Our experiments on diverse datasets show that PermGNN outperforms several state-of-the-art link predictors by a significant margin, and can predict the most likely edges fast.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/17138,10.1609/aaai.v35i11.17138,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Machine Learning IV,AAAI,NA
AAAI Conference on Artificial Intelligence,Adversarial Training for Improving Model Robustness? Look at Both Prediction and Interpretation,Hanjie Chen;Yangfeng Ji,"Neural language models show vulnerability to adversarial examples which are semantically similar to their original counterparts with a few words replaced by their synonyms. A common way to improve model robustness is adversarial training which follows two steps—collecting adversarial examples by attacking a target model, and fine-tuning the model on the augmented dataset with these adversarial examples. The objective of traditional adversarial training is to make a model produce the same correct predictions on an original/adversarial example pair. However, the consistency between model decision-makings on two similar texts is ignored. We argue that a robust model should behave consistently on original/adversarial example pairs, that is making the same predictions( what) based on the same reasons( how) which can be reflected by consistent interpretations. In this work, we propose a novel feature-level adversarial training method named FLAT. FLAT aims at improving model robustness in terms of both predictions and interpretations. FLAT incorporates variational word masks in neural networks to learn global word importance and play as a bottleneck teaching the model to make predictions based on important words. FLAT explicitly shoots at the vulnerability problem caused by the mismatch between model understandings on the replaced words and their synonyms in original/adversarial example pairs by regularizing the corresponding global word importance scores. Experiments show the effectiveness of FLAT in improving the robustness with respect to both predictions and interpretations of four neural network models( LSTM, CNN, BERT, and DeBERTa) to two adversarial attacks on four text classification tasks. The models trained via FLAT also show better robustness than baseline models on unforeseen adversarial examples across different attacks.",2022,https://ojs.aaai.org/index.php/AAAI/article/view/21289,10.1609/aaai.v36i10.21289,10,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Speech and Natural Language Processing,AAAI,NA
AAAI Conference on Artificial Intelligence,Agent Incentives: A Causal Perspective,Tom Everitt;Ryan Carey;Eric D. Langlois;Pedro A. Ortega;Shane Legg,"We present a framework for analysing agent incentives using causal influence diagrams. We establish that a well-known criterion for value of information is complete. We propose a new graphical criterion for value of control, establishing its soundness and completeness. We also introduce two new concepts for incentive analysis: response incentives indicate which changes in the environment affect an optimal decision, while instrumental control incentives establish whether an agent can influence its utility via a variable X. For both new concepts, we provide sound and complete graphical criteria. We show by example how these results can help with evaluating the safety and fairness of an AI system",2021,https://ojs.aaai.org/index.php/AAAI/article/view/17368,10.1609/aaai.v35i13.17368,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Philosophy and Ethics of AI,AAAI,NA
AAAI Conference on Artificial Intelligence,Agent-Human Coordination with Communication Costs Under Uncertainty,Asaf Frieder;Raz Lin;Sarit Kraus,"Coordination in mixed agent-human environments is an important, yet not a simple, problem. Little attention has been given to the issues raised in teams that consist of both computerized agents and people. In such situations different considerations are in order, as people tend to make mistakes and they are affected by cognitive, social and cultural factors. In this paper we present a novel agent designed to proficiently coordinate with a human counterpart. The agent uses a neural network model that is based on a pre-existing knowledge base which allows it to achieve an efficient modeling of a humans decisions and predict their behavior. A novel communication mechanism which takes into account the expected effect of communication on the other member will allow communication costs to be minimized. In extensive simulations involving more than 200 people we investigated our approach and showed that our agent achieves better coordination when involved, compared to settings in which only humans or another state-of-the-art agent are involved.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/8329,10.1609/aaai.v26i1.8329,7,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,Multidisciplinary Topics,AAAI,NA
AAAI Conference on Artificial Intelligence,AI and Parallelism in CS1: Experiences and Analysis,Steven Bogaerts,"This work considers the use of AI and parallelism as a context for learning typical programming concepts in an introductory programming course( CS1). The course includes exercises in decision trees, a novel game called Find the Gnomes to introduce supervised learning, the construction and application of a vectorized neural network unit class, and obtaining speedup in training through parallelism. The exercises are designed to teach students typical introductory programming concepts while also providing a preview and motivating example of advanced CS topics. Students understanding and motivation are considered through a detailed analysis of preand post-survey data gathered in several sections of the course each taught by one of four instructors across five semesters.",2024,https://ojs.aaai.org/index.php/AAAI/article/view/26876,10.1609/aaai.v37i13.26876,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,EAAI Symposium: Main Track,AAAI,NA
AAAI Conference on Artificial Intelligence,AI Risk Profiles: A Standards Proposal for Pre-deployment AI Risk Disclosures,Eli Sherman;Ian Eisenberg,"As AI systems’ sophistication and proliferation have increased, awareness of the risks has grown proportionally. The AI industry is increasingly emphasizing the need for transparency, with proposals ranging from standardizing use of technical disclosures, like model cards, to regulatory licensing regimes. Since the AI value chain is complicated, with actors bringing varied expertise, perspectives, and values, it is crucial that consumers of transparency disclosures be able to understand the risks of the AI system in question. In this paper we propose a risk profiling standard which can guide downstream decision-making, including triaging further risk assessment, informing procurement and deployment, and directing regulatory frameworks. The standard is built on our proposed taxonomy of AI risks, which distills the wide variety of risks proposed in the literature into a high-level categorization. We outline the myriad data sources needed to construct informative Risk Profiles and propose a template and methodology for collating risk information into a standard, yet flexible, structure. We apply this methodology to a number of prominent AI systems using publicly available information. To conclude, we discuss design decisions for the profiles and future work.",2024,https://ojs.aaai.org/index.php/AAAI/article/view/30348,10.1609/aaai.v38i21.30348,6,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,IAAI Technical Track on AI Incidents and Best Practices,AAAI,NA
AAAI Conference on Artificial Intelligence,Algorithmic and Human Teaching of Sequential Decision Tasks,Maya Cakmak;Manuel Lopes,"A helpful teacher can significantly improve the learning rate of a learning agent. Teaching algorithms have been formally studied within the field of Algorithmic Teaching. These give important insights into how a teacher can select the most informative examples while teachinga new concept. However the field has so far focused purely on classification tasks. In this paper we introducea novel method for optimally teaching sequential decision tasks. We present an algorithm that automatically selects the set of most informative demonstrations andevaluate it on several navigation tasks. Next, we explore the idea of using this algorithm to produce instructions for humans on how to choose examples when teaching sequential decision tasks. We present a user study that demonstrates the utility of such instructions.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/8333,10.1609/aaai.v26i1.8333,7,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,Multidisciplinary Topics,AAAI,NA
AAAI Conference on Artificial Intelligence,Algorithmic Fairness Verification with Graphical Models,Bishwamittra Ghosh;Debabrota Basu;Kuldeep S Meel,"In recent years, machine learning( ML) algorithms have been deployed in safety-critical and high-stake decision-making, where the fairness of algorithms is of paramount importance. Fairness in ML centers on detecting bias towards certain demographic populations induced by an ML classifier and proposes algorithmic solutions to mitigate the bias with respect to different fairness definitions. To this end, several fairness verifiers have been proposed that compute the bias in the prediction of an ML classifier—essentially beyond a finite dataset—given the probability distribution of input features. In the context of verifying linear classifiers, existing fairness verifiers are limited by accuracy due to imprecise modeling of correlations among features and scalability due to restrictive formulations of the classifiers as SSAT/SMT formulas or by sampling. In this paper, we propose an efficient fairness verifier, called FVGM, that encodes the correlations among features as a Bayesian network. In contrast to existing verifiers, FVGM proposes a stochastic subset-sum based approach for verifying linear classifiers. Experimentally, we show that FVGM leads to an accurate and scalable assessment for more diverse families of fairness-enhancing algorithms, fairness attacks, and group/causal fairness metrics than the state-of-the-art fairness verifiers. We also demonstrate that FVGM facilitates the computation of fairness influence functions as a stepping stone to detect the source of bias induced by subsets of features.",2022,https://ojs.aaai.org/index.php/AAAI/article/view/21187,10.1609/aaai.v36i9.21187,10,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Philosophy and Ethics of AI,AAAI,NA
AAAI Conference on Artificial Intelligence,Algorithms for Average Regret Minimization,Sabine Storandt;Stefan Funke,"In this paper, we study a problem from the realm of multicriteria decision making in which the goal is to select from a given set S of d-dimensional objects a minimum sized subset S0 with bounded regret. Thereby, regret measures the unhappiness of users which would like to select their favorite object from set S but now can only select their favorite object from the subset S0. Previous work focused on bounding the maximum regret which is determined by the most unhappy user. We propose to consider the average regret instead which is determined by the sum of( un) happiness of all possible users. We show that this regret measure comes with desirable properties as supermodularity which allows to construct approximation algorithms. Furthermore, we introduce the regret minimizing permutation problem and discuss extensions of our algorithms to the recently proposed k-regret measure. Our theoretical results are accompanied with experiments on a variety of inputs with d up to 7.",2019,https://ojs.aaai.org/index.php/AAAI/article/view/3975,10.1609/aaai.v33i01.33011600,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Constraint Satisfaction and Optimization,AAAI,NA
AAAI Conference on Artificial Intelligence,Aligning Domain-Specific Distribution and Classifier for Cross-Domain Classification from Multiple Sources,Yongchun Zhu;Fuzhen Zhuang;Deqing Wang,"While Unsupervised Domain Adaptation( UDA) algorithms, i. e. , there are only labeled data from source domains, have been actively studied in recent years, most algorithms and theoretical results focus on Single-source Unsupervised Domain Adaptation( SUDA). However, in the practical scenario, labeled data can be typically collected from multiple diverse sources, and they might be different not only from the target domain but also from each other. Thus, domain adapters from multiple sources should not be modeled in the same way. Recent deep learning based Multi-source Unsupervised Domain Adaptation( MUDA) algorithms focus on extracting common domain-invariant representations for all domains by aligning distribution of all pairs of source and target domains in a common feature space. However, it is often very hard to extract the same domain-invariant representations for all domains in MUDA. In addition, these methods match distributions without considering domain-specific decision boundaries between classes. To solve these problems, we propose a new framework with two alignment stages for MUDA which not only respectively aligns the distributions of each pair of source and target domains in multiple specific feature spaces, but also aligns the outputs of classifiers by utilizing the domainspecific decision boundaries. Extensive experiments demonstrate that our method can achieve remarkable results on popular benchmark datasets for image classification.",2019,https://ojs.aaai.org/index.php/AAAI/article/view/4551,10.1609/aaai.v33i01.33015989,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Machine Learning,AAAI,NA
AAAI Conference on Artificial Intelligence,AlphaHoldem: High-Performance Artificial Intelligence for Heads-Up No-Limit Poker via End-to-End Reinforcement Learning,Enmin Zhao;Renye Yan;Jinqiu Li;Kai Li;Junliang Xing,"Heads-up no-limit Texas hold’em( HUNL) is the quintessential game with imperfect information. Representative priorworks like DeepStack and Libratus heavily rely on counter-factual regret minimization( CFR) and its variants to tackleHUNL. However, the prohibitive computation cost of CFRiteration makes it difficult for subsequent researchers to learnthe CFR model in HUNL and apply it in other practical applications. In this work, we present AlphaHoldem, a high-performance and lightweight HUNL AI obtained with an end-to-end self-play reinforcement learning framework. The proposed framework adopts a pseudo-siamese architecture to directly learn from the input state information to the output actions by competing the learned model with its different historical versions. The main technical contributions include anovel state representation of card and betting information, amultitask self-play training loss function, and a new modelevaluation and selection metric to generate the final model. In a study involving 100, 000 hands of poker, AlphaHoldemdefeats Slumbot and DeepStack using only one PC with threedays training. At the same time, AlphaHoldem only takes 2. 9milliseconds for each decision-making using only a singleGPU, more than 1, 000 times faster than DeepStack. We release the history data among among AlphaHoldem, Slumbot, and top human professionals in the author’s GitHub repository to facilitate further studies in this direction.",2022,https://ojs.aaai.org/index.php/AAAI/article/view/20394,10.1609/aaai.v36i4.20394,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Domain( s) Of Application,AAAI,NA
AAAI Conference on Artificial Intelligence,Amsterdam to Dublin Eventually Delayed? LSTM and Transfer Learning for Predicting Delays of Low Cost Airlines,Nicholas McCarthy;Mohammad Karzand;Freddy Lecue,"Flight delays impact airlines, airports and passengers. Delay prediction is crucial during the decision-making process for all players in commercial aviation, and in particular for airlines to meet their on-time performance objectives. Although many machine learning approaches have been experimented with, they fail in( i) predicting delays in minutes with low errors( less than 15 minutes) , ( ii) being applied to small carriers i. e. , low cost companies characterized by a small amount of data. This work presents a Long Short-Term Memory( LSTM) approach to predicting flight delay, modeled as a sequence of flights across multiple airports for a particular aircraft throughout the day. We then suggest a transfer learning approach between heterogeneous feature spaces to train a prediction model for a given smaller airline using the data from another larger airline. Our approach is demonstrated to be robust and accurate for low cost airlines in Europe.",2019,https://ojs.aaai.org/index.php/AAAI/article/view/5013,10.1609/aaai.v33i01.33019541,6,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,IAAI Technical Track: Emerging Papers,AAAI,NA
AAAI Conference on Artificial Intelligence,An Ambiguity Aversion Model for Decision Making under Ambiguity,Wenjun Ma;Xudong Luo;Yuncheng Jiang,"In real life, decisions are often made under ambiguity, where it is difficult to estimate accurately the probability of each single possible consequence of a choice. However, this problem has not been solved well in existing work for the following two reasons. ( i) Some of them cannot cover the Ellsberg paradox and the Machina Paradox. Thus, the choices that they predict could be inconsistent with empirical observations. ( ii) Some of them rely on parameter tuning without offering explanations for the reasonability of setting such bounds of parameters. Thus, the prediction of such a model in new decision making problems is doubtful. To the end, this paper proposes a new decision making model based on D-S theory and the emotion of ambiguity aversion. Some insightful properties of our model and the validating on two famous paradoxes show that our model indeed is a better alternative for decision making under ambiguity.",2017,https://ojs.aaai.org/index.php/AAAI/article/view/10569,10.1609/aaai.v31i1.10569,NA,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Game Theory and Economic Paradigms,AAAI,NA
AAAI Conference on Artificial Intelligence,An Autonomous Override System to Prevent Airborne Loss of Control,Sweewarman Balachandran;Ella M. Atkins,"Loss of Control( LOC) is the most common precursor to aircraft accidents. This paper presents a Flight Safety Assessment and Management( FSAM) decision system to reduce in-flight LOC risk. FSAM nominally serves as a monitor to detect conditions that pose LOC risk, automatically activating the appropriate control authority if necessary to prevent LOC and restore a safe operational state. This paper contributes an efficient Markov Decision Process( MDP) formulation for FSAM. The state features capture risk associated with aircraft dynamics, configuration, health, pilot behavior and weather. The reward function trades cost of inaction against the cost of overriding the current control authority. A sparse sampling algorithm obtains a near-optimal solution for the MDP online. This approach enables the FSAM MDP to incorporate dynamically changing flight envelope and environment constraints into decision-making. Case studies based on realworld aviation incidents are presented.",2016,https://ojs.aaai.org/index.php/AAAI/article/view/19074,10.1609/aaai.v30i2.19074,6,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,IAAI Emerging Application Papers,AAAI,NA
AAAI Conference on Artificial Intelligence,An Efficient Framework for Dense Video Captioning,Maitreya Suin;A. N. Rajagopalan,"Dense video captioning is an extremely challenging task since an accurate and faithful description of events in a video requires a holistic knowledge of the video contents as well as contextual reasoning of individual events. Most existing approaches handle this problem by first proposing event boundaries from a video and then captioning on a subset of the proposals. Generation of dense temporal annotations and corresponding captions from long videos can be dramatically source consuming. In this paper, we focus on the task of generating a dense description of temporally untrimmed videos and aim to significantly reduce the computational cost by processing fewer frames while maintaining accuracy. Existing video captioning methods sample frames with a predefined frequency over the entire video or use all the frames. Instead, we propose a deep reinforcement-based approach which enables an agent to describe multiple events in a video by watching a portion of the frames. The agent needs to watch more frames when it is processing an informative part of the video, and skip frames when there is redundancy. The agent is trained using actor-critic algorithm, where the actor determines the frames to be watched from a video and the critic assesses the optimality of the decisions taken by the actor. Such an efficient frame selection simplifies the event proposal task considerably. This has the added effect of reducing the occurrence of unwanted proposals. The encoded state representation of the frame selection agent is further utilized for guiding event proposal and caption generation tasks. We also leverage the idea of knowledge distillation to improve the accuracy. We conduct extensive evaluations on ActivityNet captions dataset to validate our method.",2020,https://ojs.aaai.org/index.php/AAAI/article/view/6881,10.1609/aaai.v34i07.6881,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Vision,AAAI,NA
AAAI Conference on Artificial Intelligence,An Exercise in Tournament Design: When Some Matches Must Be Scheduled,Sushmita Gupta;Ramanujan Sridharan;Peter Strulo,"Single-elimination( SE) tournaments are a popular format used in competitive environments and decision making. Algorithms for SE tournament manipulation have been an active topic of research in recent years. In this paper, we initiate the algorithmic study of a novel variant of SE tournament manipulation that aims to model the fact that certain matchups are highly desired in a sporting context, incentivizing an organizer to manipulate the bracket to make such matchups take place. We obtain both hardness and tractability results. We show that while the problem of computing a bracket enforcing a given set of matches in an SE tournament is NP-hard, there are natural restrictions that lead to polynomial-time solvability. In particular, we show polynomial-time solvability if there is a linear ordering on the ability of players with only a constant number of exceptions where a player with lower ability beats a player with higher ability.",2024,https://ojs.aaai.org/index.php/AAAI/article/view/28833,10.1609/aaai.v38i9.28833,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Game Theory and Economic Paradigms,AAAI,NA
AAAI Conference on Artificial Intelligence,An Experimental Study of Advice in Sequential Decision-Making Under Uncertainty,Florian Benavent;Bruno Zanuttini,"We consider sequential decision making problems under uncertainty, in which a user has a general idea of the task to achieve, and gives advice to an agent in charge of computing an optimal policy. Many different notions of advice have been proposed in somewhat different settings, especially in the field of inverse reinforcement learning and for resolution of Markov Decision Problems with Imprecise Rewards. Two key questions are whether the advice required by a specific method is natural for the user to give, and how much advice is needed for the agent to compute a good policy, as evaluated by the user. We give a unified view of a number of proposals made in the literature, and propose a new notion of advice, which corresponds to a user telling why she would take a given action in a given state. For all these notions, we discuss their naturalness for a user and the integration of advice. We then report on an experimental study of the amount of advice needed for the agent to compute a good policy. Our study shows in particular that continual interaction between the user and the agent is worthwhile, and sheds light on the pros and cons of each type of advice.",2018,https://ojs.aaai.org/index.php/AAAI/article/view/12118,10.1609/aaai.v32i1.12118,NA,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Reasoning under Uncertainty,AAAI,NA
AAAI Conference on Artificial Intelligence,An Improved Generic Bet-and-Run Strategy with Performance Prediction for Stochastic Local Search,Thomas Weise;Zijun Wu;Markus Wagner,"A commonly used strategy for improving optimization algorithms is to restart the algorithm when it is believed to be trapped in an inferior part of the search space. Building on the recent success of BET-AND-RUN approaches for restarted local search solvers, we introduce a more generic version that makes use of performance prediction. It is our goal to obtain the best possible results within a given time budget t using a given black-box optimization algorithm. If no prior knowledge about problem features and algorithm behavior is available, the question about how to use the time budget most efficiently arises. We first start k ≥ 1 independent runs of the algorithm during an initialization budget t1 < t, pause these runs, then apply a decision maker D to choose 1 ≤ m < k runs from them( consuming t2 ≥ 0 time units in doing so) , and then continue these runs for the remaining t3 = t−t1−t2 time units. In previous BET-AND-RUN strategies, the decision maker D = currentBest would simply select the run with the best-so-far results at negligible time. We propose using more advanced methods to discriminate between “good” and “bad” sample runs with the goal of increasing the correlation of the chosen run with the a-posteriori best one. In over 157 million experiments, we test different approaches to predict which run may yield the best results if granted the remaining budget. We show( 1) that the currentBest method is indeed a very reliable and robust baseline approach, and( 2) that our approach can yield better results than the previous methods.",2019,https://ojs.aaai.org/index.php/AAAI/article/view/4082,10.1609/aaai.v33i01.33012395,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Heuristic Search and Optimization,AAAI,NA
AAAI Conference on Artificial Intelligence,An Integrative Framework for Artificial Intelligence Education,Pat Langley,"Modern introductory courses on AI do not train students to create intelligent systems or provide broad coverage of this complex field. In this paper, we identify problems with common approaches to teaching artificial intelligence and suggest alternative principles that courses should adopt instead. We illustrate these principles in a proposed course that teaches students not only about component methods, such as pattern matching and decision making, but also about their combination into higher-level abilities for reasoning, sequential control, plan generation, and integrated intelligent agents. We also present a curriculum that instantiates this organization, including sample programming exercises and a project that requires system integration. Participants also gain experience building knowledge-based agents that use their software to produce intelligent behavior.",2019,https://ojs.aaai.org/index.php/AAAI/article/view/5032,10.1609/aaai.v33i01.33019670,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,EAAI Symposium: Full Papers,AAAI,NA
AAAI Conference on Artificial Intelligence,An Interactive Explanatory AI System for Industrial Quality Control,Dennis Müller;Michael März;Stephan Scheele;Ute Schmid,"Machine learning based image classification algorithms, such as deep neural network approaches, will be increasingly employed in critical settings such as quality control in industry, where transparency and comprehensibility of decisions are crucial. Therefore, we aim to extend the defect detection task towards an interactive human-in-the-loop approach that allows us to integrate rich background knowledge and the inference of complex relationships going beyond traditional purely data-driven approaches. We propose an approach for an interactive support system for classifications in an industrial quality control setting that combines the advantages of both( explainable) knowledge-driven and data-driven machine learning methods, in particular inductive logic programming and convolutional neural networks, with human expertise and control. The resulting system can assist domain experts with decisions, provide transparent explanations for results, and integrate feedback from users; thus reducing workload for humans while both respecting their expertise and without removing their agency or accountability.",2022,https://ojs.aaai.org/index.php/AAAI/article/view/21530,10.1609/aaai.v36i11.21530,7,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,IAAI Technical Track on Emerging Applications of AI,AAAI,NA
AAAI Conference on Artificial Intelligence,An Interactive Regret-Based Genetic Algorithm for Solving Multi-Objective Combinatorial Optimization Problems,Nawal Benabbou;Cassandre Leroy;Thibaut Lust,"We propose a new approach consisting in combining genetic algorithms and regret-based incremental preference elicitation for solving multi-objective combinatorial optimization problems with unknown preferences. For the purpose of elicitation, we assume that the decision makers preferences can be represented by a parameterized scalarizing function but the parameters are initially not known. Instead, the parameter imprecision is progressively reduced by asking preference queries to the decision maker during the search to help identify the best solutions within a population. Our algorithm, called RIGA, can be applied to any multi-objective combinatorial optimization problem provided that the scalarizing function is linear in its parameters and that a( near-) optimal solution can be efficiently determined when preferences are known. Moreover, RIGA runs in polynomial time while asking no more than a polynomial number of queries. For the multi-objective traveling salesman problem, we provide numerical results showing its practical efficiency in terms of number of queries, computation time and gap to optimality.",2020,https://ojs.aaai.org/index.php/AAAI/article/view/5612,10.1609/aaai.v34i03.5612,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Heuristic Search and Optimization,AAAI,NA
AAAI Conference on Artificial Intelligence,An Interpretable Generative Adversarial Approach to Classification of Latent Entity Relations in Unstructured Sentences,Shiou Tian Hsu;Changsung Moon;Paul Jones;Nagiza Samatova,"We propose a generative adversarial neural network model for relation classification that attempts to emulate the way in which human analysts might process sentences. Our approach provides two unique benefits over existing capabilities:( 1) we make predictions by finding and exploiting supportive rationales to improve interpretability( i. e. words or phrases extracted from a sentence that a person can reason upon) , and( 2) we allow predictions to be easily corrected by adjusting the rationales. Our model consists of three stages: Generator, Selector, and Encoder. The Generator identifies candidate text fragments; the Selector decides which fragments can be used as rationales depending on the goal; and finally, the Encoder performs relation reasoning on the rationales. While the Encoder is trained in a supervised manner to classify relations, the Generator and Selector are designed as unsupervised models to identify rationales without prior knowledge, although they can be semi-supervised through human annotations. We evaluate our model on data from SemEval 2010 that provides 19 relation-classes. Experiments demonstrate that our approach outperforms state-of-the-art models, and that our model is capable of extracting good rationales on its own as well as benefiting from labeled rationales if provided.",2018,https://ojs.aaai.org/index.php/AAAI/article/view/11972,10.1609/aaai.v32i1.11972,NA,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,Main Track: NLP and Machine Learning,AAAI,NA
AAAI Conference on Artificial Intelligence,An Online Learning Approach to Sequential User-Centric Selection Problems,Junpu Chen;Hong Xie,"This paper proposes a new variant of multi-play MAB model, to capture important factors of the sequential user-centric selection problem arising from mobile edge computing, ridesharing applications, etc. In the proposed model, each arm is associated with discrete units of resources, each play is associate with movement costs and multiple plays can pull the same arm simultaneously. To learn the optimal action profile( an action profile prescribes the arm that each play pulls) , there are two challenges:( 1) the number of action profiles is large, i. e. , M^K, where K and M denote the number of plays and arms respectively;( 2) feedbacks on action profiles are not available, but instead feedbacks on some model parameters can be observed. To address the first challenge, we formulate a completed weighted bipartite graph to capture key factors of the offline decision problem with given model parameters. We identify the correspondence between action profiles and a special class of matchings of the graph. We also identify a dominance structure of this class of matchings. This correspondence and dominance structure enable us to design an algorithm named OffOptActPrf to locate the optimal action efficiently. To address the second challenge, we design an OnLinActPrf algorithm. We design estimators for model parameters and use these estimators to design a Quasi-UCB index for each action profile. The OnLinActPrf uses OffOptActPrf as a subroutine to select the action profile with the largest Quasi-UCB index. We conduct extensive experiments to validate the efficiency of OnLinActPrf.",2022,https://ojs.aaai.org/index.php/AAAI/article/view/20572,10.1609/aaai.v36i6.20572,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Machine Learning I,AAAI,NA
AAAI Conference on Artificial Intelligence,Analytically Tractable Models for Decision Making under Present Bias,Yasunori Akagi;Naoki Marumo;Takeshi Kurashima,"Time-inconsistency is a characteristic of human behavior in which people plan for long-term benefits but take actions that differ from the plan due to conflicts with short-term benefits. Such time-inconsistent behavior is believed to be caused by present bias, a tendency to overestimate immediate rewards and underestimate future rewards. It is essential in behavioral economics to investigate the relationship between present bias and time-inconsistency. In this paper, we propose a model for analyzing agent behavior with present bias in tasks to make progress toward a goal over a specific period. Unlike previous models, the state sequence of the agent can be described analytically in our model. Based on this property, we analyze three crucial problems related to agents under present bias: task abandonment, optimal goal setting, and optimal reward scheduling. Extensive analysis reveals how present bias affects the condition under which task abandonment occurs and optimal intervention strategies. Our findings are meaningful for preventing task abandonment and intervening through incentives in the real world.",2024,https://ojs.aaai.org/index.php/AAAI/article/view/28798,10.1609/aaai.v38i9.28798,10,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Game Theory and Economic Paradigms,AAAI,NA
AAAI Conference on Artificial Intelligence,Anytime Anyspace AND/OR Best-First Search for Bounding Marginal MAP,Qi Lou;Rina Dechter;Alexander Ihler,"Marginal MAP is a key task in Bayesian inference and decision-making. It is known to be very difficult in general, particularly because the evaluation of each MAP assignment requires solving an internal summation problem. In this paper, we propose a best-first search algorithm that provides anytime upper bounds for marginal MAP in graphical models. It folds the computation of external maximization and internal summation into an AND/OR tree search framework, and solves them simultaneously using a unified best-first search algorithm. The algorithm avoids some unnecessary computation of summation sub-problems associated with MAP assignments, and thus yields significant time savings. Furthermore, our algorithm is able to operate within limited memory. Empirical evaluation on three challenging benchmarks demonstrates that our unified best-first search algorithm using pre-compiled variational heuristics often provides tighter anytime upper bounds compared to those state-of-the-art baselines.",2018,https://ojs.aaai.org/index.php/AAAI/article/view/12123,10.1609/aaai.v32i1.12123,NA,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Reasoning under Uncertainty,AAAI,NA
AAAI Conference on Artificial Intelligence,Apparently Irrational Choice as Optimal Sequential Decision Making,Haiyang Chen;Hyung Jin Chang;Andrew Howes,"In this paper, we propose a normative approach to modeling apparently human irrational decision making( cognitive biases) that makes use of inherently rational computational mechanisms. We view preferential choice tasks as sequential decision making problems and formulate them as Partially Observable Markov Decision Processes( POMDPs). The resulting sequential decision model learns what information to gather about which options, whether to calculate option values or make comparisons between options and when to make a choice. We apply the model to choice problems where context is known to influence human choice, an effect that has been taken as evidence that human cognition is irrational. Our results show that the new model approximates a bounded optimal cognitive policy and makes quantitative predictions that correspond well to evidence about human choice. Furthermore, the model uses context to help infer which option has a maximum expected value while taking into account computational cost and cognitive limits. In addition, it predicts when, and explains why, people stop evidence accumulation and make a decision. We argue that the model provides evidence that apparent human irrationalities are emergent consequences of processes that prefer higher value( rational) policies.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/16161,10.1609/aaai.v35i1.16161,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Cognitive Modeling and Cognitive Systems,AAAI,NA
AAAI Conference on Artificial Intelligence,Applied Machine Learning for Games: A Graduate School Course,Yilei Zeng;Aayush Shah;Jameson Thai;Michael Zyda,"The game industry is moving into an era where old-style game engines are being replaced by re-engineered systems with embedded machine learning technologies for the operation, analysis and understanding of game play. In this paper, we describe our machine learning course designed for graduate students interested in applying recent advances of deep learning and reinforcement learning towards gaming. This course serves as a bridge to foster interdisciplinary collaboration among graduate schools and does not require prior experience designing or building games. Graduate students enrolled in this course apply different fields of machine learning techniques such as computer vision, natural language processing, computer graphics, human computer interaction, robotics and data analysis to solve open challenges in gaming. Student projects cover use-cases such as training AI-bots in gaming benchmark environments and competitions, understanding human decision patterns in gaming, and creating intelligent non-playable characters or environments to foster engaging gameplay. Projects demos can help students open doors for an industry career, aim for publications, or lay the foundations of a future product. Our students gained hands-on experience in applying state of the art machine learning techniques to solve real-life problems in gaming.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/17849,10.1609/aaai.v35i17.17849,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,EAAI Symposium: Full Papers,AAAI,NA
AAAI Conference on Artificial Intelligence,Apprenticeship Learning via Frank-Wolfe,Tom Zahavy;Alon Cohen;Haim Kaplan;Yishay Mansour,"We consider the applications of the Frank-Wolfe( FW) algorithm for Apprenticeship Learning( AL). In this setting, we are given a Markov Decision Process( MDP) without an explicit reward function. Instead, we observe an expert that acts according to some policy, and the goal is to find a policy whose feature expectations are closest to those of the expert policy. We formulate this problem as finding the projection of the feature expectations of the expert on the feature expectations polytope – the convex hull of the feature expectations of all the deterministic policies in the MDP. We show that this formulation is equivalent to the AL objective and that solving this problem using the FW algorithm is equivalent well-known Projection method of Abbeel and Ng( 2004). This insight allows us to analyze AL with tools from convex optimization literature and derive tighter convergence bounds on AL. Specifically, we show that a variation of the FW method that is based on taking “away steps” achieves a linear rate of convergence when applied to AL and that a stochastic version of the FW algorithm can be used to avoid precise estimation of feature expectations. We also experimentally show that this version outperforms the FW baseline. To the best of our knowledge, this is the first work that shows linear convergence rates for AL.",2020,https://ojs.aaai.org/index.php/AAAI/article/view/6150,10.1609/aaai.v34i04.6150,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Machine Learning,AAAI,NA
AAAI Conference on Artificial Intelligence,Approval-Based Committee Voting in Practice: A Case Study of( over-) Representation in the Polkadot Blockchain,Niclas Boehmer;Markus Brill;Alfonso Cevallos;Jonas Gehrlein;Luis Sánchez-Fernández;Ulrike Schmidt-Kraepelin,"We provide the first large-scale data collection of real-world approval-based committee elections. These elections have been conducted on the Polkadot blockchain as part of their Nominated Proof-of-Stake mechanism and contain around one thousand candidates and tens of thousands of( weighted) voters each. We conduct an in-depth study of application-relevant questions, including a quantitative and qualitative analysis of the outcomes returned by different voting rules. Besides considering proportionality measures that are standard in the multiwinner voting literature, we pay particular attention to less-studied measures of overrepresentation, as these are closely related to the security of the Polkadot network. We also analyze how different design decisions such as the committee size affect the examined measures.",2024,https://ojs.aaai.org/index.php/AAAI/article/view/28807,10.1609/aaai.v38i9.28807,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Game Theory and Economic Paradigms,AAAI,NA
AAAI Conference on Artificial Intelligence,Arbitrariness and Social Prediction: The Confounding Role of Variance in Fair Classification,A. Feder Cooper;Katherine Lee;Madiha Zahrah Choksi;Solon Barocas;Christopher De Sa;James Grimmelmann;Jon Kleinberg;Siddhartha Sen;Baobao Zhang,"Variance in predictions across different trained models is a significant, under-explored source of error in fair binary classification. In practice, the variance on some data examples is so large that decisions can be effectively arbitrary. To investigate this problem, we take an experimental approach and make four overarching contributions. We: 1) Define a metric called self-consistency, derived from variance, which we use as a proxy for measuring and reducing arbitrariness; 2) Develop an ensembling algorithm that abstains from classification when a prediction would be arbitrary; 3) Conduct the largest to-date empirical study of the role of variance( vis-a-vis self-consistency and arbitrariness) in fair binary classification; and, 4) Release a toolkit that makes the US Home Mortgage Disclosure Act( HMDA) datasets easily usable for future research. Altogether, our experiments reveal shocking insights about the reliability of conclusions on benchmark datasets. Most fair binary classification benchmarks are close-to-fair when taking into account the amount of arbitrariness present in predictions -- before we even try to apply any fairness interventions. This finding calls into question the practical utility of common algorithmic fairness methods, and in turn suggests that we should reconsider how we choose to measure fairness in binary classification.",2024,https://ojs.aaai.org/index.php/AAAI/article/view/30203,10.1609/aaai.v38i20.30203,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on AI for Social Impact Track,AAAI,NA
AAAI Conference on Artificial Intelligence,Argument Mining Driven Analysis of Peer-Reviews,Michael Fromm;Evgeniy Faerman;Max Berrendorf;Siddharth Bhargava;Ruoxia Qi;Yao Zhang;Lukas Dennert;Sophia Selle;Yang Mao;Thomas Seidl,"Peer reviewing is a central process in modern research and essential for ensuring high quality and reliability of published work. At the same time, it is a time-consuming process and increasing interest in emerging fields often results in a high review workload, especially for senior researchers in this area. How to cope with this problem is an open question and it is vividly discussed across all major conferences. In this work, we propose an Argument Mining based approach for the assistance of editors, meta-reviewers, and reviewers. We demonstrate that the decision process in the field of scientific publications is driven by arguments and automatic argument identification is helpful in various use-cases. One of our findings is that arguments used in the peer-review process differ from arguments in other domains making the transfer of pre-trained models difficult. Therefore, we provide the community with a new dataset of peer-reviews from different computer science conferences with annotated arguments. In our extensive empirical evaluation, we show that Argument Mining can be used to efficiently extract the most relevant parts from reviews, which are paramount for the publication decision. Also, the process remains interpretable, since the extracted arguments can be highlighted in a review without detaching them from their context.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/16607,10.1609/aaai.v35i6.16607,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track Focus Area on AI for Conference Organization and Delivery,AAAI,NA
AAAI Conference on Artificial Intelligence,Argumentation for Explainable Scheduling,Kristijonas Čyras;Dimitrios Letsios;Ruth Misener;Francesca Toni,"Mathematical optimization offers highly-effective tools for finding solutions for problems with well-defined goals, notably scheduling. However, optimization solvers are often unexplainable black boxes whose solutions are inaccessible to users and which users cannot interact with. We define a novel paradigm using argumentation to empower the interaction between optimization solvers and users, supported by tractable explanations which certify or refute solutions. A solution can be from a solver or of interest to a user( in the context of ‘what-if’ scenarios). Specifically, we define argumentative and natural language explanations for why a schedule is( not) feasible, ( not) efficient or( not) satisfying fixed user decisions, based on models of the fundamental makespan scheduling problem in terms of abstract argumentation frameworks( AFs). We define three types of AFs, whose stable extensions are in one-to-one correspondence with schedules that are feasible, efficient and satisfying fixed decisions, respectively. We extract the argumentative explanations from these AFs and the natural language explanations from the argumentative ones.",2019,https://ojs.aaai.org/index.php/AAAI/article/view/4126,10.1609/aaai.v33i01.33012752,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Knowledge Representation and Reasoning,AAAI,NA
AAAI Conference on Artificial Intelligence,Aspect-Aware Multimodal Summarization for Chinese E-Commerce Products,Haoran Li;Peng Yuan;Song Xu;Youzheng Wu;Xiaodong He;Bowen Zhou,"We present an abstractive summarization system that produces summary for Chinese e-commerce products. This task is more challenging than general text summarization. First, the appearance of a product typically plays a significant role in customers decisions to buy the product or not, which requires that the summarization model effectively use the visual information of the product. Furthermore, different products have remarkable features in various aspects, such as “energy efficiency” and “large capacity” for refrigerators. Meanwhile, different customers may care about different aspects. Thus, the summarizer needs to capture the most attractive aspects of a product that resonate with potential purchasers. We propose an aspect-aware multimodal summarization model that can effectively incorporate the visual information and also determine the most salient aspects of a product. We construct a large-scale Chinese e-commerce product summarization dataset that contains approximately 1. 4 million manually created product summaries that are paired with detailed product information, including an image, a title, and other textual descriptions for each product. The experimental results on this dataset demonstrate that our models significantly outperform the comparative methods in terms of both the ROUGE score and manual evaluations.",2020,https://ojs.aaai.org/index.php/AAAI/article/view/6332,10.1609/aaai.v34i05.6332,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Natural Language Processing,AAAI,NA
AAAI Conference on Artificial Intelligence,Assignment and Pricing in Roommate Market,Pak Chan;Xin Huang;Zhengyang Liu;Chihao Zhang;Shengyu Zhang,"We introduce a roommate market model, in which 2n people need to be assigned to n rooms, with two people in each room. Each person has a valuation to each room, as well as a valuation to each of other people as a roommate. Each room has a rent shared by the two people living in the room, and we need to decide who live together in which room and how much each should pay. Various solution concepts on stability and envy-freeness are proposed, with their existence studied and the computational complexity of the corresponding search problems analyzed. In particular, we show that maximizing the social welfare is NP-hard, and we give a polynomial time algorithm that achieves at least 2/3 of the maximum social welfare. Finally, we demonstrate a pricing scheme that can achieve envy-freeness for each room.",2016,https://ojs.aaai.org/index.php/AAAI/article/view/10019,10.1609/aaai.v30i1.10019,NA,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,Technical Papers: Game Theory and Economic Paradigms,AAAI,NA
AAAI Conference on Artificial Intelligence,Atari-HEAD: Atari Human Eye-Tracking and Demonstration Dataset,Ruohan Zhang;Calen Walshe;Zhuode Liu;Lin Guan;Karl Muller;Jake Whritner;Luxin Zhang;Mary Hayhoe;Dana Ballard,"Large-scale public datasets have been shown to benefit research in multiple areas of modern artificial intelligence. For decision-making research that requires human data, high-quality datasets serve as important benchmarks to facilitate the development of new methods by providing a common reproducible standard. Many human decision-making tasks require visual attention to obtain high levels of performance. Therefore, measuring eye movements can provide a rich source of information about the strategies that humans use to solve decision-making tasks. Here, we provide a large-scale, high-quality dataset of human actions with simultaneously recorded eye movements while humans play Atari video games. The dataset consists of 117 hours of gameplay data from a diverse set of 20 games, with 8 million action demonstrations and 328 million gaze samples. We introduce a novel form of gameplay, in which the human plays in a semi-frame-by-frame manner. This leads to near-optimal game decisions and game scores that are comparable or better than known human records. We demonstrate the usefulness of the dataset through two simple applications: predicting human gaze and imitating human demonstrated actions. The quality of the data leads to promising results in both tasks. Moreover, using a learned human gaze model to inform imitation learning leads to an 115% increase in game performance. We interpret these results as highlighting the importance of incorporating human visual attention in models of decision making and demonstrating the value of the current dataset to the research community. We hope that the scale and quality of this dataset can provide more opportunities to researchers in the areas of visual attention, imitation learning, and reinforcement learning.",2020,https://ojs.aaai.org/index.php/AAAI/article/view/6161,10.1609/aaai.v34i04.6161,10,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Machine Learning,AAAI,NA
AAAI Conference on Artificial Intelligence,Attention Guided CAM: Visual Explanations of Vision Transformer Guided by Self-Attention,Saebom Leem;Hyunseok Seo,"Vision Transformer( ViT) is one of the most widely used models in the computer vision field with its great performance on various tasks. In order to fully utilize the ViT-based architecture in various applications, proper visualization methods with a decent localization performance are necessary, but these methods employed in CNN-based models are still not available in ViT due to its unique structure. In this work, we propose an attention-guided visualization method applied to ViT that provides a high-level semantic explanation for its decision. Our method selectively aggregates the gradients directly propagated from the classification output to each self-attention, collecting the contribution of image features extracted from each location of the input image. These gradients are additionally guided by the normalized self-attention scores, which are the pairwise patch correlation scores. They are used to supplement the gradients on the patch-level context information efficiently detected by the self-attention mechanism. This approach of our method provides elaborate high-level semantic explanations with great localization performance only with the class labels. As a result, our method outperforms the previous leading explainability methods of ViT in the weakly-supervised localization task and presents great capability in capturing the full instances of the target class object. Meanwhile, our method provides a visualization that faithfully explains the model, which is demonstrated in the perturbation comparison test.",2024,https://ojs.aaai.org/index.php/AAAI/article/view/28077,10.1609/aaai.v38i4.28077,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Computer Vision III,AAAI,NA
AAAI Conference on Artificial Intelligence,Attention-Aware Sampling via Deep Reinforcement Learning for Action Recognition,Wenkai Dong;Zhaoxiang Zhang;Tieniu Tan,"Deep learning based methods have achieved remarkable progress in action recognition. Existing works mainly focus on designing novel deep architectures to achieve video representations learning for action recognition. Most methods treat sampled frames equally and average all the frame-level predictions at the testing stage. However, within a video, discriminative actions may occur sparsely in a few frames and most other frames are irrelevant to the ground truth and may even lead to a wrong prediction. As a result, we think that the strategy of selecting relevant frames would be a further important key to enhance the existing deep learning based action recognition. In this paper, we propose an attentionaware sampling method for action recognition, which aims to discard the irrelevant and misleading frames and preserve the most discriminative frames. We formulate the process of mining key frames from videos as a Markov decision process and train the attention agent through deep reinforcement learning without extra labels. The agent takes features and predictions from the baseline model as input and generates importance scores for all frames. Moreover, our approach is extensible, which can be applied to different existing deep learning based action recognition models. We achieve very competitive action recognition performance on two widely used action recognition datasets.",2019,https://ojs.aaai.org/index.php/AAAI/article/view/4836,10.1609/aaai.v33i01.33018247,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Vision,AAAI,NA
AAAI Conference on Artificial Intelligence,Attention-Based Models for Snow-Water Equivalent Prediction,Krishu K Thapa;Bhupinderjeet Singh;Supriya Savalkar;Alan Fern;Kirti Rajagopalan;Ananth Kalyanaraman,"Snow Water-Equivalent( SWE) —the amount of water available if snowpack is melted—is a key decision variable used by water management agencies to make irrigation, flood control, power generation, and drought management decisions. SWE values vary spatiotemporally—affected by weather, topography, and other environmental factors. While daily SWE can be measured by Snow Telemetry( SNOTEL) stations with requisite instrumentation, such stations are spatially sparse requiring interpolation techniques to create spatiotemporal complete data. While recent efforts have explored machine learning( ML) for SWE prediction, a number of recent ML advances have yet to be considered. The main contribution of this paper is to explore one such ML advance, attention mechanisms, for SWE prediction. Our hypothesis is that attention has a unique ability to capture and exploit correlations that may exist across locations or the temporal spectrum( or both). We present a generic attention-based modeling framework for SWE prediction and adapt it to capture spatial attention and temporal attention. Our experimental results on 323 SNOTEL stations in the Western U. S. demonstrate that our attention-based models outperform other machine-learning approaches. We also provide key results highlighting the differences between spatial and temporal attention in this context and a roadmap toward deployment for generating spatially-complete SWE maps.",2024,https://ojs.aaai.org/index.php/AAAI/article/view/30337,10.1609/aaai.v38i21.30337,7,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,IAAI Technical Track on Emerging Applications of AI,AAAI,NA
AAAI Conference on Artificial Intelligence,Attentive Experience Replay,Peiquan Sun;Wengang Zhou;Houqiang Li,"Experience replay( ER) has become an important component of deep reinforcement learning( RL) algorithms. ER enables RL algorithms to reuse past experiences for the update of current policy. By reusing a previous state for training, the RL agent would learn more accurate value estimation and better decision on that state. However, as the policy is continually updated, some states in past experiences become rarely visited, and optimization over these states might not improve the overall performance of current policy. To tackle this issue, we propose a new replay strategy to prioritize the transitions that contain states frequently visited by current policy. We introduce Attentive Experience Replay( AER) , a novel experience replay algorithm that samples transitions according to the similarities between their states and the agents state. We couple AER with different off-policy algorithms and demonstrate that AER makes consistent improvements on the suite of OpenAI gym tasks.",2020,https://ojs.aaai.org/index.php/AAAI/article/view/6049,10.1609/aaai.v34i04.6049,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Machine Learning,AAAI,NA
AAAI Conference on Artificial Intelligence,AUC Optimization with a Reject Option,Song-Qing Shen;Bin-Bin Yang;Wei Gao,"Making an erroneous decision may cause serious results in diverse mission-critical tasks such as medical diagnosis and bioinformatics. Previous work focuses on classification with a reject option, i. e. , abstain rather than classify an instance of low confidence. Most mission-critical tasks are always accompanied with class imbalance and cost sensitivity, where AUC has been shown a preferable measure than accuracy in classification. In this work, we propose the framework of AUC optimization with a reject option, and the basic idea is to withhold the decision of ranking a pair of positive and negative instances with a lower cost, rather than mis-ranking. We obtain the Bayes optimal solution for ranking, and learn the reject function and score function for ranking, simultaneously. An online algorithm has been developed for AUC optimization with a reject option, by considering the convex relaxation and plug-in rule. We verify, both theoretically and empirically, the effectiveness of the proposed algorithm.",2020,https://ojs.aaai.org/index.php/AAAI/article/view/6023,10.1609/aaai.v34i04.6023,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Machine Learning,AAAI,NA
AAAI Conference on Artificial Intelligence,Augmented Commonsense Knowledge for Remote Object Grounding,Bahram Mohammadi;Yicong Hong;Yuankai Qi;Qi Wu;Shirui Pan;Javen Qinfeng Shi,"The vision-and-language navigation( VLN) task necessitates an agent to perceive the surroundings, follow natural language instructions, and act in photo-realistic unseen environments. Most of the existing methods employ the entire image or object features to represent navigable viewpoints. However, these representations are insufficient for proper action prediction, especially for the REVERIE task, which uses concise high-level instructions, such as “Bring me the blue cushion in the master bedroom”. To address enhancing representation, we propose an augmented commonsense knowledge model( ACK) to leverage commonsense information as a spatio-temporal knowledge graph for improving agent navigation. Specifically, the proposed approach involves constructing a knowledge base by retrieving commonsense information from ConceptNet, followed by a refinement module to remove noisy and irrelevant knowledge. We further present ACK which consists of knowledge graph-aware cross-modal and concept aggregation modules to enhance visual representation and visual-textual data alignment by integrating visible objects, commonsense knowledge, and concept history, which includes object and knowledge temporal information. Moreover, we add a new pipeline for the commonsense-based decision-making process which leads to more accurate local action prediction. Experimental results demonstrate our proposed model noticeably outperforms the baseline and archives the state-of-the-art on the REVERIE benchmark. The source code is available at https://github. com/Bahram-Mohammadi/ACK.",2024,https://ojs.aaai.org/index.php/AAAI/article/view/28223,10.1609/aaai.v38i5.28223,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Computer Vision IV,AAAI,NA
AAAI Conference on Artificial Intelligence,Augmenting Markov Decision Processes with Advising,Loïs Vanhée;Laurent Jeanpierre;Abdel-Illah Mouaddib,"This paper introduces Advice-MDPs, an expansion of Markov Decision Processes for generating policies that take into consideration advising on the desirability, undesirability, and prohibition of certain states and actions. AdviceMDPs enable the design of designing semi-autonomous systems( systems that require operator support for at least handling certain situations) that can efficiently handle unexpected complex environments. Operators, through advising, can augment the planning model for covering unexpected real-world irregularities. This advising can swiftly augment the degree of autonomy of the system, so it can work without subsequent human intervention. This paper details the Advice-MDP formalism, a fast AdviceMDP resolution algorithm, and its applicability for real-world tasks, via the design of a professional-class semi-autonomous robot system ready to be deployed in a wide range of unexpected environments and capable of efficiently integrating operator advising.",2019,https://ojs.aaai.org/index.php/AAAI/article/view/4099,10.1609/aaai.v33i01.33012531,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Human-AI Collaboration,AAAI,NA
AAAI Conference on Artificial Intelligence,Auto-GAN: Self-Supervised Collaborative Learning for Medical Image Synthesis,Bing Cao;Han Zhang;Nannan Wang;Xinbo Gao;Dinggang Shen,"In various clinical scenarios, medical image is crucial in disease diagnosis and treatment. Different modalities of medical images provide complementary information and jointly helps doctors to make accurate clinical decision. However, due to clinical and practical restrictions, certain imaging modalities may be unavailable nor complete. To impute missing data with adequate clinical accuracy, here we propose a framework called self-supervised collaborative learning to synthesize missing modality for medical images. The proposed method comprehensively utilize all available information correlated to the target modality from multi-source-modality images to generate any missing modality in a single model. Different from the existing methods, we introduce an auto-encoder network as a novel, self-supervised constraint, which provides target-modality-specific information to guide generator training. In addition, we design a modality mask vector as the target modality label. With experiments on multiple medical image databases, we demonstrate a great generalization ability as well as specialty of our method compared with other state-of-the-arts.",2020,https://ojs.aaai.org/index.php/AAAI/article/view/6619,10.1609/aaai.v34i07.6619,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Vision,AAAI,NA
AAAI Conference on Artificial Intelligence,AutoCost: Evolving Intrinsic Cost for Zero-Violation Reinforcement Learning,Tairan He;Weiye Zhao;Changliu Liu,"Safety is a critical hurdle that limits the application of deep reinforcement learning to real-world control tasks. To this end, constrained reinforcement learning leverages cost functions to improve safety in constrained Markov decision process. However, constrained methods fail to achieve zero violation even when the cost limit is zero. This paper analyzes the reason for such failure, which suggests that a proper cost function plays an important role in constrained RL. Inspired by the analysis, we propose AutoCost, a simple yet effective framework that automatically searches for cost functions that help constrained RL to achieve zero-violation performance. We validate the proposed method and the searched cost function on the safety benchmark Safety Gym. We compare the performance of augmented agents that use our cost function to provide additive intrinsic costs to a Lagrangian-based policy learner and a constrained-optimization policy learner with baseline agents that use the same policy learners but with only extrinsic costs. Results show that the converged policies with intrinsic costs in all environments achieve zero constraint violation and comparable performance with baselines.",2023,https://ojs.aaai.org/index.php/AAAI/article/view/26734,10.1609/aaai.v37i12.26734,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Special Track on Safe and Robust AI,AAAI,NA
AAAI Conference on Artificial Intelligence,AutoEncoder by Forest,Ji Feng;Zhi-Hua Zhou,"Auto-encoding is an important task which is typically realized by deep neural networks( DNNs) such as convolutional neural networks( CNN). In this paper, we propose EncoderForest( abbrv. eForest) , the first tree ensemble based auto-encoder. We present a procedure for enabling forests to do backward reconstruction by utilizing the Maximal-Compatible Rule( MCR) defined by the decision paths of the trees, and demonstrate its usage in both supervised and unsupervised setting. Experiments show that, compared with DNN based auto-encoders, eForest is able to obtain lower reconstruction error with fast training speed, while the model itself is reusable and damage-tolerable.",2018,https://ojs.aaai.org/index.php/AAAI/article/view/11732,10.1609/aaai.v32i1.11732,NA,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Machine Learning,AAAI,NA
AAAI Conference on Artificial Intelligence,Automated Design of Affine Maximizer Mechanisms in Dynamic Settings,Michael Curry;Vinzenz Thoma;Darshan Chakrabarti;Stephen McAleer;Christian Kroer;Tuomas Sandholm;Niao He;Sven Seuken,"Dynamic mechanism design is a challenging extension to ordinary mechanism design in which the mechanism designer must make a sequence of decisions over time in the face of possibly untruthful reports of participating agents. Optimizing dynamic mechanisms for welfare is relatively well understood. However, there has been less work on optimizing for other goals( e. g. , revenue) , and without restrictive assumptions on valuations, it is remarkably challenging to characterize good mechanisms. Instead, we turn to automated mechanism design to find mechanisms with good performance in specific problem instances. We extend the class of affine maximizer mechanisms to MDPs where agents may untruthfully report their rewards. This extension results in a challenging bilevel optimization problem in which the upper problem involves choosing optimal mechanism parameters, and the lower problem involves solving the resulting MDP. Our approach can find truthful dynamic mechanisms that achieve strong performance on goals other than welfare, and can be applied to essentially any problem setting---without restrictions on valuations---for which RL can learn optimal policies.",2024,https://ojs.aaai.org/index.php/AAAI/article/view/28819,10.1609/aaai.v38i9.28819,10,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Game Theory and Economic Paradigms,AAAI,NA
AAAI Conference on Artificial Intelligence,Automated Dispatch of Helpdesk Email Tickets: Pushing the Limits with AI,Atri Mandal;Nikhil Malhotra;Shivali Agarwal;Anupama Ray;Giriprasad Sridhara,"Ticket assignment/dispatch is a crucial part of service delivery business with lot of scope for automation and optimization. In this paper, we present an end-to-end automated helpdesk email ticket assignment system, which is also offered as a service. The objective of the system is to determine the nature of the problem mentioned in an incoming email ticket and then automatically dispatch it to an appropriate resolver group( or team) for resolution. The proposed system uses an ensemble classifier augmented with a configurable rule engine. While design of a classifier that is accurate is one of the main challenges, we also need to address the need of designing a system that is robust and adaptive to changing business needs. We discuss some of the main design challenges associated with email ticket assignment automation and how we solve them. The design decisions for our system are driven by high accuracy, coverage, business continuity, scalability and optimal usage of computational resources. Our system has been deployed in production of three major service providers and currently assigning over 90, 000 emails per month, on an average, with an accuracy close to 90% and covering at least 90% of email tickets. This translates to achieving human-level accuracy and results in a net saving of more than 50000 man-hours of effort per annum. Till date, our deployed system has already served more than 700, 000 tickets in production.",2019,https://ojs.aaai.org/index.php/AAAI/article/view/4986,10.1609/aaai.v33i01.33019381,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,IAAI Technical Track: Deployed Papers,AAAI,NA
AAAI Conference on Artificial Intelligence,Automated Lay Language Summarization of Biomedical Scientific Reviews,Yue Guo;Wei Qiu;Yizhong Wang;Trevor Cohen,"Health literacy has emerged as a crucial factor in making appropriate health decisions and ensuring treatment outcomes. However, medical jargon and the complex structure of professional language in this domain make health information especially hard to interpret. Thus, there is an urgent unmet need for automated methods to enhance the accessibility of the biomedical literature to the general population. This problem can be framed as a type of translation problem between the language of healthcare professionals, and that of the general public. In this paper, we introduce the novel task of automated generation of lay language summaries of biomedical scientific reviews, and construct a dataset to support the development and evaluation of automated methods through which to enhance the accessibility of the biomedical literature. We conduct analyses of the various challenges in performing this task, including not only summarization of the key points but also explanation of background knowledge and simplification of professional language. We experiment with state-of-the-art summarization models as well as several data augmentation techniques, and evaluate their performance using both automated metrics and human assessment. Results indicate that automatically generated summaries produced using contemporary neural architectures can achieve promising quality and readability as compared with reference summaries developed for the lay public by experts( best ROUGE-L of 50. 24 and Flesch-Kincaid readability score of 13. 30). We also discuss the limitations of the current effort, providing insights and directions for future work.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/16089,10.1609/aaai.v35i1.16089,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Application Domains,AAAI,NA
AAAI Conference on Artificial Intelligence,Back to the Future – Temporal Adaptation of Text Representations,Johannes Bjerva;Wouter Kouw;Isabelle Augenstein,"Language evolves over time in many ways relevant to natural language processing tasks. For example, recent occurrences of tokens BERT and ELMO in publications refer to neural network architectures rather than persons. This type of temporal signal is typically overlooked, but is important if one aims to deploy a machine learning model over an extended period of time. In particular, language evolution causes data drift between time-steps in sequential decision-making tasks. Examples of such tasks include prediction of paper acceptance for yearly conferences( regular intervals) or author stance prediction for rumours on Twitter( irregular intervals). Inspired by successes in computer vision, we tackle data drift by sequentially aligning learned representations. We evaluate on three challenging tasks varying in terms of time-scales, linguistic units, and domains. These tasks show our method outperforming several strong baselines, including using all available data. We argue that, due to its low computational expense, sequential alignment is a practical solution to dealing with language evolution.",2020,https://ojs.aaai.org/index.php/AAAI/article/view/6240,10.1609/aaai.v34i05.6240,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Natural Language Processing,AAAI,NA
AAAI Conference on Artificial Intelligence,Backdoor Attacks on the DNN Interpretation System,Shihong Fang;Anna Choromanska,"Interpretability is crucial to understand the inner workings of deep neural networks( DNNs). Many interpretation methods help to understand the decision-making of DNNs by generating saliency maps that highlight parts of the input image that contribute the most to the prediction made by the DNN. In this paper we design a backdoor attack that alters the saliency map produced by the network for an input image with a specific trigger pattern while not losing the prediction performance significantly. The saliency maps are incorporated in the penalty term of the objective function that is used to train a deep model and its influence on model training is conditioned upon the presence of a trigger. We design two types of attacks: a targeted attack that enforces a specific modification of the saliency map and a non-targeted attack when the importance scores of the top pixels from the original saliency map are significantly reduced. We perform empirical evaluations of the proposed backdoor attacks on gradient-based interpretation methods, Grad-CAM and SimpleGrad, and a gradient-free scheme, VisualBackProp, for a variety of deep learning architectures. We show that our attacks constitute a serious security threat to the reliability of the interpretation methods when deploying models developed by untrusted sources. We furthermore show that existing backdoor defense mechanisms are ineffective in detecting our attacks. Finally, we demonstrate that the proposed methodology can be used in an inverted setting, where the correct saliency map can be obtained only in the presence of a trigger( key) , effectively making the interpretation system available only to selected users.",2022,https://ojs.aaai.org/index.php/AAAI/article/view/19935,10.1609/aaai.v36i1.19935,10,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Computer Vision I,AAAI,NA
AAAI Conference on Artificial Intelligence,Backpropagation Through Agents,Zhiyuan Li;Wenshuai Zhao;Lijun Wu;Joni Pajarinen,"A fundamental challenge in multi-agent reinforcement learning( MARL) is to learn the joint policy in an extremely large search space, which grows exponentially with the number of agents. Moreover, fully decentralized policy factorization significantly restricts the search space, which may lead to sub-optimal policies. In contrast, the auto-regressive joint policy can represent a much richer class of joint policies by factorizing the joint policy into the product of a series of conditional individual policies. While such factorization introduces the action dependency among agents explicitly in sequential execution, it does not take full advantage of the dependency during learning. In particular, the subsequent agents do not give the preceding agents feedback about their decisions. In this paper, we propose a new framework Back-Propagation Through Agents( BPTA) that directly accounts for both agents own policy updates and the learning of their dependent counterparts. This is achieved by propagating the feedback through action chains. With the proposed framework, our Bidirectional Proximal Policy Optimisation( BPPO) outperforms the state-of-the-art methods. Extensive experiments on matrix games, StarCraftII v2, Multi-agent MuJoCo, and Google Research Football demonstrate the effectiveness of the proposed method.",2024,https://ojs.aaai.org/index.php/AAAI/article/view/29277,10.1609/aaai.v38i12.29277,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Machine Learning III,AAAI,NA
AAAI Conference on Artificial Intelligence,Bagging Ensembles for the Diagnosis and Prognostication of Alzheimers Disease,Peng Dai;Femida Gwadry-Sridhar;Michael Bauer;Michael Borrie,"Alzheimers disease( AD) is a chronic neurodegenerative disease, which involves the degeneration of various brain functions, resulting in memory loss, cognitive disorder and death. Large amounts of multivariate heterogeneous medical test data are available for the analysis of brain deterioration. How to measure the deterioration remains a challenging problem. In this study, we first investigate how different regions of the human brain change as the patient develops AD. Correlation analysis and feature ranking are performed based on the feature vectors from different stages of the pathologic process in Alzheimer disease. Then, an automatic diagnosis system is presented, which is based on a hybrid manifold learning for feature embedding and the bootstrap aggregating( Bagging) algorithm for classification. We investigate two different tasks, i. e. diagnosis and progression prediction. Extensive comparison is made against Support Vector Machines( SVM) , Random Forest( RF) , Decision Tree( DT) and Random Subspace( RS) methods. Experimental results show that our proposed algorithm yields superior results when compared to the other methods, suggesting promising robustness for possible clinical applications.",2016,https://ojs.aaai.org/index.php/AAAI/article/view/9915,10.1609/aaai.v30i1.9915,NA,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,Special Track: Integrated AI Capabilities,AAAI,NA
AAAI Conference on Artificial Intelligence,Balancing Quality and Human Involvement: An Effective Approach to Interactive Neural Machine Translation,Tianxiang Zhao;Lemao Liu;Guoping Huang;Huayang Li;Yingling Liu;Liu GuiQuan;Shuming Shi,"Conventional interactive machine translation typically requires a human translator to validate every generated target word, even though most of them are correct in the advanced neural machine translation( NMT) scenario. Previous studies have exploited confidence approaches to address the intensive human involvement issue, which request human guidance only for a few number of words with low confidences. However, such approaches do not take the history of human involvement into account, and optimize the models only for the translation quality while ignoring the cost of human involvement. In response to these pitfalls, we propose a novel interactive NMT model, which explicitly accounts the history of human involvements and particularly is optimized towards two objectives corresponding to the translation quality and the cost of human involvement, respectively. Specifically, the model jointly predicts a target word and a decision on whether to request human guidance, which is based on both the partial translation and the history of human involvements. Since there is no explicit signals on the decisions of requesting human guidance in the bilingual corpus, we optimize the model with the reinforcement learning technique which enables our model to accurately predict when to request human guidance. Simulated and real experiments show that the proposed model can achieve higher translation quality with similar or less human involvement over the confidence-based baseline.",2020,https://ojs.aaai.org/index.php/AAAI/article/view/6514,10.1609/aaai.v34i05.6514,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Natural Language Processing,AAAI,NA
AAAI Conference on Artificial Intelligence,Balancing Relevance and Diversity in Online Bipartite Matching via Submodularity,John P. Dickerson;Karthik Abinav Sankararaman;Aravind Srinivasan;Pan Xu,"In bipartite matching problems, vertices on one side of a bipartite graph are paired with those on the other. In its online variant, one side of the graph is available offline, while the vertices on the other side arrive online. When a vertex arrives, an irrevocable and immediate decision should be made by the algorithm; either match it to an available vertex or drop it. Examples of such problems include matching workers to firms, advertisers to keywords, organs to patients, and so on. Much of the literature focuses on maximizing the total relevance—modeled via total weight—of the matching. However, in many real-world problems, it is also important to consider contributions of diversity: hiring a diverse pool of candidates, displaying a relevant but diverse set of ads, and so on. In this paper, we propose the Online Submodular Bipartite Matching( OSBM) problem, where the goal is to maximize a submodular function f over the set of matched edges. This objective is general enough to capture the notion of both diversity( e. g. , a weighted coverage function) and relevance( e. g. , the traditional linear function) —as well as many other natural objective functions occurring in practice( e. g. , limited total budget in advertising settings). We propose novel algorithms that have provable guarantees and are essentially optimal when restricted to various special cases. We also run experiments on real-world and synthetic datasets to validate our algorithms.",2019,https://ojs.aaai.org/index.php/AAAI/article/view/4013,10.1609/aaai.v33i01.33011877,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Game Theory and Economic Paradigms,AAAI,NA
AAAI Conference on Artificial Intelligence,Bandit Linear Optimization for Sequential Decision Making and Extensive-Form Games,Gabriele Farina;Robin Schmucker;Tuomas Sandholm,"Tree-form sequential decision making( TFSDM) extends classical one-shot decision making by modeling tree-form interactions between an agent and a potentially adversarial environment. It captures the online decision-making problems that each player faces in an extensive-form game, as well as Markov decision processes and partially-observable Markov decision processes where the agent conditions on observed history. Over the past decade, there has been considerable effort into designing online optimization methods for TFSDM. Virtually all of that work has been in the full-feedback setting, where the agent has access to counterfactuals, that is, information on what would have happened had the agent chosen a different action at any decision node. Little is known about the bandit setting, where that assumption is reversed( no counterfactual information is available) , despite this latter setting being well understood for almost 20 years in one-shot decision making. In this paper, we give the first algorithm for the bandit linear optimization problem for TFSDM that offers both( i) linear-time iterations( in the size of the decision tree) and( ii) O( sqrt( T) ) cumulative regret in expectation compared to any fixed strategy, at all times T. This is made possible by new results that we derive, which may have independent uses as well: 1) geometry of the dilated entropy regularizer, 2) autocorrelation matrix of the natural sampling scheme for sequence-form strategies, 3) construction of an unbiased estimator for linear losses for sequence-form strategies, and 4) a refined regret analysis for mirror descent when using the dilated entropy regularizer.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/16677,10.1609/aaai.v35i6.16677,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Game Theory and Economic Paradigms,AAAI,NA
AAAI Conference on Artificial Intelligence,Basing Decisions on Sentences in Decision Diagrams,Yexiang Xue;Arthur Choi;Adnan Darwiche,"The Sentential Decision Diagram( SDD) is a recently proposed representation of Boolean functions, containing Ordered Binary Decision Diagrams( OBDDs) as a distinguished subclass. While OBDDs are characterized by total variable orders, SDDs are characterized by dissections of variable orders, known as vtrees. Despite this generality, SDDs retain a number of properties, such as canonicity and a polytime apply operator, that have been critical to the practical success of OBDDs. Moreover, upper bounds on the size of SDDs were also given, which are tighter than comparable upper bounds on the size of OBDDs. In this paper, we analyze more closely some of the theoretical properties of SDDs and their size. In particular, we consider the impact of basing decisions on sentences( using dissections as in SDDs) , in comparison to basing decisions on variables( using total variable orders as in OBDDs). Here, we identify a class of Boolean functions where basing decisions on sentences using dissections of a variable order can lead to exponentially more compact SDDs, compared to OBDDs based on the same variable order. Moreover, we identify a fundamental property of the decompositions that underlie SDDs and use it to show how certain changes to a vtree can also lead to exponential differences in the size of an SDD.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/8221,10.1609/aaai.v26i1.8221,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Knowledge Representation and Reasoning,AAAI,NA
AAAI Conference on Artificial Intelligence,BAT: Behavior-Aware Human-Like Trajectory Prediction for Autonomous Driving,Haicheng Liao;Zhenning Li;Huanming Shen;Wenxuan Zeng;Dongping Liao;Guofa Li;Chengzhong Xu,"The ability to accurately predict the trajectory of surrounding vehicles is a critical hurdle to overcome on the journey to fully autonomous vehicles. To address this challenge, we pioneer a novel behavior-aware trajectory prediction model( BAT) that incorporates insights and findings from traffic psychology, human behavior, and decision-making. Our model consists of behavior-aware, interaction-aware, priority-aware, and position-aware modules that perceive and understand the underlying interactions and account for uncertainty and variability in prediction, enabling higher-level learning and flexibility without rigid categorization of driving behavior. Importantly, this approach eliminates the need for manual labeling in the training process and addresses the challenges of non-continuous behavior labeling and the selection of appropriate time windows. We evaluate BATs performance across the Next Generation Simulation( NGSIM) , Highway Drone( HighD) , Roundabout Drone( RounD) , and Macao Connected Autonomous Driving( MoCAD) datasets, showcasing its superiority over prevailing state-of-the-art( SOTA) benchmarks in terms of prediction accuracy and efficiency. Remarkably, even when trained on reduced portions of the training data( 25%) , our model outperforms most of the baselines, demonstrating its robustness and efficiency in predicting vehicle trajectories, and the potential to reduce the amount of data required to train autonomous vehicles, especially in corner cases. In conclusion, the behavior-aware model represents a significant advancement in the development of autonomous vehicles capable of predicting trajectories with the same level of proficiency as human drivers. The project page is available on our GitHub.",2024,https://ojs.aaai.org/index.php/AAAI/article/view/28900,10.1609/aaai.v38i9.28900,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,Intelligent Robots( ROB),AAAI,NA
AAAI Conference on Artificial Intelligence,Bayes DistNet - A Robust Neural Network for Algorithm Runtime Distribution Predictions,Jake Tuero;Michael Buro,"Randomized algorithms are used in many state-of-the-art solvers for constraint satisfaction problems( CSP) and Boolean satisfiability( SAT) problems. For many of these problems, there is no single solver which will dominate others. Having access to the underlying runtime distributions( RTD) of these solvers can allow for better use of algorithm selection, algorithm portfolios, and restart strategies. Previous state-of-the-art methods directly try to predict a fixed parametric distribution that the input instance follows. In this paper, we extend RTD prediction models into the Bayesian setting for the first time. This new model achieves robust predictive performance in the low observation setting, as well as handling censored observations. This technique also allows for richer representations which cannot be achieved by the classical models which restrict their output representations. Our model outperforms the previous state-of-the-art model in settings in which data is scarce, and can make use of censored data such as lower bound time estimates, where that type of data would otherwise be discarded. It can also quantify its uncertainty in its predictions, allowing for algorithm portfolio models to make better informed decisions about which algorithm to run on a particular instance.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/17473,10.1609/aaai.v35i14.17473,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Search and Optimization,AAAI,NA
AAAI Conference on Artificial Intelligence,Bayes-Adaptive Interactive POMDPs,Brenda Ng;Kofi Boakye;Carol Meyers;Andrew Wang,"We introduce the Bayes-Adaptive Interactive Partially Observable Markov Decision Process( BA-IPOMDP) , the first multiagent decision model that explicitly incorporates model learning. As in I-POMDPs, the BA-IPOMDP agent maintains beliefs over interactive states, which include the physical states as well as the other agents’ models. The BA-IPOMDP assumes that the state transition and observation probabilities are unknown, and augments the interactive states to include these parameters. Beliefs are maintained over this augmented interactive state space. This( necessary) state expansion exacerbates the curse of dimensionality, especially since each I-POMDP belief update is already a recursive procedure( because an agent invokes belief updates from other agents’ perspectives as part of its own belief update, in order to anticipate other agents’ actions). We extend the interactive particle filter to perform approximate belief update on BA-IPOMDPs. We present our findings on the multiagent Tiger problem.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/8264,10.1609/aaai.v26i1.8264,7,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Multiagent Systems,AAAI,NA
AAAI Conference on Artificial Intelligence,Bayes-Adaptive Monte-Carlo Planning and Learning for Goal-Oriented Dialogues,Youngsoo Jang;Jongmin Lee;Kee-Eung Kim,"We consider a strategic dialogue task, where the ability to infer the other agents goal is critical to the success of the conversational agent. While this problem can be naturally formulated as Bayesian planning, it is known to be a very difficult problem due to its enormous search space consisting of all possible utterances. In this paper, we introduce an efficient Bayes-adaptive planning algorithm for goal-oriented dialogues, which combines RNN-based dialogue generation and MCTS-based Bayesian planning in a novel way, leading to robust decision-making under the uncertainty of the other agents goal. We then introduce reinforcement learning for the dialogue agent that uses MCTS as a strong policy improvement operator, casting reinforcement learning as iterative alternation of planning and supervised-learning of self-generated dialogues. In the experiments, we demonstrate that our Bayes-adaptive dialogue planning agent significantly outperforms the state-of-the-art in a negotiation dialogue domain. We also show that reinforcement learning via MCTS further improves end-task performance without diverging from human language.",2020,https://ojs.aaai.org/index.php/AAAI/article/view/6308,10.1609/aaai.v34i05.6308,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Natural Language Processing,AAAI,NA
AAAI Conference on Artificial Intelligence,Bayes-TrEx: a Bayesian Sampling Approach to Model Transparency by Example,Serena Booth;Yilun Zhou;Ankit Shah;Julie Shah,"Post-hoc explanation methods are gaining popularity for interpreting, understanding, and debugging neural networks. Most analyses using such methods explain decisions in response to inputs drawn from the test set. However, the test set may have few examples that trigger some model behaviors, such as high-confidence failures or ambiguous classifications. To address these challenges, we introduce a flexible model inspection framework: Bayes-TrEx. Given a data distribution, Bayes-TrEx finds in-distribution examples which trigger a specified prediction confidence. We demonstrate several use cases of Bayes-TrEx, including revealing highly confident( mis) classifications, visualizing class boundaries via ambiguous examples, understanding novel-class extrapolation behavior, and exposing neural network overconfidence. We use Bayes-TrEx to study classifiers trained on CLEVR, MNIST, and Fashion-MNIST, and we show that this framework enables more flexible holistic model analysis than just inspecting the test set. Code and supplemental material are available at https://github. com/serenabooth/Bayes-TrEx.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/17361,10.1609/aaai.v35i13.17361,10,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Philosophy and Ethics of AI,AAAI,NA
AAAI Conference on Artificial Intelligence,Bayesian Fairness,Christos Dimitrakakis;Yang Liu;David C. Parkes;Goran Radanovic,"We consider the problem of how decision making can be fair when the underlying probabilistic model of the world is not known with certainty. We argue that recent notions of fairness in machine learning need to explicitly incorporate parameter uncertainty, hence we introduce the notion of Bayesian fairness as a suitable candidate for fair decision rules. Using balance, a definition of fairness introduced in( Kleinberg, Mullainathan, and Raghavan 2016) , we show how a Bayesian perspective can lead to well-performing and fair decision rules even under high uncertainty.",2019,https://ojs.aaai.org/index.php/AAAI/article/view/3824,10.1609/aaai.v33i01.3301509,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Special Technical Track: AI for Social Impact,AAAI,NA
AAAI Conference on Artificial Intelligence,Bayesian Learning of Other Agents Finite Controllers for Interactive POMDPs,Alessandro Panella;Piotr Gmytrasiewicz,"We consider an autonomous agent operating in a stochastic, partially-observable, multiagent environment, that explicitly models the other agents as probabilistic deterministic finite-state controllers( PDFCs) in order to predict their actions. We assume that such models are not given to the agent, but instead must be learned from( possibly imperfect) observations of the other agents behavior. The agent maintains a belief over the other agents models, that is updated via Bayesian inference. To represent this belief we place a flexible stick-breaking distribution over PDFCs, that allows the posterior to concentrate around controllers whose size is not bounded and scales with the complexity of the observed data. Since this Bayesian inference task is not analytically tractable, we devise a Markov chain Monte Carlo algorithm to approximate the posterior distribution. The agent then embeds the result of this inference into its own decision making process using the interactive POMDP framework. We show that our learning algorithm can learn agent models that are behaviorally accurate for problems of varying complexity, and that the agents performance increases as a result.",2016,https://ojs.aaai.org/index.php/AAAI/article/view/10136,10.1609/aaai.v30i1.10136,NA,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,Technical Papers: Multiagent Systems,AAAI,NA
AAAI Conference on Artificial Intelligence,Bayesian Optimized Monte Carlo Planning,John Mern;Anil Yildiz;Zachary Sunberg;Tapan Mukerji;Mykel J. Kochenderfer,"Online solvers for partially observable Markov decision processes have difficulty scaling to problems with large action spaces. Monte Carlo tree search with progressive widening attempts to improve scaling by sampling from the action space to construct a policy search tree. The performance of progressive widening search is dependent upon the action sampling policy, often requiring problem-specific samplers. In this work, we present a general method for efficient action sampling based on Bayesian optimization. The proposed method uses a Gaussian process to model a belief over the action-value function and selects the action that will maximize the expected improvement in the optimal action value. We implement the proposed approach in a new online tree search algorithm called Bayesian Optimized Monte Carlo Planning( BOMCP). Several experiments show that BOMCP is better able to scale to large action space POMDPs than existing state-of-the-art tree search solvers.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/17411,10.1609/aaai.v35i13.17411,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,"AAAI Technical Track on Planning, Routing, and Scheduling",AAAI,NA
AAAI Conference on Artificial Intelligence,Bayesian Persuasion in Sequential Decision-Making,Jiarui Gan;Rupak Majumdar;Goran Radanovic;Adish Singla,"We study a dynamic model of Bayesian persuasion in sequential decision-making settings. An informed principal observes an external parameter of the world and advises an uninformed agent about actions to take over time. The agent takes actions in each time step based on the current state, the principals advice/signal, and beliefs about the external parameter. The action of the agent updates the state according to a stochastic process. The model arises naturally in many applications, e. g. , an app( the principal) can advice the user( the agent) on possible choices between actions based on additional real-time information the app has. We study the problem of designing a signaling strategy from the principals point of view. We show that the principal has an optimal strategy against a myopic agent, who only optimizes their rewards locally, and the optimal strategy can be computed in polynomial time. In contrast, it is NP-hard to approximate an optimal policy against a far-sighted agent. Further, we show that if the principal has the power to threaten the agent by not providing future signals, then we can efficiently design a threat-based strategy. This strategy guarantees the principals payoff as if playing against an agent who is far-sighted but myopic to future signals.",2022,https://ojs.aaai.org/index.php/AAAI/article/view/20434,10.1609/aaai.v36i5.20434,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Game Theory and Economic Paradigms,AAAI,NA
AAAI Conference on Artificial Intelligence,Being Optimistic to Be Conservative: Quickly Learning a CVaR Policy,Ramtin Keramati;Christoph Dann;Alex Tamkin;Emma Brunskill,"While maximizing expected return is the goal in most reinforcement learning approaches, risk-sensitive objectives such as conditional value at risk( CVaR) are more suitable for many high-stakes applications. However, relatively little is known about how to explore to quickly learn policies with good CVaR. In this paper, we present the first algorithm for sample-efficient learning of CVaR-optimal policies in Markov decision processes based on the optimism in the face of uncertainty principle. This method relies on a novel optimistic version of the distributional Bellman operator that moves probability mass from the lower to the upper tail of the return distribution. We prove asymptotic convergence and optimism of this operator for the tabular policy evaluation case. We further demonstrate that our algorithm finds CVaR-optimal policies substantially faster than existing baselines in several simulated environments with discrete and continuous state spaces.",2020,https://ojs.aaai.org/index.php/AAAI/article/view/5870,10.1609/aaai.v34i04.5870,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Machine Learning,AAAI,NA
AAAI Conference on Artificial Intelligence,Belief Reward Shaping in Reinforcement Learning,Ofir Marom;Benjamin Rosman,"A key challenge in many reinforcement learning problems is delayed rewards, which can significantly slow down learning. Although reward shaping has previously been introduced to accelerate learning by bootstrapping an agent with additional information, this can lead to problems with convergence. We present a novel Bayesian reward shaping framework that augments the reward distribution with prior beliefs that decay with experience. Formally, we prove that under suitable conditions a Markov decision process augmented with our framework is consistent with the optimal policy of the original MDP when using the Q-learning algorithm. However, in general our method integrates seamlessly with any reinforcement learning algorithm that learns a value or action-value function through experience. Experiments are run on a gridworld and a more complex backgammon domain that show that we can learn tasks significantly faster when we specify intuitive priors on the reward distribution.",2018,https://ojs.aaai.org/index.php/AAAI/article/view/11741,10.1609/aaai.v32i1.11741,NA,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Machine Learning,AAAI,NA
AAAI Conference on Artificial Intelligence,Bellman Meets Hawkes: Model-Based Reinforcement Learning via Temporal Point Processes,Chao Qu;Xiaoyu Tan;Siqiao Xue;Xiaoming Shi;James Zhang;Hongyuan Mei,"We consider a sequential decision making problem where the agent faces the environment characterized by the stochastic discrete events and seeks an optimal intervention policy such that its long-term reward is maximized. This problem exists ubiquitously in social media, finance and health informatics but is rarely investigated by the conventional research in reinforcement learning. To this end, we present a novel framework of the model-based reinforcement learning where the agents actions and observations are asynchronous stochastic discrete events occurring in continuous-time. We model the dynamics of the environment by Hawkes process with external intervention control term and develop an algorithm to embed such process in the Bellman equation which guides the direction of the value gradient. We demonstrate the superiority of our method in both synthetic simulator and real-data experiments.",2023,https://ojs.aaai.org/index.php/AAAI/article/view/26142,10.1609/aaai.v37i8.26142,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Machine Learning III,AAAI,NA
AAAI Conference on Artificial Intelligence,Better Bounds on the Adaptivity Gap of Influence Maximization under Full-adoption Feedback,Gianlorenzo D'Angelo;Debashmita Poddar;Cosimo Vinci,"In the influence maximization( IM) problem, we are given a social network and a budget k, and we look for a set of k nodes in the network, called seeds, that maximize the expected number of nodes that are reached by an influence cascade generated by the seeds, according to some stochastic model for influence diffusion. Extensive studies have been done on the IM problem, since his definition by Kempe, Kleinberg, and Tardos( 2003). However, most of the work focuses on the non-adaptive version of the problem where all the k seed nodes must be selected before that the cascade starts. In this paper we study the adaptive IM, where the nodes are selected sequentially one by one, and the decision on the i-th seed can be based on the observed cascade produced by the first i-1 seeds. We focus on the full-adoption feedback in which we can observe the entire cascade of each previously selected seed and on the independent cascade model where each edge is associated with an independent probability of diffusing influence. Previous works showed that there are constant upper bounds on the adaptivity gap, which compares the performance of an adaptive algorithm against a non-adaptive one, but the analyses used to prove these bounds only works for specific graph classes such as in-arborescences, out-arborescences, and one-directional bipartite graphs. Our main result is the first sub-linear upper bound that holds for any graph. Specifically, we show that the adaptivity gap is upper-bounded by ∛n+1, where n is the number of nodes in the graph. Moreover we improve over the known upper bound for in-arborescences from 2e/( e-1) ≈3. 16 to 2e²/( e²-1) ≈2. 31. Finally, we study α-bounded graphs, a class of undirected graphs in which the sum of node degrees higher than two is at most α, and show that the adaptivity gap is upper-bounded by √α+O( 1). Moreover, we show that in 0-bounded graphs, i. e. undirected graphs in which each connected component is a path or a cycle, the adaptivity gap is at most 3e³/( e³-1) ≈3. 16. To prove our bounds, we introduce new techniques to relate adaptive policies with non-adaptive ones that might be of their own interest.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/17433,10.1609/aaai.v35i13.17433,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Reasoning under Uncertainty,AAAI,NA
AAAI Conference on Artificial Intelligence,Beyond Distributive Fairness in Algorithmic Decision Making: Feature Selection for Procedurally Fair Learning,Nina Grgić-Hlača;Muhammad Bilal Zafar;Krishna P. Gummadi;Adrian Weller,"With widespread use of machine learning methods in numerous domains involving humans, several studies have raised questions about the potential for unfairness towards certain individuals or groups. A number of recent works have proposed methods to measure and eliminate unfairness from machine learning models. However, most of this work has focused on only one dimension of fair decision making: distributive fairness, i. e. , the fairness of the decision outcomes. In this work, we leverage the rich literature on organizational justice and focus on another dimension of fair decision making: procedural fairness, i. e. , the fairness of the decision making process. We propose measures for procedural fairness that consider the input features used in the decision process, and evaluate the moral judgments of humans regarding the use of these features. We operationalize these measures on two real world datasets using human surveys on the Amazon Mechanical Turk( AMT) platform, demonstrating that our measures capture important properties of procedurally fair decision making. We provide fast submodular mechanisms to optimize the tradeoff between procedural fairness and prediction accuracy. On our datasets, we observe empirically that procedural fairness may be achieved with little cost to outcome fairness, but that some loss of accuracy is unavoidable.",2018,https://ojs.aaai.org/index.php/AAAI/article/view/11296,10.1609/aaai.v32i1.11296,NA,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Applications,AAAI,NA
AAAI Conference on Artificial Intelligence,Beyond Mimicking Under-Represented Emotions: Deep Data Augmentation with Emotional Subspace Constraints for EEG-Based Emotion Recognition,Zhi Zhang;Shenghua Zhong;Yan Liu,"In recent years, using Electroencephalography( EEG) to recognize emotions has garnered considerable attention. Despite advancements, limited EEG data restricts its potential. Thus, Generative Adversarial Networks( GANs) are proposed to mimic the observed distributions and generate EEG data. However, for imbalanced datasets, GANs struggle to produce reliable augmentations for under-represented minority emotions by merely mimicking them. Thus, we introduce Emotional Subspace Constrained Generative Adversarial Networks( ESC-GAN) as an alternative to existing frameworks. We first propose the EEG editing paradigm, editing reference EEG signals from well-represented to under-represented emotional subspaces. Then, we introduce diversity-aware and boundary-aware losses to constrain the augmented subspace. Here, the diversity-aware loss encourages a diverse emotional subspace by enlarging the sample difference, while boundary-aware loss constrains the augmented subspace near the decision boundary where recognition models can be vulnerable. Experiments show ESC-GAN boosts emotion recognition performance on benchmark datasets, DEAP, AMIGOS, and SEED, while protecting against potential adversarial attacks. Finally, the proposed method opens new avenues for editing EEG signals under emotional subspace constraints, facilitating unbiased and secure EEG data augmentation.",2024,https://ojs.aaai.org/index.php/AAAI/article/view/28891,10.1609/aaai.v38i9.28891,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Humans and AI,AAAI,NA
AAAI Conference on Artificial Intelligence,Beyond NaN: Resiliency of Optimization Layers in the Face of Infeasibility,Wai Tuck Wong;Sarah Kinsey;Ramesha Karunasena;Thanh H. Nguyen;Arunesh Sinha,"Prior work has successfully incorporated optimization layers as the last layer in neural networks for various problems, thereby allowing joint learning and planning in one neural network forward pass. In this work, we identify a weakness in such a set-up where inputs to the optimization layer lead to undefined output of the neural network. Such undefined decision outputs can lead to possible catastrophic outcomes in critical real time applications. We show that an adversary can cause such failures by forcing rank deficiency on the matrix fed to the optimization layer which results in the optimization failing to produce a solution. We provide a defense for the failure cases by controlling the condition number of the input matrix. We study the problem in the settings of synthetic data, Jigsaw Sudoku, and in speed planning for autonomous driving. We show that our proposed defense effectively prevents the framework from failing with undefined output. Finally, we surface a number of edge cases which lead to serious bugs in popular optimization solvers which can be abused as well.",2023,https://ojs.aaai.org/index.php/AAAI/article/view/26778,10.1609/aaai.v37i12.26778,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Special Track on Safe and Robust AI,AAAI,NA
AAAI Conference on Artificial Intelligence,Beyond Sparsity: Tree Regularization of Deep Models for Interpretability,Mike Wu;Michael Hughes;Sonali Parbhoo;Maurizio Zazzi;Volker Roth;Finale Doshi-Velez,"The lack of interpretability remains a key barrier to the adoption of deep models in many applications. In this work, we explicitly regularize deep models so human users might step through the process behind their predictions in little time. Specifically, we train deep time-series models so their class-probability predictions have high accuracy while being closely modeled by decision trees with few nodes. Using intuitive toy examples as well as medical tasks for treating sepsis and HIV, we demonstrate that this new tree regularization yields models that are easier for humans to simulate than simpler L1 or L2 penalties without sacrificing predictive power.",2018,https://ojs.aaai.org/index.php/AAAI/article/view/11501,10.1609/aaai.v32i1.11501,NA,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Humans and AI,AAAI,NA
AAAI Conference on Artificial Intelligence,Beyond TreeSHAP: Efficient Computation of Any-Order Shapley Interactions for Tree Ensembles,Maximilian Muschalik;Fabian Fumagalli;Barbara Hammer;Eyke Hüllermeier,"While shallow decision trees may be interpretable, larger ensemble models like gradient-boosted trees, which often set the state of the art in machine learning problems involving tabular data, still remain black box models. As a remedy, the Shapley value( SV) is a well-known concept in explainable artificial intelligence( XAI) research for quantifying additive feature attributions of predictions. The model-specific TreeSHAP methodology solves the exponential complexity for retrieving exact SVs from tree-based models. Expanding beyond individual feature attribution, Shapley interactions reveal the impact of intricate feature interactions of any order. In this work, we present TreeSHAP-IQ, an efficient method to compute any-order additive Shapley interactions for predictions of tree-based models. TreeSHAP-IQ is supported by a mathematical framework that exploits polynomial arithmetic to compute the interaction scores in a single recursive traversal of the tree, akin to Linear TreeSHAP. We apply TreeSHAP-IQ on state-of-the-art tree ensembles and explore interactions on well-established benchmark datasets.",2024,https://ojs.aaai.org/index.php/AAAI/article/view/29352,10.1609/aaai.v38i13.29352,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Machine Learning IV,AAAI,NA
AAAI Conference on Artificial Intelligence,Bi-Classifier Determinacy Maximization for Unsupervised Domain Adaptation,Shuang Li;Fangrui Lv;Binhui Xie;Chi Harold Liu;Jian Liang;Chen Qin,"Unsupervised domain adaptation challenges the problem of transferring knowledge from a well-labelled source domain to an unlabelled target domain. Recently, adversarial learning with bi-classifier has been proven effective in pushing cross-domain distributions close. Prior approaches typically leverage the disagreement between bi-classifier to learn transferable representations, however, they often neglect the classifier determinacy in the target domain, which could result in a lack of feature discriminability. In this paper, we present a simple yet effective method, namely Bi-Classifier Determinacy Maximization( BCDM) , to tackle this problem. Motivated by the observation that target samples cannot always be separated distinctly by the decision boundary, here in the proposed BCDM, we design a novel classifier determinacy disparity( CDD) metric, which formulates classifier discrepancy as the class relevance of distinct target predictions and implicitly introduces constraint on the target feature discriminability. To this end, the BCDM can generate discriminative representations by encouraging target predictive outputs to be consistent and determined, meanwhile, preserve the diversity of predictions in an adversarial manner. Furthermore, the properties of CDD as well as the theoretical guarantees of BCDMs generalization bound are both elaborated. Extensive experiments show that BCDM compares favorably against the existing state-of-the-art domain adaptation methods.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/17027,10.1609/aaai.v35i10.17027,10,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Machine Learning III,AAAI,NA
AAAI Conference on Artificial Intelligence,Bi-Kronecker Functional Decision Diagrams: A Novel Canonical Representation of Boolean Functions,Xuanxiang Huang;Kehang Fang;Liangda Fang;Qingliang Chen;Zhao-Rong Lai;Linfeng Wei,"In this paper, we present a novel data structure for compact representation and effective manipulations of Boolean functions, called Bi-Kronecker Functional Decision Diagrams( BKFDDs). BKFDDs integrate the classical expansions( the Shannon and Davio expansions) and their bi-versions. Thus, BKFDDs are the generalizations of existing decision diagrams: BDDs, FDDs, KFDDs and BBDDs. Interestingly, under certain conditions, it is sufficient to consider the above expansions( the classical expansions and their bi-versions). By imposing reduction and ordering rules, BKFDDs are compact and canonical forms of Boolean functions. The experimental results demonstrate that BKFDDs outperform other existing decision diagrams in terms of sizes.",2019,https://ojs.aaai.org/index.php/AAAI/article/view/4140,10.1609/aaai.v33i01.33012867,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Knowledge Representation and Reasoning,AAAI,NA
AAAI Conference on Artificial Intelligence,Bidirectional Domain Mixup for Domain Adaptive Semantic Segmentation,Daehan Kim;Minseok Seo;Kwanyong Park;Inkyu Shin;Sanghyun Woo;In So Kweon;Dong-Geol Choi,"Mixup provides interpolated training samples and allows the model to obtain smoother decision boundaries for better generalization. The idea can be naturally applied to the domain adaptation task, where we can mix the source and target samples to obtain domain-mixed samples for better adaptation. However, the extension of the idea from classification to segmentation( i. e. , structured output) is nontrivial. This paper systematically studies the impact of mixup under the domain adaptive semantic segmentation task and presents a simple yet effective mixup strategy called Bidirectional Domain Mixup( BDM). In specific, we achieve domain mixup in two-step: cut and paste. Given the warm-up model trained from any adaptation techniques, we forward the source and target samples and perform a simple threshold-based cut out of the unconfident regions( cut). After then, we fill-in the dropped regions with the other domain region patches( paste). In doing so, we jointly consider class distribution, spatial structure, and pseudo label confidence. Based on our analysis, we found that BDM leaves domain transferable regions by cutting, balances the dataset-level class distribution while preserving natural scene context by pasting. We coupled our proposal with various state-of-the-art adaptation models and observe significant improvement consistently. We also provide extensive ablation experiments to empirically verify our main components of the framework. Visit our project page with the code at https://sites. google. com/view/bidirectional-domain-mixup",2023,https://ojs.aaai.org/index.php/AAAI/article/view/25193,10.1609/aaai.v37i1.25193,10,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Computer Vision I,AAAI,NA
AAAI Conference on Artificial Intelligence,Big-Data Mechanisms and Energy-Policy Design,Ankit Pat;Kate Larson;Srinivasen Keshav,"A confluence of technical, economic and political forces are revolutionizing the energy sector. Policy-makers, who decide on incentives and penalties for possible courses of actions, play a critical role in determining which outcomes arise. However, designing appropriate energy policies is a complex and challenging task. Our vision is to provide tools and methodologies for policy makers so that they can leverage the power of big data to make evidence-based decisions. In this paper we present an approach we call big-data mechanism design which combines a mechanism design framework with stakeholder surveys and data to allow policy-makers to gauge the costs and benefits of potential policy decisions. We illustrate the effectiveness of this approach in a concrete application domain: the peaksaver PLUS program in Ontario, Canada.",2016,https://ojs.aaai.org/index.php/AAAI/article/view/9910,10.1609/aaai.v30i1.9910,NA,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,Special Track: Computational Sustainability,AAAI,NA
AAAI Conference on Artificial Intelligence,BIRD: Engineering an Efficient CNF-XOR SAT Solver and Its Applications to Approximate Model Counting,Mate Soos;Kuldeep S. Meel,"Given a Boolean formula φ, the problem of model counting, also referred to as #SAT is to compute the number of solutions of φ. Model counting is a fundamental problem in artificial intelligence with a wide range of applications including probabilistic reasoning, decision making under uncertainty, quantified information flow, and the like. Motivated by the success of SAT solvers, there has been surge of interest in the design of hashing-based techniques for approximate model counting for the past decade. We profiled the state of the art approximate model counter ApproxMC2 and observed that over 99. 99% of time is consumed by the underlying SAT solver, CryptoMiniSat. This observation motivated us to ask: Can we design an efficient underlying CNF-XOR SAT solver that can take advantage of the structure of hashing-based algorithms and would this lead to an efficient approximate model counter? The primary contribution of this paper is an affirmative answer to the above question. We present a novel architecture, called BIRD, to handle CNF-XOR formulas arising from hashingbased techniques. The resulting hashing-based approximate model counter, called ApproxMC3, employs the BIRD framework in its underlying SAT solver, CryptoMiniSat. To the best of our knowledge, we conducted the most comprehensive study of evaluation performance of counting algorithms involving 1896 benchmarks with computational effort totaling 86400 computational hours. Our experimental evaluation demonstrates significant runtime performance improvement for ApproxMC3 over ApproxMC2. In particular, we solve 648 benchmarks more than ApproxMC2, the state of the art approximate model counter and for all the formulas where both ApproxMC2 and ApproxMC3 did not timeout and took more than 1 seconds, the mean speedup is 284. 40 – more than two orders of magnitude. Erratum: This research is supported in part by the National Research Foundation Singapore under its AI Singapore Programme( Award Number: [AISG-RP-2018-005])",2019,https://ojs.aaai.org/index.php/AAAI/article/view/3974,10.1609/aaai.v33i01.33011592,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Constraint Satisfaction and Optimization,AAAI,NA
AAAI Conference on Artificial Intelligence,Blockwise Sequential Model Learning for Partially Observable Reinforcement Learning,Giseung Park;Sungho Choi;Youngchul Sung,"This paper proposes a new sequential model learning architecture to solve partially observable Markov decision problems. Rather than compressing sequential information at every timestep as in conventional recurrent neural network-based methods, the proposed architecture generates a latent variable in each data block with a length of multiple timesteps and passes the most relevant information to the next block for policy optimization. The proposed blockwise sequential model is implemented based on self-attention, making the model capable of detailed sequential learning in partial observable settings. The proposed model builds an additional learning network to efficiently implement gradient estimation by using self-normalized importance sampling, which does not require the complex blockwise input data reconstruction in the model learning. Numerical results show that the proposed method significantly outperforms previous methods in various partially observable environments.",2022,https://ojs.aaai.org/index.php/AAAI/article/view/20764,10.1609/aaai.v36i7.20764,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Machine Learning II,AAAI,NA
AAAI Conference on Artificial Intelligence,Bootstrap Estimated Uncertainty of the Environment Model for Model-Based Reinforcement Learning,Wenzhen Huang;Junge Zhang;Kaiqi Huang,"Model-based reinforcement learning( RL) methods attempt to learn a dynamics model to simulate the real environment and utilize the model to make better decisions. However, the learned environment simulator often has more or less model error which would disturb making decision and reduce performance. We propose a bootstrapped model-based RL method which bootstraps the modules in each depth of the planning tree. This method can quantify the uncertainty of environment model on different state-action pairs and lead the agent to explore the pairs with higher uncertainty to reduce the potential model errors. Moreover, we sample target values from their bootstrap distribution to connect the uncertainties at current and subsequent time-steps and introduce the prior mechanism to improve the exploration efficiency. Experiment results demonstrate that our method efficiently decreases model error and outperforms TreeQN and other stateof-the-art methods on multiple Atari games.",2019,https://ojs.aaai.org/index.php/AAAI/article/view/4275,10.1609/aaai.v33i01.33013870,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Machine Learning,AAAI,NA
AAAI Conference on Artificial Intelligence,Bootstrapping Multi-View Representations for Fake News Detection,Qichao Ying;Xiaoxiao Hu;Yangming Zhou;Zhenxing Qian;Dan Zeng;Shiming Ge,"Previous researches on multimedia fake news detection include a series of complex feature extraction and fusion networks to gather useful information from the news. However, how cross-modal consistency relates to the fidelity of news and how features from different modalities affect the decision-making are still open questions. This paper presents a novel scheme of Bootstrapping Multi-view Representations( BMR) for fake news detection. Given a multi-modal news, we extract representations respectively from the views of the text, the image pattern and the image semantics. Improved Multi-gate Mixture-of-Expert networks( iMMoE) are proposed for feature refinement and fusion. Representations from each view are separately used to coarsely predict the fidelity of the whole news, and the multimodal representations are able to predict the cross-modal consistency. With the prediction scores, we reweigh each view of the representations and bootstrap them for fake news detection. Extensive experiments conducted on typical fake news detection datasets prove that BMR outperforms state-of-the-art schemes.",2023,https://ojs.aaai.org/index.php/AAAI/article/view/25670,10.1609/aaai.v37i4.25670,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Domain( s) of Application,AAAI,NA
AAAI Conference on Artificial Intelligence,Bounded Optimal Exploration in MDP,Kenji Kawaguchi,"Within the framework of probably approximately correct Markov decision processes( PAC-MDP) , much theoretical work has focused on methods to attain near optimality after a relatively long period of learning and exploration. However, practical concerns require the attainment of satisfactory behavior within a short period of time. In this paper, we relax the PAC-MDP conditions to reconcile theoretically driven exploration methods and practical needs. We propose simple algorithms for discrete and continuous state spaces, and illustrate the benefits of our proposed relaxation via theoretical analyses and numerical examples. Our algorithms also maintain anytime error bounds and average loss bounds. Our approach accommodates both Bayesian and non-Bayesian methods.",2016,https://ojs.aaai.org/index.php/AAAI/article/view/10230,10.1609/aaai.v30i1.10230,NA,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,Technical Papers: Machine Learning Methods,AAAI,NA
AAAI Conference on Artificial Intelligence,Bounded Rationality of Restricted Turing Machines,Lijie Chen;Pingzhong Tang;Ruosong Wang,"Bounded rationality aims to understand the effects of how limited rationality affects decision-making. The traditional models in game theory and multiagent system research, such as finite automata or unrestricted Turing machine, fall short of capturing how intelligent agents make decision in realistic applications. To address this problem, we model bounded rational agents as restricted Turing machines: restrictions on running time and on storage space. We study our model under the context of two-person repeated games. In the case where the running time of Turing machines is restricted, we show that computing the best response of a given strategy is much harder than the strategy itself. In the case where the storage space of the Turing machines is restricted, we show the best response of a space restricted strategy can not be implemented by machines within the same size( up to a constant factor). Finally, we study how these restrictions affect the set of Nash equilibria in infinitely repeated games. We show restricting the agent’s computational resources will give rise to new Nash equilibria.",2017,https://ojs.aaai.org/index.php/AAAI/article/view/10564,10.1609/aaai.v31i1.10564,NA,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Game Theory and Economic Paradigms,AAAI,NA
AAAI Conference on Artificial Intelligence,Bounded Risk-Sensitive Markov Games: Forward Policy Design and Inverse Reward Learning with Iterative Reasoning and Cumulative Prospect Theory,Ran Tian;Liting Sun;Masayoshi Tomizuka,"Classical game-theoretic approaches for multi-agent systems in both the forward policy design problem and the inverse reward learning problem often make strong rationality assumptions: agents perfectly maximize expected utilities under uncertainties. Such assumptions, however, substantially mismatch with observed human behaviors such as satisficing with sub-optimal, risk-seeking, and loss-aversion decisions. Drawing on iterative reasoning models and cumulative prospect theory, we propose a new game-theoretic framework, bounded risk-sensitive Markov Game( BRSMG) , that captures two aspects of realistic human behaviors: bounded intelligence and risk-sensitivity. General solutions to both the forward policy design problem and the inverse reward learning problem are provided with theoretical analysis and simulation verification. We validate the proposed forward policy design algorithm and the inverse reward learning algorithm in a two-player navigation scenario. The results show that agents demonstrate bounded-intelligence, risk-averse and risk-seeking behaviors in our framework. Moreover, in the inverse reward learning task, the proposed bounded risk-sensitive inverse learning algorithm outperforms a baseline risk-neutral inverse learning algorithm by effectively learning not only more accurate reward values but also the intelligence levels and the risk-measure parameters of agents from demonstrations.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/16750,10.1609/aaai.v35i7.16750,10,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Humans and AI,AAAI,NA
AAAI Conference on Artificial Intelligence,Bounding the Probability of Resource Constraint Violations in Multi-Agent MDPs,Frits de Nijs;Erwin Walraven;Mathijs de Weerdt;Matthijs Spaan,"Multi-agent planning problems with constraints on global resource consumption occur in several domains. Existing algorithms for solving Multi-agent Markov Decision Processes can compute policies that meet a resource constraint in expectation, but these policies provide no guarantees on the probability that a resource constraint violation will occur. We derive a method to bound constraint violation probabilities using Hoeffdings inequality. This method is applied to two existing approaches for computing policies satisfying constraints: the Constrained MDP framework and a Column Generation approach. We also introduce an algorithm to adaptively relax the bound up to a given maximum violation tolerance. Experiments on a hard toy problem show that the resulting policies outperform static optimal resource allocations to an arbitrary level. By testing the algorithms on more realistic planning domains from the literature, we demonstrate that the adaptive bound is able to efficiently trade off violation probability with expected value, outperforming state-of-the-art planners.",2017,https://ojs.aaai.org/index.php/AAAI/article/view/11037,10.1609/aaai.v31i1.11037,NA,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,Main Track: Planning and Scheduling,AAAI,NA
AAAI Conference on Artificial Intelligence,Bounding Uncertainty for Active Batch Selection,Hanmo Wang;Runwu Zhou;Yi-Dong Shen,"The success of batch mode active learning( BMAL) methods lies in selecting both representative and uncertain samples. Representative samples quickly capture the global structure of the whole dataset, while the uncertain ones refine the decision boundary. There are two principles, namely the direct approach and the screening approach, to make a trade-off between representativeness and uncertainty. Although widely used in literature, little is known about the relationship between these two principles. In this paper, we discover that the two approaches both have shortcomings in the initial stage of BMAL. To alleviate the shortcomings, we bound the certainty scores of unlabeled samples from below and directly combine this lower-bounded certainty with representativeness in the objective function. Additionally, we show that the two aforementioned approaches are mathematically equivalent to two special cases of our approach. To the best of our knowledge, this is the first work that tries to generalize the direct and screening approaches. The objective function is then solved by super-modularity optimization. Extensive experiments on fifteen datasets indicate that our method has significantly higher classification accuracy on testing data than the latest state-of-the-art BMAL methods, and also scales better even when the size of the unlabeled pool reaches 106.",2019,https://ojs.aaai.org/index.php/AAAI/article/view/4459,10.1609/aaai.v33i01.33015240,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Machine Learning,AAAI,NA
AAAI Conference on Artificial Intelligence,Building Trust in Deep Learning System towards Automated Disease Detection,Zhan Wei Lim;Mong Li Lee;Wynne Hsu;Tien Yin Wong,"Though deep learning systems have achieved high accuracy in detecting diseases from medical images, few such systems have been deployed in highly automated disease screening settings due to lack of trust in how well these systems can generalize to out-of-datasets. We propose to use uncertainty estimates of the deep learning system’s prediction to know when to accept or to disregard its prediction. We evaluate the effectiveness of using such estimates in a real-life application for the screening of diabetic retinopathy. We also generate visual explanation of the deep learning system to convey the pixels in the image that influences its decision. Together, these reveal the deep learning system’s competency and limits to the human, and in turn the human can know when to trust the deep learning system.",2019,https://ojs.aaai.org/index.php/AAAI/article/view/5009,10.1609/aaai.v33i01.33019516,6,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,IAAI Technical Track: Emerging Papers,AAAI,NA
AAAI Conference on Artificial Intelligence,C2L: Causally Contrastive Learning for Robust Text Classification,Seungtaek Choi;Myeongho Jeong;Hojae Han;Seung-won Hwang,"Despite the super-human accuracy of recent deep models in NLP tasks, their robustness is reportedly limited due to their reliance on spurious patterns. We thus aim to leverage contrastive learning and counterfactual augmentation for robustness. For augmentation, existing work either requires humans to add counterfactuals to the dataset or machines to automatically matches near-counterfactuals already in the dataset. Unlike existing augmentation is affected by spurious correlations, ours, by synthesizing “a set” of counterfactuals, and making a collective decision on the distribution of predictions on this set, can robustly supervise the causality of each term. Our empirical results show that our approach, by collective decisions, is less sensitive to task model bias of attribution-based synthesis, and thus achieves significant improvements, in diverse dimensions: 1) counterfactual robustness, 2) cross-domain generalization, and 3) generalization from scarce data.",2022,https://ojs.aaai.org/index.php/AAAI/article/view/21296,10.1609/aaai.v36i10.21296,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Speech and Natural Language Processing,AAAI,NA
AAAI Conference on Artificial Intelligence,Can Eruptions Be Predicted? Short-Term Prediction of Volcanic Eruptions via Attention-Based Long Short-Term Memory,Hiep V. Le;Tsuyoshi Murata;Masato Iguchi,"Short-term prediction of volcanic eruptions is one of the ultimate objectives of volcanology. At Sakurajima volcano, an active volcano in Japan, experts monitor the volcanic sensor data and analyze the prior signal to predict the eruptions. Even though experts derived some patterns, it is hard to make a good prediction due to handcrafted features. To address this issue, we propose to predict eruptions using machine learning. In this paper, we attempt to predict the eruptions hourly by adapting several machine learning methods including traditional and deep learning approaches. As recurrent neural network is well-known for extracting the time-sensitive features, we propose the model especially for volcanic eruption prediction named VepNet. The assumption is based on domain knowledge that some specific triggers are the main causes of future eruptions. To take this advantage, VepNet deploys an attention layer to locate and prioritize these triggers in decision making. The extensive experiments ever conducted using data from Sakurajima volcano showed the effectiveness of deep learning approach over the traditional approach. On top of that, VepNet showed its effectiveness on prediction with AUC-score up to 0. 8665. Moreover, an attempt has been made to explain the mechanism of the eruptions by analyzing the attention layer of VepNet. Lastly, to support volcano expert in issuing warnings and the safety of living people around Sakurajima, a warning system named 3LWS is proposed. The system predicted the eruptions hourly with high accuracy and reliability with the eruption rate up to 68. 97% in the High-Risk level.",2020,https://ojs.aaai.org/index.php/AAAI/article/view/7043,10.1609/aaai.v34i08.7043,6,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,IAAI Technical Track: Emerging Papers,AAAI,NA
AAAI Conference on Artificial Intelligence,Can We Predict the Election Outcome from Sampled Votes?,Evi Micha;Nisarg Shah,"In the standard model of voting, it is assumed that a voting rule observes the ranked preferences of each individual over a set of alternatives and makes a collective decision. In practice, however, not every individual votes. Is it possible to make a good collective decision for a group given the preferences of only a few of its members? We propose a framework in which we are given the ranked preferences of k out of n individuals sampled from a distribution, and the goal is to predict what a given voting rule would output if applied on the underlying preferences of all n individuals. We focus on the family of positional scoring rules, derive a strong negative result when the underlying preferences can be arbitrary, and discover interesting phenomena when they are generated from a known distribution.",2020,https://ojs.aaai.org/index.php/AAAI/article/view/5593,10.1609/aaai.v34i02.5593,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Game Theory and Economic Paradigms,AAAI,NA
AAAI Conference on Artificial Intelligence,Capsule Routing via Variational Bayes,Fabio De Sousa Ribeiro;Georgios Leontidis;Stefanos Kollias,"Capsule networks are a recently proposed type of neural network shown to outperform alternatives in challenging shape recognition tasks. In capsule networks, scalar neurons are replaced with capsule vectors or matrices, whose entries represent different properties of objects. The relationships between objects and their parts are learned via trainable viewpoint-invariant transformation matrices, and the presence of a given object is decided by the level of agreement among votes from its parts. This interaction occurs between capsule layers and is a process called routing-by-agreement. In this paper, we propose a new capsule routing algorithm derived from Variational Bayes for fitting a mixture of transforming gaussians, and show it is possible transform our capsule network into a Capsule-VAE. Our Bayesian approach addresses some of the inherent weaknesses of MLE based models such as the variance-collapse by modelling uncertainty over capsule pose parameters. We outperform the state-of-the-art on smallNORB using ≃50% fewer capsules than previously reported, achieve competitive performances on CIFAR-10, Fashion-MNIST, SVHN, and demonstrate significant improvement in MNIST to affNIST generalisation over previous works. 1",2020,https://ojs.aaai.org/index.php/AAAI/article/view/5785,10.1609/aaai.v34i04.5785,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Machine Learning,AAAI,NA
AAAI Conference on Artificial Intelligence,Category Dictionary Guided Unsupervised Domain Adaptation for Object Detection,Shuai Li;Jianqiang Huang;Xian-Sheng Hua;Lei Zhang,"Unsupervised domain adaption( UDA) is a promising solution to enhance the generalization ability of a model from a source domain to a target domain without manually annotating labels for target data. Recent works in cross-domain object detection mostly resort to adversarial feature adaptation to match the marginal distributions of two domains. However, perfect feature alignment is hard to achieve and is likely to cause negative transfer due to the high complexity of object detection. In this paper, we propose a category dictionary guided( CDG) UDA model for cross-domain object detection, which learns category-specific dictionaries from the source domain to represent the candidate boxes in target domain. The representation residual can be used for not only pseudo label assignment but also quality( e. g. , IoU) estimation of the candidate box. A residual weighted self-training paradigm is then developed to implicitly align source and target domains for detection model training. Compared with decision boundary based classifiers such as softmax, the proposed CDG scheme can select more informative and reliable pseudo-boxes. Experimental results on benchmark datasets show that the proposed CDG significantly exceeds the state-of-the-arts in cross-domain object detection.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/16290,10.1609/aaai.v35i3.16290,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Computer Vision II,AAAI,NA
AAAI Conference on Artificial Intelligence,Causal Explanation Under Indeterminism: A Sampling Approach,Christopher Merck;Samantha Kleinberg,"One of the key uses of causes is to explain why things happen. Explanations of specific events, like an individuals heart attack on Monday afternoon or a particular car accident, help assign responsibility and inform our future decisions. Computational methods for causal inference make use of the vast amounts of data collected by individuals to better understand their behavior and improve their health. However, most methods for explanation of specific events have provided theoretical approaches with limited applicability. In contrast we make two main contributions: an algorithm for explanation that calculates the strength of token causes, and an evaluation based on simulated data that enables objective comparison against prior methods and ground truth. We show that the approach finds the correct relationships in classic test cases( causal chains, common cause, and backup causation) and in a realistic scenario( explaining hyperglycemic episodes in a simulation of type 1 diabetes).",2016,https://ojs.aaai.org/index.php/AAAI/article/view/10088,10.1609/aaai.v30i1.10088,NA,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,Technical Papers: Knowledge Representation and Reasoning,AAAI,NA
AAAI Conference on Artificial Intelligence,Causal Strategic Learning with Competitive Selection,Kiet Q. H. Vo;Muneeb Aadil;Siu Lun Chau;Krikamol Muandet,"We study the problem of agent selection in causal strategic learning under multiple decision makers and address two key challenges that come with it. Firstly, while much of prior work focuses on studying a fixed pool of agents that remains static regardless of their evaluations, we consider the impact of selection procedure by which agents are not only evaluated, but also selected. When each decision maker unilaterally selects agents by maximising their own utility, we show that the optimal selection rule is a trade-off between selecting the best agents and providing incentives to maximise the agents improvement. Furthermore, this optimal selection rule relies on incorrect predictions of agents outcomes. Hence, we study the conditions under which a decision makers optimal selection rule will not lead to deterioration of agents outcome nor cause unjust reduction in agents selection chance. To that end, we provide an analytical form of the optimal selection rule and a mechanism to retrieve the causal parameters from observational data, under certain assumptions on agents behaviour. Secondly, when there are multiple decision makers, the interference between selection rules introduces another source of biases in estimating the underlying causal parameters. To address this problem, we provide a cooperative protocol which all decision makers must collectively adopt to recover the true causal parameters. Lastly, we complement our theoretical results with simulation studies. Our results highlight not only the importance of causal modeling as a strategy to mitigate the effect of gaming, as suggested by previous work, but also the need of a benevolent regulator to enable it.",2024,https://ojs.aaai.org/index.php/AAAI/article/view/29466,10.1609/aaai.v38i14.29466,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Machine Learning V,AAAI,NA
AAAI Conference on Artificial Intelligence,Causal Transfer for Imitation Learning and Decision Making under Sensor-Shift,Jalal Etesami;Philipp Geiger,"Learning from demonstrations( LfD) is an efficient paradigm to train AI agents. But major issues arise when there are differences between( a) the demonstrators own sensory input, ( b) our sensors that observe the demonstrator and( c) the sensory input of the agent we train. In this paper, we propose a causal model-based framework for transfer learning under such “sensor-shifts”, for two common LfD tasks:( 1) inferring the effect of the demonstrators actions and( 2) imitation learning. First we rigorously analyze, on the population-level, to what extent the relevant underlying mechanisms( the action effects and the demonstrator policy) can be identified and transferred from the available observations together with prior knowledge of sensor characteristics. And we device an algorithm to infer these mechanisms. Then we introduce several proxy methods which are easier to calculate, estimate from finite data and interpret than the exact solutions, alongside theoretical bounds on their closeness to the exact ones. We validate our two main methods on simulated and semi-real world data.",2020,https://ojs.aaai.org/index.php/AAAI/article/view/6571,10.1609/aaai.v34i06.6571,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Reasoning under Uncertainty,AAAI,NA
AAAI Conference on Artificial Intelligence,CAVEN: An Embodied Conversational Agent for Efficient Audio-Visual Navigation in Noisy Environments,Xiulong Liu;Sudipta Paul;Moitreya Chatterjee;Anoop Cherian,"Audio-visual navigation of an agent towards locating an audio goal is a challenging task especially when the audio is sporadic or the environment is noisy. In this paper, we present CAVEN, a Conversation-based Audio-Visual Embodied Navigation framework in which the agent may interact with a human/oracle for solving the task of navigating to an audio goal. Specifically, CAVEN is modeled as a budget-aware partially observable semi-Markov decision process that implicitly learns the uncertainty in the audio-based navigation policy to decide when and how the agent may interact with the oracle. Our CAVEN agent can engage in fully-bidirectional natural language conversations by producing relevant questions and interpret free-form, potentially noisy responses from the oracle based on the audio-visual context. To enable such a capability, CAVEN is equipped with: i) a trajectory forecasting network that is grounded in audio-visual cues to produce a potential trajectory to the estimated goal, and( ii) a natural language based question generation and reasoning network to pose an interactive question to the oracle or interpret the oracles response to produce navigation instructions. To train the interactive modules, we present a large scale dataset: AVN-Instruct, based on the Landmark-RxR dataset. To substantiate the usefulness of conversations, we present experiments on the benchmark audio-goal task using the SoundSpaces simulator under various noisy settings. Our results reveal that our fully-conversational approach leads to nearly an order-of-magnitude improvement in success rate, especially in localizing new sound sources and against methods that use only uni-directional interaction.",2024,https://ojs.aaai.org/index.php/AAAI/article/view/28167,10.1609/aaai.v38i4.28167,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Computer Vision III,AAAI,NA
AAAI Conference on Artificial Intelligence,CBRAP: Contextual Bandits with RAndom Projection,Xiaotian Yu;Michael R. Lyu;Irwin King,"Contextual bandits with linear payoffs, which are also known as linear bandits, provide a powerful alternative for solving practical problems of sequential decisions, e. g. , online advertisements. In the era of big data, contextual data usually tend to be high-dimensional, which leads to new challenges for traditional linear bandits mostly designed for the setting of low-dimensional contextual data. Due to the curse of dimensionality, there are two challenges in most of the current bandit algorithms: the first is high time-complexity; and the second is extreme large upper regret bounds with high-dimensional data. In this paper, in order to attack the above two challenges effectively, we develop an algorithm of Contextual Bandits via RAndom Projection( CBRAP) in the setting of linear payoffs, which works especially for high-dimensional contextual data. The proposed CBRAP algorithm is time-efficient and flexible, because it enables players to choose an arm in a low-dimensional space, and relaxes the sparsity assumption of constant number of non-zero components in previous work. Besides, we prove an upper regret bound for the proposed algorithm, which is associated with reduced dimensions. By comparing with three benchmark algorithms, we demonstrate improved performance on cumulative payoffs of CBRAP during its sequential decisions on both synthetic and real-world datasets, as well as its superior time-efficiency.",2017,https://ojs.aaai.org/index.php/AAAI/article/view/10888,10.1609/aaai.v31i1.10888,NA,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,Machine Learning Methods,AAAI,NA
AAAI Conference on Artificial Intelligence,Centralized versus Personalized Commitments and Their Influence on Cooperation in Group Interactions,The Anh Han;Luis Moniz Pereira;Luis A. Martinez-Vaquero;Tom Lenaerts,"Before engaging in a group venture agents may seek commitments from other members in the group and, based on the level of participation( i. e. the number of actually committed participants) , decide whether it is worth joining the venture. Alternatively, agents can delegate this costly process to a( beneficent or non-costly) third-party, who helps seek commitments from the agents. Using methods from Evolutionary Game Theory, this paper shows that, in the context of Public Goods Game, much higher levels of cooperation can be achieved through such centralized commitment management. It provides a more efficient mechanism for dealing with commitment free-riders, those who are not willing to bear the cost of arranging commitments whilst enjoying the benefits provided by the paying commitment proposers. We show that the participation level plays a crucial role in the decision of whether an agreement should be formed; namely, it needs to be more strict in terms of the level of participation required from players of the centralized system for the agreement to be formed; however, once it is done right, it is much more beneficial in terms of the level of cooperation and social welfare achieved. In short, our analysis provides important insights for the design of multi-agent systems that rely on commitments to monitor agents cooperative behavior.",2017,https://ojs.aaai.org/index.php/AAAI/article/view/10704,10.1609/aaai.v31i1.10704,NA,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Multiagent Systems,AAAI,NA
AAAI Conference on Artificial Intelligence,CertiFair: A Framework for Certified Global Fairness of Neural Networks,Haitham Khedr;Yasser Shoukry,"We consider the problem of whether a Neural Network( NN) model satisfies global individual fairness. Individual Fairness( defined in( Dwork et al. 2012) ) suggests that similar individuals with respect to a certain task are to be treated similarly by the decision model. In this work, we have two main objectives. The first is to construct a verifier which checks whether the fairness property holds for a given NN in a classification task or provides a counterexample if it is violated, i. e. , the model is fair if all similar individuals are classified the same, and unfair if a pair of similar individuals are classified differently. To that end, we construct a sound and complete verifier that verifies global individual fairness properties of ReLU NN classifiers using distance-based similarity metrics. The second objective of this paper is to provide a method for training provably fair NN classifiers from unfair( biased) data. We propose a fairness loss that can be used during training to enforce fair outcomes for similar individuals. We then provide provable bounds on the fairness of the resulting NN. We run experiments on commonly used fairness datasets that are publicly available and we show that global individual fairness can be improved by 96 % without a significant drop in test accuracy.",2023,https://ojs.aaai.org/index.php/AAAI/article/view/25994,10.1609/aaai.v37i7.25994,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Machine Learning II,AAAI,NA
AAAI Conference on Artificial Intelligence,Certifying Fairness of Probabilistic Circuits,Nikil Roashan Selvam;Guy Van den Broeck;YooJung Choi,"With the increased use of machine learning systems for decision making, questions about the fairness properties of such systems start to take center stage. Most existing work on algorithmic fairness assume complete observation of features at prediction time, as is the case for popular notions like statistical parity and equal opportunity. However, this is not sufficient for models that can make predictions with partial observation as we could miss patterns of bias and incorrectly certify a model to be fair. To address this, a recently introduced notion of fairness asks whether the model exhibits any discrimination pattern, in which an individual—characterized by( partial) feature observations—receives vastly different decisions merely by disclosing one or more sensitive attributes such as gender and race. By explicitly accounting for partial observations, this provides a much more fine-grained notion of fairness. In this paper, we propose an algorithm to search for discrimination patterns in a general class of probabilistic models, namely probabilistic circuits. Previously, such algorithms were limited to naive Bayes classifiers which make strong independence assumptions; by contrast, probabilistic circuits provide a unifying framework for a wide range of tractable probabilistic models and can even be compiled from certain classes of Bayesian networks and probabilistic programs, making our method much more broadly applicable. Furthermore, for an unfair model, it may be useful to quickly find discrimination patterns and distill them for better interpretability. As such, we also propose a sampling-based approach to more efficiently mine discrimination patterns, and introduce new classes of patterns such as minimal, maximal, and Pareto optimal patterns that can effectively summarize exponentially many discrimination patterns.",2023,https://ojs.aaai.org/index.php/AAAI/article/view/26447,10.1609/aaai.v37i10.26447,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Reasoning Under Uncertainty,AAAI,NA
AAAI Conference on Artificial Intelligence,Certifying Top-Down Decision-DNNF Compilers,Florent Capelli;Jean-Marie Lagniez;Pierre Marquis,"Certifying the output of tools solving complex problems so as to ensure the correctness of the results they provide is of tremendous importance. Despite being widespread for SAT-solvers, this level of exigence has not yet percolated for tools solving more complex tasks, such as model counting or knowledge compilation. In this paper, the focus is laid on a general family of top-down Decision-DNNF compilers. We explain how those compilers can be tweaked so as to output certifiable Decision-DNNF circuits, which are mainly standard Decision-DNNF circuits decorated by annotations serving as certificates. We describe a polynomial-time checker for testing whether a given CNF formula is equivalent or not to a given certifiable Decision-DNNF circuit. Finally, leveraging a modified version of the compiler d4 for generating certifiable Decision-DNNF circuits and an implementation of the checker, we present the results of an empirical evaluation that has been conducted for assessing how large are in practice certifiable Decision-DNNF circuits, and how much time is needed to compute and to check such circuits.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/16776,10.1609/aaai.v35i7.16776,10,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Knowledge Representation and Reasoning,AAAI,NA
AAAI Conference on Artificial Intelligence,CGS-Mask: Making Time Series Predictions Intuitive for All,Feng Lu;Wei Li;Yifei Sun;Cheng Song;Yufei Ren;Albert Y. Zomaya,"Artificial intelligence( AI) has immense potential in time series prediction, but most explainable tools have limited capabilities in providing a systematic understanding of important features over time. These tools typically rely on evaluating a single time point, overlook the time ordering of inputs, and neglect the time-sensitive nature of time series applications. These factors make it difficult for users, particularly those without domain knowledge, to comprehend AI model decisions and obtain meaningful explanations. We propose CGS-Mask, a post-hoc and model-agnostic cellular genetic strip mask-based saliency approach to address these challenges. CGS-Mask uses consecutive time steps as a cohesive entity to evaluate the impact of features on the final prediction, providing binary and sustained feature importance scores over time. Our algorithm optimizes the mask population iteratively to obtain the optimal mask in a reasonable time. We evaluated CGS-Mask on synthetic and real-world datasets, and it outperformed state-of-the-art methods in elucidating the importance of features over time. According to our pilot user study via a questionnaire survey, CGS-Mask is the most effective approach in presenting easily understandable time series prediction results, enabling users to comprehend the decision-making process of AI models with ease.",2024,https://ojs.aaai.org/index.php/AAAI/article/view/29325,10.1609/aaai.v38i13.29325,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Machine Learning IV,AAAI,NA
AAAI Conference on Artificial Intelligence,Choices Are Not Independent: Stackelberg Security Games with Nested Quantal Response Models,Tien Mai;Arunesh Sinha,"The quantal response( QR) model is widely used in Stackelberg security games( SSG) to model a bounded rational adversary. The QR model is a model of human response from among a large variety of prominent models known as discrete choice models. QR is the simplest type of discrete choice models and does not capture commonly observed phenomenon such as correlation among choices. We introduce the nested QR adversary model( based on nested logit model in discrete choice theory) in SSG which addresses shortcoming of the QR model. We present tractable approximation of the resulting equilibrium problem with nested QR adversary. We do so by deriving an interesting property of the equilibrium problem, namely a loosely coupled split into nested problems that mirrors the nested decision making by the adversary in the nested QR model. We show that each separate nested problem can be approximated efficiently and that the loosely coupled overall problem can be solved approximately by formulating it as a discretized version of a continuous dynamic program. Finally, we conduct experiments that show the scalability and parallelizability of our approach, as well as advantages of the nested QR model.",2022,https://ojs.aaai.org/index.php/AAAI/article/view/20448,10.1609/aaai.v36i5.20448,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Game Theory and Economic Paradigms,AAAI,NA
AAAI Conference on Artificial Intelligence,ClaimEval: Integrated and Flexible Framework for Claim Evaluation Using Credibility of Sources,Mehdi Samadi;Partha Talukdar;Manuela Veloso;Manuel Blum,"The World Wide Web( WWW) has become a rapidly growing platform consisting of numerous sources which provide supporting or contradictory information about claims( e. g. , Chicken meat is healthy). In order to decide whether a claim is true or false, one needs to analyze content of different sources of information on the Web, measure credibility of information sources, and aggregate all these information. This is a tedious process and the Web search engines address only part of the overall problem, viz. , producing only a list of relevant sources. In this paper, we present ClaimEval, a novel and integrated approach which given a set of claims to validate, extracts a set of pro and con arguments from the Web information sources, and jointly estimates credibility of sources and correctness of claims. ClaimEval uses Probabilistic Soft Logic( PSL) , resulting in a flexible and principled framework which makes it easy to state and incorporate different forms of prior-knowledge. Through extensive experiments on real-world datasets, we demonstrate ClaimEval’s capability in determining validity of a set of claims, resulting in improved accuracy compared to state-of-the-art baselines.",2016,https://ojs.aaai.org/index.php/AAAI/article/view/9996,10.1609/aaai.v30i1.9996,NA,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,Technical Papers: AI and the Web,AAAI,NA
AAAI Conference on Artificial Intelligence,Clairvoyant Restarts in Branch-and-Bound Search Using Online Tree-Size Estimation,Daniel Anderson;Gregor Hendel;Pierre Le Bodic;Merlin Viernickel,"We propose a simple and general online method to measure the search progress within the Branch-and-Bound algorithm, from which we estimate the size of the remaining search tree. We then show how this information can help solvers algorithmically at runtime by designing a restart strategy for MixedInteger Programming( MIP) solvers that decides whether to restart the search based on the current estimate of the number of remaining nodes in the tree. We refer to this type of algorithm as clairvoyant. Our clairvoyant restart strategy outperforms a state-of-the-art solver on a large set of publicly available MIP benchmark instances. It is implemented in the MIP solver SCIP and will be available in future releases.",2019,https://ojs.aaai.org/index.php/AAAI/article/view/3944,10.1609/aaai.v33i01.33011427,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Constraint Satisfaction and Optimization,AAAI,NA
AAAI Conference on Artificial Intelligence,Classification with Costly Features Using Deep Reinforcement Learning,Jaromír Janisch;Tomáš Pevný;Viliam Lisý,"We study a classification problem where each feature can be acquired for a cost and the goal is to optimize a trade-off between the expected classification error and the feature cost. We revisit a former approach that has framed the problem as a sequential decision-making problem and solved it by Q-learning with a linear approximation, where individual actions are either requests for feature values or terminate the episode by providing a classification decision. On a set of eight problems, we demonstrate that by replacing the linear approximation with neural networks the approach becomes comparable to the state-of-the-art algorithms developed specifically for this problem. The approach is flexible, as it can be improved with any new reinforcement learning enhancement, it allows inclusion of pre-trained high-performance classifier, and unlike prior art, its performance is robust across all evaluated datasets.",2019,https://ojs.aaai.org/index.php/AAAI/article/view/4287,10.1609/aaai.v33i01.33013959,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Machine Learning,AAAI,NA
AAAI Conference on Artificial Intelligence,Classification with Strategically Withheld Data,Anilesh K. Krishnaswamy;Haoming Li;David Rein;Hanrui Zhang;Vincent Conitzer,"Machine learning techniques can be useful in applications such as credit approval and college admission. However, to be classified more favorably in such contexts, an agent may decide to strategically withhold some of her features, such as bad test scores. This is a missing data problem with a twist: which data is missing depends on the chosen classifier, because the specific classifier is what may create the incentive to withhold certain feature values. We address the problem of training classifiers that are robust to this behavior. We design three classification methods: MINCUT, Hill-Climbing( HC) and Incentive-Compatible Logistic Regression( IC-LR). We show that MINCUT is optimal when the true distribution of data is fully known. However, it can produce complex decision boundaries, and hence be prone to overfitting in some cases. Based on a characterization of truthful classifiers( i. e. , those that give no incentive to strategically hide features) , we devise a simpler alternative called HC which consists of a hierarchical ensemble of out-of-the-box classifiers, trained using a specialized hill-climbing procedure which we show to be convergent. For several reasons, MINCUT and HC are not effective in utilizing a large number of complementarily informative features. To this end, we present IC-LR, a modification of Logistic Regression that removes the incentive to strategically drop features. We also show that our algorithms perform well in experiments on real-world data sets, and present insights into their relative performance in different settings.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/16694,10.1609/aaai.v35i6.16694,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Game Theory and Economic Paradigms,AAAI,NA
AAAI Conference on Artificial Intelligence,CLIPSyntel: CLIP and LLM Synergy for Multimodal Question Summarization in Healthcare,Akash Ghosh;Arkadeep Acharya;Raghav Jain;Sriparna Saha;Aman Chadha;Setu Sinha,"In the era of modern healthcare, swiftly generating medical question summaries is crucial for informed and timely patient care. Despite the increasing complexity and volume of medical data, existing studies have focused solely on text-based summarization, neglecting the integration of visual information. Recognizing the untapped potential of combining textual queries with visual representations of medical conditions, we introduce the Multimodal Medical Question Summarization( MMQS) Dataset. This dataset, a major contribution of our work, pairs medical queries with visual aids, facilitating a richer and more nuanced understanding of patient needs. We also propose a framework, utilizing the power of Contrastive Language Image Pretraining( CLIP) and Large Language Models( LLMs) , consisting of four modules that identify medical disorders, generate relevant context, filter medical concepts, and craft visually aware summaries. Our comprehensive framework harnesses the power of CLIP, a multimodal foundation model, and various general-purpose LLMs, comprising four main modules: the medical disorder identification module, the relevant context generation module, the context filtration module for distilling relevant medical concepts and knowledge, and finally, a general-purpose LLM to generate visually aware medical question summaries. Leveraging our MMQS dataset, we showcase how visual cues from images enhance the generation of medically nuanced summaries. This multimodal approach not only enhances the decision-making process in healthcare but also fosters a more nuanced understanding of patient queries, laying the groundwork for future research in personalized and responsive medical care. Disclaimer: The article features graphic medical imagery, a result of the subjects inherent requirements.",2024,https://ojs.aaai.org/index.php/AAAI/article/view/30206,10.1609/aaai.v38i20.30206,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on AI for Social Impact Track,AAAI,NA
AAAI Conference on Artificial Intelligence,CoCoX: Generating Conceptual and Counterfactual Explanations via Fault-Lines,Arjun Akula;Shuai Wang;Song-Chun Zhu,"We present CoCoX( short for Conceptual and Counterfactual Explanations) , a model for explaining decisions made by a deep convolutional neural network( CNN). In Cognitive Psychology, the factors( or semantic-level features) that humans zoom in on when they imagine an alternative to a model prediction are often referred to as fault-lines. Motivated by this, our CoCoX model explains decisions made by a CNN using fault-lines. Specifically, given an input image I for which a CNN classification model M predicts class cpred, our fault-line based explanation identifies the minimal semantic-level features( e. g. , stripes on zebra, pointed ears of dog) , referred to as explainable concepts, that need to be added to or deleted from I in order to alter the classification category of I by M to another specified class calt. We argue that, due to the conceptual and counterfactual nature of fault-lines, our CoCoX explanations are practical and more natural for both expert and non-expert users to understand the internal workings of complex deep learning models. Extensive quantitative and qualitative experiments verify our hypotheses, showing that CoCoX significantly outperforms the state-of-the-art explainable AI models. Our implementation is available at https://github. com/arjunakula/CoCoX",2020,https://ojs.aaai.org/index.php/AAAI/article/view/5643,10.1609/aaai.v34i03.5643,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Humans and AI,AAAI,NA
AAAI Conference on Artificial Intelligence,Coevolutionary Algorithm for Building Robust Decision Trees under Minimax Regret,Adam Żychowski;Andrew Perrault;Jacek Mańdziuk,"In recent years, there has been growing interest in developing robust machine learning( ML) models that can withstand adversarial attacks, including one of the most widely adopted, efficient, and interpretable ML algorithms—decision trees( DTs). This paper proposes a novel coevolutionary algorithm( CoEvoRDT) designed to create robust DTs capable of handling noisy high-dimensional data in adversarial contexts. Motivated by the limitations of traditional DT algorithms, we leverage adaptive coevolution to allow DTs to evolve and learn from interactions with perturbed input data. CoEvoRDT alternately evolves competing populations of DTs and perturbed features, enabling construction of DTs with desired properties. CoEvoRDT is easily adaptable to various target metrics, allowing the use of tailored robustness criteria such as minimax regret. Furthermore, CoEvoRDT has potential to improve the results of other state-of-the-art methods by incorporating their outcomes( DTs they produce) into the initial population and optimize them in the process of coevolution. Inspired by the game theory, CoEvoRDT utilizes mixed Nash equilibrium to enhance convergence. The method is tested on 20 popular datasets and shows superior performance compared to 4 state-of-the-art algorithms. It outperformed all competing methods on 13 datasets with adversarial accuracy metrics, and on all 20 considered datasets with minimax regret. Strong experimental results and flexibility in choosing the error measure make CoEvoRDT a promising approach for constructing robust DTs in real-world applications.",2024,https://ojs.aaai.org/index.php/AAAI/article/view/30188,10.1609/aaai.v38i19.30188,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,"AAAI Technical Track on Safe, Robust and Responsible AI Track",AAAI,NA
AAAI Conference on Artificial Intelligence,CoLAL: Co-learning Active Learning for Text Classification,Linh Le;Genghong Zhao;Xia Zhang;Guido Zuccon;Gianluca Demartini,"In the machine learning field, the challenge of effectively learning with limited data has become increasingly crucial. Active Learning( AL) algorithms play a significant role in this by enhancing model performance. We introduce a novel AL algorithm, termed Co-learning( CoLAL) , designed to select the most diverse and representative samples within a training dataset. This approach utilizes noisy labels and predictions made by the primary model on unlabeled data. By leveraging a probabilistic graphical model, we combine two multi-class classifiers into a binary one. This classifier determines if both the main and the peer models agree on a prediction. If they do, the unlabeled sample is assumed to be easy to classify and is thus not beneficial to increase the target models performance. We prioritize data that represents the unlabeled set without overlapping decision boundaries. The discrepancies between these boundaries can be estimated by the probability that two models result in the same prediction. Through theoretical analysis and experimental validation, we reveal that the integration of noisy labels into the peer model effectively identifies target models potential inaccuracies. We evaluated the CoLAL method across seven benchmark datasets: four text datasets( AGNews, DBPedia, PubMed, SST-2) and text-based state-of-the-art( SOTA) baselines, and three image datasets( CIFAR100, MNIST, OpenML-155) and computer vision SOTA baselines. The results show that our CoLAL method significantly outperforms existing SOTA in text-based AL, and is competitive with SOTA image-based AL techniques.",2024,https://ojs.aaai.org/index.php/AAAI/article/view/29235,10.1609/aaai.v38i12.29235,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Machine Learning III,AAAI,NA
AAAI Conference on Artificial Intelligence,Collective Intelligence in Human-AI Teams: A Bayesian Theory of Mind Approach,Samuel Westby;Christoph Riedl,"We develop a network of Bayesian agents that collectively model the mental states of teammates from the observed communication. Using a generative computational approach to cognition, we make two contributions. First, we show that our agent could generate interventions that improve the collective intelligence of a human-AI team beyond what humans alone would achieve. Second, we develop a real-time measure of humans theory of mind ability and test theories about human cognition. We use data collected from an online experiment in which 145 individuals in 29 human-only teams of five communicate through a chat-based system to solve a cognitive task. We find that humans( a) struggle to fully integrate information from teammates into their decisions, especially when communication load is high, and( b) have cognitive biases which lead them to underweight certain useful, but ambiguous, information. Our theory of mind ability measure predicts both individualand team-level performance. Observing teams first 25% of messages explains about 8% of the variation in final team performance, a 170% improvement compared to the current state of the art.",2023,https://ojs.aaai.org/index.php/AAAI/article/view/25755,10.1609/aaai.v37i5.25755,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Humans and AI,AAAI,NA
AAAI Conference on Artificial Intelligence,Collective Multiagent Sequential Decision Making Under Uncertainty,Duc Thien Nguyen;Akshat Kumar;Hoong Chuin Lau,"Multiagent sequential decision making has seen rapid progress with formal models such as decentralized MDPs and POMDPs. However, scalability to large multiagent systems and applicability to real world problems remain limited. To address these challenges, we study multiagent planning problems where the collective behavior of a population of agents affects the joint-reward and environment dynamics. Our work exploits recent advances in graphical models for modeling and inference with a population of individuals such as collective graphical models and the notion of finite partial exchangeability in lifted inference. We develop a collective decentralized MDP model where policies can be computed based on counts of agents in different states. As the policy search space over counts is combinatorial, we develop a sampling based framework that can compute open and closed loop policies. Comparisons with previous best approaches on synthetic instances and a real world taxi dataset modeling supply-demand matching show that our approach significantly outperforms them w. r. t. solution quality.",2017,https://ojs.aaai.org/index.php/AAAI/article/view/10708,10.1609/aaai.v31i1.10708,NA,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Multiagent Systems,AAAI,NA
AAAI Conference on Artificial Intelligence,Combating Unknown Bias with Effective Bias-Conflicting Scoring and Gradient Alignment,Bowen Zhao;Chen Chen;Qian-Wei Wang;Anfeng He;Shu-Tao Xia,"Models notoriously suffer from dataset biases which are detrimental to robustness and generalization. The identify-emphasize paradigm shows a promising effect in dealing with unknown biases. However, we find that it is still plagued by two challenges: A, the quality of the identified bias-conflicting samples is far from satisfactory; B, the emphasizing strategies just yield suboptimal performance. In this work, for challenge A, we propose an effective bias-conflicting scoring method to boost the identification accuracy with two practical strategies --- peer-picking and epoch-ensemble. For challenge B, we point out that the gradient contribution statistics can be a reliable indicator to inspect whether the optimization is dominated by bias-aligned samples. Then, we propose gradient alignment, which employs gradient statistics to balance the contributions of the mined bias-aligned and bias-conflicting samples dynamically throughout the learning process, forcing models to leverage intrinsic features to make fair decisions. Experiments are conducted on multiple datasets in various settings, demonstrating that the proposed solution can alleviate the impact of unknown biases and achieve state-of-the-art performance.",2023,https://ojs.aaai.org/index.php/AAAI/article/view/25466,10.1609/aaai.v37i3.25466,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Computer Vision III,AAAI,NA
AAAI Conference on Artificial Intelligence,Combining Experts’ Causal Judgments,Dalal Alrajeh;Hana Chockler;Joseph Halpern,"Consider a policymaker who wants to decide which intervention to perform in order to change a currently undesirable situation. The policymaker has at her disposal a team of experts, each with their own understanding of the causal dependencies between different factors contributing to the outcome. The policymaker has varying degrees of confidence in the experts’ opinions. She wants to combine their opinions in order to decide on the most effective intervention. We formally define the notion of an effective intervention, and then consider how experts’ causal judgments can be combined in order to determine the most effective intervention. We define a notion of two causal models being compatible, and show how compatible causal models can be combined. We then use it as the basis for combining experts causal judgments. We illustrate our approach on a number of real-life examples.",2018,https://ojs.aaai.org/index.php/AAAI/article/view/12112,10.1609/aaai.v32i1.12112,NA,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Reasoning under Uncertainty,AAAI,NA
AAAI Conference on Artificial Intelligence,Combining Machine Learning and Queueing Theory for Data-Driven Incarceration-Diversion Program Management,Bingxuan Li;Antonio Castellanos;Pengyi Shi;Amy Ward,"Incarceration-diversion programs have proven effective in reducing recidivism. Accurate prediction of the number of individuals with different characteristics in the program and their program outcomes based on given eligibility criteria is crucial for successful implementation, because this prediction serves as the foundation for determining the appropriate program size and the consequent staffing requirements. However, this task poses challenges due to the complexities arising from varied outcomes and lengths-of-stay for the diverse individuals in incarceration-diversion programs. In collaboration with an Illinois government agency, we develop a framework to address these issues. Our framework combines ML and queueing model simulation, providing accurate predictions for the program census and interpretable insights into program dynamics and the impact of different decisions in counterfactual scenarios. Additionally, we deploy a user-friendly web app beta-version that allows program managers to visualize census data by counties and race groups. We showcase two decision support use cases: Changing program admission criteria and launching similar programs in new counties.",2024,https://ojs.aaai.org/index.php/AAAI/article/view/30330,10.1609/aaai.v38i21.30330,7,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,IAAI Technical Track on Emerging Applications of AI,AAAI,NA
AAAI Conference on Artificial Intelligence,Combining Reinforcement Learning and Constraint Programming for Combinatorial Optimization,Quentin Cappart;Thierry Moisan;Louis-Martin Rousseau;Isabeau Prémont-Schwarz;Andre A. Cire,"Combinatorial optimization has found applications in numerous fields, from aerospace to transportation planning and economics. The goal is to find an optimal solution among a finite set of possibilities. The well-known challenge one faces with combinatorial optimization is the state-space explosion problem: the number of possibilities grows exponentially with the problem size, which makes solving intractable for large problems. In the last years, deep reinforcement learning( DRL) has shown its promise for designing good heuristics dedicated to solve NP-hard combinatorial optimization problems. However, current approaches have an important shortcoming: they only provide an approximate solution with no systematic ways to improve it or to prove optimality. In another context, constraint programming( CP) is a generic tool to solve combinatorial optimization problems. Based on a complete search procedure, it will always find the optimal solution if we allow an execution time large enough. A critical design choice, that makes CP non-trivial to use in practice, is the branching decision, directing how the search space is explored. In this work, we propose a general and hybrid approach, based on DRL and CP, for solving combinatorial optimization problems. The core of our approach is based on a dynamic programming formulation, that acts as a bridge between both techniques. We experimentally show that our solver is efficient to solve three challenging problems: the traveling salesman problem with time windows, the 4-moments portfolio optimization problem, and the 0-1 knapsack problem. Results obtained show that the framework introduced outperforms the stand-alone RL and CP solutions, while being competitive with industrial solvers.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/16484,10.1609/aaai.v35i5.16484,11,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Constraint Satisfaction and Optimization,AAAI,NA
AAAI Conference on Artificial Intelligence,Comparing Population Means Under Local Differential Privacy: With Significance and Power,Bolin Ding;Harsha Nori;Paul Li;Joshua Allen,"A statistical hypothesis test determines whether a hypothesis should be rejected based on samples from populations. In particular, randomized controlled experiments( or A/B testing) that compare population means using, e. g. , t-tests, have been widely deployed in technology companies to aid in making data-driven decisions. Samples used in these tests are collected from users and may contain sensitive information. Both the data collection and the testing process may compromise individuals’ privacy. In this paper, we study how to conduct hypothesis tests to compare population means while preserving privacy. We use the notation of local differential privacy( LDP) , which has recently emerged as the main tool to ensure each individual’s privacy without the need of a trusted data collector. We propose LDP tests that inject noise into every user’s data in the samples before collecting them( so users do not need to trust the data collector) , and draw conclusions with bounded type-I( significance level) and type-II errors( 1 - power). Our approaches can be extended to the scenario where some users require LDP while some are willing to provide exact data. We report experimental results on real-world datasets to verify the effectiveness of our approaches.",2018,https://ojs.aaai.org/index.php/AAAI/article/view/11301,10.1609/aaai.v32i1.11301,NA,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Applications,AAAI,NA
AAAI Conference on Artificial Intelligence,Compatibility Family Learning for Item Recommendation and Generation,Yong-Siang Shih;Kai-Yueh Chang;Hsuan-Tien Lin;Min Sun,"Compatibility between items, such as clothes and shoes, is a major factor among customers purchasing decisions. However, learning compatibility is challenging due to( 1) broader notions of compatibility than those of similarity, ( 2) the asymmetric nature of compatibility, and( 3) only a small set of compatible and incompatible items are observed. We propose an end-to-end trainable system to embed each item into a latent vector and project a query item into K compatible prototypes in the same space. These prototypes reflect the broad notions of compatibility. We refer to both the embedding and prototypes as Compatibility Family. In our learned space, we introduce a novel Projected Compatibility Distance( PCD) function which is differentiable and ensures diversity by aiming for at least one prototype to be close to a compatible item, whereas none of the prototypes are close to an incompatible item. We evaluate our system on a toy dataset, two Amazon product datasets, and Polyvore outfit dataset. Our method consistently achieves state-of-the-art performance. Finally, we show that we can visualize the candidate compatible prototypes using a Metric-regularized Conditional Generative Adversarial Network( MrCGAN) , where the input is a projected prototype and the output is a generated image of a compatible item. We ask human evaluators to judge the relative compatibility between our generated images and images generated by CGANs conditioned directly on query items. Our generated images are significantly preferred, with roughly twice the number of votes as others.",2018,https://ojs.aaai.org/index.php/AAAI/article/view/11839,10.1609/aaai.v32i1.11839,NA,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,Main Track: Machine Learning Applications,AAAI,NA
AAAI Conference on Artificial Intelligence,Competing for Resources: Estimating Adversary Strategy for Effective Plan Generation,Lukáš Chrpa;Pavel Rytíř;Rostislav Horčík;Stefan Edelkamp,"Effective decision making while competing for limited resources in adversarial environments is important for many real-world applications( e. g. two Taxi companies competing for customers). Decision-making techniques such as Automated planning have to take into account possible actions of adversary( or competing) agents. That said, the agent should know what the competitor will likely do and then generate its plan accordingly. In this paper we propose a novel approach for estimating strategies of the adversary( or the competitor) , sampling its actions that might hinder agents goals by interfering with the agents actions. The estimated competitor strategies are used in plan generation such that agents actions have to be applied prior to the ones of the competitor, whose estimated times dictate the deadlines. We empirically evaluate our approach leveraging sampling of competitors actions by comparing it to the naive approach optimising the make-span( not taking the competing agent into account at all) and to Nash Equilibrium( mixed) strategies.",2022,https://ojs.aaai.org/index.php/AAAI/article/view/21205,10.1609/aaai.v36i9.21205,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,"AAAI Technical Track on Planning, Routing, and Scheduling",AAAI,NA
AAAI Conference on Artificial Intelligence,Competing with Humans at Fantasy Football: Team Formation in Large Partially-Observable Domains,Tim Matthews;Sarvapali Ramchurn;Georgios Chalkiadakis,"We present the first real-world benchmark for sequentially-optimal team formation, working within the framework of a class of online football prediction games known as Fantasy Football. We model the problem as a Bayesian reinforcement learning one, where the action space is exponential in the number of players and where the decision makers beliefs are over multiple characteristics of each footballer. We then exploit domain knowledge to construct computationally tractable solution techniques in order to build a competitive automated Fantasy Football manager. Thus, we are able to establish the baseline performance in this domain, even without complete information on footballers performances( accessible to human managers) , showing that our agent is able to rank at around the top percentile when pitched against 2. 5M human players.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/8259,10.1609/aaai.v26i1.8259,7,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Multiagent Systems,AAAI,NA
AAAI Conference on Artificial Intelligence,Competition among Pairwise Lottery Contests,Xiaotie Deng;Hangxin Gan;Ningyuan Li;Weian Li;Qi Qi,"We investigate a two-stage competitive model involving multiple contests. In this model, each contest designer chooses two participants from a pool of candidate contestants and determines the biases. Contestants strategically distribute their efforts across various contests within their budget. We first show the existence of a pure strategy Nash equilibrium( PNE) for the contestants, and propose a fully polynomial-time approximation scheme to compute an approximate PNE. In the scenario where designers simultaneously decide the participants and biases, the subgame perfect equilibrium( SPE) may not exist. Nonetheless, when designers decisions are made in two substages, the existence of SPE is established. In the scenario where designers can hold multiple contests, we show that the SPE always exists under mild conditions and can be computed efficiently.",2024,https://ojs.aaai.org/index.php/AAAI/article/view/28823,10.1609/aaai.v38i9.28823,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Game Theory and Economic Paradigms,AAAI,NA
AAAI Conference on Artificial Intelligence,Competitive Analysis for Two-Level Ski-Rental Problem,Binghan Wu;Wei Bao;Dong Yuan,"In this paper, we study a two-level ski-rental problem. There are multiple commodities, each one can be “rented”( paying for on-demand usage) or “purchased”( paying for life-time usage). There is also a combo purchase available so that all commodities can be purchased as a combo. Since the usages of the commodities in future are not known in advance, to minimize the overall cost, we design an online algorithm to decide if we rent a commodity, purchase a commodity, or make a combo purchase. We first propose a deterministic online algorithm. It can achieve 3 competitive ratio, which is optimal and tight. Next, we further propose a randomized online algorithm, leading to a e^σ/( e^σ-1) competitive ratio, where σ is the ratio between the price of a single commodity and the price of combo purchase. Finally, we apply simulation to verify the theoretical competitive ratios and evaluate the actual performance against benchmarks.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/17429,10.1609/aaai.v35i13.17429,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,"AAAI Technical Track on Planning, Routing, and Scheduling",AAAI,NA
AAAI Conference on Artificial Intelligence,Compiling Bayesian Network Classifiers into Decision Graphs,Andy Shih;Arthur Choi;Adnan Darwiche,"We propose an algorithm for compiling Bayesian network classifiers into decision graphs that mimic the input and output behavior of the classifiers. In particular, we compile Bayesian network classifiers into ordered decision graphs, which are tractable and can be exponentially smaller in size than decision trees. This tractability facilitates reasoning about the behavior of Bayesian network classifiers, including the explanation of decisions they make. Our compilation algorithm comes with guarantees on the time of compilation and the size of compiled decision graphs. We apply our compilation algorithm to classifiers from the literature and discuss some case studies in which we show how to automatically explain their decisions and verify properties of their behavior.",2019,https://ojs.aaai.org/index.php/AAAI/article/view/4797,10.1609/aaai.v33i01.33017966,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Reasoning under Uncertainty,AAAI,NA
AAAI Conference on Artificial Intelligence,Compiling Graph Substructures into Sentential Decision Diagrams,Masaaki Nishino;Norihito Yasuda;Shin-ichi Minato;Masaaki Nagata,"The Zero-suppressed Sentential Decision Diagram( ZSDD) is a recentlydiscovered tractable representation of Boolean functions. ZSDD subsumes theZero-suppressed Binary Decision Diagram( ZDD) as a strict subset, andsimilar to ZDD, it can perform several useful operations like model countingand Apply operations. We propose a top-down compilation algorithmfor ZSDD that represents sets of specific graph substructures, e. g. , matchings and simple paths of a graph. We experimentally confirm that theproposed algorithm is faster than other construction methods includingbottom-up methods and top-down methods for ZDDs, and the resulting ZSDDsare smaller than ZDDs representing the same graph substructures. We alsoshow that the size constructed ZSDDs can be bounded by the branch-width of thegraph. This bound is tighter than that of ZDDs.",2017,https://ojs.aaai.org/index.php/AAAI/article/view/10697,10.1609/aaai.v31i1.10697,NA,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Knowledge Representation and Reasoning,AAAI,NA
AAAI Conference on Artificial Intelligence,Complementary Attention Gated Network for Pedestrian Trajectory Prediction,Jinghai Duan;Le Wang;Chengjiang Long;Sanping Zhou;Fang Zheng;Liushuai Shi;Gang Hua,"Pedestrian trajectory prediction is crucial in many practical applications due to the diversity of pedestrian movements, such as social interactions and individual motion behaviors. With similar observable trajectories and social environments, different pedestrians may make completely different future decisions. However, most existing methods only focus on the frequent modal of the trajectory and thus are difficult to generalize to the peculiar scenario, which leads to the decline of the multimodal fitting ability when facing similar scenarios. In this paper, we propose a complementary attention gated network( CAGN) for pedestrian trajectory prediction, in which a dual-path architecture including normal and inverse attention is proposed to capture both frequent and peculiar modals in spatial and temporal patterns, respectively. Specifically, a complementary block is proposed to guide normal and inverse attention, which are then be summed with learnable weights to get attention features by a gated network. Finally, multiple trajectory distributions are estimated based on the fused spatio-temporal attention features due to the multimodality of future trajectory. Experimental results on benchmark datasets, i. e. , the ETH, and the UCY, demonstrate that our method outperforms state-of-the-art methods by 13. 8% in Average Displacement Error( ADE) and 10. 4% in Final Displacement Error( FDE). Code will be available at https://github. com/jinghaiD/CAGN",2022,https://ojs.aaai.org/index.php/AAAI/article/view/19933,10.1609/aaai.v36i1.19933,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Computer Vision I,AAAI,NA
AAAI Conference on Artificial Intelligence,Complexity of Abstract Argumentation under a Claim-Centric View,Wolfgang Dvořák;Stefan Woltran,"Abstract argumentation frameworks have been introduced by Dung as part of an argumentation process, where arguments and conflicts are derived from a given knowledge base. It is solely this relation between arguments that is then used in order to identify acceptable sets of arguments. A final step concerns the acceptance status of particular statements by reviewing the actual contents of the acceptable arguments. Complexity analysis of abstract argumentation so far has neglected this final step and is concerned with argument names instead of their contents, i. e. their claims. As we outline in this paper, this is not only a slight deviation but can lead to different complexity results. We, therefore, give a comprehensive complexity analysis of abstract argumentation under a claim-centric view and analyse the four main decision problems under seven popular semantics. In addition, we also address the complexity of common sub-classes and introduce novel parameterisations – which exploit the nature of claims explicitly – along with fixed-parameter tractability results.",2019,https://ojs.aaai.org/index.php/AAAI/article/view/4132,10.1609/aaai.v33i01.33012801,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Knowledge Representation and Reasoning,AAAI,NA
AAAI Conference on Artificial Intelligence,Compressed Conditional Mean Embeddings for Model-Based Reinforcement Learning,Guy Lever;John Shawe-Taylor;Ronnie Stafford;Csaba Szepesvari,"We present a model-based approach to solving Markov decision processes( MDPs) in which the system dynamics are learned using conditional mean embeddings( CMEs). This class of methods comes with strong performance guarantees, and enables planning to be performed in an induced finite( pseudo-) MDP, which approximates the MDP, but can be solved exactly using dynamic programming. Two drawbacks of existing methods exist: firstly, the size of the induced finite( pseudo-) MDP scales quadratically with the amount of data used to learn the model, costing much memory and time when planning with the learned model; secondly, learning the CME itself using powerful kernel least-squares is costly – a second computational bottleneck. We present an algorithm which maintains a rich kernelized CME model class, but solves both problems: firstly we demonstrate that the loss function for the CME model suggests a principled approach to compressing the induced( pseudo-) MDP, leading to faster planning, while maintaining guarantees; secondly we propose to learn the CME model itself using fast sparse-greedy kernel regression well-suited to the RL context. We demonstrate superior performance to existing methods in this class of modelbased approaches on a range of MDPs.",2016,https://ojs.aaai.org/index.php/AAAI/article/view/10304,10.1609/aaai.v30i1.10304,NA,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,Technical Papers: Machine Learning Methods,AAAI,NA
AAAI Conference on Artificial Intelligence,Compressed Decentralized Learning of Conditional Mean Embedding Operators in Reproducing Kernel Hilbert Spaces,Boya Hou;Sina Sanjari;Nathan Dahlin;Subhonmesh Bose,"Conditional mean embedding( CME) operators encode conditional probability densities within Reproducing Kernel Hilbert Space( RKHS). In this paper, we present a decentralized algorithm for a collection of agents to cooperatively approximate CME over a network. Communication constraints limit the agents from sending all data to their neighbors; we only allow sparse representations of covariance operators to be exchanged among agents, compositions of which defines CME. Using a coherence-based compression scheme, we present a consensus-type algorithm that preserves the average of the approximations of the covariance operators across the network. We theoretically prove that the iterative dynamics in RKHS is stable. We then empirically study our algorithm to estimate CMEs to learn spectra of Koopman operators for Markovian dynamical systems and to execute approximate value iteration for Markov decision processes( MDPs).",2023,https://ojs.aaai.org/index.php/AAAI/article/view/25956,10.1609/aaai.v37i7.25956,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Machine Learning II,AAAI,NA
AAAI Conference on Artificial Intelligence,Computational Issues in Time-Inconsistent Planning,Pingzhong Tang;Yifeng Teng;Zihe Wang;Shenke Xiao;Yichong Xu,"Time-inconsistency refers to a paradox in decision making where agents exhibit inconsistent behaviors over time. Examples are procrastination where agents tend to postpone easy tasks, and abandonments where agents start a plan and quit in the middle. To capture such behaviors and to quantify inefficiency caused by such behaviors, Kleinberg and Oren( 2014) propose a graph model with a certain cost structure and initiate the study of several interesting computation problems: 1) cost ratio: the worst ratio between the actual cost of the agent and the optimal cost, over all the graph instances; 2) motivating subgraph: how to motivate the agent to reach the goal by deleting nodes and edges; 3) Intermediate rewards: how to incentivize agents to reach the goal by placing intermediate rewards. Kleinberg and Oren give partial answers to these questions, but the main problems are open. In this paper, we give answers to all three open problems. First, we show a tight upper bound of cost ratio for graphs, and confirm the conjecture by Kleinberg and Oren that Akerlof’s structure is indeed the worst case for cost ratio. Second, we prove that finding a motivating subgraph is NP-hard, showing that it is generally inefficient to motivate agents by deleting nodes and edges in the graph. Last but not least, we show that computing a strategy to place minimum amount of total reward is also NP-hard and we provide a 2napproximation algorithm.",2017,https://ojs.aaai.org/index.php/AAAI/article/view/11017,10.1609/aaai.v31i1.11017,NA,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,Main Track: Planning and Scheduling,AAAI,NA
AAAI Conference on Artificial Intelligence,Computing an Efficient Exploration Basis for Learning with Univariate Polynomial Features,Chaitanya Amballa;Manu K. Gupta;Sanjay P. Bhat,"Barycentric spanners have been used as an efficient exploration basis in online linear optimization problems in a bandit framework. We characterise the barycentric spanner for decision problems in which the cost( or reward) is a polynomial in a single decision variable. Our characterisation of the barycentric spanner is two-fold: we show that the barycentric spanner under a polynomial cost function is the unique solution to a set of nonlinear algebraic equations, as well as the solution to a convex optimization problem. We provide numerical results to show that our method computes the barycentric spanner for the polynomial case significantly faster than the only other known algorithm for the purpose. As an application, we consider a dynamic pricing problem in which the revenue is an unknown polynomial function of the price. We then empirically show that the use of a barycentric spanner to initialise the prior distribution in a Thompson sampling setting leads to lower cumulative regret as compared to standard initialisations. We also illustrate the importance of barycentric spanners in adversarial settings by showing, both theoretically and empirically, that a barycentric spanner achieves the minimax value in a static adversarial linear regression problem where the learner selects the training points while an adversary selects the testing points and controls the variance of the noise corrupting the training samples",2021,https://ojs.aaai.org/index.php/AAAI/article/view/16821,10.1609/aaai.v35i8.16821,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Machine Learning I,AAAI,NA
AAAI Conference on Artificial Intelligence,Computing Possible and Necessary Equilibrium Actions( and Bipartisan Set Winners),Markus Brill;Rupert Freeman;Vincent Conitzer,"In many multiagent environments, a designer has some, but limited control over the game being played. In this paper, we formalize this by considering incompletely specified games, in which some entries of the payoff matrices can be chosen from a specified set. We show that it is NP-hard for the designer to make this choices optimally, even in zero-sum games. In fact, it is already intractable to decide whether a given action is( potentially or necessarily) played in equilibrium. We also consider incompletely specified symmetric games in which all completions are required to be symmetric. Here, hardness holds even in weak tournament games( symmetric zero-sum games whose entries are all -1, 0, or 1) and in tournament games( symmetric zero-sum games whose non-diagonal entries are all -1 or 1). The latter result settles the complexity of the possible and necessary winner problems for a social-choice-theoretic solution concept known as the bipartisan set. We finally give a mixed-integer linear programming formulation for weak tournament games and evaluate it experimentally.",2016,https://ojs.aaai.org/index.php/AAAI/article/view/10052,10.1609/aaai.v30i1.10052,NA,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,Technical Papers: Game Theory and Economic Paradigms,AAAI,NA
AAAI Conference on Artificial Intelligence,Computing Quantal Stackelberg Equilibrium in Extensive-Form Games,Jakub Černý;Viliam Lisý;Branislav Bošanský;Bo An,"Deployments of game-theoretic solution concepts in the real world have highlighted the necessity to consider human opponents boundedly rational behavior. If subrationality is not addressed, the system can face significant losses in terms of expected utility. While there exist algorithms for computing optimal strategies to commit to when facing subrational decision-makers in one-shot interactions, these algorithms cannot be generalized for solving sequential scenarios because of the inherent curse of strategy-space dimensionality in sequential games and because humans act subrationally in each decision point separately. We study optimal strategies to commit to against subrational opponents in sequential games for the first time and make the following key contributions:( 1) we prove the problem is NP-hard in general;( 2) to enable further analysis, we introduce a non-fractional reformulation of the direct non-concave representation of the equilibrium;( 3) we identify conditions under which the problem can be approximated in polynomial time in the size of the representation;( 4) we show how an MILP can approximate the reformulation with a guaranteed bounded error, and( 5) we experimentally demonstrate that our algorithm provides higher quality results several orders of magnitude faster than a baseline method for general non-linear optimization.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/16664,10.1609/aaai.v35i6.16664,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Game Theory and Economic Paradigms,AAAI,NA
AAAI Conference on Artificial Intelligence,Computing Rational Decisions In Extensive Games With Limited Foresight,Paolo Turrini,"We introduce a class of extensive form games whereplayers might not be able to foresee the possible consequences of their decisions and form a model of theiropponents which they exploit to achieve a more profitable outcome. We improve upon existing models ofgames with limited foresight, endowing players with theability of higher order reasoning and proposing a novelsolution concept to address intuitions coming from realgame play. We analyse the resulting equilibria, devisingan effective procedure to compute them.",2016,https://ojs.aaai.org/index.php/AAAI/article/view/10015,10.1609/aaai.v30i1.10015,NA,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,Technical Papers: Game Theory and Economic Paradigms,AAAI,NA
AAAI Conference on Artificial Intelligence,Conditional PSDDs: Modeling and Learning With Modular Knowledge,Yujia Shen;Arthur Choi;Adnan Darwiche,"Probabilistic Sentential Decision Diagrams( PSDDs) have been proposed for learning tractable probability distributions from a combination of data and background knowledge( in the form of Boolean constraints). In this paper, we propose a variant on PSDDs, called conditional PSDDs, for representing a family of distributions that are conditioned on the same set of variables. Conditional PSDDs can also be learned from a combination of data and( modular) background knowledge. We use conditional PSDDs to define a more structured version of Bayesian networks, in which nodes can have an exponential number of states, hence expanding the scope of domains where Bayesian networks can be applied. Compared to classical PSDDs, the new representation exploits the independencies captured by a Bayesian network to decompose the learning process into localized learning tasks, which enables the learning of better models while using less computation. We illustrate the promise of conditional PSDDs and structured Bayesian networks empirically, and by providing a case study to the modeling of distributions over routes on a map.",2018,https://ojs.aaai.org/index.php/AAAI/article/view/12119,10.1609/aaai.v32i1.12119,NA,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Reasoning under Uncertainty,AAAI,NA
AAAI Conference on Artificial Intelligence,Condorcet Relaxation In Spatial Voting,Arnold Filtser;Omrit Filtser,"Consider a set of voters V, represented by a multiset in a metric space( X, d). The voters have to reach a decision - a point in X. A choice p∈ X is called a β-plurality point for V, if for any other choice q∈ X it holds that |{v∈ V ∣ β⋅ d( p, v) ≤ d( q, v) }| ≥|V|/2. In other words, at least half of the voters ``prefer over q, when an extra factor of β is taken in favor of p. For β=1, this is equivalent to Condorcet winner, which rarely exists. The concept of β-plurality was suggested by Aronov, de Berg, Gudmundsson, and Horton [SoCG 2020] as a relaxation of the Condorcet criterion. Denote by β*( X, d) the value sup{ β ∣ every finite multiset V in X admits a β-plurality point}}. The parameter β* determines the amount of relaxation required in order to reach a stable decision. Aronov et al. showed that for the Euclidean plane β*( ℝ2, \\|⋅\\|2) =√3/2, and more generally, for d-dimensional Euclidean space, 1/√d ≤ β*( ℝd, \\|⋅\\|2) ≤√3/2. In this paper, we show that 0. 557≤ β*( ℝd, \\|⋅\\|2) for any dimension d( notice that 1/√d <0. 557 for any d≥ 4). In addition, we prove that for every metric space( X, d) it holds that √2-1≤β*( X, d) , and show that there exists a metric space for which β*( X, d) ≤ 1/2.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/16681,10.1609/aaai.v35i6.16681,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Game Theory and Economic Paradigms,AAAI,NA
AAAI Conference on Artificial Intelligence,Congestion Graphs for Automated Time Predictions,Arik Senderovich;J. Christopher Beck;Avigdor Gal;Matthias Weidlich,"Time prediction is an essential component of decision making in various Artificial Intelligence application areas, including transportation systems, healthcare, and manufacturing. Predictions are required for efficient resource allocation and scheduling, optimized routing, and temporal action planning. In this work, we focus on time prediction in congested systems, where entities share scarce resources. To achieve accurate and explainable time prediction in this setting, features describing system congestion( e. g. , workload and resource availability) , must be considered. These features are typically gathered using process knowledge, ( i. e. , insights on the interplay of a system’s entities). Such knowledge is expensive to gather and may be completely unavailable. In order to automatically extract such features from data without prior process knowledge, we propose the model of congestion graphs, which are grounded in queueing theory. We show how congestion graphs are mined from raw event data using queueing theory based assumptions on the information contained in these logs. We evaluate our approach on two real-world datasets from healthcare systems where scarce resources prevail: an emergency department and an outpatient cancer clinic. Our experimental results show that using automatic generation of congestion features, we get an up to 23% improvement in terms of relative error in time prediction, compared to common baseline methods. We also detail how congestion graphs can be used to explain delays in the system.",2019,https://ojs.aaai.org/index.php/AAAI/article/view/4413,10.1609/aaai.v33i01.33014854,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Machine Learning,AAAI,NA
AAAI Conference on Artificial Intelligence,Connecting Language to Images: A Progressive Attention-Guided Network for Simultaneous Image Captioning and Language Grounding,Lingyun Song;Jun Liu;Buyue Qian;Yihe Chen,"Image captioning and visual language grounding are two important tasks for image understanding, but are seldom considered together. In this paper, we propose a Progressive Attention-Guided Network( PAGNet) , which simultaneously generates image captions and predicts bounding boxes for caption words. PAGNet mainly has two distinctive properties: i) It can progressively refine the predictive results of image captioning, by updating the attention map with the predicted bounding boxes. ii) It learns bounding boxes of the words using a weakly supervised strategy, which combines the frameworks of Multiple Instance Learning( MIL) and Markov Decision Process( MDP). By using the attention map generated in the captioning process, PAGNet significantly reduces the search space of the MDP. We conduct experiments on benchmark datasets to demonstrate the effectiveness of PAGNet and results show that PAGNet achieves the best performance.",2019,https://ojs.aaai.org/index.php/AAAI/article/view/4916,10.1609/aaai.v33i01.33018885,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Vision,AAAI,NA
AAAI Conference on Artificial Intelligence,ConsistentEE: A Consistent and Hardness-Guided Early Exiting Method for Accelerating Language Models Inference,Ziqian Zeng;Yihuai Hong;Hongliang Dai;Huiping Zhuang;Cen Chen,"Early Exiting is one of the most popular methods to achieve efficient inference. Current early exiting methods adopt the( weighted) sum of the cross entropy loss of all internal classifiers as the objective function during training, imposing all these classifiers to predict all instances correctly. However, during inference, as long as one internal classifier predicts an instance correctly, it can accelerate without losing accuracy. Thus, there is a notable gap between training and inference. We propose ConsistentEE, an early exiting method that is consistent in training and inference. ConsistentEE formulates the early exiting process as a reinforcement learning problem. A policy network is added to decide whether an instance should exit or continue. The training objective of ConsistentEE only requires each instance to be predicted correctly by one internal classifier. Additionally, we introduce the concept Memorized Layer to measure the hardness of an instance. We incorporate the memorized layer into reward function design, which allows easy instances to focus more on acceleration while ``hard instances to focus more on accuracy. Experimental results show that our method outperforms other baselines on various natural language understanding and generation tasks using PLMs and LLMs as backbones respectively.",2024,https://ojs.aaai.org/index.php/AAAI/article/view/29922,10.1609/aaai.v38i17.29922,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Natural Language Processing II,AAAI,NA
AAAI Conference on Artificial Intelligence,Constrained Prescriptive Trees via Column Generation,Shivaram Subramanian;Wei Sun;Youssef Drissi;Markus Ettl,"With the abundance of available data, many enterprises seek to implement data-driven prescriptive analytics to help them make informed decisions. These prescriptive policies need to satisfy operational constraints, and proactively eliminate rule conflicts, both of which are ubiquitous in practice. It is also desirable for them to be simple and interpretable, so they can be easily verified and implemented. Existing approaches from the literature center around constructing variants of prescriptive decision trees to generate interpretable policies. However, none of the existing methods is able to handle constraints. In this paper, we propose a scalable method that solves the constrained prescriptive policy generation problem. We introduce a novel path-based mixed-integer program( MIP) formulation which identifies a( near) optimal policy efficiently via column generation. The policy generated can be represented as a multiway-split tree which is more interpretable and informative than binary-split trees due to its shorter rules. We demonstrate the efficacy of our method with extensive computational experiments on both synthetic and real datasets.",2022,https://ojs.aaai.org/index.php/AAAI/article/view/20384,10.1609/aaai.v36i4.20384,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Domain( s) Of Application,AAAI,NA
AAAI Conference on Artificial Intelligence,Constrained Pure Nash Equilibria in Polymatrix Games,Sunil Simon;Dominik Wojtczak,"We study the problem of checking for the existence of constrained pure Nash equilibria in a subclass of polymatrix games defined on weighted directed graphs. The payoff of a player is defined as the sum of nonnegative rational weights on incoming edges from players who picked the same strategy augmented by a fixed integer bonus for picking a given strategy. These games capture the idea of coordination within a local neighbourhood in the absence of globally common strategies. We study the decision problem of checking whether a given set of strategy choices for a subset of the players is consistent with some pure Nash equilibrium or, alternatively, with all pure Nash equilibria. We identify the most natural tractable cases and show NP or coNP-completness of these problems already for unweighted DAGs.",2017,https://ojs.aaai.org/index.php/AAAI/article/view/10599,10.1609/aaai.v31i1.10599,NA,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Game Theory and Economic Paradigms,AAAI,NA
AAAI Conference on Artificial Intelligence,Constrained Reinforcement Learning in Hard Exploration Problems,Pathmanathan Pankayaraj;Pradeep Varakantham,"One approach to guaranteeing safety in Reinforcement Learning is through cost constraints that are dependent on the policy. Recent works in constrained RL have developed methods that ensure constraints are enforced even at learning time while maximizing the overall value of the policy. Unfortunately, as demonstrated in our experimental results, such approaches do not perform well on complex multi-level tasks, with longer episode lengths or sparse rewards. To that end, we propose a scalable hierarchical approach for constrained RL problems that employs backward cost value functions in the context of task hierarchy and a novel intrinsic reward function in lower levels of the hierarchy to enable cost constraint enforcement. One of our key contributions is in proving that backward value functions are theoretically viable even when there are multiple levels of decision making. We also show that our new approach, referred to as Hierarchically Limited consTraint Enforcement( HiLiTE) significantly improves on state of the art Constrained RL approaches for many benchmark problems from literature. We further demonstrate that this performance( on value and constraint enforcement) clearly outperforms existing best approaches for constrained RL and hierarchical RL.",2023,https://ojs.aaai.org/index.php/AAAI/article/view/26757,10.1609/aaai.v37i12.26757,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Special Track on Safe and Robust AI,AAAI,NA
AAAI Conference on Artificial Intelligence,Constrained Risk-Averse Markov Decision Processes,Mohamadreza Ahmadi;Ugo Rosolia;Michel D. Ingham;Richard M. Murray;Aaron D. Ames,"We consider the problem of designing policies for Markov decision processes( MDPs) with dynamic coherent risk objectives and constraints. We begin by formulating the problem in a Lagrangian framework. Under the assumption that the risk objectives and constraints can be represented by a Markov risk transition mapping, we propose an optimization-based method to synthesize Markovian policies that lower-bound the constrained risk-averse problem. We demonstrate that the formulated optimization problems are in the form of difference convex programs( DCPs) and can be solved by the disciplined convex-concave programming( DCCP) framework. We show that these results generalize linear programs for constrained MDPs with total discounted expected costs and constraints. Finally, we illustrate the effectiveness of the proposed method with numerical experiments on a rover navigation problem involving conditional-value-at-risk( CVaR) and entropic-value-at-risk( EVaR) coherent risk measures.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/17393,10.1609/aaai.v35i13.17393,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,"AAAI Technical Track on Planning, Routing, and Scheduling",AAAI,NA
AAAI Conference on Artificial Intelligence,Constraint-Based Sequential Pattern Mining with Decision Diagrams,Amin Hosseininasab;Willem-Jan van Hoeve;Andre A. Cire,"Constraint-based sequential pattern mining aims at identifying frequent patterns on a sequential database of items while observing constraints defined over the item attributes. We introduce novel techniques for constraint-based sequential pattern mining that rely on a multi-valued decision diagram( MDD) representation of the database. Specifically, our representation can accommodate multiple item attributes and various constraint types, including a number of non-monotone constraints. To evaluate the applicability of our approach, we develop an MDD-based prefix-projection algorithm and compare its performance against a typical generate-and-check variant, as well as a state-of-the-art constraint-based sequential pattern mining algorithm. Results show that our approach is competitive with or superior to these other methods in terms of scalability and efficiency.",2019,https://ojs.aaai.org/index.php/AAAI/article/view/3962,10.1609/aaai.v33i01.33011495,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Constraint Satisfaction and Optimization,AAAI,NA
AAAI Conference on Artificial Intelligence,Constructing a Fair Classifier with Generated Fair Data,Taeuk Jang;Feng Zheng;Xiaoqian Wang,"Fairness in machine learning is getting rising attention as it is directly related to real-world applications and social problems. Recent methods have been explored to alleviate the discrimination between certain demographic groups that are characterized by sensitive attributes( such as race, age, or gender). Some studies have found that the data itself is biased, so training directly on the data causes unfair decision making. Models directly trained on raw data can replicate or even exacerbate bias in the prediction between demographic groups. This leads to vastly different prediction performance in different demographic groups. In order to address this issue, we propose a new approach to improve machine learning fairness by generating fair data. We introduce a generative model to generate cross-domain samples w. r. t. multiple sensitive attributes. This ensures that we can generate infinite number of samples that are balanced \\wrt both target label and sensitive attributes to enhance fair prediction. By training the classifier solely with the synthetic data and then transfer the model to real data, we can overcome the under-representation problem which is non-trivial since collecting real data is extremely time and resource consuming. We provide empirical evidence to demonstrate the benefit of our model with respect to both fairness and accuracy.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/16965,10.1609/aaai.v35i9.16965,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Machine Learning II,AAAI,NA
AAAI Conference on Artificial Intelligence,Constructive Preference Elicitation Over Hybrid Combinatorial Spaces,Paolo Dragone;Stefano Teso;Andrea Passerini,"Peference elicitation is the task of suggesting a highly preferred configuration to a decision maker. The preferences are typically learned by querying the user for choice feedback over pairs or sets of objects. In its constructive variant, new objects are synthesized from scratch by maximizing an estimate of the user utility over a combinatorial( possibly infinite) space of candidates. In the constructive setting, most existing elicitation techniques fail because they rely on exhaustive enumeration of the candidates. A previous solution explicitly designed for constructive tasks comes with no formal performance guarantees, and can be very expensive in( or unapplicable to) problems with non-Boolean attributes. We propose the Choice Perceptron, a Perceptron-like algorithm for learning user preferences from set-wise choice feedback over constructive domains and hybrid Boolean-numeric feature spaces. We provide a theoretical analysis on the attained regret that holds for a large class of query selection strategies, and devise a heuristic strategy that aims at optimizing the regret in practice. Finally, we demonstrate its effectiveness by empirical evaluation against existing competitors on constructive scenarios of increasing complexity.",2018,https://ojs.aaai.org/index.php/AAAI/article/view/11804,10.1609/aaai.v32i1.11804,NA,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Machine Learning,AAAI,NA
AAAI Conference on Artificial Intelligence,"ConTaCT: Deciding to Communicate during Time-Critical Collaborative Tasks in Unknown, Deterministic Domains",Vaibhav Unhelkar;Julie Shah,"Communication between agents has the potential to improve team performance of collaborative tasks. However, communication is not free in most domains, requiring agents to reason about the costs and benefits of sharing information. In this work, we develop an online, decentralized communication policy, ConTaCT, that enables agents to decide whether or not to communicate during time-critical collaborative tasks in unknown, deterministic environments. Our approach is motivated by real-world applications, including the coordination of disaster response and search and rescue teams. These settings motivate a model structure that explicitly represents the world model as initially unknown but deterministic in nature, and that de-emphasizes uncertainty about action outcomes. Simulated experiments are conducted in which ConTaCT is compared to other multi-agent communication policies, and results indicate that ConTaCT achieves comparable task performance while substantially reducing communication overhead.",2016,https://ojs.aaai.org/index.php/AAAI/article/view/10123,10.1609/aaai.v30i1.10123,NA,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,Technical Papers: Multiagent Systems,AAAI,NA
AAAI Conference on Artificial Intelligence,Contextual Pandora’s Box,Alexia Atsidakou;Constantine Caramanis;Evangelia Gergatsouli;Orestis Papadigenopoulos;Christos Tzamos,"Pandora’s Box is a fundamental stochastic optimization problem, where the decision-maker must find a good alternative, while minimizing the search cost of exploring the value of each alternative. In the original formulation, it is assumed that accurate distributions are given for the values of all the alternatives, while recent work studies the online variant of Pandora’s Box where the distributions are originally unknown. In this work, we study Pandora’s Box in the online setting, while incorporating context. At each round, we are presented with a number of alternatives each having a context, an exploration cost and an unknown value drawn from an unknown distribution that may change at every round. Our main result is a no-regret algorithm that performs comparably well against the optimal algorithm which knows all prior distributions exactly. Our algorithm works even in the bandit setting where the algorithm never learns the values of the alternatives that were not explored. The key technique that enables our result is a novel modification of the realizability condition in contextual bandits that connects a context to a sufficient statistic of each alternative’s distribution( its reservation value) rather than its mean.",2024,https://ojs.aaai.org/index.php/AAAI/article/view/28969,10.1609/aaai.v38i10.28969,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Machine Learning I,AAAI,NA
AAAI Conference on Artificial Intelligence,Contiguous Cake Cutting: Hardness Results and Approximation Algorithms,Paul W. Goldberg;Alexandros Hollender;Warut Suksompong,"We study the fair allocation of a cake, which serves as a metaphor for a divisible resource, under the requirement that each agent should receive a contiguous piece of the cake. While it is known that no finite envy-free algorithm exists in this setting, we exhibit efficient algorithms that produce allocations with low envy among the agents. We then establish NP-hardness results for various decision problems on the existence of envy-free allocations, such as when we fix the ordering of the agents or constrain the positions of certain cuts. In addition, we consider a discretized setting where indivisible items lie on a line and show a number of hardness results strengthening those from prior work.",2020,https://ojs.aaai.org/index.php/AAAI/article/view/5570,10.1609/aaai.v34i02.5570,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Game Theory and Economic Paradigms,AAAI,NA
AAAI Conference on Artificial Intelligence,Contrastive Balancing Representation Learning for Heterogeneous Dose-Response Curves Estimation,Minqin Zhu;Anpeng Wu;Haoxuan Li;Ruoxuan Xiong;Bo Li;Xiaoqing Yang;Xuan Qin;Peng Zhen;Jiecheng Guo;Fei Wu;Kun Kuang,"Estimating the individuals potential response to varying treatment doses is crucial for decision-making in areas such as precision medicine and management science. Most recent studies predict counterfactual outcomes by learning a covariate representation that is independent of the treatment variable. However, such independence constraints neglect much of the covariate information that is useful for counterfactual prediction, especially when the treatment variables are continuous. To tackle the above issue, in this paper, we first theoretically demonstrate the importance of the balancing and prognostic representations for unbiased estimation of the heterogeneous dose-response curves, that is, the learned representations are constrained to satisfy the conditional independence between the covariates and both of the treatment variables and the potential responses. Based on this, we propose a novel Contrastive balancing Representation learning Network using a partial distance measure, called CRNet, for estimating the heterogeneous dose-response curves without losing the continuity of treatments. Extensive experiments are conducted on synthetic and real-world datasets demonstrating that our proposal significantly outperforms previous methods.",2024,https://ojs.aaai.org/index.php/AAAI/article/view/29663,10.1609/aaai.v38i15.29663,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Machine Learning VI,AAAI,NA
AAAI Conference on Artificial Intelligence,Contribution-Aware Federated Learning for Smart Healthcare,Zelei Liu;Yuanyuan Chen;Yansong Zhao;Han Yu;Yang Liu;Renyi Bao;Jinpeng Jiang;Zaiqing Nie;Qian Xu;Qiang Yang,"Artificial intelligence( AI) is a promising technology to transform the healthcare industry. Due to the highly sensitive nature of patient data, federated learning( FL) is often leveraged to build models for smart healthcare applications. Existing deployed FL frameworks cannot address the key issues of varying data quality and heterogeneous data distributions across multiple institutions in this sector. In this paper, we report our experience developing and deploying the Contribution-Aware Federated Learning( CAFL) framework for smart healthcare. It provides an efficient and accurate approach to fairly evaluate FL participants contribution to model performance without exposing their private data, and improves the FL model training protocol to allow the best performing intermediate models to be distributed to participants for FL training. Since its deployment in Yidu Cloud Technology Inc. in March 2021, CAFL has served 8 well-established medical institutions in China to build healthcare decision support models. It can perform contribution evaluations 2. 84 times faster than the best existing approach, and has improved the average accuracy of the resulting models by 2. 62% compared to the previous system( which is significant in industrial settings). To our knowledge, it is the first contribution-aware federated learning successfully deployed in the healthcare industry.",2022,https://ojs.aaai.org/index.php/AAAI/article/view/21505,10.1609/aaai.v36i11.21505,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,IAAI Technical Track on Highly Innovative Applications of AI,AAAI,NA
AAAI Conference on Artificial Intelligence,Coordinated Multi-Robot Exploration Under Communication Constraints Using Decentralized Markov Decision Processes,Laetitia Matignon;Laurent Jeanpierre;Abdel-Illah Mouaddib,"Recent works on multi-agent sequential decision making using decentralized partially observable Markov decision processes have been concerned with interaction-oriented resolution techniques and provide promising results. These techniques take advantage of local interactions and coordination. In this paper, we propose an approach based on an interaction-oriented resolution of decentralized decision makers. To this end, distributed value functions( DVF) have been used by decoupling the multi-agent problem into a set of individual agent problems. However existing DVF techniques assume permanent and free communication between the agents. In this paper, we extend the DVF methodology to address full local observability, limited share of information and communication breaks. We apply our new DVF in a real-world application consisting of multi-robot exploration where each robot computes locally a strategy that minimizes the interactions between the robots and maximizes the space coverage of the team even under communication constraints. Our technique has been implemented and evaluated in simulation and in real-world scenarios during a robotic challenge for the exploration and mapping of an unknown environment. Experimental results from real-world scenarios and from the challenge are given where our system was vice-champion.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/8380,10.1609/aaai.v26i1.8380,7,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,Robotics,AAAI,NA
AAAI Conference on Artificial Intelligence,Coordinated Reasoning for Cross-Lingual Knowledge Graph Alignment,Kun Xu;Linfeng Song;Yansong Feng;Yan Song;Dong Yu,"Existing entity alignment methods mainly vary on the choices of encoding the knowledge graph, but they typically use the same decoding method, which independently chooses the local optimal match for each source entity. This decoding method may not only cause the “many-to-one” problem but also neglect the coordinated nature of this task, that is, each alignment decision may highly correlate to the other decisions. In this paper, we introduce two coordinated reasoning methods, i. e. , the Easy-to-Hard decoding strategy and joint entity alignment algorithm. Specifically, the Easy-to-Hard strategy first retrieves the model-confident alignments from the predicted results and then incorporates them as additional knowledge to resolve the remaining model-uncertain alignments. To achieve this, we further propose an enhanced alignment model that is built on the current state-of-the-art baseline. In addition, to address the many-to-one problem, we propose to jointly predict entity alignments so that the one-to-one constraint can be naturally incorporated into the alignment prediction. Experimental results show that our model achieves the state-of-the-art performance and our reasoning methods can also significantly improve existing baselines.",2020,https://ojs.aaai.org/index.php/AAAI/article/view/6476,10.1609/aaai.v34i05.6476,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Natural Language Processing,AAAI,NA
AAAI Conference on Artificial Intelligence,Copy That! Editing Sequences by Copying Spans,Sheena Panthaplackel;Miltiadis Allamanis;Marc Brockschmidt,"Neural sequence-to-sequence models are finding increasing use in editing of documents, for example in correcting a text document or repairing source code. In this paper, we argue that common seq2seq models( with a facility to copy single tokens) are not a natural fit for such tasks, as they have to explicitly copy each unchanged token. We present an extension of seq2seq models capable of copying entire spans of the input to the output in one step, greatly reducing the number of decisions required during inference. This extension means that there are now many ways of generating the same output, which we handle by deriving a new objective for training and a variation of beam search for inference that explicitly handles this problem. In our experiments on a range of editing tasks of natural language and source code, we show that our new model consistently outperforms simpler baselines.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/17606,10.1609/aaai.v35i15.17606,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Speech and Natural Language Processing II,AAAI,NA
AAAI Conference on Artificial Intelligence,CORE: Automatic Molecule Optimization Using Copy & Refine Strategy,Tianfan Fu;Cao Xiao;Jimeng Sun,"Molecule optimization is about generating molecule Y with more desirable properties based on an input molecule X. The state-of-the-art approaches partition the molecules into a large set of substructures S and grow the new molecule structure by iteratively predicting which substructure from S to add. However, since the set of available substructures S is large, such an iterative prediction task is often inaccurate especially for substructures that are infrequent in the training data. To address this challenge, we propose a new generating strategy called “Copy&Refine”( CORE) , where at each step the generator first decides whether to copy an existing substructure from input X or to generate a new substructure, then the most promising substructure will be added to the new molecule. Combining together with scaffolding tree generation and adversarial training, CORE can significantly improve several latest molecule optimization methods in various measures including drug likeness( QED) , dopamine receptor( DRD2) and penalized LogP. We tested CORE and baselines using the ZINC database and CORE obtained up to 11% and 21% relatively improvement over the baselines on success rate on the complete test set and the subset with infrequent substructures, respectively.",2020,https://ojs.aaai.org/index.php/AAAI/article/view/5404,10.1609/aaai.v34i01.5404,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Applications,AAAI,NA
AAAI Conference on Artificial Intelligence,Correcting Predictions for Approximate Bayesian Inference,Tomasz Kuśmierczyk;Joseph Sakaya;Arto Klami,"Bayesian models quantify uncertainty and facilitate optimal decision-making in downstream applications. For most models, however, practitioners are forced to use approximate inference techniques that lead to sub-optimal decisions due to incorrect posterior predictive distributions. We present a novel approach that corrects for inaccuracies in posterior inference by altering the decision-making process. We train a separate model to make optimal decisions under the approximate posterior, combining interpretable Bayesian modeling with optimization of direct predictive accuracy in a principled fashion. The solution is generally applicable as a plug-in module for predictive decision-making for arbitrary probabilistic programs, irrespective of the posterior inference strategy. We demonstrate the approach empirically in several problems, confirming its potential.",2020,https://ojs.aaai.org/index.php/AAAI/article/view/5879,10.1609/aaai.v34i04.5879,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Machine Learning,AAAI,NA
AAAI Conference on Artificial Intelligence,"Counterfactual Explanations for Oblique Decision Trees:Exact, Efficient Algorithms",Miguel  Á. Carreira-Perpiñán;Suryabhan Singh Hada,"We consider counterfactual explanations, the problem of minimally adjusting features in a source input instance so that it is classified as a target class under a given classifier. This has become a topic of recent interest as a way to query a trained model and suggest possible actions to overturn its decision. Mathematically, the problem is formally equivalent to that of finding adversarial examples, which also has attracted significant attention recently. Most work on either counterfactual explanations or adversarial examples has focused on differentiable classifiers, such as neural nets. We focus on classification trees, both axis-aligned and oblique( having hyperplane splits). Although here the counterfactual optimization problem is nonconvex and nondifferentiable, we show that an exact solution can be computed very efficiently, even with high-dimensional feature vectors and with both continuous and categorical features, and demonstrate it in different datasets and settings. The results are particularly relevant for finance, medicine or legal applications, where interpretability and counterfactual explanations are particularly important.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/16851,10.1609/aaai.v35i8.16851,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Machine Learning I,AAAI,NA
AAAI Conference on Artificial Intelligence,Counterfactual Fairness Is Basically Demographic Parity,Lucas Rosenblatt;R. Teal Witter,"Making fair decisions is crucial to ethically implementing machine learning algorithms in social settings. In this work, we consider the celebrated definition of counterfactual fairness. We begin by showing that an algorithm which satisfies counterfactual fairness also satisfies demographic parity, a far simpler fairness constraint. Similarly, we show that all algorithms satisfying demographic parity can be trivially modified to satisfy counterfactual fairness. Together, our results indicate that counterfactual fairness is basically equivalent to demographic parity, which has important implications for the growing body of work on counterfactual fairness. We then validate our theoretical findings empirically, analyzing three existing algorithms for counterfactual fairness against three simple benchmarks. We find that two simple benchmark algorithms outperform all three existing algorithms---in terms of fairness, accuracy, and efficiency---on several data sets. Our analysis leads us to formalize a concrete fairness goal: to preserve the order of individuals within protected groups. We believe transparency around the ordering of individuals within protected groups makes fair algorithms more trustworthy. By design, the two simple benchmark algorithms satisfy this goal while the existing algorithms do not.",2023,https://ojs.aaai.org/index.php/AAAI/article/view/26691,10.1609/aaai.v37i12.26691,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Special Track on AI for Social Impact,AAAI,NA
AAAI Conference on Artificial Intelligence,Counterfactual Learning with General Data-Generating Policies,Yusuke Narita;Kyohei Okumura;Akihiro Shimizu;Kohei Yata,"Off-policy evaluation( OPE) attempts to predict the performance of counterfactual policies using log data from a different policy. We extend its applicability by developing an OPE method for a class of both full support and deficient support logging policies in contextual-bandit settings. This class includes deterministic bandit( such as Upper Confidence Bound) as well as deterministic decision-making based on supervised and unsupervised learning. We prove that our methods prediction converges in probability to the true performance of a counterfactual policy as the sample size increases. We validate our method with experiments on partly and entirely deterministic logging policies. Finally, we apply it to evaluate coupon targeting policies by a major online platform and show how to improve the existing policy.",2023,https://ojs.aaai.org/index.php/AAAI/article/view/26113,10.1609/aaai.v37i8.26113,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Machine Learning III,AAAI,NA
AAAI Conference on Artificial Intelligence,Counterfactual Randomization: Rescuing Experimental Studies from Obscured Confounding,Andrew Forney;Elias Bareinboim,"Randomized clinical trials( RCTs) like those conducted by the FDA provide medical practitioners with average effects of treatments, and are generally more desirable than observational studies due to their control of unobserved confounders( UCs) , viz. , latent factors that influence both treatment and recovery. However, recent results from causal inference have shown that randomization results in a subsequent loss of information about the UCs, which may impede treatment efficacy if left uncontrolled in practice( Bareinboim, Forney, and Pearl 2015). Our paper presents a novel experimental design that can be noninvasively layered atop past and future RCTs to not only expose the presence of UCs in a system, but also reveal patientand practitioner-specific treatment effects in order to improve decision-making. Applications are given to personalized medicine, second opinions in diagnosis, and employing offline results in online recommender systems.",2019,https://ojs.aaai.org/index.php/AAAI/article/view/4090,10.1609/aaai.v33i01.33012454,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Human-AI Collaboration,AAAI,NA
AAAI Conference on Artificial Intelligence,Counting-Based Reliability Estimation for Power-Transmission Grids,Leonardo Duenas-Osorio;Kuldeep Meel;Roger Paredes;Moshe Vardi,"Modern society is increasingly reliant on the functionality of infrastructure facilities and utility services. Consequently, there has been surge of interest in the problem of quantification of system reliability, which is known to be #P-complete. Reliability also contributes to the resilience of systems, so as to effectively make them bounce back after contingencies. Despite diverse progress, most techniques to estimate system reliability and resilience remain computationally expensive. In this paper, we investigate how recent advances in hashing-based approaches to counting can be exploited to improve computational techniques for system reliability. The primary contribution of this paper is a novel framework, RelNet, that reduces the problem of computing reliability for a given network to counting the number of satisfying assignments of a Σ11 formula, which is amenable to recent hashing-based techniques developed for counting satisfying assignments of SAT formula. We then apply RelNet to ten real world power-transmission grids across different cities in the U. S. and are able to obtain, to the best of our knowledge, the first theoretically sound a priori estimates of reliability between several pairs of nodes of interest. Such estimates will help managing uncertainty and support rational decision making for community resilience.",2017,https://ojs.aaai.org/index.php/AAAI/article/view/11178,10.1609/aaai.v31i1.11178,NA,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,Special Track on Computational Sustainability,AAAI,NA
AAAI Conference on Artificial Intelligence,Counting-MLNs: Learning Relational Structure for Decision Making,Aniruddh Nath;Matthew Richardson,"Many first-order probabilistic models can be represented much more compactly using aggregation operations such as counting. While traditional statistical relational representations share factors across sets of interchangeable random variables, representations that explicitly model aggregations also exploit interchangeability of random variables within factors. This is especially useful in decision making settings, where an agent might need to reason about counts of the different types of objects it interacts with. Previous work on counting formulas in statistical relational representations has mostly focused on the problem of exact inference on an existing model. The problem of learning such models is largely unexplored. In this paper, we introduce Counting Markov Logic Networks( C-MLNs) , an extension of Markov logic networks that can compactly represent complex counting formulas. We present a structure learning algorithm for C-MLNs; we apply this algorithm to the novel problem of generalizing natural language instructions, and to relational reinforcement learning in the Crossblock domain, in which standard MLN learning algorithms fail to find any useful structure. The C-MLN policies learned from natural language instructions are compact and intuitive, and, despite requiring no instructions on test games, win 20% more Crossblock games than a state-of-the-art algorithm for following natural language instructions.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/8318,10.1609/aaai.v26i1.8318,7,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Machine Learning,AAAI,NA
AAAI Conference on Artificial Intelligence,Covering Number as a Complexity Measure for POMDP Planning and Learning,Zongzhang Zhang;Michael Littman;Xiaoping Chen,"Finding a meaningful way of characterizing the difficulty of partially observable Markov decision processes( POMDPs) is a core theoretical problem in POMDP research. State-space size is often used as a proxy for POMDP difficulty, but it is a weak metric at best. Existing work has shown that the covering number for the reachable belief space, which is a set of belief points that are reachable from the initial belief point, has interesting links with the complexity of POMDP planning, theoretically. In this paper, we present empirical evidence that the covering number for the reachable belief space( or just ``covering number, for brevity) is a far better complexity measure than the state-space size for both planning and learning POMDPs on several small-scale benchmark problems. We connect the covering number to the complexity of learning POMDPs by proposing a provably convergent learning algorithm for POMDPs without reset given knowledge of the covering number.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/8360,10.1609/aaai.v26i1.8360,7,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,"Reasoning about Plans, Processes and Actions",AAAI,NA
AAAI Conference on Artificial Intelligence,Critic-Guided Decision Transformer for Offline Reinforcement Learning,Yuanfu Wang;Chao Yang;Ying Wen;Yu Liu;Yu Qiao,"Recent advancements in offline reinforcement learning( RL) have underscored the capabilities of Return-Conditioned Supervised Learning( RCSL) , a paradigm that learns the action distribution based on target returns for each state in a supervised manner. However, prevailing RCSL methods largely focus on deterministic trajectory modeling, disregarding stochastic state transitions and the diversity of future trajectory distributions. A fundamental challenge arises from the inconsistency between the sampled returns within individual trajectories and the expected returns across multiple trajectories. Fortunately, value-based methods offer a solution by leveraging a value function to approximate the expected returns, thereby addressing the inconsistency effectively. Building upon these insights, we propose a novel approach, termed the Critic-Guided Decision Transformer( CGDT) , which combines the predictability of long-term returns from value-based methods with the trajectory modeling capability of the Decision Transformer. By incorporating a learned value function, known as the critic, CGDT ensures a direct alignment between the specified target returns and the expected returns of actions. This integration bridges the gap between the deterministic nature of RCSL and the probabilistic characteristics of value-based methods. Empirical evaluations on stochastic environments and D4RL benchmark datasets demonstrate the superiority of CGDT over traditional RCSL methods. These results highlight the potential of CGDT to advance the state of the art in offline RL and extend the applicability of RCSL to a wide range of RL tasks.",2024,https://ojs.aaai.org/index.php/AAAI/article/view/29499,10.1609/aaai.v38i14.29499,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Machine Learning V,AAAI,NA
AAAI Conference on Artificial Intelligence,Cross-Class Feature Augmentation for Class Incremental Learning,Taehoon Kim;Jaeyoo Park;Bohyung Han,"We propose a novel class incremental learning approach, which incorporates a feature augmentation technique motivated by adversarial attacks. We employ a classifier learned in the past to complement training examples of previous tasks. The proposed approach has an unique perspective to utilize the previous knowledge in class incremental learning since it augments features of arbitrary target classes using examples in other classes via adversarial attacks on a previously learned classifier. By allowing the Cross-Class Feature Augmentations( CCFA) , each class in the old tasks conveniently populates samples in the feature space, which alleviates the collapse of the decision boundaries caused by sample deficiency for the previous tasks, especially when the number of stored exemplars is small. This idea can be easily incorporated into existing class incremental learning algorithms without any architecture modification. Extensive experiments on the standard benchmarks show that our method consistently outperforms existing class incremental learning methods by significant margins in various scenarios, especially under an environment with an extremely limited memory budget.",2024,https://ojs.aaai.org/index.php/AAAI/article/view/29216,10.1609/aaai.v38i12.29216,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Machine Learning III,AAAI,NA
AAAI Conference on Artificial Intelligence,Cross-Constrained Progressive Inference for 3D Hand Pose Estimation with Dynamic Observer-Decision-Adjuster Networks,Zhehan Kan;Xueting Hu;Zihan Liao;Ke Yu;Zhihai He,"Generalization is very important for pose estimation, especially for 3D pose estimation where small changes in the 2D images could trigger structural changes in the 3D space. To achieve generalization, the system needs to have the capability of detecting estimation errors by double-checking the projection coherence between the 3D and 2D spaces and adapting its network inference process based on this feedback. Current pose estimation is one-time feed-forward and lacks the capability to gather feedback and adapt the inference outcome. To address this problem, we propose to explore the concept of progressive inference where the network learns an observer to continuously detect the prediction error based on constraints matching, as well as an adjuster to refine its inference outcome based on these constraints errors. Within the context of 3D hand pose estimation, we find that this observer-adjuster design is relatively unstable since the observer is operating in the 2D image domain while the adjuster is operating in the 3D domain. To address this issue, we propose to construct two sets of observers-adjusters with complementary constraints from different perspectives. They operate in a dynamic sequential manner controlled by a decision network to progressively improve the 3D pose estimation. We refer to this method as Cross-Constrained Progressive Inference( CCPI). Our extensive experimental results on FreiHAND and HO-3D benchmark datasets demonstrate that the proposed CCPI method is able to significantly improve the generalization capability and performance of 3D hand pose estimation.",2024,https://ojs.aaai.org/index.php/AAAI/article/view/28048,10.1609/aaai.v38i3.28048,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Computer Vision II,AAAI,NA
AAAI Conference on Artificial Intelligence,Cross-Oilfield Reservoir Classification via Multi-Scale Sensor Knowledge Transfer,Zhi Li;Zhefeng Wang;Zhicheng Wei;Xiangguang Zhou;Yijun Wang;Baoxing Huai;Qi Liu;Nicholas Jing Yuan;Renbin Gong;Enhong Chen,"Reservoir classification is an essential step for the exploration and production process in the oil and gas industry. An appropriate automatic reservoir classification will not only reduce the manual workloads of experts, but also help petroleum companies to make optimal decisions efficiently, which in turn will dramatically reduce the costs. Existing methods mainly focused on generating reservoir classification in a single geological block but failed to work well on a new oilfield block. Indeed, how to transfer the subsurface characteristics and make accurate reservoir classification across the geological oilfields is a very important but challenging problem. To that end, in this paper, we present a focused study on the cross-oilfield reservoir classification task. Specifically, we first propose a Multi-scale Sensor Extraction( MSE) to extract the multi-scale feature representations of geological characteristics from multivariate well logs. Furthermore, we design an encoder-decoder module, Specific Feature Learning( SFL) , to take advantage of specific information of both oilfields. Then, we develop a Knowledge-Attentive Transfer( KAT) module to learn the feature-invariant representation and transfer the geological knowledge from a source oilfield to a target oilfield. Finally, we evaluate our approaches by conducting extensive experiments with real-world industrial datasets. The experimental results clearly demonstrate the effectiveness of our proposed approaches to transfer the geological knowledge and generate the cross-oilfield reservoir classifications.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/16545,10.1609/aaai.v35i5.16545,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Data Mining and Knowledge Management,AAAI,NA
AAAI Conference on Artificial Intelligence,Crowd Counting with Decomposed Uncertainty,Min-hwan Oh;Peder Olsen;Karthikeyan Natesan Ramamurthy,"Research in neural networks in the field of computer vision has achieved remarkable accuracy for point estimation. However, the uncertainty in the estimation is rarely addressed. Uncertainty quantification accompanied by point estimation can lead to a more informed decision, and even improve the prediction quality. In this work, we focus on uncertainty estimation in the domain of crowd counting. With increasing occurrences of heavily crowded events such as political rallies, protests, concerts, etc. , automated crowd analysis is becoming an increasingly crucial task. The stakes can be very high in many of these real-world applications. We propose a scalable neural network framework with quantification of decomposed uncertainty using a bootstrap ensemble. We demonstrate that the proposed uncertainty quantification method provides additional insight to the crowd counting problem and is simple to implement. We also show that our proposed method exhibits state-of-the-art performances in many benchmark crowd counting datasets.",2020,https://ojs.aaai.org/index.php/AAAI/article/view/6852,10.1609/aaai.v34i07.6852,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Vision,AAAI,NA
AAAI Conference on Artificial Intelligence,Crowdfunding Dynamics Tracking: A Reinforcement Learning Approach,Jun Wang;Hefu Zhang;Qi Liu;Zhen Pan;Hanqing Tao,"Recent years have witnessed the increasing interests in research of crowdfunding mechanism. In this area, dynamics tracking is a significant issue but is still under exploration. Existing studies either fit the fluctuations of time-series or employ regularization terms to constrain learned tendencies. However, few of them take into account the inherent decision-making process between investors and crowdfunding dynamics. To address the problem, in this paper, we propose a Trajectory-based Continuous Control for Crowdfunding( TC3) algorithm to predict the funding progress in crowdfunding. Specifically, actor-critic frameworks are employed to model the relationship between investors and campaigns, where all of the investors are viewed as an agent that could interact with the environment derived from the real dynamics of campaigns. Then, to further explore the in-depth implications of patterns( i. e. , typical characters) in funding series, we propose to subdivide them into fast-growing and slow-growing ones. Moreover, for the purpose of switching from different kinds of patterns, the actor component of TC3 is extended with a structure of options, which comes to the TC3-Options. Finally, extensive experiments on the Indiegogo dataset not only demonstrate the effectiveness of our methods, but also validate our assumption that the entire pattern learned by TC3-Options is indeed the U-shaped one.",2020,https://ojs.aaai.org/index.php/AAAI/article/view/6087,10.1609/aaai.v34i04.6087,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Machine Learning,AAAI,NA
AAAI Conference on Artificial Intelligence,CTO-SLAM: Contour Tracking for Object-Level Robust 4D SLAM,Xiaohan Li;Dong Liu;Jun Wu,"The demand for 4D( 3D+time) SLAM system is increasingly urgent, especially for decision-making and scene understanding. However, most of the existing simultaneous localization and mapping( SLAM) systems primarily assume static environments. They fail to represent dynamic scenarios due to the challenge of establishing robust long-term spatiotemporal associations in dynamic object tracking. We address this limitation and propose CTO-SLAM, a monocular and RGB-D object-level 4D SLAM system to track moving objects and estimate their motion simultaneously. In this paper, we propose contour tracking, which introduces contour features to enhance the keypoint representation of dynamic objects and coupled with pixel tracking to achieve long-term robust object tracking. Based on contour tracking, we propose a novel sampling-based object pose initialization algorithm and the following adapted bundle adjustment( BA) optimization algorithm to estimate dynamic object poses with high accuracy. The CTO-SLAM system is verified on both KITTI and VKITTI datasets. The experimental results demonstrate that our system effectively addresses cumulative errors in long-term spatiotemporal association and hence obtains substantial improvements over the state-of-the-art systems. The source code is available at https://github. com/realXiaohan/CTO-SLAM.",2024,https://ojs.aaai.org/index.php/AAAI/article/view/28899,10.1609/aaai.v38i9.28899,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,Intelligent Robots( ROB),AAAI,NA
AAAI Conference on Artificial Intelligence,Cumulative Difference Learning VAE for Time-Series with Temporally Correlated Inflow-Outflow,Tianchun Li;Chengxiang Wu;Pengyi Shi;Xiaoqian Wang,"Time-series generation has crucial practical significance for decision-making under uncertainty. Existing methods have various limitations like accumulating errors over time, significantly impacting downstream tasks. We develop a novel generation method, DT-VAE, that incorporates generalizable domain knowledge, is mathematically justified, and significantly outperforms existing methods by mitigating error accumulation through a cumulative difference learning mechanism. We evaluate the performance of DT-VAE on several downstream tasks using both semi-synthetic and real time-series datasets, including benchmark datasets and our newly curated COVID-19 hospitalization datasets. The COVID-19 datasets enrich existing resources for time-series analysis. Additionally, we introduce Diverse Trend Preserving( DTP) , a time-series clustering-based evaluation for direct and interpretable assessments of generated samples, serving as a valuable tool for evaluating time-series generative models.",2024,https://ojs.aaai.org/index.php/AAAI/article/view/29266,10.1609/aaai.v38i12.29266,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Machine Learning III,AAAI,NA
AAAI Conference on Artificial Intelligence,Curriculum Temperature for Knowledge Distillation,Zheng Li;Xiang Li;Lingfeng Yang;Borui Zhao;Renjie Song;Lei Luo;Jun Li;Jian Yang,"Most existing distillation methods ignore the flexible role of the temperature in the loss function and fix it as a hyper-parameter that can be decided by an inefficient grid search. In general, the temperature controls the discrepancy between two distributions and can faithfully determine the difficulty level of the distillation task. Keeping a constant temperature, i. e. , a fixed level of task difficulty, is usually sub-optimal for a growing student during its progressive learning stages. In this paper, we propose a simple curriculum-based technique, termed Curriculum Temperature for Knowledge Distillation( CTKD) , which controls the task difficulty level during the students learning career through a dynamic and learnable temperature. Specifically, following an easy-to-hard curriculum, we gradually increase the distillation loss w. r. t. the temperature, leading to increased distillation difficulty in an adversarial manner. As an easy-to-use plug-in technique, CTKD can be seamlessly integrated into existing knowledge distillation frameworks and brings general improvements at a negligible additional computation cost. Extensive experiments on CIFAR-100, ImageNet-2012, and MS-COCO demonstrate the effectiveness of our method.",2023,https://ojs.aaai.org/index.php/AAAI/article/view/25236,10.1609/aaai.v37i2.25236,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Computer Vision II,AAAI,NA
AAAI Conference on Artificial Intelligence,Curved Representation Space of Vision Transformers,Juyeop Kim;Junha Park;Songkuk Kim;Jong-Seok Lee,"Neural networks with self-attention( a. k. a. Transformers) like ViT and Swin have emerged as a better alternative to traditional convolutional neural networks( CNNs). However, our understanding of how the new architecture works is still limited. In this paper, we focus on the phenomenon that Transformers show higher robustness against corruptions than CNNs, while not being overconfident. This is contrary to the intuition that robustness increases with confidence. We resolve this contradiction by empirically investigating how the output of the penultimate layer moves in the representation space as the input data moves linearly within a small area. In particular, we show the following. ( 1) While CNNs exhibit fairly linear relationship between the input and output movements, Transformers show nonlinear relationship for some data. For those data, the output of Transformers moves in a curved trajectory as the input moves linearly. ( 2) When a data is located in a curved region, it is hard to move it out of the decision region since the output moves along a curved trajectory instead of a straight line to the decision boundary, resulting in high robustness of Transformers. ( 3) If a data is slightly modified to jump out of the curved region, the movements afterwards become linear and the output goes to the decision boundary directly. In other words, there does exist a decision boundary near the data, which is hard to find only because of the curved representation space. This explains the underconfident prediction of Transformers. Also, we examine mathematical properties of the attention operation that induce nonlinear response to linear perturbation. Finally, we share our additional findings, regarding what contributes to the curved representation space of Transformers, and how the curvedness evolves during training.",2024,https://ojs.aaai.org/index.php/AAAI/article/view/29213,10.1609/aaai.v38i12.29213,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Machine Learning III,AAAI,NA
AAAI Conference on Artificial Intelligence,CUTS+: High-Dimensional Causal Discovery from Irregular Time-Series,Yuxiao Cheng;Lianglong Li;Tingxiong Xiao;Zongren Li;Jinli Suo;Kunlun He;Qionghai Dai,"Causal discovery in time-series is a fundamental problem in the machine learning community, enabling causal reasoning and decision-making in complex scenarios. Recently, researchers successfully discover causality by combining neural networks with Granger causality, but their performances degrade largely when encountering high-dimensional data because of the highly redundant network design and huge causal graphs. Moreover, the missing entries in the observations further hamper the causal structural learning. To overcome these limitations, We propose CUTS+, which is built on the Granger-causality-based causal discovery method CUTS and raises the scalability by introducing a technique called Coarse-to-fine-discovery( C2FD) and leveraging a message-passing-based graph neural network( MPGNN). Compared to previous methods on simulated, quasi-real, and real datasets, we show that CUTS+ largely improves the causal discovery performance on high-dimensional data with different types of irregular sampling.",2024,https://ojs.aaai.org/index.php/AAAI/article/view/29034,10.1609/aaai.v38i10.29034,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Machine Learning I,AAAI,NA
AAAI Conference on Artificial Intelligence,Cyclically Disentangled Feature Translation for Face Anti-spoofing,Haixiao Yue;Keyao Wang;Guosheng Zhang;Haocheng Feng;Junyu Han;Errui Ding;Jingdong Wang,"Current domain adaptation methods for face anti-spoofing leverage labeled source domain data and unlabeled target domain data to obtain a promising generalizable decision boundary. However, it is usually difficult for these methods to achieve a perfect domain-invariant liveness feature disentanglement, which may degrade the final classification performance by domain differences in illumination, face category, spoof type, etc. In this work, we tackle cross-scenario face anti-spoofing by proposing a novel domain adaptation method called cyclically disentangled feature translation network( CDFTN). Specifically, CDFTN generates pseudo-labeled samples that possess: 1) source domain-invariant liveness features and 2) target domain-specific content features, which are disentangled through domain adversarial training. A robust classifier is trained based on the synthetic pseudo-labeled images under the supervision of source domain labels. We further extend CDFTN for multi-target domain adaptation by leveraging data from more unlabeled target domains. Extensive experiments on several public datasets demonstrate that our proposed approach significantly outperforms the state of the art. Code and models are available at https://github. com/vis-face/CDFTN.",2023,https://ojs.aaai.org/index.php/AAAI/article/view/25443,10.1609/aaai.v37i3.25443,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Computer Vision III,AAAI,NA
AAAI Conference on Artificial Intelligence,Dancing with Decision Diagrams: A Combined Approach to Exact Cover,Masaaki Nishino;Norihito Yasuda;Shin-ichi Minato;Masaaki Nagata,"Exact cover is the problem of finding subfamilies, S*, of a family of sets, S, over universe U, where S* forms a partition of U. It is a popular NP-hard problem appearing in a wide range of computer science studies. Knuths algorithm DLX, a backtracking-based depth-first search implemented with the data structure called dancing links, is known as state-of-the-art for finding all exact covers. We propose a method to accelerate DLX. Our method constructs a Zero-suppressed Binary Decision Diagram( ZDD) that represents the set of solutions while running depth-first search in DLX. Constructing ZDDs enables the efficient use of memo cache to speed up the search. Moreover, our method has a virtue that it outputs ZDDs; we can perform several useful operations with them. Experiments confirm that the proposed method is up to several orders of magnitude faster than DLX.",2017,https://ojs.aaai.org/index.php/AAAI/article/view/10662,10.1609/aaai.v31i1.10662,NA,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Heuristic Search and Optimization,AAAI,NA
AAAI Conference on Artificial Intelligence,DAST: Unsupervised Domain Adaptation in Semantic Segmentation Based on Discriminator Attention and Self-Training,Fei Yu;Mo Zhang;Hexin Dong;Sheng Hu;Bin Dong;Li Zhang,"Unsupervised domain adaption has recently been used to reduce the domain shift, which would ultimately improve the performance of the semantic segmentation on unlabeled real-world data. In this paper, we follow the trend to propose a novel method to reduce the domain shift using strategies of discriminator attention and self-training. The discriminator attention strategy contains a two-stage adversarial learning process, which explicitly distinguishes the well-aligned( domain-invariant) and poorly-aligned( domain-specific) features, and then guides the model to focus on the latter. The self-training strategy adaptively improves the decision boundary of the model for the target domain, which implicitly facilitates the extraction of domain-invariant features. By combining the two strategies, we find a more effective way to reduce the domain shift. Extensive experiments demonstrate the effectiveness of the proposed method on numerous benchmark datasets.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/17285,10.1609/aaai.v35i12.17285,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Machine Learning V,AAAI,NA
AAAI Conference on Artificial Intelligence,Data-Driven Structural Fire Risk Prediction for City Properties,Rupasree Dey;Alan Fern,"Fire Departments conduct inspections to prevent fires but it is unclear how to best allocate their limited inspection resources across the properties in a city. Currently, they use their intuition and experience to decide on which properties to inspect and lack a data-driven approach that could lead to a more principled use of inspection resources. The main contribution of this paper is to investigate such an approach, based on machine learning for predicting a fire risk score for properties in a city based on historical fire-incident data. These scores can then be used to help prioritize inspection resources toward higher-risk properties. We present a case study using data from a South Dakota fire department which contains information about properties in a city along with records of fire inincidents. We use this data consisting of more than 72, 000 properties to train a machine learning model to predict fire risk and evaluate its ability to rank the fire risk of properties in the city. We conduct and analyze experiments with variations of XG-Boost, which is an algorithm well-suited to the challenges in application, including missing data and a highly-skewed class distribution. Our evaluation of the model-generated rankings, based on ranking metrics, shows that the model significantly outperforms random rankings and other natural baselines. We also analyze the feature importance computed for the models, which provides further insight into the model behavior. This model has been integrated into an interface for displaying the rankings across a city and is ready for beta testing.",2024,https://ojs.aaai.org/index.php/AAAI/article/view/30325,10.1609/aaai.v38i21.30325,7,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,IAAI Technical Track on Emerging Applications of AI,AAAI,NA
AAAI Conference on Artificial Intelligence,Dec-SGTS: Decentralized Sub-Goal Tree Search for Multi-Agent Coordination,Minglong Li;Zhongxuan Cai;Wenjing Yang;Lixia Wu;Yinghui Xu;Ji Wang,"Multi-agent coordination tends to benefit from efficient communication, where cooperation often happens based on exchanging information about what the agents intend to do, i. e. intention sharing. It becomes a key problem to model the intention by some proper abstraction. Currently, it is either too coarse such as final goals or too fined as primitive steps, which is inefficient due to the lack of modularity and semantics. In this paper, we design a novel multi-agent coordination protocol based on subgoal intentions, defined as the probability distribution over feasible subgoal sequences. The subgoal intentions encode macro-action behaviors with modularity so as to facilitate joint decision making at higher abstraction. Built over the proposed protocol, we present Dec-SGTS( Decentralized Sub-Goal Tree Search) to solve decentralized online multi-agent planning hierarchically and efficiently. Each agent runs Dec-SGTS asynchronously by iteratively performing three phases including local sub-goal tree search, local subgoal intention update and global subgoal intention sharing. We conduct the experiments on courier dispatching problem, and the results show that Dec-SGTS achieves much better reward while enjoying a significant reduction of planning time and communication cost compared with Dec-MCTS( Decentralized Monte Carlo Tree Search).",2021,https://ojs.aaai.org/index.php/AAAI/article/view/17345,10.1609/aaai.v35i13.17345,8,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Multiagent Systems,AAAI,NA
AAAI Conference on Artificial Intelligence,Decentralized Monte Carlo Tree Search for Partially Observable Multi-Agent Pathfinding,Alexey Skrynnik;Anton Andreychuk;Konstantin Yakovlev;Aleksandr Panov,"The Multi-Agent Pathfinding( MAPF) problem involves finding a set of conflict-free paths for a group of agents confined to a graph. In typical MAPF scenarios, the graph and the agents starting and ending vertices are known beforehand, allowing the use of centralized planning algorithms. However, in this study, we focus on the decentralized MAPF setting, where the agents may observe the other agents only locally and are restricted in communications with each other. Specifically, we investigate the lifelong variant of MAPF, where new goals are continually assigned to the agents upon completion of previous ones. Drawing inspiration from the successful AlphaZero approach, we propose a decentralized multi-agent Monte Carlo Tree Search( MCTS) method for MAPF tasks. Our approach utilizes the agents observations to recreate the intrinsic Markov decision process, which is then used for planning with a tailored for multi-agent tasks version of neural MCTS. The experimental results show that our approach outperforms state-of-the-art learnable MAPF solvers. The source code is available at https://github. com/AIRI-Institute/mats-lp.",2024,https://ojs.aaai.org/index.php/AAAI/article/view/29703,10.1609/aaai.v38i16.29703,10,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Multiagent Systems,AAAI,NA
AAAI Conference on Artificial Intelligence,Decentralized Planning in Stochastic Environments with Submodular Rewards,Rajiv Kumar;Pradeep Varakantham;Akshat Kumar,"Decentralized Markov Decision Process( Dec-MDP) provides a rich framework to represent cooperative decentralized and stochastic planning problems under transition uncertainty. However, solving a Dec-MDP to generate coordinated yet decentralized policies is NEXP-Hard. Researchers have made significant progress in providing approximate approaches to improve scalability with respect to number of agents. However, there has been little or no research devoted to finding guarantees on solution quality for approximate approaches considering multiple( more than 2 agents) agents. We have a similar situation with respect to the competitive decentralized planning problem and the Stochastic Game( SG) model. To address this, we identify models in the cooperative and competitive case that rely on submodular rewards, where we show that existing approximate approaches can provide strong quality guarantees( a priori, and for cooperative case also posteriori guarantees). We then provide solution approaches and demonstrate improved online guarantees on benchmark problems from the literature for the cooperative case.",2017,https://ojs.aaai.org/index.php/AAAI/article/view/10709,10.1609/aaai.v31i1.10709,NA,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track: Multiagent Systems,AAAI,NA
AAAI Conference on Artificial Intelligence,Decentralized Policy Gradient Descent Ascent for Safe Multi-Agent Reinforcement Learning,Songtao Lu;Kaiqing Zhang;Tianyi Chen;Tamer Başar;Lior Horesh,"This paper deals with distributed reinforcement learning problems with safety constraints. In particular, we consider that a team of agents cooperate in a shared environment, where each agent has its individual reward function and safety constraints that involve all agents joint actions. As such, the agents aim to maximize the team-average long-term return, subject to all the safety constraints. More intriguingly, no central controller is assumed to coordinate the agents, and both the rewards and constraints are only known to each agent locally/privately. Instead, the agents are connected by a peer-to-peer communication network to share information with their neighbors. In this work, we first formulate this problem as a distributed constrained Markov decision process( D-CMDP) with networked agents. Then, we propose a decentralized policy gradient( PG) method, Safe Dec-PG, to perform policy optimization based on this D-CMDP model over a network. Convergence guarantees, together with numerical results, showcase the superiority of the proposed algorithm. To the best of our knowledge, this is the first decentralized PG algorithm that accounts for the coupled safety constraints with a quantifiable convergence rate in multi-agent reinforcement learning. Finally, we emphasize that our algorithm is also novel in solving a class of decentralized stochastic nonconvex-concave minimax optimization problems, where both the algorithm design and corresponding theoretical analysis are of independent interest.",2021,https://ojs.aaai.org/index.php/AAAI/article/view/17062,10.1609/aaai.v35i10.17062,9,top-tier,yes,artificial intelligence,0.9,"The AAAI Conference on Artificial Intelligence is a leading conference in AI. It is known for its rigorous peer review process and significant impact within the research community, helping to establish it as a top-tier venue.",aaai_venues.csv,Proceedings of the AAAI Conference on Artificial Intelligence,AAAI Technical Track on Machine Learning III,AAAI,NA
AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment,Anthology: A Social Simulation Framework,Sasha Azad;Jennifer Wellnitz;Luis Garcia;Chris Martens,"Social simulation research seeks to understand the dynamics of complex human behavior by simulating populations of individual decision-makers as multi-agent systems. However, prior work in games and entertainment fail to account for interactions between social behavior, geography, and relationships in a manner that allows researchers to easily reuse their frameworks and model social characters. We present Anthology, an extensible software framework for modeling human social systems, within the context of an ongoing research agenda to integrate AI techniques from social simulation games and computational social science to enable researchers to model and reason about the complex dynamics of human social behavior. Anthology comprises a motive-based agent decision making algorithm; a knowledge representation system for relationships; a flexible specification language for precondition-effect-style actions; a user interface to inspect and interact with the simulation as it runs in real-time; and an extensive user documentation and reference manual. We describe our participatory research design process used for the developing Anthology, the state of the current system, its limitations and our future development directions.",2022,https://ojs.aaai.org/index.php/AIIDE/article/view/21967,10.1609/aiide.v18i1.21967,8,top-tier,yes,"artificial intelligence, interactive entertainment",0.9,"The AAAI Conference on AI and Interactive Digital Entertainment is recognized as a top-tier venue for research at the intersection of AI and entertainment, known for rigorous peer-review and high-impact papers.",aaai_venues.csv,AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment,Software Track Papers,AAAI,NA
AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment,Creative Wand: A System to Study Effects of Communications in Co-creative Settings,Zhiyu Lin;Rohan Agarwal;Mark Riedl,"Recent neural generation systems have demonstrated the potential for procedurally generating game content, images, stories, and more. However, most neural generation algorithms are “uncontrolled” in the sense that the user has little say in creative decisions beyond the initial prompt specification. Co-creative, mixed-initiative systems require user-centric means of influencing the algorithm, especially when users are unlikely to have machine learning expertise. The key to co-creative systems is the ability to communicate ideas and intent from the user to the agent, as well as from the agent to the user. Key questions in co-creative AI include: How can users express their creative intentions? How can creative AI systems communicate their beliefs, explain their moves, or instruct users to act on their behalf? When should creative AI systems take initiative? The answer to such questions and more will enable us to develop better co-creative systems that make humans more capable of expressing their creative intents. We introduce CREATIVE-WAND, a customizable framework for investigating co-creative mixed-initiative generation. CREATIVE-WAND enables plug-and-play injection of generative models and human-agent communication channels into a chat-based interface. It provides a number of dimensions along which an AI generator and humans can communicate during the co-creative process. We illustrate the CREATIVE-WAND framework by using it to study one dimension of co-creative communication—global versus local creative intent specification by the user—in the context of storytelling.",2022,https://ojs.aaai.org/index.php/AIIDE/article/view/21946,10.1609/aiide.v18i1.21946,8,top-tier,yes,"artificial intelligence, interactive entertainment",0.9,"The AAAI Conference on AI and Interactive Digital Entertainment is recognized as a top-tier venue for research at the intersection of AI and entertainment, known for rigorous peer-review and high-impact papers.",aaai_venues.csv,AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment,Research Track Papers,AAAI,NA
AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment,Evaluating the Efficacy of LLMs to Emulate Realistic Human Personalities,Lawrence J. Klinkert;Steph Buongiorno;Corey Clark,"To enhance immersion and engagement in video games, the design of Affective Non-Player Characters( NPCs) is a key focus for researchers and practitioners. Affective Computing frameworks improve Non-player characters( NPC) by providing personalities, emotions, and social relations. Large Language Models( LLMs) bring the promise to dynamically enhance character design when coupled with these frameworks, but further research is needed to validate the models truly represent human qualities. In this research, a comprehensive analysis investigates the capabilities of LLMs to generate content that aligns with human personality, using the Big Five and human responses from the International Personality Item Pool( IPIP) questionnaire. Our goal is to benchmark the performance of various LLMs, including frontier models and local models, against an extensive dataset comprising over 50, 000 human surveys of self-reported personality tests to determine whether LLMs can replicate human-like decision-making with personality-driven prompts. A range of personality profiles were used to cluster the test results from the human survey dataset. Our methodology involved prompting LLMs with self-evaluated test items for each personality profile, comparing their outputs to human baseline responses, and evaluating the accuracy and consistency. Our findings show that some local models had 0% alignment of any personality profiles when compared to the human dataset, while the frontier models, in some cases, had 100% alignment. The results indicate that NPCs can successfully emulate human-like personality traits using LLMs, as demonstrated by benchmarking the LLMs output against human data. This foundational work serves as a methodology for game developers and researchers to test and evaluate LLMs, ensuring they accurately represent the desired human personalities and can be expanded for further validation.",2024,https://ojs.aaai.org/index.php/AIIDE/article/view/31867,10.1609/aiide.v20i1.31867,11,top-tier,yes,"artificial intelligence, interactive entertainment",0.9,"The AAAI Conference on AI and Interactive Digital Entertainment is recognized as a top-tier venue for research at the intersection of AI and entertainment, known for rigorous peer-review and high-impact papers.",aaai_venues.csv,AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment,Full Technical,AAAI,NA
"AAAI/ACM Conference on AI, Ethics, and Society",A Geometric Solution to Fair Representations,"He, Yuzi; Burghardt, Keith; Lerman, Kristina","To reduce human error and prejudice, many high-stakes decisions have been turned over to machine algorithms. However, recent research suggests that this does not remove discrimination, and can perpetuate harmful stereotypes. While algorithms have been developed to improve fairness, they typically face at least one of three shortcomings: they are not interpretable, their prediction quality deteriorates quickly compared to unbiased equivalents, and %the methodology cannot easily extend other algorithms they are not easily transferable across models% (e.g., methods to reduce bias in random forests cannot be extended to neural networks) . To address these shortcomings, we propose a geometric method that removes correlations between data and any number of protected variables. Further, we can control the strength of debiasing through an adjustable parameter to address the trade-off between prediction quality and fairness. The resulting features are interpretable and can be used with many popular models, such as linear regression, random forest, and multilayer perceptrons. The resulting predictions are found to be more accurate and fair compared to several state-of-the-art fair AI algorithms across a variety of benchmark datasets. Our work shows that debiasing data is a simple and effective solution toward improving fairness.",2020,https://doi.org/10.1145/3375627.3375864,10.1145/3375627.3375864,7,top-tier,yes,ai and ethics,0.9,"This conference is a collaboration between AAAI and ACM, known for high-quality, impactful research. It draws top scholars in AI and ethics, indicating a high standard of peer review and a significant reputation in its field.",acm_venues.csv,"Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society",NA,ACM,NA
"AAAI/ACM Conference on AI, Ethics, and Society",A Just Approach Balancing Rawlsian Leximax Fairness and Utilitarianism,"Chen, Violet (Xinying); Hooker, J. N.","Numerous AI-assisted resource allocation decisions need to balance the conflicting goals of fairness and efficiency. Our paper studies the challenging task of defining and modeling a proper fairness-efficiency trade off. We define fairness with Rawlsian leximax fairness, which views the lexicographic maximum among all feasible outcomes as the most equitable; and define efficiency with Utilitarianism, which seeks to maximize the sum of utilities received by entities regardless of individual differences. Motivated by a justice-driven trade off principle: prioritize fairness to benefit the less advantaged unless too much efficiency is sacrificed, we propose a sequential optimization procedure to balance leximax fairness and utilitarianism in decision-making. Each iteration of our approach maximizes a social welfare function, and we provide a practical mixed integer/linear programming (MILP) formulation for each maximization problem. We illustrate our method on a budget allocation example. Compared with existing approaches of balancing equity and efficiency, our method is more interpretable in terms of parameter selection, and incorporates a strong equity criterion with a thoroughly balanced perspective.",2020,https://doi.org/10.1145/3375627.3375844,10.1145/3375627.3375844,7,top-tier,yes,ai and ethics,0.9,"This conference is a collaboration between AAAI and ACM, known for high-quality, impactful research. It draws top scholars in AI and ethics, indicating a high standard of peer review and a significant reputation in its field.",acm_venues.csv,"Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society",NA,ACM,NA
"AAAI/ACM Conference on AI, Ethics, and Society",Algorithmic Fairness from a Non-ideal Perspective,"Fazelpour, Sina; Lipton, Zachary C.","Inspired by recent breakthroughs in predictive modeling, practitioners in both industry and government have turned to machine learning with hopes of operationalizing predictions to drive automated decisions. Unfortunately, many social desiderata concerning consequential decisions, such as justice or fairness, have no natural formulation within a purely predictive framework. In the hopes of mitigating these problems, researchers have proposed a variety of metrics for quantifying deviations from various statistical parities that we might hope to observe in a fair world, offering a variety of algorithms that attempt to satisfy subsets of these parities or to trade off the degree to which they are satisfied against utility. In this paper, we connect this approach to fair machine learning to the literature on ideal and non-ideal methodological approaches in political philosophy. The ideal approach requires positing the principles according to which a just world would operate. In the most straightforward application of ideal theory, one supports a proposed policy by arguing that it closes a discrepancy between the real and ideal worlds. However, by failing to account for the mechanisms by which our non-ideal world arose, the responsibilities of various decision-makers, and the impacts of their actions, naive applications of ideal thinking can lead to misguided policies. In this paper, we demonstrate a connection between the recent literature on fair machine learning and the ideal approach in political philosophy, and show that some recently uncovered shortcomings in proposed algorithms reflect broader troubles faced by the ideal approach. We work this analysis through for different formulations of fairness and conclude with a critical discussion of real-world impacts and directions for new research.",2020,https://doi.org/10.1145/3375627.3375828,10.1145/3375627.3375828,7,top-tier,yes,ai and ethics,0.9,"This conference is a collaboration between AAAI and ACM, known for high-quality, impactful research. It draws top scholars in AI and ethics, indicating a high standard of peer review and a significant reputation in its field.",acm_venues.csv,"Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society",NA,ACM,NA
"AAAI/ACM Conference on AI, Ethics, and Society",An Invitation to System-wide Algorithmic Fairness,"Cruz Cortés, Efrén; Ghosh, Debashis","We propose a framework for analyzing and evaluating system-wide algorithmic fairness. The core idea is to use simulation techniques in order to extend the scope of current fairness assessments by incorporating context and feedback to a phenomenon of interest. By doing so, we expect to better understand the interaction among the social behavior giving rise to discrimination, automated decision making tools, and fairness-inspired statistical constraints. In particular, we invite the community to use agent based models as an explanatory tool for causal mechanisms of population level properties. We also propose embedding these into a reinforcement learning algorithm to find optimal actions for meaningful change. As an incentive for taking a system-wide approach , we show through a simple model of predictive policing and trials that if we limit our attention to one portion of the system, we may determine some blatantly unfair practices as fair, and be blind to overall unfairness.",2020,https://doi.org/10.1145/3375627.3375860,10.1145/3375627.3375860,7,top-tier,yes,ai and ethics,0.9,"This conference is a collaboration between AAAI and ACM, known for high-quality, impactful research. It draws top scholars in AI and ethics, indicating a high standard of peer review and a significant reputation in its field.",acm_venues.csv,"Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society",NA,ACM,NA
"AAAI/ACM Conference on AI, Ethics, and Society",Arbiter: A Domain-Specific Language for Ethical Machine Learning,"Zucker, Julian; d'Leeuwen, Myraeka","The widespread deployment of machine learning models in high- stakes decision making scenarios requires a code of ethics for machine learning practitioners. We identify four of the primary components required for the ethical practice of machine learn- ing: transparency, fairness, accountability, and reproducibility. We introduce Arbiter, a domain-specific programming language for machine learning practitioners that is designed for ethical machine learning. Arbiter provides a notation for recording how machine learning models will be trained, and we show how this notation can encourage the four described components of ethical machine learning.",2020,https://doi.org/10.1145/3375627.3375858,10.1145/3375627.3375858,5,top-tier,yes,ai and ethics,0.9,"This conference is a collaboration between AAAI and ACM, known for high-quality, impactful research. It draws top scholars in AI and ethics, indicating a high standard of peer review and a significant reputation in its field.",acm_venues.csv,"Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society",NA,ACM,NA
"AAAI/ACM Conference on AI, Ethics, and Society",Artificial Artificial Intelligence: Measuring Influence of AI 'Assessments' on Moral Decision-Making,"Chan, Lok; Doyle, Kenzie; McElfresh, Duncan; Conitzer, Vincent; Dickerson, John P.; Schaich Borg, Jana; Sinnott-Armstrong, Walter","Given AI's growing role in modeling and improving decision-making, how and when to present users with feedback is an urgent topic to address. We empirically examined the effect of feedback from false AI on moral decision-making about donor kidney allocation. We found some evidence that judgments about whether a patient should receive a kidney can be influenced by feedback about participants' own decision-making perceived to be given by AI, even if the feedback is entirely random. We also discovered different effects between assessments presented as being from human experts and assessments presented as being from AI.",2020,https://doi.org/10.1145/3375627.3375870,10.1145/3375627.3375870,7,top-tier,yes,ai and ethics,0.9,"This conference is a collaboration between AAAI and ACM, known for high-quality, impactful research. It draws top scholars in AI and ethics, indicating a high standard of peer review and a significant reputation in its field.",acm_venues.csv,"Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society",NA,ACM,NA
"AAAI/ACM Conference on AI, Ethics, and Society",Assessing Post-hoc Explainability of the BKT Algorithm,"Zhou, Tongyu; Sheng, Haoyu; Howley, Iris","As machine intelligence is increasingly incorporated into educational technologies, it becomes imperative for instructors and students to understand the potential flaws of the algorithms on which their systems rely. This paper describes the design and implementation of an interactive post-hoc explanation of the Bayesian Knowledge Tracing algorithm which is implemented in learning analytics systems used across the United States. After a user-centered design process to smooth out interaction design difficulties, we ran a controlled experiment to evaluate whether the interactive or static version of the explainable led to increased learning. Our results reveal that learning about an algorithm through an explainable depends on users' educational background. For other contexts, designers of post-hoc explainables must consider their users' educational background to best determine how to empower more informed decision-making with AI-enhanced systems.",2020,https://doi.org/10.1145/3375627.3375856,10.1145/3375627.3375856,7,top-tier,yes,ai and ethics,0.9,"This conference is a collaboration between AAAI and ACM, known for high-quality, impactful research. It draws top scholars in AI and ethics, indicating a high standard of peer review and a significant reputation in its field.",acm_venues.csv,"Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society",NA,ACM,NA
"AAAI/ACM Conference on AI, Ethics, and Society",Bayesian Sensitivity Analysis for Offline Policy Evaluation,"Jung, Jongbin; Shroff, Ravi; Feller, Avi; Goel, Sharad","On a variety of complex decision-making tasks, from doctors prescribing treatment to judges setting bail, machine learning algorithms have been shown to outperform expert human judgments. One complication, however, is that it is often difficult to anticipate the effects of algorithmic policies prior to deployment, as one generally cannot use historical data to directly observe what would have happened had the actions recommended by the algorithm been taken. A common strategy is to model potential outcomes for alternative decisions assuming that there are no unmeasured confounders (i.e., to assume ignorability). But if this ignorability assumption is violated, the predicted and actual effects of an algorithmic policy can diverge sharply. In this paper we present a flexible Bayesian approach to gauge the sensitivity of predicted policy outcomes to unmeasured confounders. In particular, and in contrast to past work, our modeling framework easily enables confounders to vary with the observed covariates. We demonstrate the efficacy of our method on a large dataset of judicial actions, in which one must decide whether defendants awaiting trial should be required to pay bail or can be released without payment.",2020,https://doi.org/10.1145/3375627.3375822,10.1145/3375627.3375822,7,top-tier,yes,ai and ethics,0.9,"This conference is a collaboration between AAAI and ACM, known for high-quality, impactful research. It draws top scholars in AI and ethics, indicating a high standard of peer review and a significant reputation in its field.",acm_venues.csv,"Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society",NA,ACM,NA
"AAAI/ACM Conference on AI, Ethics, and Society",Data Augmentation for Discrimination Prevention and Bias Disambiguation,"Sharma, Shubham; Zhang, Yunfeng; Ríos Aliaga, Jesús M.; Bouneffouf, Djallel; Muthusamy, Vinod; Varshney, Kush R.","Machine learning models are prone to biased decisions due to biases in the datasets they are trained on. In this paper, we introduce a novel data augmentation technique to create a fairer dataset for model training that could also lend itself to understanding the type of bias existing in the dataset i.e. if bias arises from a lack of representation for a particular group (sampling bias) or if it arises because of human bias reflected in the labels (prejudice based bias). Given a dataset involving a protected attribute with a privileged and unprivileged group, we create an ""ideal world” dataset: for every data sample, we create a new sample having the same features (except the protected attribute(s)) and label as the original sample but with the opposite protected attribute value. The synthetic data points are sorted in order of their proximity to the original training distribution and added successively to the real dataset to create intermediate datasets. We theoretically show that two different notions of fairness: statistical parity difference (independence) and average odds difference (separation) always change in the same direction using such an augmentation. We also show submodularity of the proposed fairness-aware augmentation approach that enables an efficient greedy algorithm. We empirically study the effect of training models on the intermediate datasets and show that this technique reduces the two bias measures while keeping the accuracy nearly constant for three datasets. We then discuss the implications of this study on the disambiguation of sample bias and prejudice based bias and discuss how pre-processing techniques should be evaluated in general. The proposed method can be used by policy makers who want to use unbiased datasets to train machine learning models for their applications to add a subset of synthetic points to an extent that they are comfortable with to mitigate unwanted bias.",2020,https://doi.org/10.1145/3375627.3375865,10.1145/3375627.3375865,7,top-tier,yes,ai and ethics,0.9,"This conference is a collaboration between AAAI and ACM, known for high-quality, impactful research. It draws top scholars in AI and ethics, indicating a high standard of peer review and a significant reputation in its field.",acm_venues.csv,"Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society",NA,ACM,NA
"AAAI/ACM Conference on AI, Ethics, and Society",Joint Optimization of AI Fairness and Utility: A Human-Centered Approach,"Zhang, Yunfeng; Bellamy, Rachel; Varshney, Kush","Today, AI is increasingly being used in many high-stakes decision-making applications in which fairness is an important concern. Already, there are many examples of AI being biased and making questionable and unfair decisions. The AI research community has proposed many methods to measure and mitigate unwanted biases, but few of them involve inputs from human policy makers. We argue that because different fairness criteria sometimes cannot be simultaneously satisfied, and because achieving fairness often requires sacrificing other objectives such as model accuracy, it is key to acquire and adhere to human policy makers' preferences on how to make the tradeoff among these objectives. In this paper, we propose a framework and some exemplar methods for eliciting such preferences and for optimizing an AI model according to these preferences.",2020,https://doi.org/10.1145/3375627.3375862,10.1145/3375627.3375862,7,top-tier,yes,ai and ethics,0.9,"This conference is a collaboration between AAAI and ACM, known for high-quality, impactful research. It draws top scholars in AI and ethics, indicating a high standard of peer review and a significant reputation in its field.",acm_venues.csv,"Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society",NA,ACM,NA
"AAAI/ACM Conference on AI, Ethics, and Society",Steps Towards Value-Aligned Systems,"Osoba, Osonde A.; Boudreaux, Benjamin; Yeung, Douglas","Algorithmic (including AI/ML) decision-making artifacts are an established and growing part of our decision-making ecosystem. They are now indispensable tools that help us manage the flood of information we use to try to make effective decisions in a complex world. The current literature is full of examples of how individual artifacts violate societal norms and expectations (e.g. violations of fairness, privacy, or safety norms). Against this backdrop, this discussion highlights an under-emphasized perspective in the body of research focused on assessing value misalignment in AI-equipped sociotechnical systems. The research on value misalignment so far has a strong focus on the behavior of individual tech artifacts. This discussion argues for a more structured systems-level approach for assessing value-alignment in sociotechnical systems. We rely primarily on the research on fairness to make our arguments more concrete. And we use the opportunity to highlight how adopting a system perspective improves our ability to explain and address value misalignments better. Our discussion ends with an exploration of priority questions that demand attention if we are to assure the value alignment of whole systems, not just individual artifacts.",2020,https://doi.org/10.1145/3375627.3375872,10.1145/3375627.3375872,5,top-tier,yes,ai and ethics,0.9,"This conference is a collaboration between AAAI and ACM, known for high-quality, impactful research. It draws top scholars in AI and ethics, indicating a high standard of peer review and a significant reputation in its field.",acm_venues.csv,"Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society",NA,ACM,NA
AACL-IJCNLP (Asia-Pacific Chapter of the ACL and International Joint Conference on NLP),AVAST: Attentive Variational State Tracker in a Reinforced Navigator,"Jang, Je-Wei; Rohmatillah, Mahdin; Chien, Jen-Tzung","Recently, emerging approaches have been proposed to deal with robotic navigation problems, especially vision-and-language navigation task which is one of the most realistic indoor navigation challenge tasks. This task can be modelled as a sequential decision-making problem, which is suitable to be solved by deep reinforcement learning. Unfortunately, the observations provided from the simulator in this task are not fully observable states, which exacerbate the difficulty of implementing reinforcement learning. To deal with this challenge, this paper presents a novel method, called as attentive variational state tracker (AVAST), a variational approach to approximate belief state distribution for the construction of a reinforced navigator. The variational approach is introduced to improve generalization to the unseen environment which barely achieved by traditional deterministic state tracker. In order to stabilize the learning procedure, a fine-tuning process using policy optimization is proposed. From the experimental results, the proposed AVAST does improve the generalization relative to previous works in vision-and-language navigation task. A significant performance is achieved without requiring any additional exploration in the unseen environment.",2022,https://aclanthology.org/2022.aacl-main.33,10.18653/v1/2022.aacl-main.33,NA,top-tier,yes,computational linguistics,0.9,"AACL (Asia-Pacific Chapter of the ACL) together with IJCNLP are reputable conferences in the computational linguistics community. These conferences are peer-reviewed and have a strong standing, making them top-tier venues for publishing significant research work.",acl_venues.csv,Proceedings of the 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),conferencePaper,ACL,NA
AACL-IJCNLP (Asia-Pacific Chapter of the ACL and International Joint Conference on NLP),CrowdChecked: Detecting Previously Fact-Checked Claims in Social Media,"Hardalov, Momchil; Chernyavskiy, Anton; Koychev, Ivan; Ilvovsky, Dmitry; Nakov, Preslav","While there has been substantial progress in developing systems to automate fact-checking, they still lack credibility in the eyes of the users. Thus, an interesting approach has emerged: to perform automatic fact-checking by verifying whether an input claim has been previously fact-checked by professional fact-checkers and to return back an article that explains their decision. This is a sensible approach as people trust manual fact-checking, and as many claims are repeated multiple times. Yet, a major issue when building such systems is the small number of known tweet–verifying article pairs available for training. Here, we aim to bridge this gap by making use of crowd fact-checking, i.e., mining claims in social media for which users have responded with a link to a fact-checking article. In particular, we mine a large-scale collection of 330,000 tweets paired with a corresponding fact-checking article. We further propose an end-to-end framework to learn from this noisy data based on modified self-adaptive training, in a distant supervision scenario. Our experiments on the CLEF'21 CheckThat! test set show improvements over the state of the art by two points absolute. Our code and datasets are available at https://github.com/mhardalov/crowdchecked-claims",2022,https://aclanthology.org/2022.aacl-main.22,10.18653/v1/2022.aacl-main.22,NA,top-tier,yes,computational linguistics,0.9,"AACL (Asia-Pacific Chapter of the ACL) together with IJCNLP are reputable conferences in the computational linguistics community. These conferences are peer-reviewed and have a strong standing, making them top-tier venues for publishing significant research work.",acl_venues.csv,Proceedings of the 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),conferencePaper,ACL,NA
AACL-IJCNLP (Asia-Pacific Chapter of the ACL and International Joint Conference on NLP),Double Trouble: How to not Explain a Text Classifier's Decisions Using Counterfactuals Synthesized by Masked Language Models?,"Pham, Thang; Bui, Trung; Mai, Long; Nguyen, Anh","A principle behind dozens of attribution methods is to take the prediction difference between before-and-after an input feature (here, a token) is removed as its attribution. A popular Input Marginalization (IM) method (Kim et al., 2020) uses BERT to replace a token, yielding more plausible counterfactuals. While Kim et al., 2020 reported that IM is effective, we find this conclusion not convincing as the Deletion-BERT metric used in their paper is biased towards IM. Importantly, this bias exists in Deletion-based metrics, including Insertion, Sufficiency, and Comprehensiveness. Furthermore, our rigorous evaluation using 6 metrics and 3 datasets finds no evidence that IM is better than a Leave-One-Out (LOO) baseline. We find two reasons why IM is not better than LOO: (1) deleting a single word from the input only marginally reduces a classifier's accuracy; and (2) a highly predictable word is always given near-zero attribution, regardless of its true importance to the classifier. In contrast, making LIME samples more natural via BERT consistently improves LIME accuracy under several ROAR metrics.",2022,https://aclanthology.org/2022.aacl-main.2,10.18653/v1/2022.aacl-main.2,NA,top-tier,yes,computational linguistics,0.9,"AACL (Asia-Pacific Chapter of the ACL) together with IJCNLP are reputable conferences in the computational linguistics community. These conferences are peer-reviewed and have a strong standing, making them top-tier venues for publishing significant research work.",acl_venues.csv,Proceedings of the 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),conferencePaper,ACL,NA
Academic Emergency Medicine,A machine learning approach to predicting need for hospitalization for pediatric asthma exacerbation at the time of emergency department triage,Shilpa J. Patel MD;MPH;Daniel B. Chamberlain MS;James M. Chamberlain MD,"Objectives Pediatric asthma is a leading cause of emergency department (ED) utilization and hospitalization. Earlier identification of need for hospital-level care could triage patients more efficiently to high- or low-resource ED tracks. Existing tools to predict disposition for pediatric asthma use only clinical data, perform best several hours into the ED stay, and are static or score-based. Machine learning offers a population-specific, dynamic option that allows real-time integration of available nonclinical data at triage. Our objective was to compare the performance of four common machine learning approaches, incorporating clinical data available at the time of triage with information about weather, neighborhood characteristics, and community viral load for early prediction of the need for hospital-level care in pediatric asthma. Methods Retrospective analysis of patients ages 2 to 18 years seen at two urban pediatric EDs with asthma exacerbation over 4 years. Asthma exacerbation was defined as receiving both albuterol and systemic corticosteroids. We included patient features, measures of illness severity available in triage, weather features, and Centers for Disease Control and Prevention influenza patterns. We tested four models: decision trees, LASSO logistic regression, random forests, and gradient boosting machines. For each model, 80% of the data set was used for training and 20% was used to validate the models. The area under the receiver operating characteristic (AUC) curve was calculated for each model. Results There were 29,392 patients included in the analyses: mean (±SD) age of 7.0 (±4.2) years, 42% female, 77% non-Hispanic black, and 76% public insurance. The AUCs for each model were: decision tree 0.72 (95% confidence interval [CI] = 0.66–0.77), logistic regression 0.83 (95% CI = 0.82–0.83), random forests 0.82 (95% CI = 0.81–0.83), and gradient boosting machines 0.84 (95% CI = 0.83–0.85). In the lowest decile of risk, only 3% of patients required hospitalization; in the highest decile this rate was 100%. After patient vital signs and acuity, age and weight, followed by socioeconomic status (SES) and weather-related features, were the most important for predicting hospitalization. Conclusions Three of the four machine learning models performed well with decision trees preforming the worst. The gradient boosting machines model demonstrated a slight advantage over other approaches at predicting need for hospital-level care at the time of triage in pediatric patients presenting with asthma exacerbation. The addition of weight, SES, and weather data improved the performance of this model.",2018,https://onlinelibrary.wiley.com/doi/10.1111/acem.13655,10.1111/acem.13655,8,top-tier,yes,emergency medicine,0.9,"Academic Emergency Medicine is a highly respected journal within the field of emergency medicine. It covers significant research, practices, and developments in this medical specialty, and is known for rigorous peer review.",wiley.csv,Academic Emergency Medicine,NA,Wiley,NA
Academic Emergency Medicine,Automated outcome classification of computed tomography imaging reports for pediatric traumatic brain injury,Kabir Yadav MDCM;MS;MSHS;Efsun Sarioglu PhD;Hyeong−Ah Choi PhD;Walter B. Cartwright MD;Pamela S. Hinds PhD;RN;James M. Chamberlain MD,"Background The authors have previously demonstrated highly reliable automated classification of free-text computed tomography (CT) imaging reports using a hybrid system that pairs linguistic (natural language processing) and statistical (machine learning) techniques. Previously performed for identifying the outcome of orbital fracture in unprocessed radiology reports from a clinical data repository, the performance has not been replicated for more complex outcomes. Objectives To validate automated outcome classification performance of a hybrid natural language processing (NLP) and machine learning system for brain CT imaging reports. The hypothesis was that our system has performance characteristics for identifying pediatric traumatic brain injury (TBI). Methods This was a secondary analysis of a subset of 2,121 CT reports from the Pediatric Emergency Care Applied Research Network (PECARN) TBI study. For that project, radiologists dictated CT reports as free text, which were then deidentified and scanned as PDF documents. Trained data abstractors manually coded each report for TBI outcome. Text was extracted from the PDF files using optical character recognition. The data set was randomly split evenly for training and testing. Training patient reports were used as input to the Medical Language Extraction and Encoding (MedLEE) NLP tool to create structured output containing standardized medical terms and modifiers for negation, certainty, and temporal status. A random subset stratified by site was analyzed using descriptive quantitative content analysis to confirm identification of TBI findings based on the National Institute of Neurological Disorders and Stroke (NINDS) Common Data Elements project. Findings were coded for presence or absence, weighted by frequency of mentions, and past/future/indication modifiers were filtered. After combining with the manual reference standard, a decision tree classifier was created using data mining tools WEKA 3.7.5 and Salford Predictive Miner 7.0. Performance of the decision tree classifier was evaluated on the test patient reports. Results The prevalence of TBI in the sampled population was 159 of 2,217 (7.2%). The automated classification for pediatric TBI is comparable to our prior results, with the notable exception of lower positive predictive value. Manual review of misclassified reports, 95.5% of which were false-positives, revealed that a sizable number of false-positive errors were due to differing outcome definitions between NINDS TBI findings and PECARN clinical important TBI findings and report ambiguity not meeting definition criteria. Conclusions A hybrid NLP and machine learning automated classification system continues to show promise in coding free-text electronic clinical data. For complex outcomes, it can reliably identify negative reports, but manual review of positive reports may be required. As such, it can still streamline data collection for clinical research and performance improvement.",2016,https://onlinelibrary.wiley.com/doi/10.1111/acem.12859,10.1111/acem.12859,8,top-tier,yes,emergency medicine,0.9,"Academic Emergency Medicine is a highly respected journal within the field of emergency medicine. It covers significant research, practices, and developments in this medical specialty, and is known for rigorous peer review.",wiley.csv,Academic Emergency Medicine,NA,Wiley,NA
Academic Emergency Medicine,Bacteremia prediction model for community-acquired pneumonia: external validation in a multicenter retrospective cohort,Byunghyun Kim;Jungho Choi;Kyuseok Kim;Sujin Jang;Tae Gun Shin;Won Young Kim;Jung-Youn Kim;Yoo Seok Park;Soo Hyun Kim;Hui Jai Lee;Jonghwan Shin;Je Sung You;Kyung Su Kim;Sung Phil Chung,"Objective Many studies have described constructing a prediction model for bacteremia in community-acquired pneumonia (CAP), but these studies were not validated in external heterogeneous groups. The objective of this study was to test the generalizability of a previous bacteremia prediction model for CAP by external validation. Methods This multicenter retrospective cohort analysis was performed in eight tertiary urban hospital emergency departments (EDs). We reviewed adult patients who were hospitalized after presentation to the ED with CAP. We categorized the enrolled patients into three groups according to the bacteremia prediction model score and calculated the number of patients with or without a blood culture–positive result. We performed a multivariable analysis to identify significant predictors for bacteremia. Results Among the enrolled 2,001 patients, 1,592 (79.6%), 371 (18.5%), and 38 (1.9%) were stratified to a low-, moderate-, and high-risk group, respectively, and this proportion was similar with previous study. Each group had a bacteremia-positive rate as follows: 1.2% for the low-risk group, 7.2% for the moderate-risk group, and 31.5% for the high-risk group. The area under the receiver operating characteristic curve for the bacteremia model in the external validation cohort was 0.81, and there was no significant difference with that of the previous internal validation cohort (p = 0.246). Assuming that blood cultures were not performed in the low-risk patients, the sensitivity and specificity of this model were 0.68 and 0.81, respectively. Additionally, the positive predictive value and negative predictive value were 9.54 and 98.87%, respectively. A platelet count less than 130 × 109 cells/L, albumin less than 3.3 mg/dL, and C-reactive protein greater than 17 mg/dL were identified as significant predictors with a sensitivity and specificity of 0.70 and 0.83, respectively. Conclusion The bacteremia prediction model was well validated in the general population and could help physicians make the decision to reduce the number of blood cultures in patients with CAP.",2017,https://onlinelibrary.wiley.com/doi/10.1111/acem.13255,10.1111/acem.13255,9,top-tier,yes,emergency medicine,0.9,"Academic Emergency Medicine is a highly respected journal within the field of emergency medicine. It covers significant research, practices, and developments in this medical specialty, and is known for rigorous peer review.",wiley.csv,Academic Emergency Medicine,NA,Wiley,NA
Academic Emergency Medicine,Building a natural language processing tool to identify patients with high clinical suspicion for kawasaki disease from emergency department notes,Son Doan PhD;Cleo K. Maehara MD;MMSc;Juan D. Chaparro MD;Sisi Lu MS;Ruiling Liu MS;Amanda Graham MPH;Erika Berry;Chun-Nan Hsu PhD;John T. Kanegaye MD;David D. Lloyd MD;Lucila Ohno-Machado MD;Jane C. Burns MD;Adriana H. Tremoulet MD;MAS;the Pediatric Emergency Medicine Kawasaki Disease Research Group,"Objective Delayed diagnosis of Kawasaki disease (KD) may lead to serious cardiac complications. We sought to create and test the performance of a natural language processing (NLP) tool, the KD-NLP, in the identification of emergency department (ED) patients for whom the diagnosis of KD should be considered. Methods We developed an NLP tool that recognizes the KD diagnostic criteria based on standard clinical terms and medical word usage using 22 pediatric ED notes augmented by Unified Medical Language System vocabulary. With high suspicion for KD defined as fever and three or more KD clinical signs, KD-NLP was applied to 253 ED notes from children ultimately diagnosed with either KD or another febrile illness. We evaluated KD-NLP performance against ED notes manually reviewed by clinicians and compared the results to a simple keyword search. Results KD-NLP identified high-suspicion patients with a sensitivity of 93.6% and specificity of 77.5% compared to notes manually reviewed by clinicians. The tool outperformed a simple keyword search (sensitivity = 41.0%; specificity = 76.3%). Conclusions KD-NLP showed comparable performance to clinician manual chart review for identification of pediatric ED patients with a high suspicion for KD. This tool could be incorporated into the ED electronic health record system to alert providers to consider the diagnosis of KD. KD-NLP could serve as a model for decision support for other conditions in the ED.",2016,https://onlinelibrary.wiley.com/doi/10.1111/acem.12925,10.1111/acem.12925,9,top-tier,yes,emergency medicine,0.9,"Academic Emergency Medicine is a highly respected journal within the field of emergency medicine. It covers significant research, practices, and developments in this medical specialty, and is known for rigorous peer review.",wiley.csv,Academic Emergency Medicine,NA,Wiley,NA
Academic Emergency Medicine,D-dimer in adolescent pulmonary embolism,Nematullah Sharaf;Victoria B. Sharaf;Sharon E. Mace MD;Amy S. Nowacki PhD;James K. Stoller MD;MS;John C. Carl MD,"Background D-dimer is used to aid in diagnosing adult pulmonary embolism (PE). D-dimer has not been validated in adolescents. Clinicians must balance the risk of overtesting with that of a missed PE. D-dimer may be useful in this context. This study evaluates D-dimer in PE-positive and PE-negative adolescents. Methods PE-positive patients < 22 years were diagnosed with PE by computed tomography (CT) or high-probability ventilation/perfusion, seen at emergency departments (EDs)/hospitals within a 16-hospital system across two states, January 1998 through December 2016. Of the 189 PE-positive patients, 88 (46.5%) had a D-dimer and were matched 1:1 by age, sex, and race to patients suspected of PE but confirmed negative by CT angiogram. Results Ages of PE-positive patients ranged from 13 to 21 years, 64 (73%) were female, and 52 (60%) were Caucasian. Mean D-dimer was significantly higher (3,256 ng/mL, 95% confidence interval [CI] = 2,505–4,006 ng/mL) in PE-positive versus PE-negative patients (1,244 ng/mL, 95% CI = 493–1,995 ng/mL; p < 0.001). Mean D-dimer was higher in patients with massive or submassive PE (8,742 ng/mL, 95% CI = 5,994–11,491 ng/mL), followed by PE in central (4,795 ng/mL [95% CI = 3,465–6,125 ng/mL), lobar (3,758 ng/mL [95% CI = 1,841–5,676), and distal (2,327 ng/mL [95% CI = 1,273–3,381 ng/mL]) arteries. When comparing thresholds of positive D-dimer (≥500, ≥750, and ≥1,000 ng/mL), D-dimer had sensitivities of 90, 82, and 67% and specificities of 16, 53, and 67%, respectively. Negative predictive values were 61, 75, and 71% while positive likelihood ratios were 1.1, 1.8, and 2.2, respectively. Conclusions This study represents the largest available cohort of adolescent patients examining the diagnostic value of D-dimer for PE. Our results indicate that depending on the threshold selected, D-dimer can be a sensitive test for PE in adolescents and that discriminative value is higher for a cutoff of 750 ng/mL than that for 500 ng/mL. Prospective studies investigating the diagnostic value of D-dimer and a clinical decision rule for PE in pediatrics are needed.",2018,https://onlinelibrary.wiley.com/doi/10.1111/acem.13517,10.1111/acem.13517,7,top-tier,yes,emergency medicine,0.9,"Academic Emergency Medicine is a highly respected journal within the field of emergency medicine. It covers significant research, practices, and developments in this medical specialty, and is known for rigorous peer review.",wiley.csv,Academic Emergency Medicine,NA,Wiley,NA
Academic Emergency Medicine,D-dimer interval likelihood ratios for pulmonary embolism,Michael A. Kohn MD;MPP;Frederikus A. Klok MD;PhD;Nick van Es MD,"Objective The objective was to estimate D-dimer interval likelihood ratios (iLRs) for diagnosing pulmonary embolism (PE). Methods The authors used pooled patient-level data from five PE diagnostic management studies to estimate iLRs for the eight D-dimer intervals with boundaries 250, 500, 750, 1,000, 1,500, 2,500, and 5,000 ng/mL. Logistic regression was used to fit the data so that an interval increase corresponds to increasing the likelihood ratio by a constant factor. Results The iLR for the D-dimer interval 1,000–1,499 ng/mL was essentially 1.0 (0.98 with 95% confidence interval [CI] = 0.82–1.18). In the logistic regression model, the constant between-interval factor was 2.0 (95% CI = 1.9–2.1). Using these iLR estimates, if the pre–D-dimer probability of PE is 15%, only a D-dimer less than 500 ng/mL will result in a posttest probability below 3%; if the pretest probability is 5%, the threshold for a “negative” D-dimer is 1,000 ng/mL. Conclusions A decision strategy based on these approximate iLRs agrees with several published strategies.",2017,https://onlinelibrary.wiley.com/doi/10.1111/acem.13191,10.1111/acem.13191,6,top-tier,yes,emergency medicine,0.9,"Academic Emergency Medicine is a highly respected journal within the field of emergency medicine. It covers significant research, practices, and developments in this medical specialty, and is known for rigorous peer review.",wiley.csv,Academic Emergency Medicine,NA,Wiley,NA
Academic Emergency Medicine,Emergency department triage of traumatic head injury using a brain electrical activity biomarker: a multisite prospective observational validation trial,Daniel Hanley MD;Leslie S. Prichep PhD;Jeffrey Bazarian MD;J. Stephen Huff MD;Rosanne Naunheim MD;John Garrett MD;Elizabeth B. Jones MD;David W. Wright MD;John O'Neill MD;Neeraj Badjatia MD;Dheeraj Gandhi MD;Kenneth C. Curley MD;Richard Chiacchierini PhD;Brian O'Neil MD;Dallas C. Hack MD,"Objectives A brain electrical activity biomarker for identifying traumatic brain injury (TBI) in emergency department (ED) patients presenting with high Glasgow Coma Scale (GCS) after sustaining a head injury has shown promise for objective, rapid triage. The main objective of this study was to prospectively evaluate the efficacy of an automated classification algorithm to determine the likelihood of being computed tomography (CT) positive, in high-functioning TBI patients in the acute state. Methods Adult patients admitted to the ED for evaluation within 72 hours of sustaining a closed head injury with GCS 12 to 15 were candidates for study. A total of 720 patients (18–85 years) meeting inclusion/exclusion criteria were enrolled in this observational, prospective validation trial, at 11 U.S. EDs. GCS was 15 in 97%, with the first and third quartiles being 15 (interquartile range = 0) in the study population at the time of the evaluation. Standard clinical evaluations were conducted and 5 to 10 minutes of electroencephalogram (EEG) was acquired from frontal and frontal–temporal scalp locations. Using an a priori derived EEG-based classification algorithm developed on an independent population and applied to this validation population prospectively, the likelihood of each subject being CT+ was determined, and performance metrics were computed relative to adjudicated CT findings. Results Sensitivity of the binary classifier (likely CT+ or CT–) was 92.3% (95% confidence interval [CI] = 87.8%–95.5%) for detection of any intracranial injury visible on CT (CT+), with specificity of 51.6% (95% CI = 48.1%–55.1%) and negative predictive value (NPV) of 96.0% (95% CI = 93.2%–97.9%). Using ternary classification (likely CT+, equivocal, likely CT–) demonstrated enhanced sensitivity to traumatic hematomas (≥1 mL of blood), 98.6% (95% CI = 92.6%–100.0%), and NPV of 98.2% (95% CI = 95.5%–99.5%). Conclusion Using an EEG-based biomarker high accuracy of predicting the likelihood of being CT+ was obtained, with high NPV and sensitivity to any traumatic bleeding and to hematomas. Specificity was significantly higher than standard CT decision rules. The short time to acquire results and the ease of use in the ED environment suggests that EEG-based classifier algorithms have potential to impact triage and clinical management of head-injured patients.",2017,https://onlinelibrary.wiley.com/doi/10.1111/acem.13175,10.1111/acem.13175,11,top-tier,yes,emergency medicine,0.9,"Academic Emergency Medicine is a highly respected journal within the field of emergency medicine. It covers significant research, practices, and developments in this medical specialty, and is known for rigorous peer review.",wiley.csv,Academic Emergency Medicine,NA,Wiley,NA
Academic Emergency Medicine,Identifying signs and symptoms of urinary tract infection from emergency department clinical notes using large language models,Mark Iscoe MD;MHS;Vimig Socrates MS;Aidan Gilson;Ling Chi;Huan Li MS;Thomas Huang;Thomas Kearns MD;Rachelle Perkins MD;Laura Khandjian MD;R. Andrew Taylor MD;MHS,"Background Natural language processing (NLP) tools including recently developed large language models (LLMs) have myriad potential applications in medical care and research, including the efficient labeling and classification of unstructured text such as electronic health record (EHR) notes. This opens the door to large-scale projects that rely on variables that are not typically recorded in a structured form, such as patient signs and symptoms. Objectives This study is designed to acquaint the emergency medicine research community with the foundational elements of NLP, highlighting essential terminology, annotation methodologies, and the intricacies involved in training and evaluating NLP models. Symptom characterization is critical to urinary tract infection (UTI) diagnosis, but identification of symptoms from the EHR has historically been challenging, limiting large-scale research, public health surveillance, and EHR-based clinical decision support. We therefore developed and compared two NLP models to identify UTI symptoms from unstructured emergency department (ED) notes. Methods The study population consisted of patients aged ≥ 18 who presented to an ED in a northeastern U.S. health system between June 2013 and August 2021 and had a urinalysis performed. We annotated a random subset of 1250 ED clinician notes from these visits for a list of 17 UTI symptoms. We then developed two task-specific LLMs to perform the task of named entity recognition: a convolutional neural network-based model (SpaCy) and a transformer-based model designed to process longer documents (Clinical Longformer). Models were trained on 1000 notes and tested on a holdout set of 250 notes. We compared model performance (precision, recall, F1 measure) at identifying the presence or absence of UTI symptoms at the note level. Results A total of 8135 entities were identified in 1250 notes; 83.6% of notes included at least one entity. Overall F1 measure for note-level symptom identification weighted by entity frequency was 0.84 for the SpaCy model and 0.88 for the Longformer model. F1 measure for identifying presence or absence of any UTI symptom in a clinical note was 0.96 (232/250 correctly classified) for the SpaCy model and 0.98 (240/250 correctly classified) for the Longformer model. Conclusions The study demonstrated the utility of LLMs and transformer-based models in particular for extracting UTI symptoms from unstructured ED clinical notes; models were highly accurate for detecting the presence or absence of any UTI symptom on the note level, with variable performance for individual symptoms.",2024,https://onlinelibrary.wiley.com/doi/10.1111/acem.14883,10.1111/acem.14883,12,top-tier,yes,emergency medicine,0.9,"Academic Emergency Medicine is a highly respected journal within the field of emergency medicine. It covers significant research, practices, and developments in this medical specialty, and is known for rigorous peer review.",wiley.csv,Academic Emergency Medicine,NA,Wiley,NA
Academic Emergency Medicine,"Leveraging artificial intelligence to reduce diagnostic errors in emergency medicine: challenges, opportunities, and future directions",R. Andrew Taylor MD;MHS;Rohit B. Sangal MD;MBA;Moira E. Smith MD;MPH;Adrian D. Haimovich MD;PhD;Adam Rodman MD;MPH;Mark S. Iscoe MD;MHS;Suresh K. Pavuluri MD;MPH;Christian Rose MD;Alexander T. Janke MD;MHS;MSc;Donald S. Wright MD;MHS;Vimig Socrates MS;Arwen Declan MD;PhD,"Diagnostic errors in health care pose significant risks to patient safety and are disturbingly common. In the emergency department (ED), the chaotic and high-pressure environment increases the likelihood of these errors, as emergency clinicians must make rapid decisions with limited information, often under cognitive overload. Artificial intelligence (AI) offers promising solutions to improve diagnostic errors in three key areas: information gathering, clinical decision support (CDS), and feedback through quality improvement. AI can streamline the information-gathering process by automating data retrieval, reducing cognitive load, and providing clinicians with essential patient details quickly. AI-driven CDS systems enhance diagnostic decision making by offering real-time insights, reducing cognitive biases, and prioritizing differential diagnoses. Furthermore, AI-powered feedback loops can facilitate continuous learning and refinement of diagnostic processes by providing targeted education and outcome feedback to clinicians. By integrating AI into these areas, the potential for reducing diagnostic errors and improving patient safety in the ED is substantial. However, successfully implementing AI in the ED is challenging and complex. Developing, validating, and implementing AI as a safe, human-centered ED tool requires thoughtful design and meticulous attention to ethical and practical considerations. Clinicians and patients must be integrated as key stakeholders across these processes. Ultimately, AI should be seen as a tool that assists clinicians by supporting better, faster decisions and thus enhances patient outcomes.",2024,https://onlinelibrary.wiley.com/doi/10.1111/acem.15066,10.1111/acem.15066,NA,top-tier,yes,emergency medicine,0.9,"Academic Emergency Medicine is a highly respected journal within the field of emergency medicine. It covers significant research, practices, and developments in this medical specialty, and is known for rigorous peer review.",wiley.csv,Academic Emergency Medicine,NA,Wiley,NA
Academic Emergency Medicine,Machine learning versus usual care for diagnostic and prognostic prediction in the emergency department: a systematic review,Hashim Kareemi MD;Christian Vaillancourt MD;MSc;Hans Rosenberg MD;Karine Fournier MSI;Krishan Yadav MD;MSc,"Objective Having shown promise in other medical fields, we sought to determine whether machine learning (ML) models perform better than usual care in diagnostic and prognostic prediction for emergency department (ED) patients. Methods In this systematic review, we searched MEDLINE, Embase, Central, and CINAHL from inception to October 17, 2019. We included studies comparing diagnostic and prognostic prediction of ED patients by ML models to usual care methods (triage-based scores, clinical prediction tools, clinician judgment) using predictor variables readily available to ED clinicians. We extracted commonly reported performance metrics of model discrimination and classification. We used the PROBAST tool for risk of bias assessment (PROSPERO registration: CRD42020158129). Results The search yielded 1,656 unique records, of which 23 studies involving 16,274,647 patients were included. In all seven diagnostic studies, ML models outperformed usual care in all performance metrics. In six studies assessing in-hospital mortality, the best-performing ML models had better discrimination (area under the receiver operating characteristic curve [AUROC] =0.74–0.94) than any clinical decision tool (AUROC =0.68–0.81). In four studies assessing hospitalization, ML models had better discrimination (AUROC =0.80–0.83) than triage-based scores (AUROC =0.68–0.82). Clinical heterogeneity precluded meta-analysis. Most studies had high risk of bias due to lack of external validation, low event rates, and insufficient reporting of calibration. Conclusions Our review suggests that ML may have better prediction performance than usual care for ED patients with a variety of clinical presentations and outcomes. However, prediction model reporting guidelines should be followed to provide clinically applicable data. Interventional trials are needed to assess the impact of ML models on patient-centered outcomes.",2020,https://onlinelibrary.wiley.com/doi/10.1111/acem.14190,10.1111/acem.14190,13,top-tier,yes,emergency medicine,0.9,"Academic Emergency Medicine is a highly respected journal within the field of emergency medicine. It covers significant research, practices, and developments in this medical specialty, and is known for rigorous peer review.",wiley.csv,Academic Emergency Medicine,NA,Wiley,NA
Academic Emergency Medicine,Real-time artificial intelligence predicts adverse outcomes in acute pancreatitis in the emergency department: comparison with clinical decision rule,Ching-Hung Chang MD;Chia-Jung Chen MBA;Yu-Shan Ma;Yu-Ting Shen;Mei-I Sung;Chien-Chin Hsu MD;PhD;Hung-Jung Lin MD;MBA;Zhih-Cherng Chen MD;MBA;Chien-Cheng Huang MD;PhD;Chung-Feng Liu PhD,"Objective Artificial intelligence (AI) prediction is increasingly used for decision making in health care, but its application for adverse outcomes in emergency department (ED) patients with acute pancreatitis (AP) is not well understood. This study aimed to clarify this aspect. Methods Data from 8274 ED patients with AP in three hospitals from 2009 to 2018 were analyzed. Demographic data, comorbidities, laboratory results, and adverse outcomes were included. Six algorithms were evaluated, and the one with the highest area under the curve (AUC) was implemented into the hospital information system (HIS) for real-time prediction. Predictive accuracy was compared between the AI model and Bedside Index for Severity in Acute Pancreatitis (BISAP). Results The mean ± SD age was 56.1 ± 16.7 years, with 67.7% being male. The AI model was successfully implemented in the HIS, with Light Gradient Boosting Machine (LightGBM) showing the highest AUC for sepsis (AUC 0.961) and intensive care unit (ICU) admission (AUC 0.973), and eXtreme Gradient Boosting (XGBoost) showing the highest AUC for mortality (AUC 0.975). Compared to BISAP, the AI model had superior AUC for sepsis (BISAP 0.785), ICU admission (BISAP 0.778), and mortality (BISAP 0.817). Conclusions The first real-time AI prediction model implemented in the HIS for predicting adverse outcomes in ED patients with AP shows favorable initial results. However, further external validation is needed to ensure its reliability and accuracy.",2023,https://onlinelibrary.wiley.com/doi/10.1111/acem.14824,10.1111/acem.14824,7,top-tier,yes,emergency medicine,0.9,"Academic Emergency Medicine is a highly respected journal within the field of emergency medicine. It covers significant research, practices, and developments in this medical specialty, and is known for rigorous peer review.",wiley.csv,Academic Emergency Medicine,NA,Wiley,NA
Academic Emergency Medicine,Real-time interactive artificial intelligence of things–based prediction for adverse outcomes in adult patients with pneumonia in the emergency department,You-Ming Chen MD;Yuan Kao MD;Chien-Chin Hsu MD;PhD;Chia-Jung Chen MBA;Yu-Shan Ma;Yu-Ting Shen;Tzu-Lan Liu;Shu-Lien Hsu RN;Hung-Jung Lin MD;MBA;Jhi-Joung Wang MD;PhD;Chien-Cheng Huang MD;PhD;Chung-Feng Liu PhD,"Background Artificial intelligence of things (AIoT) may be a solution for predicting adverse outcomes in emergency department (ED) patients with pneumonia; however, this issue remains unclear. Therefore, we conducted this study to clarify it. Methods We identified 52,626 adult ED patients with pneumonia from three hospitals between 2010 and 2019 for this study. Thirty-three feature variables from electronic medical records were used to construct an artificial intelligence (AI) model to predict sepsis or septic shock, respiratory failure, and mortality. After comparisons of the predictive accuracies among logistic regression, random forest, support-vector machine (SVM), light gradient boosting machine (LightGBM), multilayer perceptron (MLP), and eXtreme Gradient Boosting (XGBoost), we selected the best one to build the model. We further combined the AI model with the Internet of things as AIoT, added an interactive mode, and implemented it in the hospital information system to assist clinicians with decision making in real time. We also compared the AIoT-based model with the confusion-urea-respiratory rate-blood pressure-65 (CURB-65) and pneumonia severity index (PSI) for predicting mortality. Results The best AI algorithms were random forest for sepsis or septic shock (area under the curve [AUC] = 0.781), LightGBM for respiratory failure (AUC = 0.847), and mortality (AUC = 0.835). The AIoT-based model represented better performance than CURB-65 and PSI indicators for predicting mortality (0.835 vs. 0.681 and 0.835 vs. 0.728). Conclusions A real-time interactive AIoT-based model might be a better tool for predicting adverse outcomes in ED patients with pneumonia. Further validation in other populations is warranted.",2021,https://onlinelibrary.wiley.com/doi/10.1111/acem.14339,10.1111/acem.14339,9,top-tier,yes,emergency medicine,0.9,"Academic Emergency Medicine is a highly respected journal within the field of emergency medicine. It covers significant research, practices, and developments in this medical specialty, and is known for rigorous peer review.",wiley.csv,Academic Emergency Medicine,NA,Wiley,NA
Academic Emergency Medicine,Systematic review of aortic dissection detection risk score plus d-dimer for diagnostic rule-out of suspected acute aortic syndromes,Paolo Bima MD;Emanuele Pivetta MD;PhD;Peiman Nazerian MD;Mamoru Toyofuku MD;Riccardo Gorla MD;PhD;Eduardo Bossone MD;Raimund Erbel MD;Enrico Lupia MD;PhD;Fulvio Morello MD;PhD,"Objectives In patients at low clinical probability of acute aortic syndromes (AASs), decision on advanced aortic imaging is cumbersome. Integration of the aortic dissection detection risk score (ADD-RS) with D-dimer (DD) provides a potential pipeline for standardized diagnostic rule-out. We systematically reviewed and summarized supporting data. Methods Cross-sectional studies assessing integration of ADD-RS with DD for diagnosis of AASs were identified on MEDLINE, EMBASE and Web Of Science databases. Two reviewers independently screened articles, assessed quality, and extracted data. The quality of design and reporting was evaluated with the QUADAS-2 and STARD tools. Individual patient data were obtained, to allow analysis of both conventional (500 ng/mL) and age-adjusted (DDage-adj) DD cutoffs. Data were summarized for four diagnostic strategies combining ADD-RS = 0 or ≤ 1, with DD < 500 ng/mL or < DDage-adj. The statistical heterogeneity of the diagnostic variables was estimated with Higgins’ I2. Pooled values were calculated for variables showing nonsignificant heterogeneity. Results After screening of 680 studies, four articles (including a total of 3,804 patients) met inclusion criteria. One prospective study provided a low risk of bias/applicability concerns, while methodologic limitations were found in the other three retrospective studies. Statistical heterogeneity was negligible for sensitivity and negative likelihood ratio (LR) values and significant for specificity and positive LR values of all diagnostic strategies. Pooled sensitivity was 99.9% (95% confidence interval [CI] = 99.3% to 100%, I2 = 0) for ADD-RS = 0 and DD < 500 ng/mL or < DDage-adj, 98.9% (95% CI = 97.9% to 99.9%, I2 = 0) for ADD-RS ≤ 1 and DD < 500 ng/mL, and 97.6% (95% CI = 96.3% to 98.9%, I2 = 0) for ADD-RS ≤ 1 and DD < DDage-adj. Conclusions Despite methodologic limitations, integration of ADD-RS = 0 or ≤ 1 with DD < 500 ng/mL shows negligible heterogeneity and consistently high sensitivity across studies, thus supporting reliability for diagnostic rule-out of AASs. Data supporting ADD-RS = 0 plus DDage-adj appear preliminary and require further scrutiny.",2020,https://onlinelibrary.wiley.com/doi/10.1111/acem.13969,10.1111/acem.13969,15,top-tier,yes,emergency medicine,0.9,"Academic Emergency Medicine is a highly respected journal within the field of emergency medicine. It covers significant research, practices, and developments in this medical specialty, and is known for rigorous peer review.",wiley.csv,Academic Emergency Medicine,NA,Wiley,NA
Academy of Management Perspectives,"Who, me? An inductive study of novice experts in the context of how editors come to understand theoretical contribution",KEVIN G. CORLEY;BETH S. SCHINOFF,"The social sciences, including management, are at a crossroads. Globally, scholars are increasingly pressured to publish in top journals, compelling editorial boards to recruit more individuals—including those with less experience—to meet the demand. Furthermore, the validity of the social sciences is under scrutiny in light of ethical violations, article retractions, and calls for more relevant research. At the epicenter of this conundrum lie journal editors, those who adjudicate the quality and potential of submitted research. With these issues as backdrop, we report an inductive study of how journal editors come to understand the notion of theoretical contribution. Working with a data set of editorial decision letters and interviews with editors at two top management journals, we provide critical insight into how new editors, despite not yet having the requisite experience or knowledge to make expert judgments, experience being labeled experts by their scholarly community—a phenomenon we label novice experts. We find that the process of making sense of theoretical contribution differs for novice experts than for those with more experience. Given the rise in less experienced editors, our data suggest that now is the time to rethink the hows and whys of knowledge dissemination at the heart of our profession.",2017,http://www.jstor.org/stable/44645055,10.2307/44645055,24,top-tier,yes,"management, business",0.95,"Academy of Management Perspectives is a well-regarded journal that publishes accessible research and insights in the field of management. It is associated with the Academy of Management, a leading professional association, indicating a top-tier and peer-reviewed status.",jstor_venues.csv,Academy of Management Perspectives,Research-article,JSTOR,NA
Accident Analysis & Prevention,A comparative study of machine learning classifiers for injury severity prediction of crashes involving three-wheeled motorized rickshaw,Muhammad Ijaz;Liu lan;Muhammad Zahid;Arshad Jamal,"Motorcycles and motorcyclists have a variety of attributes that have been found to be a potential contributor to the high liability of vulnerable road users (VRUs). Vulnerable Road Users (VRUs) that include pedestrians, bicyclists, cycle-rickshaw occupants, and motorcyclists constitute by far the highest share of road traffic accidents in developing countries. Motorized three-wheeled Rickshaws (3W-MR) is a popular public transport mode in almost all Pakistani cities and is used primarily for short trips to carry passengers and small-scale goods movement. Despite being an important mode of public transport in the developing world, little work has been done to understand the factors affecting the injury severity of three-wheeled motorized vehicles. Crash injury severity prediction is a promising research target in traffic safety. Traditional statistical models have underlying assumptions and predefined associations, which can yield misleading results if flouted. Machine learning(ML) is an emerging non-parametric method that can effectively capture the non-linear effects of both continuous and discrete variables without prior assumptions and achieve better prediction accuracy. This research analyzed injury severity of three-wheeled motorized rickshaws (3W-MR) using various machine learning-based identification algorithms, i.e., Decision jungle (DJ), Random Forest (RF), and Decision Tree (DT). Three years of crash data (from 2017 to 2019) was collected from Provincial Emergency Response Service RESCUE 1122 for Rawalpindi city, Pakistan. A total of 2,743 3W-MR crashes were reported during the study period that resulted in 258 fatalities. The predictive performance of proposed ML models was assessed using several evaluation metrics such as overall accuracy, macro-average precision, macro-average recall, and geometric means of individual class accuracies. Results revealed that DJ with an overall accuracy of 83.7 % outperformed the DT and RF-based on a stratified 10-fold cross-validation approach. Finally, Spearman correlation analysis showed that factors such as the lighting condition, crashes involving young drivers (aged 20–30 years), facilities with high-speed limits (over 60 mph), weekday, off-peak, and shiny weather conditions were more likely to worsen injury severity of 3W-MR crashes. The outcomes of this study could provide necessary and essential guidance to road safety agencies, particularly in the study area, for proactive implementation of appropriate countermeasures to curb road safety issues pertaining to three-wheeled motorized vehicles.",2021,https://www.sciencedirect.com/science/article/pii/S0001457521001251,https://doi.org/10.1016/j.aap.2021.106094,NA,top-tier,yes,"safety, transportation, engineering",0.9,"Accident Analysis & Prevention is a well-regarded journal focusing on research in road safety, engineering, and transportation. It is known for high-quality peer-reviewed articles that contribute substantially to the safety and prevention field.",elsevier_venues.csv,Accident Analysis & Prevention,NA,Elsevier,NA
Accident Analysis & Prevention,A cooperative collision-avoidance control methodology for virtual coupling trains,Shuai Su;Wentao Liu;Qingyang Zhu;Ruoqing Li;Tao Tang;Jidong Lv,"To further improve the line transport capacity, virtual coupling has become a frontier hot topic in the field of rail transit. Specially, the safe and efficient following control strategy based on relative distance braking mode (RDBM) is one of the core technologies. This paper innovatively proposes a cooperative collision-avoidance control methodology, which can enhance the operation efficiency on the premise of ensuring the safety. Firstly, a novel framework for the RDBM based on the predicted trajectory of the preceding train is proposed for the train collision-avoidance control. To reduce the train following distance, a cooperative control model is further proposed and is formulated as a Markov decision process. Then, the Deep-Q-Network (DQN) algorithm is introduced to solve the efficient control problem by learning the safe and efficient control strategy for the following train where the critical elements of the reinforcement learning framework are designed. Finally, experimental simulations are conducted based on the simulated environment to illustrate the effectiveness of the proposed approach. Compared with the absolute distance braking mode (ADBM), the minimum following distance between the adjacent trains can be reduced by 70.23% on average via the proposed approach while the safety can be guaranteed.",2022,https://www.sciencedirect.com/science/article/pii/S0001457522001397,https://doi.org/10.1016/j.aap.2022.106703,NA,top-tier,yes,"safety, transportation, engineering",0.9,"Accident Analysis & Prevention is a well-regarded journal focusing on research in road safety, engineering, and transportation. It is known for high-quality peer-reviewed articles that contribute substantially to the safety and prevention field.",elsevier_venues.csv,Accident Analysis & Prevention,NA,Elsevier,NA
Accident Analysis & Prevention,"A data-driven, kinematic feature-based, near real-time algorithm for injury severity prediction of vehicle occupants",Qingfan Wang;Shun Gan;Wentao Chen;Quan Li;Bingbing Nie,"Accurate real-time prediction of occupant injury severity in unavoidable collision scenarios is a prerequisite for enhancing road traffic safety with the development of highly automated vehicles. Specifically, a safety prediction model provides a decision reference for the trajectory planning system in the pre-crash phase and the adaptive restraint system in the in-crash phase. The main goal of the current study is to construct a data-driven, vehicle kinematic feature-based model to realize accurate and near real-time prediction of in-vehicle occupant injury severity. A large-scale numerical database was established focusing on occupant kinetics. A first-step deep-learning model was established to predict occupant kinetics and injury severity using a convolutional neural network (CNN). To reduce the computational time for real-time application, the second step was to extract simplified kinematic features from vehicle crash pulses via a feature extraction method, which was inspired by a visualization approach applied to the CNN-based model. The features were incorporated with a low-complexity machine-learning algorithm and achieved satisfactory accuracy (85.4 % on the numerical database, 78.7 % on a 192-case real-world dataset) and decreased computational time (1.2 ± 0.4 ms) on the prediction tasks. This study demonstrated the feasibility of using data-driven and feature-based approaches to achieve accurate injury risk estimation prior to collision. The proposed model is expected to provide a decision reference for integrated safety systems in the next generation of automated vehicles.",2021,https://www.sciencedirect.com/science/article/pii/S0001457521001809,https://doi.org/10.1016/j.aap.2021.106149,NA,top-tier,yes,"safety, transportation, engineering",0.9,"Accident Analysis & Prevention is a well-regarded journal focusing on research in road safety, engineering, and transportation. It is known for high-quality peer-reviewed articles that contribute substantially to the safety and prevention field.",elsevier_venues.csv,Accident Analysis & Prevention,NA,Elsevier,NA
Accident Analysis & Prevention,A hierarchical machine learning classification approach for secondary task identification from observed driving behavior data,Osama A. Osman;Mustafa Hajij;Sogand Karbalaieali;Sherif Ishak,"According to NHTSA, more than 3477 people (including 551 non-occupants) were killed and 391,000 were injured due to distraction-related crashes in 2015. The distracted driving epidemic has long been under research to identify its impact on driving behavior. There have been a few attempts to detect drivers’ engagement in secondary tasks from observed driving behavior. Yet, to the authors’ knowledge, not much effort has been directed to identify the types of secondary tasks from driving behavior parameters. This study proposes a bi-level hierarchical classification methodology using machine learning to identify the different types of secondary tasks drivers are engaged in using their driving behavior parameters. At the first level, drivers’ engagement in secondary tasks is detected, while at the second level, the distinct types of secondary tasks are identified. Comparative evaluation is performed between nine ensemble tree classification methods to identify three types of secondary tasks (hand-held cellphone calling, cellphone texting, and interaction with an adjacent passenger). The inputs to the models are five driving behavior parameters (speed, longitudinal acceleration, lateral acceleration, pedal position, and yaw rate) along with their standard deviations. The results showed that the overall secondary task detection accuracy ranged from 66% to 96%, except for the Decision Tree that was able to detect engagement in secondary tasks with a high accuracy of 99.8%. For the identification of secondary tasks types, the overall accuracy ranged from 55% to 79%, with the highest accuracy of 82.2% achieved by the Random Forest method. The findings of the paper show the proposed methodology promising to (1) characterize drivers’ engagement in unlawful secondary tasks (such as texting) as a counter measure to prevent crashes, and (2) alert drivers to pay attention back to the main driving task when risky changes to their driving behavior take place.",2019,https://www.sciencedirect.com/science/article/pii/S000145751831114X,https://doi.org/10.1016/j.aap.2018.12.005,8,top-tier,yes,"safety, transportation, engineering",0.9,"Accident Analysis & Prevention is a well-regarded journal focusing on research in road safety, engineering, and transportation. It is known for high-quality peer-reviewed articles that contribute substantially to the safety and prevention field.",elsevier_venues.csv,Accident Analysis & Prevention,NA,Elsevier,NA
Accident Analysis & Prevention,A high-resolution trajectory data driven method for real-time evaluation of traffic safety,Yuping Hu;Ye Li;Helai Huang;Jaeyoung Lee;Chen Yuan;Guoqing Zou,"Real-time safety evaluation is essential for developing proactive safety management strategy and improving the overall traffic safety. This paper proposes a method for real-time evaluation of road safety, in which traffic states and conflicts are combined to explore the internal relationship based on high-resolution trajectory data. In order to assess the real-time traffic safety at a lane level, the trajectory data of the HighD dataset from Germany are utilized to collect lane-based dataset. A surrogate safety measure, time-to-collision (TTC) index, is used for the conflict identification. A binary logistic regression model is employed to quantify the relationship between traffic states and conflicts. Moreover, machine learning methods, including support vector machine, decision tree, random forest, and gradient boosting decision tree, are applied for real-time evaluation. A total of 24 models are trained using the selected four classifier algorithms, and random forest achieves the best performance with 0.85 of the overall accuracy. The results show that the conflict risk can be well estimated by the proposed method. The findings of this study contribute to the high-precision evaluation of real-time traffic safety and the development of proactive safety management.",2022,https://www.sciencedirect.com/science/article/pii/S0001457521005340,https://doi.org/10.1016/j.aap.2021.106503,NA,top-tier,yes,"safety, transportation, engineering",0.9,"Accident Analysis & Prevention is a well-regarded journal focusing on research in road safety, engineering, and transportation. It is known for high-quality peer-reviewed articles that contribute substantially to the safety and prevention field.",elsevier_venues.csv,Accident Analysis & Prevention,NA,Elsevier,NA
Accident Analysis & Prevention,A methodology to design heuristics for model selection based on the characteristics of data: application to investigate when the negative binomial lindley (nb-l) is preferred over the negative binomial (nb),Mohammadali Shirazi;Soma Sekhar Dhavala;Dominique Lord;Srinivas Reddy Geedipally,"Safety analysts usually use post-modeling methods, such as the Goodness-of-Fit statistics or the Likelihood Ratio Test, to decide between two or more competitive distributions or models. Such metrics require all competitive distributions to be fitted to the data before any comparisons can be accomplished. Given the continuous growth in introducing new statistical distributions, choosing the best one using such post-modeling methods is not a trivial task, in addition to all theoretical or numerical issues the analyst may face during the analysis. Furthermore, and most importantly, these measures or tests do not provide any intuitions into why a specific distribution (or model) is preferred over another (Goodness-of-Logic). This paper ponders into these issues by proposing a methodology to design heuristics for Model Selection based on the characteristics of data, in terms of descriptive summary statistics, before fitting the models. The proposed methodology employs two analytic tools: (1) Monte-Carlo Simulations and (2) Machine Learning Classifiers, to design easy heuristics to predict the label of the ‘most-likely-true’ distribution for analyzing data. The proposed methodology was applied to investigate when the recently introduced Negative Binomial Lindley (NB-L) distribution is preferred over the Negative Binomial (NB) distribution. Heuristics were designed to select the ‘most-likely-true’ distribution between these two distributions, given a set of prescribed summary statistics of data. The proposed heuristics were successfully compared against classical tests for several real or observed datasets. Not only they are easy to use and do not need any post-modeling inputs, but also, using these heuristics, the analyst can attain useful information about why the NB-L is preferred over the NB - or vice versa- when modeling data.",2017,https://www.sciencedirect.com/science/article/pii/S0001457517302373,https://doi.org/10.1016/j.aap.2017.07.002,9,top-tier,yes,"safety, transportation, engineering",0.9,"Accident Analysis & Prevention is a well-regarded journal focusing on research in road safety, engineering, and transportation. It is known for high-quality peer-reviewed articles that contribute substantially to the safety and prevention field.",elsevier_venues.csv,Accident Analysis & Prevention,NA,Elsevier,NA
Accident Analysis & Prevention,A proactive crash risk prediction framework for lane-changing behavior incorporating individual driving styles,Yunchao Zhang;Yanyan Chen;Xin Gu;N.N. Sze;Jianling Huang,"Driving style may have an important effect on traffic safety. Proactive crash risk prediction for lane-changing behaviors incorporating individual driving styles can help drivers make safe lane-changing decisions. However, the interaction between driving styles and lane-changing risk is still not fully understood, making it difficult for advanced driver-assistance systems (ADASs) to provide personalized lane-changing risk information services. This paper proposes a personalized risk lane-changing prediction framework that considers driving style. Several driving volatility indices based on vehicle interactive features have been proposed, and a dynamic clustering method is developed to determine the best identification time window and methods of driving style. The Light Gradient Boosting Machine (LightGBM) based on Shapley additive explanation is used to predict lane-changing risk for cautious, normal, and aggressive drivers and to analyze their risk factors. The highD trajectory dataset is used to evaluate the proposed framework. The obtained results show that i) spectral clustering and a time window of 3 s can accurately identify driving styles during the lane-changing intention process; ii) the LightGBM algorithm outperforms other machine learning methods in personalized lane-changing risk prediction; iii) aggressive drivers seek more individual driving freedom than cautious and normal drivers and tend to ignore the state of the car behind them in the target lane, with a greater lane-changing risk. The research conclusion can provide basic support for the development and application of personalized lane-changing warning systems in ADASs.",2023,https://www.sciencedirect.com/science/article/pii/S0001457523001197,https://doi.org/10.1016/j.aap.2023.107072,NA,top-tier,yes,"safety, transportation, engineering",0.9,"Accident Analysis & Prevention is a well-regarded journal focusing on research in road safety, engineering, and transportation. It is known for high-quality peer-reviewed articles that contribute substantially to the safety and prevention field.",elsevier_venues.csv,Accident Analysis & Prevention,NA,Elsevier,NA
Accident Analysis & Prevention,A proactive lane-changing risk prediction framework considering driving intention recognition and different lane-changing patterns,Qiangqiang Shangguan;Ting Fu;Junhua Wang;Shou'en Fang;Liping Fu,"Proactive lane-changing (LC) risk prediction can assist driver’s LC decision-making to ensure driving safety. However, most previous studies on LC risk prediction did not consider the driver’s intention recognition, which made it difficult to guarantee the timeliness and practicability of LC risk prediction. Moreover, the difference in driving risks and its influencing factors between LC to left lane (LCL) and LC to right lane (LCR) have rarely been investigated. To bridge the above research gaps, this study proposes a proactive LC risk prediction framework which integrates the LC intention recognition module and LC risk prediction module. The Long Short-term Memory (LSTM) neural network with time-series input was employed to recognize the driver’s LC intention. The Light Gradient Boosting Machine (LGBM) algorithm was then applied to predict the LC risk. Feature importance analysis was lastly conducted to obtain the key features that affect the LC risk. The highD trajectory dataset was used for framework validation. Results show that the recognition accuracy of the driver’s LCL, LCR and lane-keeping (LK) intentions based on the proposed LSTM model are 97%, 96% and 97%, respectively. Meanwhile, the LGBM algorithm outperforms other machine learning algorithms in LC risk prediction. The results from feature importance analysis show that the interaction characteristics of the LC vehicle and its preceding vehicle in the current lane have the greatest impact on the LC risk. The proposed framework could potentially be implemented in advanced driver-assistance system (ADAS) or autonomous driving system for improved driving safety.",2022,https://www.sciencedirect.com/science/article/pii/S0001457521005315,https://doi.org/10.1016/j.aap.2021.106500,NA,top-tier,yes,"safety, transportation, engineering",0.9,"Accident Analysis & Prevention is a well-regarded journal focusing on research in road safety, engineering, and transportation. It is known for high-quality peer-reviewed articles that contribute substantially to the safety and prevention field.",elsevier_venues.csv,Accident Analysis & Prevention,NA,Elsevier,NA
Accident Analysis & Prevention,A task-level emergency experience reuse method for freeway accidents onsite disposal with policy distilled reinforcement learning,Longhao Yan;Ping Wang;Fan Qi;Zhuohang Xu;Ronghui Zhang;Yu Han,"A large number of freeway accident disposals are well-recorded by accident reports and surveillance videos, but it is not easy to get the emergency experience reused from past recorded accidents. To reuse emergency experience for better emergency decision-making, this paper proposed a knowledge-based experience transfer method to transfer task-level freeway accident disposal experience via multi-agent reinforcement learning algorithm with policy distillation. First, the Markov decision process is used to simulate the emergency decision-making process of multi-type freeway accident scene at the task level. Then, an adaptive knowledge transfer method named policy distilled multi-agent deep deterministic policy gradient (PD-MADDPG) algorithm is proposed to reuse experience from past freeway accident records to current accidents for fast decision-making and optimal onsite disposal. The performance of the proposed algorithm is evaluated on instantiated cases of freeway accidents that occurred on the freeway in Shaanxi Province, China. Aside from achieving better emergency decisions performance than various typical decision-making methods, the result shows decision maker with transferred knowledge owns 65.22%, 11.37%, 9.23%, 7.76% and 1.71% higher average reward than those without in the five studied cases, respectively. Indicating that the emergency experience transferred from past accidents contributes to fast emergency decision-making and optimal accident onsite disposal.",2023,https://www.sciencedirect.com/science/article/pii/S0001457523002269,https://doi.org/10.1016/j.aap.2023.107179,NA,top-tier,yes,"safety, transportation, engineering",0.9,"Accident Analysis & Prevention is a well-regarded journal focusing on research in road safety, engineering, and transportation. It is known for high-quality peer-reviewed articles that contribute substantially to the safety and prevention field.",elsevier_venues.csv,Accident Analysis & Prevention,NA,Elsevier,NA
Accident Analysis & Prevention,Advancing urban traffic accident forecasting through sparse spatio-temporal dynamic learning,Pengfei Cui;Xiaobao Yang;Mohamed Abdel-Aty;Jinlei Zhang;Xuedong Yan,"Traffic accidents have emerged as one of the most public health safety matters, raising concerns from both the public and urban administrators. The ability to accurately predict traffic accident not only supports the governmental decision-making in advance but also enhances public confidence in safety measures. However, the efficacy of traditional spatio-temporal prediction models are compromised by the skewed distributions and sparse labeling of accident data. To this end, we propose a Sparse Spatio-Temporal Dynamic Hypergraph Learning (SST-DHL) framework that captures higher-order dependencies in sparse traffic accidents by combining hypergraph learning and self-supervised learning. The SST-DHL model incorporates a multi-view spatiotemporal convolution block to capture local correlations and semantics of traffic accidents, a cross-regional dynamic hypergraph learning model to identify global spatiotemporal dependencies, and a two-supervised self-learning paradigm to capture both local and global spatiotemporal patterns. Through experimentation on New York City and London accident datasets, we demonstrate that our proposed SST-DHL exhibits significant improvements compared to optimal baseline models at different sparsity levels. Additionally, it offers enhanced interpretability of results by elucidating complex spatio-temporal dependencies among various traffic accident instances. Our study demonstrates the effectiveness of the SST-DHL framework in accurately predicting traffic accidents, thereby enhancing public safety and trust.",2024,https://www.sciencedirect.com/science/article/pii/S000145752400109X,https://doi.org/10.1016/j.aap.2024.107564,NA,top-tier,yes,"safety, transportation, engineering",0.9,"Accident Analysis & Prevention is a well-regarded journal focusing on research in road safety, engineering, and transportation. It is known for high-quality peer-reviewed articles that contribute substantially to the safety and prevention field.",elsevier_venues.csv,Accident Analysis & Prevention,NA,Elsevier,NA
Accident Analysis & Prevention,Analysis of mobile phone use engagement during naturalistic driving through explainable imbalanced machine learning,Apostolos Ziakopoulos;Armira Kontaxi;George Yannis,"While driver distraction remains an issue in modernized societies, technological advancements in data collection, storage and analysis provide the means for deeper insights of this complex phenomenon. In this research, factors influencing when driver distraction through mobile phone use occurs during naturalistic driving are investigated. Naturalistic data from a 6-stage, 230-driver experiment are exploited, in which drivers installed a non-intrusive driving recording application in their devices and conducted their trips normally across a 21-month timespan, coupled with corresponding questionnaire data. The various experiment stages involved providing progressively more behavioral feedback to drivers while continuing to record them. Subsequently, supervised Machine Learning XGBoost algorithms were employed to model the contributions of naturalistic driving and questionnaire features to the decision to engage mobile phone use. Mobile phone use percentages were heavily skewed towards zero, therefore imbalanced ML with a minority-oversampling approach in a binary format was employed. To increase the explainability offered by the algorithm, SHAP values were calculated for the informative features. Results indicate that the decision of drivers to use a mobile while driving is governed by a number of complex, non-linear relationships. Total trip distance is the most significant predictor variable by a wide margin, with mean SHAP values of 0.79 towards affecting the model decisions for the probability of mobile phone use of each driver. However, other variables influence the final predictions as well, such as the number of tickets in the last three years (m.SHAP = 0.30), declared mobile phone use (m.SHAP = 0.26), the amount and variety of provided feedback (m.SHAP = 0.17) (i.e. experiment phase number) and family member numbers (m.SHAP = 0.09) decrease the probability of using a mobile phone while driving. Conversely, increases in driver experience (m.SHAP = 0.22), driver age (m.SHAP = 0.11), engine capacity (m.SHAP = 0.11) and total kilometers driven annually (m.SHAP = 0.08) increase the probability of using a mobile phone in naturalistic driving conditions. SHAP dependency plots reveal non-linear effects present in almost all variables. Fuel consumption had a particularly strong non-linear effect, as higher values of this variable lead to both higher and lower probability of drivers using a mobile phone, deviating from the safer average. Legislation, campaigns and enforcement measures can be restructured to take advantage of gains margins in terms of understanding and predicting driver distraction behavior, as explored in the present study.",2023,https://www.sciencedirect.com/science/article/pii/S0001457522003712,https://doi.org/10.1016/j.aap.2022.106936,NA,top-tier,yes,"safety, transportation, engineering",0.9,"Accident Analysis & Prevention is a well-regarded journal focusing on research in road safety, engineering, and transportation. It is known for high-quality peer-reviewed articles that contribute substantially to the safety and prevention field.",elsevier_venues.csv,Accident Analysis & Prevention,NA,Elsevier,NA
Accident Analysis & Prevention,The novel approaches to classify cyclist accident injury-severity: hybrid fuzzy decision mechanisms,Burak Yiğit Katanalp;Ezgi Eren,"In this study, two novel fuzzy decision approaches, where the fuzzy logic (FL) model was revised with the C4.5 decision tree (DT) algorithm, were applied to the classification of cyclist injury-severity in bicycle-vehicle accidents. The study aims to evaluate two main research topics. The first one is investigation of the effect of road infrastructure, road geometry, street, accident, atmospheric and cyclist related parameters on the classification of cyclist injury-severity similarly to other studies in the literature. The second one is examination of the performance of the new fuzzy decision approaches described in detail in this study for the classification of cyclist injury-severity. For this purpose, the data set containing bicycle-vehicle accidents in 2013–2017 was analyzed with the classic C4.5 algorithm and two different hybrid fuzzy decision mechanisms, namely DT-based converted FL (DT-CFL) and novel DT-based revised FL (DT-RFL). The model performances were compared according to their accuracy, precision, recall, and F-measure values. The results indicated that the parameters that have the greatest effect on the injury-severity in bicycle-vehicle accidents are gender, vehicle damage-extent, road-type as well as the highly effective parameters such as pavement type, accident type, and vehicle-movement. The most successful classification performance among the three models was achieved by the DT-RFL model with 72.0 % F-measure and 69.96 % Accuracy. With 59.22 % accuracy and %57.5 F-measure values, the DT-CFL model, rules of which were created according to the splitting criteria of C4.5 algorithm, gave worse results in the classification of the injury-severity in bicycle-vehicle accidents than the classical C4.5 algorithm. In light of these results, the use of fuzzy decision mechanism models presented in this study on more comprehensive datasets is recommended for further studies.",2020,https://www.sciencedirect.com/science/article/pii/S0001457520305522,https://doi.org/10.1016/j.aap.2020.105590,NA,top-tier,yes,"safety, transportation, engineering",0.9,"Accident Analysis & Prevention is a well-regarded journal focusing on research in road safety, engineering, and transportation. It is known for high-quality peer-reviewed articles that contribute substantially to the safety and prevention field.",elsevier_venues.csv,Accident Analysis & Prevention,NA,Elsevier,NA
Accident Analysis & Prevention,Tracking traffic congestion and accidents using social media data: a case study of shanghai,Haoliang Chang;Lishuai Li;Jianxiang Huang;Qingpeng Zhang;Kwai-Sang Chin,"Traffic congestion and accidents take a toll on commuters' daily experiences and society. Locating the venues prone to congestion and accidents and capturing their perception by public members is invaluable for transport policy-makers. However, few previous methods consider user perception toward the accidents and congestion in finding and profiling the accident- and congestion-prone areas, leaving decision-makers unaware of the subsequent behavior responses and priorities of retrofitting measures. This study develops a framework to identify and characterize the accident- and congestion-prone areas heatedly discussed on social media. First, we use natural language processing and deep learning to detect the accident- and congestion-relevant Chinese microblogs posted on Sina Weibo, a Chinese social media platform. Then a modified Kernel Density Estimation method considering the sentiment of microblogs is employed to find the accident- and congestion-prone regions. The results show that the 'congestion-prone areas' discussed on social media are mainly distributed throughout the historical urban core and the Northwest of Pudong New Area, in reasonably good agreements with actual congestion records. In contrast, the 'accident-prone areas' are primarily found in locations with severe accidents. Finally, the above venues are characterized in spatio-temporal and semantic aspects to understand the nature of the incidents and assess the priority level for mitigation measures. The outcomes can provide a reference for traffic authorities to inform resource allocation and prioritize mitigation measures in future traffic management.",2022,https://www.sciencedirect.com/science/article/pii/S0001457522000549,https://doi.org/10.1016/j.aap.2022.106618,NA,top-tier,yes,"safety, transportation, engineering",0.9,"Accident Analysis & Prevention is a well-regarded journal focusing on research in road safety, engineering, and transportation. It is known for high-quality peer-reviewed articles that contribute substantially to the safety and prevention field.",elsevier_venues.csv,Accident Analysis & Prevention,NA,Elsevier,NA
Accident Analysis & Prevention,Unraveling preference heterogeneity in willingness-to-pay for enhanced road safety: a hybrid approach of machine learning and quantile regression,Fazle Subhan;Yasir Ali;Shengchuan Zhao,"Investing in road safety enhancement programs highly depends on the economic valuation of road traffic accidents and their outcomes. Such evaluation underpins road safety interventions in cost-benefit analysis. To this end, understanding and modeling public willingness-to-pay for enhanced road safety have received significant attention in the past few decades. However, despite considerable modeling efforts, some issues still persist in earlier studies, namely, (i) using standard regression approaches that assume a homogeneous impact of explanatory variables on willingness-to-pay, not accounting for heterogeneity, and depends on a priori distribution of the dependent variable, and (ii) the absence of higher-order interactions from models, leading to omitted variable bias and erroneous model inferences. To overcome this critical research gap, our study proposes a new modeling framework, integrating a machine learning technique (decision tree) to identify a priori relationships for higher-order interactions and a quantile regression model to account for heterogeneity along the entire range of willingness-to-pay. The proposed framework examines the determinants of willingness-to-pay for enhanced road safety using a sample of car drivers from Peshawar, Pakistan. Modeling results indicate that variables not significant in a linear model become significant at specific quantiles of the willingness-to-pay distribution. Further, including higher-order interactions among the explanatory variables provides additional insights into the complex relationship between willingness-to-pay and its determinants. In addition, willingness-to-pay for fatal and severe injury risk reductions is estimated at different quartiles and used to calculate the values of corresponding risk reductions. Overall, the proposed framework provides a better understanding of public sensitivities to willingness-to-pay for enhanced road safety.",2023,https://www.sciencedirect.com/science/article/pii/S0001457523002233,https://doi.org/10.1016/j.aap.2023.107176,NA,top-tier,yes,"safety, transportation, engineering",0.9,"Accident Analysis & Prevention is a well-regarded journal focusing on research in road safety, engineering, and transportation. It is known for high-quality peer-reviewed articles that contribute substantially to the safety and prevention field.",elsevier_venues.csv,Accident Analysis & Prevention,NA,Elsevier,NA
Accident Analysis & Prevention,Unraveling the determinants of traffic incident duration: a causal investigation using the framework of causal forests with debiased machine learning,Yaming Guo;Meng Li;Keqiang Li;Huiping Li;Yunxuan Li,"Predicting the duration of traffic incidents is challenging due to their stochastic nature. Accurate predictions can greatly benefit end-users by informing their route choices and safety warnings, while helping traffic operation managers more effectively manage non-recurrent traffic congestion and enhance road safety. This study conducts a comprehensive causal analysis of traffic incident duration using a data collected over a long time and including different types of roads across the city of Tianjin, China. Employing the innovative framework of causal forests with biased machine learning (CF-DML) techniques, this study advances beyond traditional methods by focusing on interpreting the causal relationships between various factors and incident duration, emphasizing the role of heterogeneity among these factors. The CF-DML framework enables the assessment of the average treatment effects (ATEs) of various factors on incident duration. Notably, the significant influence of road type and suburban setting on treatment effects is underscored, which is generally consistent with the results obtained through classical methods. Second, to look more closely at the important factors such as road and collision types, a conditional average treatment effects (CATE) analysis is conducted, explaining heterogeneity through a causal heterogeneity tree. Third, based on insights from causal analysis, policies related to lane configurations are explored, emphasizing the necessity of considering causal effects in traffic management decisions. The CF-DML framework enhances our understanding of traffic incident dynamics, contributing to improved road safety and traffic flow in diverse urban environments.",2024,https://www.sciencedirect.com/science/article/pii/S0001457524003518,https://doi.org/10.1016/j.aap.2024.107806,NA,top-tier,yes,"safety, transportation, engineering",0.9,"Accident Analysis & Prevention is a well-regarded journal focusing on research in road safety, engineering, and transportation. It is known for high-quality peer-reviewed articles that contribute substantially to the safety and prevention field.",elsevier_venues.csv,Accident Analysis & Prevention,NA,Elsevier,NA
Accounts of Chemical Research,"Addressing Atropisomerism in the Development of Sotorasib, a Covalent Inhibitor of KRAS G12C: Structural, Analytical, and Synthetic Considerations",Brian A. Lanman;Andrew T. Parsons;Stephan G. Zech,"ConspectusNearly a century after its first description, configurationally stable axial chirality remains a rare feature in marketed drugs. In the development of the KRASG12C inhibitor sotorasib (LUMAKRAS/LUMYKRAS), an axially chiral biaryl moiety proved a critical structural element in engaging a “cryptic” protein binding pocket and enhancing inhibitor potency. Restricted rotation about this axis of chirality gave rise to configurationally stable atropisomers that demonstrated a 10-fold difference in potency. The decision to develop sotorasib as a single-atropisomer drug gave rise to a range of analytical and synthetic challenges, whose resolution we review here.Assessing the configurational stability of differentially substituted biaryl units in early inhibitor candidates represented the first challenge to be overcome, as differing atropisomer stability profiles called for differing development strategies (e.g., as rapidly equilibrating rotamers vs as single atropisomers). We relied on a range of NMR, HPLC, and computational methods to assess atropisomer stability. Here, we describe the various variable-temperature NMR, time-course NMR, and chiral HPLC approaches used to assess the configurational stability of axially chiral bonds displaying a range of rotational barriers.As optimal engagement of the “cryptic” pocket of KRASG12C was ultimately achieved with a configurationally stable atropisomeric linkage, the second challenge to be overcome entailed preparing the preferred (M)-atropisomer of sotorasib on industrial scale. This synthetic challenge centered on the large-scale synthesis of an atropisomerically pure building block comprising the central azaquinazolinone and pyridine rings of sotorasib. We examined a range of strategies to prepare this compound as a single atropisomer: asymmetric catalysis, chiral chromatographic purification, and classical resolution. Although chiral liquid and simulated moving bed chromatography provided expedient access to initial multikilo supplies of this key intermediate, a classical resolution process was ultimately developed that proved significantly more efficient on metric-ton scale. To avoid discarding half of the material from this resolution, this process was subsequently refined to enable thermal recycling of the undesired atropisomer, providing an even more efficient commercial process that proved both robust and green.While the preparation of sotorasib as a single atropisomer significantly increased both the analytical and synthetic complexity of its development, the axially chiral biaryl linkage that gave rise to the atropisomerism of sotorasib proved a key design element in optimizing sotorasib’s binding to KRASG12C. It is hoped that this review will help in outlining the range of analytical techniques and synthetic strategies that can be brought to bear in addressing the challenges posed by such axially chiral compounds and that this account may provide helpful guidelines for future efforts aimed at the development of such single atropisomer, axially chiral pharmaceutical agents.",2022,https://pubs.acs.org/doi/abs/10.1021/acs.accounts.2c00479,10.1021/acs.accounts.2c00479,12,top-tier,yes,chemistry,0.95,"Accounts of Chemical Research is a highly respected journal published by the American Chemical Society that provides concise reviews of recent advances in chemistry. Given its reputation and impact factor, it is considered a top-tier, peer-reviewed publication venue in the field of Chemistry.",acs_venues.csv,Accounts of Chemical Research,Article,ACS,NA
Accounts of Chemical Research,Combating Antimicrobial Resistance via Single-Cell Diagnostic Technologies Powered by Droplet Microfluidics,Kuangwen Hsieh;Kathleen E. Mach;Pengfei Zhang;Joseph C. Liao;Tza-Huei Wang,"ConspectusAntimicrobial resistance is a global threat that if left unchecked could lead to 10 million annual mortalities by 2050. One factor contributing to the rise of multi-drug-resistant (MDR) pathogens is the reliance on traditional culture-based pathogen identification (ID) and antimicrobial susceptibility testing (AST) that typically takes several days. This delay of objective pathogen ID and AST information to inform clinical decision making results in clinicians treating patients empirically often using first-line, broad-spectrum antibiotics, contributing to the misuse/overuse of antibiotics. To combat the rise in MDR pathogens, there is a critical demand for rapid ID and AST technologies. Among the advances in ID and AST technologies in the past decade, single-cell diagnostic technologies powered by droplet microfluidics offer great promise due to their potential for high-sensitivity detection and rapid turnaround time. Our laboratory has been at the forefront of developing such technologies and applying them to diagnosing urinary tract infections (UTIs), one of the most common infections and a frequent reason for the prescription of antimicrobials. For pathogen ID, we first demonstrated the highly sensitive, amplification-free detection of single bacterial cells by confining them in picoliter-scale droplets and detection with fluorogenic peptide nucleic acid (PNA) probes that target their 16S rRNA (rRNA), a well-characterized marker for phylogenic classification. We subsequently improved the PNA probe design and enhanced detection sensitivity. For single-cell AST, we first employed a growth indicator dye and engineered an integrated device that allows us to detect growth from single bacterial cells under antibiotic exposure within 1 h, equivalent to two to three bacterial replications. To expand beyond testing a single antibiotic condition per device, a common limitation for droplet microfluidics, we developed an integrated programmable droplet microfluidic device for scalable single-cell AST. Using the scalable single-cell AST platform, we demonstrated the generation of up to 32 droplet groups in a single device with custom antibiotic titers and the capacity to scale up single-cell AST, and providing reliable pathogen categories beyond a binary call embodies a critical advance. Finally, we developed an integrated ID and AST platform. To this end, we developed a PNA probe panel that can identify nearly 90% of uropathogens and showed the quantitative detection of 16S rRNA from single bacterial cells in droplet-enabled AST after as little as 10 min of antibiotic exposure. This platform achieved both ID and AST from minimally processed urine samples in 30 min, representing one of the fastest turnaround times to date. In addition to tracing the development of our technologies, we compare them with contemporary research advances and offer our perspectives for future development, with the vision that single-cell ID and AST technologies powered by droplet microfluidics can indeed become a useful diagnostic tool for combating antimicrobial resistance.",2022,https://pubs.acs.org/doi/abs/10.1021/acs.accounts.1c00462,10.1021/acs.accounts.1c00462,11,top-tier,yes,chemistry,0.95,"Accounts of Chemical Research is a highly respected journal published by the American Chemical Society that provides concise reviews of recent advances in chemistry. Given its reputation and impact factor, it is considered a top-tier, peer-reviewed publication venue in the field of Chemistry.",acs_venues.csv,Accounts of Chemical Research,Article,ACS,NA
Accounts of Chemical Research,"Dreams, False Starts, Dead Ends, and Redemption: A Chronicle of the Evolution of a Chemoinformatic Workflow for the Optimization of Enantioselective Catalysts",N. Ian Rinehart;Andrew F. Zahrt;Jeremy J. Henle;Scott E. Denmark,"ConspectusCatalyst design in enantioselective catalysis has historically been driven by empiricism. In this endeavor, experimentalists attempt to qualitatively identify trends in structure that lead to a desired catalyst function. In this body of work, we lay the groundwork for an improved, alternative workflow that uses quantitative methods to inform decision making at every step of the process. At the outset, we define a library of synthetically accessible permutations of a catalyst scaffold with the philosophy that the library contains every potential catalyst we are willing to make. To represent these chiral molecules, we have developed general 3D representations, which can be calculated for tens of thousands of structures. This defines the total chemical space of a given catalyst scaffold; it is constructed on the basis of catalyst structure only without regard to a specific reaction or mechanism. As such, any algorithmic subset selection method, which is unsupervised (i.e., only considers catalyst structure), should provide an ideal initial screening set for any new reaction that can be catalyzed by that scaffold. Notably, because this design strategy, the same set of catalysts can be used for any reaction that can be catalyzed with that parent catalyst scaffold. These are tested experimentally, and statistical learning tools can be used to create a model relating catalyst structure to catalyst function. Further, this model can be used to predict the performance of each catalyst candidate in the greater database of virtual catalyst candidates. In this way, it is possible estimate the performance of tens of thousands of catalysts by experimentally testing a smaller subset. Using error assessment metrics, it is possible to understand the confidence in new predictions. An experimentalist using this tool can balance the predicted results (reward) with the prediction confidence (risk) when deciding which catalysts to synthesize next in an optimization campaign. These catalysts are synthesized and tested experimentally. At this stage, either the optimization is a success or the predicted values were incorrect and further optimization is required. In the case of the latter, the information can be fed back into the statistical learning model to refine the model, and this iterative process can be used to determine the optimal catalyst. In this body of work, we not only establish this workflow but quantitatively establish how best to execute each step. Herein, we evaluate several 3D molecular representations to determine how best to represent molecules. Several selection protocols are examined to best decide which set of molecules can be used to represent the library of interest. In addition, the number of reactions needed to make accurate, statistical learning models is evaluated. Taken together these components establish a tool ready to progress from the development stage to the utility stage. As such, current research endeavors focus on applying these tools to optimize new reactions.",2021,https://pubs.acs.org/doi/abs/10.1021/acs.accounts.0c00826,10.1021/acs.accounts.0c00826,14,top-tier,yes,chemistry,0.95,"Accounts of Chemical Research is a highly respected journal published by the American Chemical Society that provides concise reviews of recent advances in chemistry. Given its reputation and impact factor, it is considered a top-tier, peer-reviewed publication venue in the field of Chemistry.",acs_venues.csv,Accounts of Chemical Research,Article,ACS,NA
Accounts of Chemical Research,Engineering Steps for Mobile Point-of-Care Diagnostic Devices,Ayden Malekjahani;Shrey Sindhwani;Abdullah Muhammad Syed;Warren C. W. Chan,"ConspectusMobile phone technology is a perfect companion for point-of-care diagnostics as they come equipped with advanced processors, high resolution cameras, and network connectivity. Despite several academic pursuits, only a few mobile phone diagnostics have been tested in the field, commercialized or achieved regulatory approval. This review will address the challenges associated with developing mobile diagnostics and suggest strategies to overcome them. We aim to provide a resource for researchers to accelerate the development of new diagnostics. Our Account includes an overview of published mobile phone diagnostics and highlights lessons learned from their approach to diagnostic development. Also, we have included recommendations from regulatory and public health agencies, such as the U.S. Food and Drug Administration and World Health Organization, to further guide researchers.We believe that the development of mobile phone point-of-care diagnostics takes place in four distinct steps: (1) Needs and Value Assessment, (2) Technology Development, (3) Preclinical Verification, and (4) Clinical Validation and Field Trials. During each step, we outline developmental strategies to help researchers avoid potential challenges. (1) Researchers commonly develop devices to maximize technical parameters such as sensitivity and time which do not necessarily translate to increased clinical impact. Researchers must focus on assessing specific diagnostic needs and the value which a potential device would offer. (2) Often, researchers claim they have developed devices for feasible implementation at the point-of-care, yet they rely on laboratory resources. Researchers must develop equipment-free devices which are agnostic to any mobile phone. (3) Another challenge researchers face is decreased performance during field evaluations relative to initial laboratory verification. Researchers must ensure that they simulate the field conditions during laboratory verification to achieve successful translation. (4) Finally, proper field testing of devices must be performed in conditions which match that of the final intended use.The future of mobile phone point-of-care diagnostic devices is bright and has the potential to radically change how patients are diagnosed. Before we reach this point, researchers must take a step backward and focus on the first-principles of basic research. The widespread adoption and rapid scaling of these devices can only be achieved once the fundamentals have been considered. The insights and strategies provided here will help researchers avoid pitfalls, streamline development and make better decisions during the development of new diagnostics. Further, we believe this Account can help push the field of mobile diagnostics toward increased productivity, leading to more approved devices and ultimately helping curb the burden of disease worldwide.",2019,https://pubs.acs.org/doi/abs/10.1021/acs.accounts.9b00200,10.1021/acs.accounts.9b00200,9,top-tier,yes,chemistry,0.95,"Accounts of Chemical Research is a highly respected journal published by the American Chemical Society that provides concise reviews of recent advances in chemistry. Given its reputation and impact factor, it is considered a top-tier, peer-reviewed publication venue in the field of Chemistry.",acs_venues.csv,Accounts of Chemical Research,Article,ACS,NA
Accounts of Chemical Research,First-Principles Molecular Dynamics Studies of Organometallic Complexes and Homogeneous Catalytic Processes,Pietro Vidossich;Agustí Lledós;Gregori Ujaque,"ConspectusComputational chemistry is a valuable aid to complement experimental studies of organometallic systems and their reactivity. It allows probing mechanistic hypotheses and investigating molecular structures, shedding light on the behavior and properties of molecular assemblies at the atomic scale. When approaching a chemical problem, the computational chemist has to decide on the theoretical approach needed to describe electron/nuclear interactions and the composition of the model used to approximate the actual system. Both factors determine the reliability of the modeling study. The community dedicated much effort to developing and improving the performance and accuracy of theoretical approaches for electronic structure calculations, on which the description of (inter)atomic interactions rely.Here, the importance of the model system used in computational studies is highlighted through examples from our recent research focused on organometallic systems and homogeneous catalytic processes. We show how the inclusion of explicit solvent allows the characterization of molecular events that would otherwise not be accessible in reduced model systems (clusters). These include the stabilization of nascent charged fragments via microscopic solvation (notably, hydrogen bonding), transfer of charge (protons) between distant fragments mediated by solvent molecules, and solvent coordination to unsaturated metal centers. Furthermore, when weak interactions are involved, we show how conformational and solvation properties of organometallic complexes are also affected by the explicit inclusion of solvent molecules. Such extended model systems may be treated under periodic boundary conditions, thus removing the cluster/continuum (or vacuum) boundary, and require a statistical mechanics simulation technique to sample the accessible configurational space. First-principles molecular dynamics, in which atomic forces are computed from electronic structure calculations (namely, density functional theory), is certainly the technique of choice to investigate chemical events in solution. This methodology is well established and thanks to advances in both algorithms and computational resources simulation times required for the modeling of chemical events are nowadays accessible, though the computational requirements use to be high. Specific applications reviewed here include mechanistic studies of the Shilov and Wacker processes, speciation in Pd chemistry, hydrogen bonding to metal centers, and the dynamics of agostic interactions.",2016,https://pubs.acs.org/doi/abs/10.1021/acs.accounts.6b00054,10.1021/acs.accounts.6b00054,8,top-tier,yes,chemistry,0.95,"Accounts of Chemical Research is a highly respected journal published by the American Chemical Society that provides concise reviews of recent advances in chemistry. Given its reputation and impact factor, it is considered a top-tier, peer-reviewed publication venue in the field of Chemistry.",acs_venues.csv,Accounts of Chemical Research,Article,ACS,NA
Accounts of Chemical Research,Knowledge Engineering in Chemistry: From Expert Systems to Agents of Creation,Aleksandar Kondinski;Jiaru Bai;Sebastian Mosbach;Jethro Akroyd;Markus Kraft,"ConspectusPassing knowledge from human to human is a natural process that has continued since the beginning of humankind. Over the past few decades, we have witnessed that knowledge is no longer passed only between humans but also from humans to machines. The latter form of knowledge transfer represents a cornerstone in artificial intelligence (AI) and lays the foundation for knowledge engineering (KE). In order to pass knowledge to machines, humans need to structure, formalize, and make knowledge machine-readable. Subsequently, humans also need to develop software that emulates their decision-making process. In order to engineer chemical knowledge, chemists are often required to challenge their understanding of chemistry and thinking processes, which may help improve the structure of chemical knowledge.Knowledge engineering in chemistry dates from the development of expert systems that emulated the thinking process of analytical and organic chemists. Since then, many different expert systems employing rather limited knowledge bases have been developed, solving problems in retrosynthesis, analytical chemistry, chemical risk assessment, etc. However, toward the end of the 20th century, the AI winters slowed down the development of expert systems for chemistry. At the same time, the increasing complexity of chemical research, alongside the limitations of the available computing tools, made it difficult for many chemistry expert systems to keep pace.In the past two decades, the semantic web, the popularization of object-oriented programming, and the increase in computational power have revitalized knowledge engineering. Knowledge formalization through ontologies has become commonplace, triggering the subsequent development of knowledge graphs and cognitive software agents. These tools enable the possibility of interoperability, enabling the representation of more complex systems, inference capabilities, and the synthesis of new knowledge.This Account introduces the history, the core principles of KE, and its applications within the broad realm of chemical research and engineering. In this regard, we first discuss how chemical knowledge is formalized and how a chemist’s cognition can be emulated with the help of reasoning algorithms. Following this, we discuss various applications of knowledge graph and agent technology used to solve problems in chemistry related to molecular engineering, chemical mechanisms, multiscale modeling, automation of calculations and experiments, and chemist–machine interactions. These developments are discussed in the context of a universal and dynamic knowledge ecosystem, referred to as The World Avatar (TWA).",2023,https://pubs.acs.org/doi/abs/10.1021/acs.accounts.2c00617,10.1021/acs.accounts.2c00617,12,top-tier,yes,chemistry,0.95,"Accounts of Chemical Research is a highly respected journal published by the American Chemical Society that provides concise reviews of recent advances in chemistry. Given its reputation and impact factor, it is considered a top-tier, peer-reviewed publication venue in the field of Chemistry.",acs_venues.csv,Accounts of Chemical Research,Article,ACS,NA
Accounts of Chemical Research,Liquid Organic Hydrogen Carriers (LOHCs): Toward a Hydrogen-free Hydrogen Economy,Patrick Preuster;Christian Papp;Peter Wasserscheid,"ConspectusThe need to drastically reduce CO2 emissions will lead to the transformation of our current, carbon-based energy system to a more sustainable, renewable-based one. In this process, hydrogen will gain increasing importance as secondary energy vector. Energy storage requirements on the TWh scale (to bridge extended times of low wind and sun harvest) and global logistics of renewable energy equivalents will create additional driving forces toward a future hydrogen economy. However, the nature of hydrogen requires dedicated infrastructures, and this has prevented so far the introduction of elemental hydrogen into the energy sector to a large extent. Recent scientific and technological progress in handling hydrogen in chemically bound form as liquid organic hydrogen carrier (LOHC) supports the technological vision that a future hydrogen economy may work without handling large amounts of elemental hydrogen. LOHC systems are composed of pairs of hydrogen-lean and hydrogen-rich organic compounds that store hydrogen by repeated catalytic hydrogenation and dehydrogenation cycles. While hydrogen handling in the form of LOHCs allows for using the existing infrastructure for fuels, it also builds on the existing public confidence in dealing with liquid energy carriers. In contrast to hydrogen storage by hydrogenation of gases, such as CO2 or N2, hydrogen release from LOHC systems produces pure hydrogen after condensation of the high-boiling carrier compounds.This Account highlights the current state-of-the-art in hydrogen storage using LOHC systems. It first introduces fundamental aspects of a future hydrogen economy and derives therefrom requirements for suitable LOHC compounds. Molecular structures that have been successfully applied in the literature are presented, and their property profiles are discussed. Fundamental and applied aspects of the involved hydrogenation and dehydrogenation catalysis are discussed, characteristic differences for the catalytic conversion of pure hydrocarbon and nitrogen-containing LOHC compounds are derived from the literature, and attractive future research directions are highlighted.Finally, applications of the LOHC technology are presented. This part covers stationary energy storage (on-grid and off-grid), hydrogen logistics, and on-board hydrogen production for mobile applications. Technology readiness of these fields is very different. For stationary energy storage systems, the feasibility of the LOHC technology has been recently proven in commercial demonstrators, and cost aspects will decide on their further commercial success. For other highly attractive options, such as, hydrogen delivery to hydrogen filling stations or direct-LOHC-fuel cell applications, significant efforts in fundamental and applied research are still needed and, hopefully, encouraged by this Account.",2017,https://pubs.acs.org/doi/abs/10.1021/acs.accounts.6b00474,10.1021/acs.accounts.6b00474,12,top-tier,yes,chemistry,0.95,"Accounts of Chemical Research is a highly respected journal published by the American Chemical Society that provides concise reviews of recent advances in chemistry. Given its reputation and impact factor, it is considered a top-tier, peer-reviewed publication venue in the field of Chemistry.",acs_venues.csv,Accounts of Chemical Research,Article,ACS,NA
Accounts of Chemical Research,Machine Learning in Computer-Aided Synthesis Planning,Connor\nW. Coley;William H. Green;Klavs F. Jensen,"ConspectusComputer-aided synthesis planning (CASP) is focused on the goal of accelerating the process by which chemists decide how to synthesize small molecule compounds. The ideal CASP program would take a molecular structure as input and output a sorted list of detailed reaction schemes that each connect that target to purchasable starting materials via a series of chemically feasible reaction steps. Early work in this field relied on expert-crafted reaction rules and heuristics to describe possible retrosynthetic disconnections and selectivity rules but suffered from incompleteness, infeasible suggestions, and human bias. With the relatively recent availability of large reaction corpora (such as the United States Patent and Trademark Office (USPTO), Reaxys, and SciFinder databases), consisting of millions of tabulated reaction examples, it is now possible to construct and validate purely data-driven approaches to synthesis planning. As a result, synthesis planning has been opened to machine learning techniques, and the field is advancing rapidly.In this Account, we focus on two critical aspects of CASP and recent machine learning approaches to both challenges. First, we discuss the problem of retrosynthetic planning, which requires a recommender system to propose synthetic disconnections starting from a target molecule. We describe how the search strategy, necessary to overcome the exponential growth of the search space with increasing number of reaction steps, can be assisted through a learned synthetic complexity metric. We also describe how the recursive expansion can be performed by a straightforward nearest neighbor model that makes clever use of reaction data to generate high quality retrosynthetic disconnections. Second, we discuss the problem of anticipating the products of chemical reactions, which can be used to validate proposed reactions in a computer-generated synthesis plan (i.e., reduce false positives) to increase the likelihood of experimental success. While we introduce this task in the context of reaction validation, its utility extends to the prediction of side products and impurities, among other applications. We describe neural network-based approaches that we and others have developed for this forward prediction task that can be trained on previously published experimental data.Machine learning and artificial intelligence have revolutionized a number of disciplines, not limited to image recognition, dictation, translation, content recommendation, advertising, and autonomous driving. While there is a rich history of using machine learning for structure–activity models in chemistry, it is only now that it is being successfully applied more broadly to organic synthesis and synthesis design. As reported in this Account, machine learning is rapidly transforming CASP, but there are several remaining challenges and opportunities, many pertaining to the availability and standardization of both data and evaluation metrics, which must be addressed by the community at large.",2018,https://pubs.acs.org/doi/abs/10.1021/acs.accounts.8b00087,10.1021/acs.accounts.8b00087,9,top-tier,yes,chemistry,0.95,"Accounts of Chemical Research is a highly respected journal published by the American Chemical Society that provides concise reviews of recent advances in chemistry. Given its reputation and impact factor, it is considered a top-tier, peer-reviewed publication venue in the field of Chemistry.",acs_venues.csv,Accounts of Chemical Research,Article,ACS,NA
Accounts of Chemical Research,New Opportunities for Organic Synthesis with Superheated Flow Chemistry,Pauline Bianchi and Jean-Christophe M. Monbaliu,"ConspectusFlow chemistry has brought a fresh breeze with great promises for chemical manufacturing, yet critical deterrents persist. To remain economically viable at production scales, flow processes demand quick reactions, which are actually not that common. Superheated flow technology stands out as a promising alternative poised to confront modern chemistry challenges. While continuous micro- and mesofluidic reactors offer uniform heating and rapid cooling across different scales, operating above solvent boiling points (i.e., operating under superheated conditions) significantly enhances reaction rates. Despite the energy costs associated with high temperatures, superheated flow chemistry aligns with sustainability goals by improving productivity (process intensification), offering solvent flexibility, and enhancing safety.However, navigating the unconventional chemical space of superheated flow chemistry can be cumbersome, particularly for neophytes. Expanding the temperature/pressure process window beyond the conventional boiling point under the atmospheric pressure limit vastly increases the optimization space. When associated with conventional trial-and-error approaches, this can become exceedingly wasteful, resource-intensive, and discouraging. Over the years, flow chemists have developed various tools to mitigate these challenges, with an increased reliance on statistical models, artificial intelligence, and experimental (kinetics, preliminary test reactions under microwave irradiation) or theoretical (quantum mechanics) a priori knowledge. Yet, the rationale for using superheated conditions has been slow to emerge, despite the growing emphasis on predictive methodologies.To fill this gap, this Account provides a concise yet comprehensive overview of superheated flow chemistry. Key concepts are illustrated with examples from our laboratory’s research, as well as other relevant examples from the literature. These examples have been thoroughly studied to answer the main questions Why? At what cost? How? For what? The answers we provide will encourage educated and widespread adoption. The discussion begins with a demonstration of the various advantages arising from superheated flow chemistry. Different reactor alternatives suitable for high temperatures and pressures are then presented. Next, a clear workflow toward strategic adoption of superheated conditions is resorted either using Design of Experiments (DoE), microwave test chemistry, kinetics data, or Quantum Mechanics (QM). We provide rationalization for chemistries that are well suited for superheated conditions (e.g., additions to carbonyl functions, aromatic substitutions, as well as C–Y [Y = N, O, S, C, Br, Cl] heterolytic cleavages). Lastly, we bring the reader to a rational decision analysis toward superheated flow conditions. We believe this Account will become a reference guide for exploring extended chemical spaces, accelerating organic synthesis, and advancing molecular sciences.",2024,https://pubs.acs.org/doi/abs/10.1021/acs.accounts.4c00340,10.1021/acs.accounts.4c00340,12,top-tier,yes,chemistry,0.95,"Accounts of Chemical Research is a highly respected journal published by the American Chemical Society that provides concise reviews of recent advances in chemistry. Given its reputation and impact factor, it is considered a top-tier, peer-reviewed publication venue in the field of Chemistry.",acs_venues.csv,Accounts of Chemical Research,Article,ACS,NA
Accounts of Chemical Research,Pro-Death or Pro-Survival: Contrasting Paradigms on Nanomaterial-Induced Autophagy and Exploitations for Cancer Therapy,Yunjiao Zhang;Li Zhang;Jinhao Gao;Longping Wen,"ConspectusAutophagy is a critical lysosome-mediated cellular degradation process for the clearance of damaged organelles, obsolete proteins, and invading pathogens and plays important roles in the pathogenesis and treatment of human diseases including cancer. While not a cell death process per se, autophagy is nevertheless intimately linked to a cell’s live/die decision. Basal autophagy, operating constitutively at low levels in essentially every mammalian cell, is vital for maintaining cellular homeostasis and promotes cell survival. On the other hand, elevated level of autophagy is frequently observed in cells responding to a physical, chemical, or biological stress. This “induced” autophagy, a hallmark under a variety of pathological and pathophysiological conditions, may be either pro-death or pro-survival, two contrasting paradigms for cell fate determination.Research in our laboratory and other groups around the world over the last 15 years has revealed nanomaterials as a unique class of autophagy inducers, with the capability of elevating the cellular autophagy to extremely high levels. In this Account we focus on the contrasting cell fate decision impacted by nanomaterial-induced autophagy. First, we give a brief introduction to nanomaterial-induced autophagy and summarize our current understanding on how it affects a cell’s live/die decision. Autophagy induced by nanomaterials, in most cases, promotes cell death, but a significant number of nanomaterials are also able to elicit pro-survival autophagy. Although not a common feature, some nanomaterials may induce pro-death autophagy in one cell type while eliciting pro-survival autophagy in a different cell type. The ability to control the level of the induced autophagy, and furthermore its pro-death/pro-survival nature, is critically important for nanomedicine. Second, we discuss several possible mechanistic insights on the pro-death/pro-survival decision for nanomaterial-induced autophagy. “Disrupted” autophagic processes, with a “block” or perhaps “diversion” at the various stages, may be a characteristic hallmark for nanomaterial-induced autophagy, rendering it intrinsically pro-death in nature. On the other hand, autophagy-mediated upregulation and activation of pro-survival factors or signaling pathways, overriding the intrinsic pro-death nature, may be a common mechanism for nanomaterial-induced pro-survival autophagy. In addition, cargo degradation and reactive oxygen species may also play important roles in the pro-death/pro-survival decision impacted by nanomaterial-induced autophagy. Finally, we focus on the situation where nanomaterials induce autophagy in cancer cells and summarize the different strategies in exploiting the pro-death or pro-survival nature of nanomaterial-induced autophagy to enhance the various modalities of cancer therapy, including direct cancer cell killing, chemotherapy and radiotherapy, photothermal therapy, and integrated diagnosis and therapy. While the details vary, the basic principle is simple and straightforward. If the induced autophagy is pro-death, maximize it. Otherwise, inhibit it. Effective exploitation of nanomaterial-induced autophagy has the potential to become a new weapon in our ever-increasing arsenal to fight cancer, particularly difficult-to-treat and drug-resistant cancer.",2019,https://pubs.acs.org/doi/abs/10.1021/acs.accounts.9b00397,10.1021/acs.accounts.9b00397,13,top-tier,yes,chemistry,0.95,"Accounts of Chemical Research is a highly respected journal published by the American Chemical Society that provides concise reviews of recent advances in chemistry. Given its reputation and impact factor, it is considered a top-tier, peer-reviewed publication venue in the field of Chemistry.",acs_venues.csv,Accounts of Chemical Research,Article,ACS,NA
ACL-IJCNLP System Demonstrations,LOA: Logical Optimal Actions for Text-based Interaction Games,"Kimura, Daiki; Chaudhury, Subhajit; Ono, Masaki; Tatsubori, Michiaki; Agravante, Don Joven; Munawar, Asim; Wachi, Akifumi; Kohita, Ryosuke; Gray, Alexander","We present Logical Optimal Actions (LOA), an action decision architecture of reinforcement learning applications with a neuro-symbolic framework which is a combination of neural network and symbolic knowledge acquisition approach for natural language interaction games. The demonstration for LOA experiments consists of a web-based interactive platform for text-based games and visualization for acquired knowledge for improving interpretability for trained rules. This demonstration also provides a comparison module with other neuro-symbolic approaches as well as non-symbolic state-of-the-art agent models on the same text-based games. Our LOA also provides open-sourced implementation in Python for the reinforcement learning environment to facilitate an experiment for studying neuro-symbolic agents. Demo site: https://ibm.biz/acl21-loa, Code: https://github.com/ibm/loa",2021,https://aclanthology.org/2021.acl-demo.27,10.18653/v1/2021.acl-demo.27,NA,top-tier,yes,computational linguistics,0.9,"The Annual Meeting of the Association for Computational Linguistics (ACL) is one of the top-tier conferences in natural language processing. System demo tracks are typically peer-reviewed and part of the main conference, showcasing practical implementations alongside theoretical advances.",acl_venues.csv,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: System Demonstrations,conferencePaper,ACL,NA
ACL-IJCNLP System Demonstrations,Supporting Complaints Investigation for Nursing and Midwifery Regulatory Agencies,"Lertvittayakumjorn, Piyawat; Petej, Ivan; Gao, Yang; Krishnamurthy, Yamuna; Van Der Gaag, Anna; Jago, Robert; Stathis, Kostas","Health professional regulators aim to protect the health and well-being of patients and the public by setting standards for scrutinising and overseeing the training and conduct of health and care professionals. A major task of such regulators is the investigation of complaints against practitioners. However, processing a complaint often lasts several months and is particularly costly. Hence, we worked with international regulators from different countries (the UK, US and Australia), to develop the first decision support tool that aims to help such regulators process complaints more efficiently. Our system uses state-of-the-art machine learning and natural language processing techniques to process complaints and predict their risk level. Our tool also provides additional useful information including explanations, to help the regulatory staff interpret the prediction results, and similar past cases as well as non-compliance to regulations, to support the decision making.",2021,https://aclanthology.org/2021.acl-demo.10,10.18653/v1/2021.acl-demo.10,NA,top-tier,yes,computational linguistics,0.9,"The Annual Meeting of the Association for Computational Linguistics (ACL) is one of the top-tier conferences in natural language processing. System demo tracks are typically peer-reviewed and part of the main conference, showcasing practical implementations alongside theoretical advances.",acl_venues.csv,Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: System Demonstrations,conferencePaper,ACL,NA
ACM Asia Conference on Computer and Communications Security,Stealing Deep Reinforcement Learning Models for Fun and Profit,"Chen, Kangjie; Guo, Shangwei; Zhang, Tianwei; Xie, Xiaofei; Liu, Yang","This paper presents the first model extraction attack against Deep Reinforcement Learning (DRL), which enables an external adversary to precisely recover a black-box DRL model only from its interaction with the environment. Model extraction attacks against supervised Deep Learning models have been widely studied. However, those techniques cannot be applied to the reinforcement learning scenario due to DRL models' high complexity, stochasticity and limited observable information. We propose a novel methodology to overcome the above challenges. The key insight of our approach is that the process of DRL model extraction is equivalent to imitation learning, a well-established solution to learn sequential decision-making policies. Based on this observation, our methodology first builds a classifier to reveal the training algorithm family of the targeted black-box DRL model only based on its predicted actions, and then leverages state-of-the-art imitation learning techniques to replicate the model from the identified algorithm family. Experimental results indicate that our methodology can effectively recover the DRL models with high fidelity and accuracy. We also demonstrate two use cases to show that our model extraction attack can (1) significantly improve the success rate of adversarial attacks, and (2) steal DRL models stealthily even they are protected by DNN watermarks. These pose a severe threat to the intellectual property and privacy protection of DRL applications.",2021,https://doi.org/10.1145/3433210.3453090,10.1145/3433210.3453090,13,top-tier,yes,computer security,0.95,"The ACM Asia Conference on Computer and Communications Security (AsiaCCS) is considered a top-tier conference in computer security, with rigorous peer review, and is highly respected in the field.",acm_venues.csv,Proceedings of the 2021 ACM Asia Conference on Computer and Communications Security,NA,ACM,NA
ACM Asia Conference on Computer and Communications Security,A Data-driven Attack against Support Vectors of SVM,"Liu, Shigang; Zhang, Jun; Wang, Yu; Zhou, Wanlei; Xiang, Yang; Vel., Olivier De","Machine learning (ML) is commonly used in multiple disciplines and real-world applications, such as information retrieval, financial systems, health, biometrics and online social networks. However, their security profiles against deliberate attacks have not often been considered. Sophisticated adversaries can exploit specific vulnerabilities exposed by classical ML algorithms to deceive intelligent systems. It is emerging to perform a thorough security evaluation as well as potential attacks against the machine learning techniques before developing novel methods to guarantee that machine learning can be securely applied in adversarial setting. In this paper, an effective attack strategy for crafting foreign support vectors in order to attack a classic ML algorithm, the Support Vector Machine (SVM) has been proposed with mathematical proof. The new attack can minimize the margin around the decision boundary and maximize the hinge loss simultaneously. We evaluate the new attack in different real-world applications including social spam detection, Internet traffic classification and image recognition. Experimental results highlight that the security of classifiers can be worsened by poisoning a small group of support vectors.",2018,https://doi.org/10.1145/3196494.3196539,10.1145/3196494.3196539,12,top-tier,yes,computer and communications security,0.9,"ASIACCS is a well-regarded conference under the ACM SIGSAC umbrella, focusing on computer and communication security in the Asia region, known for rigorous peer-review and high research impact.",acm_venues.csv,Proceedings of the 2018 on Asia Conference on Computer and Communications Security,NA,ACM,NA
ACM Asia Conference on Computer and Communications Security,Evaluating Behavioral Biometrics for Continuous Authentication: Challenges and Metrics,"Eberz, Simon; Rasmussen, Kasper B.; Lenders, Vincent; Martinovic, Ivan","In recent years, behavioral biometrics have become a popular approach to support continuous authentication systems. Most generally, a continuous authentication system can make two types of errors: false rejects and false accepts. Based on this, the most commonly reported metrics to evaluate systems are the False Reject Rate (FRR) and False Accept Rate (FAR). However, most papers only report the mean of these measures with little attention paid to their distribution. This is problematic as systematic errors allow attackers to perpetually escape detection while random errors are less severe. Using 16 biometric datasets we show that these systematic errors are very common in the wild. We show that some biometrics (such as eye movements) are particularly prone to systematic errors, while others (such as touchscreen inputs) show more even error distributions. Our results also show that the inclusion of some distinctive features lowers average error rates but significantly increases the prevalence of systematic errors. As such, blind optimization of the mean EER (through feature engineering or selection) can sometimes lead to lower security. Following this result we propose the Gini Coefficient (GC) as an additional metric to accurately capture different error distributions. We demonstrate the usefulness of this measure both to compare different systems and to guide researchers during feature selection. In addition to the selection of features and classifiers, some non- functional machine learning methodologies also affect error rates. The most notable examples of this are the selection of training data and the attacker model used to develop the negative class. 13 out of the 25 papers we analyzed either include imposter data in the negative class or randomly sample training data from the entire dataset, with a further 6 not giving any information on the methodology used. Using real-world data we show that both of these decisions lead to significant underestimation of error rates by 63% and 81%, respectively. This is an alarming result, as it suggests that researchers are either unaware of the magnitude of these effects or might even be purposefully attempting to over-optimize their EER without actually improving the system.",2017,https://doi.org/10.1145/3052973.3053032,10.1145/3052973.3053032,14,top-tier,yes,computer security,0.9,"The ACM Asia Conference on Computer and Communications Security is recognized as a top-tier conference in the field of computer security, featuring rigorous peer review and attracting high-quality research contributions.",acm_venues.csv,Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security,NA,ACM,NA
ACM Asia Conference on Computer and Communications Security,Hardware Performance Counters Can Detect Malware: Myth or Fact?,"Zhou, Boyou; Gupta, Anmol; Jahanshahi, Rasoul; Egele, Manuel; Joshi, Ajay","The ever-increasing prevalence of malware has led to the explorations of various detection mechanisms. Several recent works propose to use Hardware Performance Counters (HPCs) values with machine learning classification models for malware detection. HPCs are hardware units that record low-level micro-architectural behavior, such as cache hits/misses, branch (mis)prediction, and load/store operations. However, this information does not reliably capture the nature of the application, i.e. whether it is benign or malicious. In this paper, we claim and experimentally support that using the micro-architectural level information obtained from HPCs cannot distinguish between benignware and malware. We evaluate the fidelity of malware detection using HPCs. We perform quantitative analysis using Principal Component Analysis (PCA) to systematically select micro-architectural events that have the most predictive powers. We then run 1,924 programs, 962 benignware and 962 malware, on our experimental setups. We achieve 83.39%, 84.84%, 83.59%, 75.01%, 78.75%, and 14.32% F1-score (a metric of detection rates) of Decision Tree (DT), Random Forest (RF), K Nearest Neighbors (KNN), Adaboost, Neural Net (NN), and Naive Bayes, respectively. We cross-validate our models 1,000 times to show the distributions of detection rates in various models. Our cross-validation analysis shows that many of the experiments produce low F1-scores. The F1-score of models in DT, RF, KNN, Adaboost, NN, and Naive Bayes is 80.22%, 81.29%, 80.22%, 70.32%, 35.66%, and 9.903%, respectively. To further highlight the incapability of malware detection using HPCs, we show that one benignware (Notepad++) infused with malware (ransomware) cannot be detected by HPC-based malware detection.",2018,https://doi.org/10.1145/3196494.3196515,10.1145/3196494.3196515,12,top-tier,yes,computer and communications security,0.9,"ASIACCS is a well-regarded conference under the ACM SIGSAC umbrella, focusing on computer and communication security in the Asia region, known for rigorous peer-review and high research impact.",acm_venues.csv,Proceedings of the 2018 on Asia Conference on Computer and Communications Security,NA,ACM,NA
ACM Asia Conference on Computer and Communications Security,PARL: Poisoning Attacks Against Reinforcement Learning-based Recommender Systems,"Du, Linkang; Yuan, Quan; Chen, Min; Sun, Mingyang; Cheng, Peng; Chen, Jiming; Zhang, Zhikun","Recommender systems predict and suggest relevant options to users in various domains, such as e-commerce, streaming services, and social media. Recently, deep reinforcement learning (DRL)-based recommendation systems have become increasingly popular in academics and industry since DRL can characterize the long-term interaction between the system and users to achieve a better recommendation experience, e.g., Netflix, Spotify, Google, and YouTube.This paper demonstrates that an adversary can manipulate the DRL-based recommender system by injecting carefully designed user-system interaction records. The poisoning attack against the DRL-based recommender system is formulated as a non-convex integer programming problem. To solve the problem, we proposed a three-phase mechanism (called PARL) to maximize the hit ratio (the proportion of recommendations that result in actual user interactions, such as clicks, purchases, or other relevant actions) while avoiding easy detection. The core idea of PARL is to improve the ranking of the target item while fixing the rankings of other items. Considering the sequential decision-making characteristics of DRL, PARL rearranges the items' order of the fake users to mimic the normal users' sequential features, an aspect usually overlooked in existing work. Our experiments on three real-world datasets demonstrate the effectiveness of PARL and better concealment against the detection techniques. PARL is open-sourced at https://github.com/PARL-RS/PARL.",2024,https://doi.org/10.1145/3634737.3637660,10.1145/3634737.3637660,14,top-tier,yes,security,0.95,"AsiaCCS is a well-respected venue associated with SIGSAC, focusing on security and privacy issues. It is recognized as a top-tier conference in the security and privacy community, providing high-quality research papers.",acm_venues.csv,Proceedings of the 19th ACM Asia Conference on Computer and Communications Security,NA,ACM,NA
ACM Asia Conference on Computer and Communications Security,POSTER: A Teacher-Student with Human Feedback Model for Human-AI Collaboration in Cybersecurity,"Chowdhury, Abdullahi; Nguyen, Hung; Ashenden, Debi; Pogrebna, Ganna","We have developed a novel ’Teacher-Student with human feedback’ model for Human-Artificial Intelligence (AI) collaborations in cybersecurity tasks. In our model, AI furnishes sufficient information about its decision-making process to enable human agents to provide feedback to improve the model. Our key innovations include: enhancing the interpretability of AI models by analyzing falsely detected samples using LIME and SHAP values; developing a novel posthoc explanation-based dynamic teacher-student model to address concept drift or concept shift; integrating human experts’ feedback on falsely detected samples to increase accuracy, precision, and recall values, without retraining the entire model; establishing a list of attack-based feature values for human experts to promote reproducibility. We show in experiments with real data and threat detection tasks that our model significantly improves the accuracy of existing AI algorithms for these tasks.",2023,https://doi.org/10.1145/3579856.3592829,10.1145/3579856.3592829,3,top-tier,yes,computer and communications security,0.9,"The ACM Asia Conference on Computer and Communications Security (AsiaCCS) is a recognized academic conference in cybersecurity, established by ACM. It is peer-reviewed and widely considered a top-tier venue due to its strict acceptance rates and high-quality research presentations.",acm_venues.csv,Proceedings of the 2023 ACM Asia Conference on Computer and Communications Security,NA,ACM,NA
ACM Conference on Economics and Computation,Variance-Weighted Estimators to Improve Sensitivity in Online Experiments,"Liou, Kevin; Taylor, Sean J.","As companies increasingly rely on experiments to make product decisions, precisely measuring changes in key metrics is important. Various methods to increase sensitivity in experiments have been proposed, including methods that use pre-experiment data, machine learning, and more advanced experimental designs. However, prior work has not explored modeling heterogeneity in the variance of individual experimental users. We propose a more sensitive treatment effect estimator that relies on estimating the individual variances of experimental users using pre-experiment data. We show that that weighted estimators using individual-level variance estimates can reduce the variance of treatment effect estimates, and prove that the coefficient of variation of the sample population variance is a sufficient statistic for determining the scale of possible variance reduction. We provide empirical results from case studies at Facebook demonstrating the effectiveness of this approach, where the average experiment achieved a 17% reduction in variance with minimal impact on bias.",2020,https://doi.org/10.1145/3391403.3399542,10.1145/3391403.3399542,14,top-tier,yes,economics and computation,0.9,"The ACM Conference on Economics and Computation is a leading conference that combines computer science, economics, and game theory, attracting high-quality research. It is well-regarded in its field and is known for rigorous peer-review.",acm_venues.csv,Proceedings of the 21st ACM Conference on Economics and Computation,NA,ACM,NA
ACM Conference on Economics and Computation,AI Oversight and Human Mistakes: Evidence from Centre Court,"Almog, David; Gauriot, Romain; Page, Lionel; Martin, Daniel","Powered by the increasing predictive capabilities of machine learning algorithms, artificial intelligence (AI) systems have acquired the ability to improve outcomes by overruling human mistakes. However, to assess the full impact of adding AI oversight, we must understand whether its presence alters human decision-making. While a large amount of research has focused on how humans respond when being assisted by AI, very little is known about how humans respond when their decisions might be overruled by AI. Because being overruled can carry psychological costs (e.g., shame and embarrassment of being overruled) and psychological benefits (e.g., relief at having their mistakes fixed), individuals might alter their decision-making under AI oversight. We provide the first field evidence that AI oversight carries psychological costs that can impact human decision-making.",2024,https://doi.org/10.1145/3670865.3673481,10.1145/3670865.3673481,3,top-tier,yes,economics and computation,0.9,"The ACM Conference on Economics and Computation (EC) is a highly respected venue focusing on the intersection of computer science and economics, making it top-tier in its field. It is peer-reviewed to ensure high-quality contributions.",acm_venues.csv,Proceedings of the 25th ACM Conference on Economics and Computation,NA,ACM,NA
ACM Conference on Economics and Computation,Coarse Personalization,"Zhang, Walter; Misra, Sanjog","Advances in estimating heterogeneous treatment effects enable firms to personalize marketing mix elements and target individuals at an unmatched level of granularity, but feasibility constraints limit such personalization. In practice, firms choose which unique treatments to offer and which individuals to offer these treatments with the goal of maximizing profits: we call this the coarse personalization problem. We propose a two-step solution that makes segmentation and targeting decisions in concert. First, the firm personalizes by estimating conditional average treatment effects. Second, the firm discretizes by utilizing treatment effects to choose which unique treatments to offer and who to assign to these treatments. We show that a combination of available machine learning tools for estimating heterogeneous treatment effects and a novel application of optimal transport methods provides a viable and efficient solution. With data from a large-scale field experiment for promotions management, we find that our methodology outperforms extant approaches that segment on consumer characteristics or preferences and those that only search over a prespecified grid. Using our procedure, the firm recoups over 99.5% of its expected incremental profits under fully granular personalization while offering only five unique treatments. We conclude by discussing how coarse personalization arises in other domains.https://arxiv.org/abs/2204.05793",2024,https://doi.org/10.1145/3670865.3673540,10.1145/3670865.3673540,3,top-tier,yes,economics and computation,0.9,"The ACM Conference on Economics and Computation (EC) is a highly respected venue focusing on the intersection of computer science and economics, making it top-tier in its field. It is peer-reviewed to ensure high-quality contributions.",acm_venues.csv,Proceedings of the 25th ACM Conference on Economics and Computation,NA,ACM,NA
ACM Conference on Economics and Computation,"The Good, the Bad, and the Unflinchingly Selfish: Cooperative Decision-Making can be Predicted with high Accuracy when using only Three Behavioral Types","Epstein, Ziv; Peysakhovich, Alexander; Rand, David G.","The human willingness to pay costs to benefit anonymous others is often explained by social preferences: rather than only valuing their own material payoff, people also care in some fashion about the outcomes of others. But how successful is this concept of outcome-based social preferences for actually predicting out-of-sample behavior? We investigate this question by having 1067 human subjects each make 20 cooperation decisions, and using machine learning to predict their last 5 choices based on their first 15. We find that decisions can be predicted with high accuracy by models that include outcome-based features and allow for heterogeneity across individuals in baseline cooperativeness and the weights placed on the outcome-based features (AUC=0.89). It is not necessary, however, to have a fully heterogeneous model – excellent predictive power (AUC=0.88) is achieved by a model that allows three different sets of baseline cooperativeness and feature weights (i.e. three behavioral types), defined based on the participant's cooperation frequency in the 15 training trials: those who cooperated at least half the time, those who cooperated less than half the time, and those who never cooperated. Finally, we provide evidence that this inclination to cooperate cannot be well proxied by other personality/morality survey measures or demographics, and thus is a natural kind (or ""cooperative phenotype"").",2016,https://doi.org/10.1145/2940716.2940761,10.1145/2940716.2940761,13,top-tier,yes,economics and computation,0.9,"The ACM Conference on Economics and Computation (EC) is a reputable conference that focuses on the intersection of economics and computational approaches, known for rigorous peer review and high impacts in both fields.",acm_venues.csv,Proceedings of the 2016 ACM Conference on Economics and Computation,NA,ACM,NA
ACM Conference on Economics and Computation,Understanding Iterative Combinatorial Auction Designs via Multi-Agent Reinforcement Learning,"d'Eon, Greg; Newman, Neil; Leyton-Brown, Kevin","Iterative combinatorial auctions are widely used in high stakes settings such as spectrum auctions. Such auctions can be hard to analyze, making it difficult for bidders to determine how to behave and for designers to optimize auction rules to ensure desirable outcomes such as high revenue or welfare. In this paper, we investigate whether multi-agent reinforcement learning (MARL) algorithms can be used to understand iterative combinatorial auctions, given that these algorithms have recently shown empirical success in several other domains. We find that MARL can indeed benefit auction analysis, but that deploying it effectively is nontrivial. We begin by describing modelling decisions that keep the resulting game tractable without sacrificing important features such as imperfect information or asymmetry between bidders. We also discuss how to navigate pitfalls of various MARL algorithms, how to overcome challenges in verifying convergence, and how to generate and interpret multiple equilibria. We illustrate the promise of our resulting approach by using it to evaluate a specific rule change to a clock auction, finding substantially different auction outcomes due to complex changes in bidders' behavior.",2024,https://doi.org/10.1145/3670865.3673644,10.1145/3670865.3673644,29,top-tier,yes,economics and computation,0.9,"The ACM Conference on Economics and Computation (EC) is a highly respected venue focusing on the intersection of computer science and economics, making it top-tier in its field. It is peer-reviewed to ensure high-quality contributions.",acm_venues.csv,Proceedings of the 25th ACM Conference on Economics and Computation,NA,ACM,NA
ACM Conference on Embedded Networked Sensor Systems (SenSys),Attention-Based Deep Bayesian Counting For AI-Augmented Agriculture,"Wang, Yucheng; Gu, Mengmeng; Zhou, Mingyuan; Qian, Xiaoning","Object counting in images has been studied extensively, in particular using deep network models recently. The existing counting models typically output the point estimates of the object counts in given images. However, none of these can provide reliable uncertainty quantification of the derived count estimates, which is critical for consequent decision making when adopting these counting models in real-world applications. In this paper, we propose a novel deep counting model in a Bayesian framework. With the designed Bayesian attention module and Bayesian counting loss function, our deep Bayesian counting model not only improves the accuracy of count estimates with varying object and background appearance; but also enables their uncertainty quantification. We specifically focus on plant counting, which plays important roles in AI-augmented agriculture, for example crop yield estimates and farm management. Our ablation studies and experiments with the real-world agriculture data in the Global Wheat dataset have demonstrated that our deep Bayesian counting model obtains high count estimation accuracy as well as reliable uncertainty quantification. In addition, with the integrated Bayesian attention modules, it may help improve the interpretability of the derived count estimates, especially when the distribution of the interested plants in images is heterogeneous.",2023,https://doi.org/10.1145/3560905.3568417,10.1145/3560905.3568417,7,top-tier,yes,"computer science, sensor systems",1,"The ACM Conference on Embedded Networked Sensor Systems (SenSys) is a prestigious and highly-ranked conference in the field of sensor systems, widely recognized for its rigorous peer-review process and impactful research.",acm_venues.csv,Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems,NA,ACM,NA
"ACM Conference on Fairness, Accountability, and Transparency",“How Biased are Your Features?”: Computing Fairness Influence Functions with Global Sensitivity Analysis,"Ghosh, Bishwamittra; Basu, Debabrota; Meel, Kuldeep S.","Fairness in machine learning has attained significant focus due to the widespread application in high-stake decision-making tasks. Unregulated machine learning classifiers can exhibit bias towards certain demographic groups in data, thus the quantification and mitigation of classifier bias is a central concern in fairness in machine learning. In this paper, we aim to quantify the influence of different features in a dataset on the bias of a classifier. To do this, we introduce the Fairness Influence Function (FIF). This function breaks down bias into its components among individual features and the intersection of multiple features. The key idea is to represent existing group fairness metrics as the difference of the scaled conditional variances in the classifier’s prediction and apply a decomposition of variance according to global sensitivity analysis. To estimate FIFs, we instantiate an algorithm that applies variance decomposition of classifier’s prediction following local regression. Experiments demonstrate that captures FIFs of individual feature and intersectional features, provides a better approximation of bias based on FIFs, demonstrates higher correlation of FIFs with fairness interventions, and detects changes in bias due to fairness affirmative/punitive actions in the classifier. The code is available at https://github.com/ReAILe/bias-explainer. The extended version of the paper is at https://arxiv.org/pdf/2206.00667.pdf.",2023,https://doi.org/10.1145/3593013.3593983,10.1145/3593013.3593983,11,top-tier,yes,"fairness, accountability, and transparency in ai",0.95,ACM FAccT is a prestigious conference focusing on critical issues in AI and machine learning. It is highly regarded in the academic community for its rigorous peer-review process and impact on the field.,acm_venues.csv,"Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency",NA,ACM,NA
"ACM Conference on Fairness, Accountability, and Transparency",“There Is Not Enough Information”: On the Effects of Explanations on Perceptions of Informational Fairness and Trustworthiness in Automated Decision-Making,"Schoeffer, Jakob; Kuehl, Niklas; Machowski, Yvette","Automated decision systems (ADS) are increasingly used for consequential decision-making. These systems often rely on sophisticated yet opaque machine learning models, which do not allow for understanding how a given decision was arrived at. In this work, we conduct a human subject study to assess people’s perceptions of informational fairness (i.e., whether people think they are given adequate information on and explanation of the process and its outcomes) and trustworthiness of an underlying ADS when provided with varying types of information about the system. More specifically, we instantiate an ADS in the area of automated loan approval and generate different explanations that are commonly used in the literature. We randomize the amount of information that study participants get to see by providing certain groups of people with the same explanations as others plus additional explanations. From our quantitative analyses, we observe that different amounts of information as well as people’s (self-assessed) AI literacy significantly influence the perceived informational fairness, which, in turn, positively relates to perceived trustworthiness of the ADS. A comprehensive analysis of qualitative feedback sheds light on people’s desiderata for explanations, among which are (i) consistency (both with people’s expectations and across different explanations), (ii) disclosure of monotonic relationships between features and outcome, and (iii) actionability of recommendations.",2022,https://doi.org/10.1145/3531146.3533218,10.1145/3531146.3533218,13,top-tier,yes,"computer science, ethics, social impact",0.9,"ACM FAccT is a highly regarded conference in the interdisciplinary space at the intersection of technology and ethics. It is well-cited and attracts significant contributions from leading researchers, indicating its top-tier status.",acm_venues.csv,"Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency",NA,ACM,NA
"ACM Conference on Fairness, Accountability, and Transparency",A Causal Perspective on Label Bias,"Mhasawade, Vishwali; D'Amour, Alexander; Pfohl, Stephen R","Predictive models developed with machine learning techniques are commonly used to inform decision making and resource allocation in high-stakes contexts, such as healthcare and public health. One means through which this practice may propagate equity-related harms is when the data used for model development or evaluation exhibits label bias. In such cases, the target of prediction is a proxy label of a construct of interest that may be difficult or impossible to measure, while the relationship between the proxy and the construct of interest differs systematically across subgroups. Label bias can be especially challenging to identify and mitigate in practice because consequential fairness violations are masked when the model is evaluated with respect to the proxy label. In this work, we aim to develop further formal understanding of label bias to inform the development of approaches for the identification and mitigation of it. To do so, we present desiderata for unbiased and biased proxy labels, introduce candidate causal graphical criteria for label bias, and consider the extent to which proxy labels can be used to reason about fairness with respect to a true construct of interest. We validate our findings with a simulation study and experiments with synthetic health insurance data used in the context of a care management system.",2024,https://doi.org/10.1145/3630106.3658972,10.1145/3630106.3658972,13,top-tier,yes,"fairness, accountability, and transparency in computing",1,"ACM FAccT is recognized as a premier venue for research on fairness, accountability, and transparency in computing. It is rigorously peer-reviewed and attracts high-quality submissions, indicating its top-tier status.",acm_venues.csv,"Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency",NA,ACM,NA
"ACM Conference on Fairness, Accountability, and Transparency",On the Existence of Simpler Machine Learning Models,"Semenova, Lesia; Rudin, Cynthia; Parr, Ronald","It is almost always easier to find an accurate-but-complex model than an accurate-yet-simple model. Finding optimal, sparse, accurate models of various forms (linear models with integer coefficients, decision sets, rule lists, decision trees) is generally NP-hard. We often do not know whether the search for a simpler model will be worthwhile, and thus we do not go to the trouble of searching for one. In this work, we ask an important practical question: can accurate-yet-simple models be proven to exist, or shown likely to exist, before explicitly searching for them? We hypothesize that there is an important reason that simple-yet-accurate models often do exist. This hypothesis is that the size of the Rashomon set is often large, where the Rashomon set is the set of almost-equally-accurate models from a function class. If the Rashomon set is large, it contains numerous accurate models, and perhaps at least one of them is the simple model we desire. In this work, we formally present the Rashomon ratio as a new gauge of simplicity for a learning problem, depending on a function class and a data set. The Rashomon ratio is the ratio of the volume of the set of accurate models to the volume of the hypothesis space, and it is different from standard complexity measures from statistical learning theory. Insight from studying the Rashomon ratio provides an easy way to check whether a simpler model might exist for a problem before finding it, namely whether several different machine learning methods achieve similar performance on the data. In that sense, the Rashomon ratio is a powerful tool for understanding why and when an accurate-yet-simple model might exist. If, as we hypothesize in this work, many real-world data sets admit large Rashomon sets, the implications are vast: it means that simple or interpretable models may often be used for high-stakes decisions without losing accuracy.",2022,https://doi.org/10.1145/3531146.3533232,10.1145/3531146.3533232,32,top-tier,yes,"computer science, ethics, social impact",0.9,"ACM FAccT is a highly regarded conference in the interdisciplinary space at the intersection of technology and ethics. It is well-cited and attracts significant contributions from leading researchers, indicating its top-tier status.",acm_venues.csv,"Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency",NA,ACM,NA
"ACM Conference on Fairness, Accountability, and Transparency",On the Impact of Explanations on Understanding of Algorithmic Decision-Making,"Schmude, Timothée; Koesten, Laura; Möller, Torsten; Tschiatschek, Sebastian","Ethical principles for algorithms are gaining importance as more and more stakeholders are affected by ""high-risk"" algorithmic decision-making (ADM) systems. Understanding how these systems work enables stakeholders to make informed decisions and to assess the systems’ adherence to ethical values. Explanations are a promising way to create understanding, but current explainable artificial intelligence (XAI) research does not always consider existent theories on how understanding is formed and evaluated. In this work, we aim to contribute to a better understanding of understanding by conducting a qualitative task-based study with 30 participants, including users and affected stakeholders. We use three explanation modalities (textual, dialogue, and interactive) to explain a ""high-risk"" ADM system to participants and analyse their responses both inductively and deductively, using the ""six facets of understanding"" framework by Wiggins &amp; McTighe [63]. Our findings indicate that the ""six facets"" framework is a promising approach to analyse participants’ thought processes in understanding, providing categories for both rational and emotional understanding. We further introduce the ""dialogue"" modality as a valid explanation approach to increase participant engagement and interaction with the ""explainer"", allowing for more insight into their understanding in the process. Our analysis further suggests that individuality in understanding affects participants’ perceptions of algorithmic fairness, demonstrating the interdependence between understanding and ADM assessment that previous studies have outlined. We posit that drawing from theories on learning and understanding like the ""six facets"" and leveraging explanation modalities can guide XAI research to better suit explanations to learning processes of individuals and consequently enable their assessment of ethical values of ADM systems.",2023,https://doi.org/10.1145/3593013.3594054,10.1145/3593013.3594054,12,top-tier,yes,"fairness, accountability, and transparency in ai",0.95,ACM FAccT is a prestigious conference focusing on critical issues in AI and machine learning. It is highly regarded in the academic community for its rigorous peer-review process and impact on the field.,acm_venues.csv,"Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency",NA,ACM,NA
"ACM Conference on Fairness, Accountability, and Transparency",Optimization’s Neglected Normative Commitments,"Laufer, Benjamin; Gilbert, Thomas; Nissenbaum, Helen","Optimization is offered as an objective approach to resolving complex, real-world decisions involving uncertainty and conflicting interests. It drives business strategies as well as public policies and, increasingly, lies at the heart of sophisticated machine learning systems. A paradigm used to approach potentially high-stakes decisions, optimization relies on abstracting the real world to a set of decision(s), objective(s) and constraint(s). Drawing from the modeling process and a range of actual cases, this paper describes the normative choices and assumptions that are necessarily part of using optimization. It then identifies six emergent problems that may be neglected: 1) Misspecified values can yield optimizations that omit certain imperatives altogether or incorporate them incorrectly as a constraint or as part of the objective, 2) Problematic decision boundaries can lead to faulty modularity assumptions and feedback loops, 3) Failing to account for multiple agents’ divergent goals and decisions can lead to policies that serve only certain narrow interests, 4) Mislabeling and mismeasurement can introduce bias and imprecision, 5) Faulty use of relaxation and approximation methods, unaccompanied by formal characterizations and guarantees, can severely impede applicability, and 6) Treating optimization as a justification for action, without specifying the necessary contextual information, can lead to ethically dubious or faulty decisions. Suggestions are given to further understand and curb the harms that can arise when optimization is used wrongfully.",2023,https://doi.org/10.1145/3593013.3593976,10.1145/3593013.3593976,14,top-tier,yes,"fairness, accountability, and transparency in ai",0.95,ACM FAccT is a prestigious conference focusing on critical issues in AI and machine learning. It is highly regarded in the academic community for its rigorous peer-review process and impact on the field.,acm_venues.csv,"Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency",NA,ACM,NA
"ACM Conference on Fairness, Accountability, and Transparency",Organizational Governance of Emerging Technologies: AI Adoption in Healthcare,"Kim, Jee Young; Boag, William; Gulamali, Freya; Hasan, Alifia; Hogg, Henry David Jeffry; Lifson, Mark; Mulligan, Deirdre; Patel, Manesh; Raji, Inioluwa Deborah; Sehgal, Ajai; Shaw, Keo; Tobey, Danny; Valladares, Alexandra; Vidal, David; Balu, Suresh; Sendak, Mark","Private and public sector structures and norms refine how emerging technology is used in practice. In healthcare, despite a proliferation of AI adoption, the organizational governance (i.e. institutional governance) surrounding its use and integration is often poorly understood. What the Health AI Partnership (HAIP) aims to do in this research is to better define the requirements for adequate organizational governance of AI systems in healthcare settings and support health system leaders to make more informed decisions around AI adoption. To work towards this understanding, we first identify how the standards for the AI adoption in healthcare may be designed to be used easily and efficiently. Then, we map out the precise decision points involved in the practical institutional adoption of AI technology within specific health systems. Practically, we achieve this through a multi-organizational collaboration with leaders from major health systems across the United States and key informants from related fields. Working with the consultancy IDEO.org, we were able to conduct usability-testing sessions with healthcare and AI ethics professionals. Usability analysis revealed a prototype structured around mock key decision points that align with how organizational leaders approach technology adoption. Concurrently, we conducted semi-structured interviews with 89 professionals in healthcare and other relevant fields. Using a modified grounded theory approach, we were able to identify 8 key decision points and comprehensive procedures throughout the AI adoption lifecycle. This is one of the most detailed qualitative analyses to date of the current governance structures and processes involved in AI adoption by health systems in the United States. We hope these findings can inform future efforts to build capabilities to promote the safe, effective, and responsible adoption of emerging technologies in healthcare.",2023,https://doi.org/10.1145/3593013.3594089,10.1145/3593013.3594089,22,top-tier,yes,"fairness, accountability, and transparency in ai",0.95,ACM FAccT is a prestigious conference focusing on critical issues in AI and machine learning. It is highly regarded in the academic community for its rigorous peer-review process and impact on the field.,acm_venues.csv,"Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency",NA,ACM,NA
"ACM Conference on Fairness, Accountability, and Transparency",Participation in the age of foundation models,"Suresh, Harini; Tseng, Emily; Young, Meg; Gray, Mary; Pierson, Emma; Levy, Karen","Growing interest and investment in the capabilities of foundation models has positioned such systems to impact a wide array of services, from banking to healthcare. Alongside these opportunities is the risk that these systems reify existing power imbalances and cause disproportionate harm to historically marginalized groups. The larger scale and domain-agnostic manner in which these models operate further heightens the stakes: any errors or harms are liable to reoccur across use cases. In AI &amp; ML more broadly, participatory approaches hold promise to lend agency and decision-making power to marginalized stakeholders, leading to systems that better benefit justice through equitable and distributed governance. But existing approaches in participatory AI/ML are typically grounded in a specific application and set of relevant stakeholders, and it is not straightforward how to apply these lessons to the context of foundation models. Our paper aims to fill this gap. First, we examine existing attempts at incorporating participation into foundation models. We highlight the tension between participation and scale, demonstrating that it is intractable for impacted communities to meaningfully shape a foundation model that is intended to be universally applicable. In response, we develop a blueprint for participatory foundation models that identifies more local, application-oriented opportunities for meaningful participation. In addition to the “foundation” layer, our framework proposes the “subfloor” layer, in which stakeholders develop shared technical infrastructure, norms and governance for a grounded domain such as clinical care, journalism, or finance, and the “surface” (or application) layer, in which affected communities shape the use of a foundation model for a specific downstream task. The intermediate “subfloor” layer scopes the range of potential harms to consider, and affords communities more concrete avenues for deliberation and intervention. At the same time, it avoids duplicative effort by scaling input across relevant use cases. Through three case studies in clinical care, financial services, and journalism, we illustrate how this multi-layer model can create more meaningful opportunities for participation than solely intervening at the foundation layer.",2024,https://doi.org/10.1145/3630106.3658992,10.1145/3630106.3658992,13,top-tier,yes,"fairness, accountability, and transparency in computing",1,"ACM FAccT is recognized as a premier venue for research on fairness, accountability, and transparency in computing. It is rigorously peer-reviewed and attracts high-quality submissions, indicating its top-tier status.",acm_venues.csv,"Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency",NA,ACM,NA
"ACM Conference on Fairness, Accountability, and Transparency",People are not coins: Morally distinct types of predictions necessitate different fairness constraints,"Viganò, Eleonora; Hertweck, Corinna; Heitz, Christoph; Loi, Michele","In a recent paper [1], Brian Hedden has argued that most of the group fairness constraints discussed in the machine learning literature are not necessary conditions for the fairness of predictions, and hence that there are no genuine fairness metrics. This is proven by discussing a special case of a fair prediction. In our paper, we show that Hedden's argument does not hold for the most common kind of predictions used in data science, which are about people and based on data from similar people; we call these “human-group-based practices.” We argue that there is a morally salient distinction between human-group-based practices and those that are based on data of only one person, which we call “human-individual-based practices.” Thus, what may be a necessary condition for the fairness of human-group-based practices may not be a necessary condition for the fairness of human-individual-based practices, on which Hedden's argument is based. Accordingly, the group fairness metrics discussed in the machine learning literature may still be relevant for most applications of prediction-based decision making.",2022,https://doi.org/10.1145/3531146.3534643,10.1145/3531146.3534643,9,top-tier,yes,"computer science, ethics, social impact",0.9,"ACM FAccT is a highly regarded conference in the interdisciplinary space at the intersection of technology and ethics. It is well-cited and attracts significant contributions from leading researchers, indicating its top-tier status.",acm_venues.csv,"Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency",NA,ACM,NA
"ACM Conference on Fairness, Accountability, and Transparency",Preventing Discriminatory Decision-making in Evolving Data Streams,"Wang, Zichong; Saxena, Nripsuta; Yu, Tongjia; Karki, Sneha; Zetty, Tyler; Haque, Israat; Zhou, Shan; Kc, Dukka; Stockwell, Ian; Wang, Xuyu; Bifet, Albert; Zhang, Wenbin","Bias in machine learning has rightly received significant attention over the past decade. However, most fair machine learning (fair-ML) works to address bias in decision-making systems has focused solely on the offline setting. Despite the wide prevalence of online systems in the real world, work on identifying and correcting bias in the online setting is severely lacking. The unique challenges of the online environment make addressing bias more difficult than in the offline setting. First, Streaming Machine Learning (SML) algorithms must deal with the constantly evolving real-time data stream. Secondly, they need to adapt to changing data distributions (concept drift) to make accurate predictions on new incoming data. Incorporating fairness constraints into this already intricate task is not straightforward. In this work, we focus on the challenges of achieving fairness in biased data streams while accounting for the presence of concept drift, accessing one sample at a time. We present Fair Sampling over Stream (FS2), a novel fair rebalancing approach capable of being integrated with SML classification algorithms. Furthermore, we devise the first unified performance-fairness metric, Fairness Bonded Utility (FBU), to efficiently evaluate and compare the trade-offs between performance and fairness across various bias mitigation methods. FBU simplifies the comparison of fairness-performance trade-offs of multiple techniques through one unified and intuitive evaluation, allowing model designers to easily choose a technique. Overall, extensive evaluations show our measures surpass those of other fair online techniques previously reported in the literature.",2023,https://doi.org/10.1145/3593013.3593984,10.1145/3593013.3593984,11,top-tier,yes,"fairness, accountability, and transparency in ai",0.95,ACM FAccT is a prestigious conference focusing on critical issues in AI and machine learning. It is highly regarded in the academic community for its rigorous peer-review process and impact on the field.,acm_venues.csv,"Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency",NA,ACM,NA
"ACM Conference on Fairness, Accountability, and Transparency",Promoting Ethical Awareness in Communication Analysis: Investigating Potentials and Limits of Visual Analytics for Intelligence Applications,"Fischer, Maximilian T.; Hirsbrunner, Simon David; Jentner, Wolfgang; Miller, Matthias; Keim, Daniel A.; Helm, Paula","Digital systems for analyzing human communication data have become prevalent in recent years. This may be related to the increasing abundance of data that can be harnessed but can hardly be managed manually. Intelligence analysis of communications data in investigative journalism, criminal intelligence, and law present particularly interesting cases, as they must take into account the often highly sensitive properties of the underlying operations and data. At the same time, these are areas where increasingly automated, sophisticated approaches and tailored systems can be particularly useful and relevant, especially in terms of Big Data manageability. However, by the shifting of responsibilities, this also poses dangers. In addition to privacy concerns, these dangers relate to uncertain or poor data quality, leading to discrimination and potentially misleading insights. Other problems relate to a lack of transparency and traceability, making it difficult to accurately identify problems and determine appropriate remedial strategies. Visual analytics combines machine learning methods with interactive visual interfaces to enable human sense- and decision-making. This technique can be key for designing and operating meaningful interactive communication analysis systems that consider these ethical challenges. In this interdisciplinary work, a joint endeavor of computer scientists, ethicists, and scholars in Science &amp; Technology Studies, we investigate and evaluate opportunities and risks involved in using Visual analytics approaches for communication analysis in intelligence applications in particular. We introduce, at first, the common technological systems used in communication analysis, with a special focus on intelligence analysis in criminal investigations, further discussing the domain-specific ethical implications, tensions, and risks involved. We then make the case of how tailored Visual Analytics approaches may reduce and mitigate the described problems, both theoretically and through practical examples. Offering interactive analysis capabilities and what-if explorations while facilitating guidance, provenance generation, and bias awareness (through nudges, for example) can improve analysts’ understanding of their data, increasing trustworthiness, accountability, and generating knowledge. We show that finding Visual Analytics design solutions for ethical issues is not a mere optimization task with an ideal final solution. Design solutions for specific ethical problems (e.g., privacy) often trigger new ethical issues (e.g., accountability) in other areas. Balancing out and negotiating these trade-offs has, as we argue, to be an integral aspect of the system design process from the outset. Finally, our work identifies existing gaps and highlights research opportunities, further describing how our results can be transferred to other domains. With this contribution, we aim at informing more ethically-aware approaches to communication analysis in intelligence operations.",2022,https://doi.org/10.1145/3531146.3533151,10.1145/3531146.3533151,13,top-tier,yes,"computer science, ethics, social impact",0.9,"ACM FAccT is a highly regarded conference in the interdisciplinary space at the intersection of technology and ethics. It is well-cited and attracts significant contributions from leading researchers, indicating its top-tier status.",acm_venues.csv,"Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency",NA,ACM,NA
"ACM Conference on Fairness, Accountability, and Transparency",Promoting Fairness in Learned Models by Learning to Active Learn under Parity Constraints,"Sharaf, Amr; Daume III, Hal; Ni, Renkun","Machine learning models can have consequential effects when used to automate decisions, and disparities between groups of people in the error rates of those decisions can lead to harms suffered more by some groups than others. Past algorithmic approaches aim to enforce parity across groups given a fixed set of training data; instead, we ask: what if we can gather more data to mitigate disparities? We develop a meta-learning algorithm for parity-constrained active learning that learns a policy to decide which labels to query so as to maximize accuracy subject to parity constraints. To optimize the active learning policy, our proposed algorithm formulates the parity-constrained active learning task as a bi-level optimization problem. The inner level corresponds to training a classifier on a subset of labeled examples. The outer level corresponds to updating the selection policy choosing this subset to achieve a desired fairness and accuracy behavior on the trained classifier. To solve this constrained bi-level optimization problem, we employ the Forward-Backward Splitting optimization method. Empirically, across several parity metrics and classification tasks, our approach outperforms alternatives by a large margin.",2022,https://doi.org/10.1145/3531146.3534632,10.1145/3531146.3534632,8,top-tier,yes,"computer science, ethics, social impact",0.9,"ACM FAccT is a highly regarded conference in the interdisciplinary space at the intersection of technology and ethics. It is well-cited and attracts significant contributions from leading researchers, indicating its top-tier status.",acm_venues.csv,"Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency",NA,ACM,NA
"ACM Conference on Fairness, Accountability, and Transparency",Questioning the ability of feature-based explanations to empower non-experts in robo-advised financial decision-making,"Bertrand, Astrid; Eagan, James R.; Maxwell, Winston","Robo-advisors are democratizing access to life-insurance by enabling fully online underwriting. In Europe, financial legislation requires that the reasons for recommending a life insurance plan be explained according to the characteristics of the client, in order to empower the client to make a “fully informed decision”. In this study conducted in France, we seek to understand whether legal requirements for feature-based explanations actually help users in their decision-making. We conduct a qualitative study to characterize the explainability needs formulated by non-expert users and by regulators expert in customer protection. We then run a large-scale quantitative study using Robex, a simplified robo-advisor built using ecological interface design that delivers recommendations with explanations in different hybrid textual and visual formats: either “dialogic”—more textual—or “graphical”—more visual. We find that providing feature-based explanations does not improve appropriate reliance or understanding compared to not providing any explanation. In addition, dialogic explanations increase users’ trust in the recommendations of the robo-advisor, sometimes to the users’ detriment. This real-world scenario illustrates how XAI can address information asymmetry in complex areas such as finance. This work has implications for other critical, AI-based recommender systems, where the General Data Protection Regulation (GDPR) may require similar provisions for feature-based explanations.",2023,https://doi.org/10.1145/3593013.3594053,10.1145/3593013.3594053,16,top-tier,yes,"fairness, accountability, and transparency in ai",0.95,ACM FAccT is a prestigious conference focusing on critical issues in AI and machine learning. It is highly regarded in the academic community for its rigorous peer-review process and impact on the field.,acm_venues.csv,"Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency",NA,ACM,NA
"ACM Conference on Fairness, Accountability, and Transparency",Rational Shapley Values,"Watson, David","Explaining the predictions of opaque machine learning algorithms is an important and challenging task, especially as complex models are increasingly used to assist in high-stakes decisions such as those arising in healthcare and finance. Most popular tools for post-hoc explainable artificial intelligence (XAI) are either insensitive to context (e.g., feature attributions) or difficult to summarize (e.g., counterfactuals). In this paper, I introduce rational Shapley values, a novel XAI method that synthesizes and extends these seemingly incompatible approaches in a rigorous, flexible manner. I leverage tools from decision theory and causal modeling to formalize and implement a pragmatic approach that resolves a number of known challenges in XAI. By pairing the distribution of random variables with the appropriate reference class for a given explanation task, I illustrate through theory and experiments how user goals and knowledge can inform and constrain the solution set in an iterative fashion. The method compares favorably to state of the art XAI tools in a range of quantitative and qualitative comparisons.",2022,https://doi.org/10.1145/3531146.3533170,10.1145/3531146.3533170,12,top-tier,yes,"computer science, ethics, social impact",0.9,"ACM FAccT is a highly regarded conference in the interdisciplinary space at the intersection of technology and ethics. It is well-cited and attracts significant contributions from leading researchers, indicating its top-tier status.",acm_venues.csv,"Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency",NA,ACM,NA
"ACM Conference on Fairness, Accountability, and Transparency",Rethinking open source generative AI: open-washing and the EU AI Act,"Liesenfeld, Andreas; Dingemanse, Mark","The past year has seen a steep rise in generative AI systems that claim to be open. But how open are they really? The question of what counts as open source in generative AI is poised to take on particular importance in light of the upcoming EU AI Act that regulates open source systems differently, creating an urgent need for practical openness assessment. Here we use an evidence-based framework that distinguishes 14 dimensions of openness, from training datasets to scientific and technical documentation and from licensing to access methods. Surveying over 45 generative AI systems (both text and text-to-image), we find that while the term open source is widely used, many models are ‘open weight’ at best and many providers seek to evade scientific, legal and regulatory scrutiny by withholding information on training and fine-tuning data. We argue that openness in generative AI is necessarily composite (consisting of multiple elements) and gradient (coming in degrees), and point out the risk of relying on single features like access or licensing to declare models open or not. Evidence-based openness assessment can help foster a generative AI landscape in which models can be effectively regulated, model providers can be held accountable, scientists can scrutinise generative AI, and end users can make informed decisions.",2024,https://doi.org/10.1145/3630106.3659005,10.1145/3630106.3659005,14,top-tier,yes,"fairness, accountability, and transparency in computing",1,"ACM FAccT is recognized as a premier venue for research on fairness, accountability, and transparency in computing. It is rigorously peer-reviewed and attracts high-quality submissions, indicating its top-tier status.",acm_venues.csv,"Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency",NA,ACM,NA
"ACM Conference on Fairness, Accountability, and Transparency",Social Inclusion in Curated Contexts: Insights from Museum Practices,"Huang, Han-Yin; Liem, Cynthia C. S.","Artificial intelligence literature suggests that minority and fragile communities in society can be negatively impacted by machine learning algorithms due to inherent biases in the design process, which lead to socially exclusive decisions and policies. Faced with similar challenges in dealing with an increasingly diversified audience, the museum sector has seen changes in theory and practice, particularly in the areas of representation and meaning-making. While rarity and grandeur used to be at the centre stage of the early museum practices, folk life and museums’ relationships with the diverse communities they serve become a widely integrated part of the contemporary practices. These changes address issues of diversity and accessibility in order to offer more socially inclusive services. Drawing on these changes and reflecting back on the AI world, we argue that the museum experience provides useful lessons for building AI with socially inclusive approaches, especially in situations in which both a collection and access to it will need to be curated or filtered, as frequently happens in search engines, recommender systems and digital libraries. We highlight three principles: (1) Instead of upholding the value of neutrality, practitioners are aware of the influences of their own backgrounds and those of others on their work. By not claiming to be neutral but practising cultural humility, the chances of addressing potential biases can be increased. (2) There should be room for situational interpretation beyond the stages of data collection and machine learning. Before applying models and predictions, the contexts in which relevant parties exist should be taken into account. (3) Community participation serves the needs of communities and has the added benefit of bringing practitioners and communities together.",2022,https://doi.org/10.1145/3531146.3533095,10.1145/3531146.3533095,10,top-tier,yes,"computer science, ethics, social impact",0.9,"ACM FAccT is a highly regarded conference in the interdisciplinary space at the intersection of technology and ethics. It is well-cited and attracts significant contributions from leading researchers, indicating its top-tier status.",acm_venues.csv,"Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency",NA,ACM,NA
"ACM Conference on Fairness, Accountability, and Transparency",The Conflict Between Explainable and Accountable Decision-Making Algorithms,"Lima, Gabriel; Grgić-Hlača, Nina; Jeong, Jin Keun; Cha, Meeyoung","Decision-making algorithms are being used in important decisions, such as who should be enrolled in health care programs and be hired. Even though these systems are currently deployed in high-stakes scenarios, many of them cannot explain their decisions. This limitation has prompted the Explainable Artificial Intelligence (XAI) initiative, which aims to make algorithms explainable to comply with legal requirements, promote trust, and maintain accountability. This paper questions whether and to what extent explainability can help solve the responsibility issues posed by autonomous AI systems. We suggest that XAI systems that provide post-hoc explanations could be seen as blameworthy agents, obscuring the responsibility of developers in the decision-making process. Furthermore, we argue that XAI could result in incorrect attributions of responsibility to vulnerable stakeholders, such as those who are subjected to algorithmic decisions (i.e., patients), due to a misguided perception that they have control over explainable algorithms. This conflict between explainability and accountability can be exacerbated if designers choose to use algorithms and patients as moral and legal scapegoats. We conclude with a set of recommendations for how to approach this tension in the socio-technical process of algorithmic decision-making and a defense of hard regulation to prevent designers from escaping responsibility.",2022,https://doi.org/10.1145/3531146.3534628,10.1145/3531146.3534628,11,top-tier,yes,"computer science, ethics, social impact",0.9,"ACM FAccT is a highly regarded conference in the interdisciplinary space at the intersection of technology and ethics. It is well-cited and attracts significant contributions from leading researchers, indicating its top-tier status.",acm_venues.csv,"Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency",NA,ACM,NA
ACM Conference on Learning at Scale,Convincing the Expert: Reducing Algorithm Aversion in Administrative Higher Education Decision-making,"Xu, Lingrui; Pardos, Zachary A.; Pai, Anirudh","Algorithm aversion can be described as the tendency of human decision-makers to discount algorithmic recommendations more heavily than similar recommendations made by humans. It has been a phenomenon observed to be most acutely exhibited by domain experts. In our work, we focus on expert administrators in higher education making course credit equivalency decisions that affect the academic planning and potential degree progress of millions of prospective transfer students. Using human-centered design, we construct an AI-based platform for recommending matches to courses on a student's transcript to courses offered at another institution. We conduct a 2 x 2, between-subject experiment to investigate potential aversion mitigation techniques by manipulating the presence of outliers and allowing users to provide feedback to the algorithm. Our findings indicate that intentional, human-centered design and careful presentation of algorithm-based recommendations can help improve Human-AI interaction and productivity with implications for various domains of expertise.",2023,https://doi.org/10.1145/3573051.3593378,10.1145/3573051.3593378,11,top-tier,yes,educational technology and computer science,0.9,"The ACM Conference on Learning at Scale focuses on learning technologies, massive open online courses (MOOCs), and human-computer interaction in education. It is a well-regarded venue attracting high-quality research contributions, indicating a top-tier and peer-reviewed status.",acm_venues.csv,Proceedings of the Tenth ACM Conference on Learning @ Scale,NA,ACM,NA
ACM Conference on Learning at Scale,Evaluating a Learned Admission-Prediction Model as a Replacement for Standardized Tests in College Admissions,"Lee, Hansol; Kizilcec, René F.; Joachims, Thorsten","A growing number of college applications has presented an annual challenge for college admissions in the United States. Admission offices have historically relied on standardized test scores to organize large applicant pools into viable subsets for review. However, this approach may be subject to bias in test scores and selection bias in test-taking with recent trends toward test-optional admission. We explore a machine learning-based approach to replace the role of standardized tests in subset generation while taking into account a wide range of factors extracted from student applications to support a more holistic review. We evaluate the approach on data from an undergraduate admission office at a selective US institution (13,248 applications). We find that a prediction model trained on past admission data outperforms an SAT-based heuristic and matches the demographic composition of the last admitted class. We discuss the risks and opportunities for how such a learned model could be leveraged to support human decision-making in college admissions.",2023,https://doi.org/10.1145/3573051.3593382,10.1145/3573051.3593382,9,top-tier,yes,educational technology and computer science,0.9,"The ACM Conference on Learning at Scale focuses on learning technologies, massive open online courses (MOOCs), and human-computer interaction in education. It is a well-regarded venue attracting high-quality research contributions, indicating a top-tier and peer-reviewed status.",acm_venues.csv,Proceedings of the Tenth ACM Conference on Learning @ Scale,NA,ACM,NA
ACM Conference on Learning at Scale,LENS: Predictive Diagnostics for Flexible and Efficient Assessments,"Christie, S. Thomas; Johnson, Hayden; Cook, Carson; Gianopulos, Garron; Rafferty, Anna N.","The utility of assessment systems lies in their capacity to transform observations of student behavior into meaningful inferences about learning, knowledge, and skills. Common practice is to use latent variable models and produce scores on scales. However the simplicity of these psychometric models may filter out potentially valuable information present in student behavior. In particular, scale scores are not optimized to support granular instructional decisions. Machine learning offers promising alternatives, but proposed deep learning architectures are not ideally suited for operational testing conditions involving sparse data and shifting category labels for test questions.We present criteria for a model architecture that can leverage the rich, sparse behavioral data made available by modern assessment systems. We argue that behavioral predictions with well-quantified uncertainties are a viable alternative to scale scores for many applications. To satisfy these goals, we propose the LENS model architecture that combines the flexibility of machine learning and the uncertainty quantification of latent variable models to produce high-quality predictive diagnostic claims. Inspired by variational autoencoders, LENS maps student behavior to a latent probability distribution. In addition, LENS performs explicit Bayesian integration of each behavioral observation, allowing the model to incorporate sparse data with informative prior beliefs about students.We then compare the predictive capability of LENS to both latent variable and machine learning approaches. LENS generates competitive or superior predictions of behavior, particularly on sparse data, while requiring fewer modeling assumptions than other options and allowing for easy incorporation of auxiliary behavioral data. We also show how to produce interpretable claims about student behavior at multiple levels of granularity, allowing the same model to serve multiple reporting needs. Finally, we discuss the flexibility afforded by the proposed model for constructing assessments customized to both educator needs and student skills.",2023,https://doi.org/10.1145/3573051.3593392,10.1145/3573051.3593392,11,top-tier,yes,educational technology and computer science,0.9,"The ACM Conference on Learning at Scale focuses on learning technologies, massive open online courses (MOOCs), and human-computer interaction in education. It is a well-regarded venue attracting high-quality research contributions, indicating a top-tier and peer-reviewed status.",acm_venues.csv,Proceedings of the Tenth ACM Conference on Learning @ Scale,NA,ACM,NA
ACM Conference on Learning at Scale,Leveraging Human Feedback to Scale Educational Datasets: Combining Crowdworkers and Comparative Judgement,"Henkel, Owen; Hills, Libby","Machine Learning models have many potentially beneficial applications in education settings, but a key barrier to their development is securing enough high-quality, labelled data to train these models. This process has traditionally relied on highly skilled raters using complex, multi-class rubrics, which made labelling expensive and difficult to scale. A more scalable approach would be to use non-expert crowdworkers to evaluate student work, but maintaining high levels of accuracy and inter-rater reliability when using non-expert workers can be challenging. This paper reports on two experiments in which non-expert crowdworkers hired to evaluate (i.e., score) student work and were randomly assigned to one of two conditions: the control, where they were asked to assign a rubrics based score (i.e., a categorical judgement), or the treatment, where they were shown the same student answers, but were asked to decide which of two candidate answers was better (i.e., a comparative/preference-based judgement). We found that using comparative judgement substantially improved inter-rater reliability on both tasks. These results are in-line with well-established literature on the benefits of comparative judgement in the field of educational assessment, as well as with recent trends in artificial intelligence research, where comparative judgement is becoming the preferred method for providing human feedback on model outputs. These results are novel and important in demonstrating the effects of using the combination of comparative judgement and crowdworkers to evaluate educational data",2023,https://doi.org/10.1145/3573051.3596198,10.1145/3573051.3596198,5,top-tier,yes,educational technology and computer science,0.9,"The ACM Conference on Learning at Scale focuses on learning technologies, massive open online courses (MOOCs), and human-computer interaction in education. It is a well-regarded venue attracting high-quality research contributions, indicating a top-tier and peer-reviewed status.",acm_venues.csv,Proceedings of the Tenth ACM Conference on Learning @ Scale,NA,ACM,NA
ACM Conference on Recommender Systems,Bayesian Optimization with LLM-Based Acquisition Functions for Natural Language Preference Elicitation,"Austin, David; Korikov, Anton; Toroghi, Armin; Sanner, Scott","Designing preference elicitation (PE) methodologies that can quickly ascertain a user’s top item preferences in a cold-start setting is a key challenge for building effective and personalized conversational recommendation (ConvRec) systems. While large language models (LLMs) enable fully natural language (NL) PE dialogues, we hypothesize that monolithic LLM NL-PE approaches lack the multi-turn, decision-theoretic reasoning required to effectively balance the exploration and exploitation of user preferences towards an arbitrary item set. In contrast, traditional Bayesian optimization PE methods define theoretically optimal PE strategies, but cannot generate arbitrary NL queries or reason over content in NL item descriptions – requiring users to express preferences via ratings or comparisons of unfamiliar items. To overcome the limitations of both approaches, we formulate NL-PE in a Bayesian Optimization (BO) framework that seeks to actively elicit NL feedback to identify the best recommendation. Key challenges in generalizing BO to deal with natural language feedback include determining: (a) how to leverage LLMs to model the likelihood of NL preference feedback as a function of item utilities, and (b) how to design an acquisition function for NL BO that can elicit preferences in the infinite space of language. We demonstrate our framework in a novel NL-PE algorithm, PEBOL, which uses: 1) Natural Language Inference (NLI) between user preference utterances and NL item descriptions to maintain Bayesian preference beliefs, and 2) BO strategies such as Thompson Sampling (TS) and Upper Confidence Bound (UCB) to guide LLM query generation. We numerically evaluate our methods in controlled simulations, finding that after 10 turns of dialogue, PEBOL can achieve an MRR@10 of up to 0.27 compared to the best monolithic LLM baseline’s MRR@10 of 0.17, despite relying on earlier and smaller LLMs.1",2024,https://doi.org/10.1145/3640457.3688142,10.1145/3640457.3688142,10,top-tier,yes,recommender systems,0.9,"The ACM Conference on Recommender Systems (RecSys) is a leading venue in the area of recommender systems, consistently showcasing groundbreaking research and innovations. It is a well-respected, peer-reviewed conference, attracting top researchers and practitioners.",acm_venues.csv,Proceedings of the 18th ACM Conference on Recommender Systems,NA,ACM,NA
ACM Conference on Recommender Systems,Bridging Viewpoints in News with Recommender Systems,"Jeng, Jia Hua","News Recommender systems (NRSs) aid in decision-making in news media. However, undesired effects can emerge. Among these are selective exposures that may contribute to polarization, potentially reinforcing existing attitudes through belief perseverance—discounting contrary evidence due to their opposing attitudinal strength. This can be unsafe for people, making it difficult to accept information objectively. A crucial issue in news recommender system research is how to mitigate these undesired effects by designing recommender interfaces and machine learning models that enable people to consider to be more open to different perspectives. Alongside accurate models, the user experience is an equally important measure. Indeed, the core statistics are based on users’ behaviors and experiences in this research project. Therefore, this research agenda aims to steer the choices of readers’ based on altering their attitudes. The core methods plan to concentrate on the interface design and ML model building involving manipulations of cues, users’ behaviors prediction, NRSs algorithm and changing the nudges. In sum, the project aims to provide insight in the extent to which news recommender systems can be effective in mitigating polarized opinions.",2024,https://doi.org/10.1145/3640457.3688008,10.1145/3640457.3688008,7,top-tier,yes,recommender systems,0.9,"The ACM Conference on Recommender Systems (RecSys) is a leading venue in the area of recommender systems, consistently showcasing groundbreaking research and innovations. It is a well-respected, peer-reviewed conference, attracting top researchers and practitioners.",acm_venues.csv,Proceedings of the 18th ACM Conference on Recommender Systems,NA,ACM,NA
ACM Conference on Recommender Systems,Computational Methods for Designing Human-Centered Recommender Systems: A Case Study Approach Intersecting Visual Arts and Healthcare,"Yilma, Bereket Abera","Recommender Systems (RecSys) are essential tools in sectors like e-commerce, entertainment, and social media, providing personalized user experiences. Their impact is also growing in education, healthcare, tourism, transport, and logistics, enhancing decision-making and user engagement. Hence, designing modern RecSys requires a multi-disciplinary approach, incorporating machine learning, information retrieval, and human-computer interaction (HCI). This tutorial focuses on human-centric RecSys design, emphasizing both computational methods and user-centered principles. Participants will learn fundamental concepts, advanced algorithms, and practical implementation, with case studies linking visual arts and healthcare applications.",2024,https://doi.org/10.1145/3640457.3687091,10.1145/3640457.3687091,3,top-tier,yes,recommender systems,0.9,"The ACM Conference on Recommender Systems (RecSys) is a leading venue in the area of recommender systems, consistently showcasing groundbreaking research and innovations. It is a well-respected, peer-reviewed conference, attracting top researchers and practitioners.",acm_venues.csv,Proceedings of the 18th ACM Conference on Recommender Systems,NA,ACM,NA
ACM Conference on Recommender Systems,Drug Discovery as a Recommendation Problem: Challenges and Complexities in Biological Decisions,"Gogleva, Anna; papa, eliseo; Jansson, Erik; De Baets, Greet","Drug discovery is notorious for its low success rates [5]. Despite best research efforts, the majority of drugs fail at early stages of development, even before they enter clinical trials. This phenomenon stems from the inherent complexity of biological systems and our poor understanding of human diseases. To improve that understanding, swaths of data have been generated in recent years. Still, data does not easily translate into knowledge or actionable insights. Here we explore how approaches from the recommendation system domain could help scientists comprehend the ever-growing amount of biomedical facts. The aim of these efforts is to make better drug development decisions, which ultimately result in safe and efficient treatments for patients [3]. Recommendation systems are well established in e-commerce, streaming and social media platforms, however in the biomedical domain their usage is limited to a few recent studies [1, 6, 7, 8]. Direct transfer of classic recommendation approaches to the biomedical domain is not trivial. Specifics of the problem space impose numerous challenges for a recommendation system practitioner, to name a few: Regardless of the challenges, the adoption of recommendation systems presents numerous opportunities to support and accelerate drug discovery. Even a slight increase in success rate of drug pipelines will result in a vast number of patients gaining access to safe and effective treatments. Recommendation systems could play a leading role in this process. Adding context to experimental data is one class of problems that could benefit from recommenders. In this process new data is integrated with prior evidence to produce a new hypothesis. In a typical scenario, thousands of genes need to be ranked by their relevance to a disease given new and existing data. As a case study we focused on finding out why some lung cancer patients develop resistance to treatments. Current protocol to find resistance markers starts with high-throughput genomic screens resulting in an initial list of potential gene candidates, followed by tedious manual curation by several experts to reduce the list to a manageable number for further follow-up. To find resistance markers faster and to reduce bias we built a hybrid recommendation system on top of a heterogeneous biomedical knowledge graph [2]. In the absence of continuous feedback and training data, we approached recommendations as a multi-objective optimization problem [4]. Genes were ranked by trading off diverse types of evidence that link them to potential mechanisms of resistance in lung cancer. We used a knowledge graph as the primary source of features, so that the relevance of a gene could be expressed via properties of a graph. Our hybrid feature set also included clinical and pre-clinical data as well as metrics of literature support obtained with natural language processing techniques. This hybrid approach helped to identify novel resistance mechanisms that could have been overlooked by experts due to inherent bias or limited integration of data. Most importantly, our method reduced the time required to prioritise resistance markers from months to minutes and became a standard procedure for processing genomic screens. Another class of problems exists around target identification tasks. The idea here is to find a molecular target, often a gene or a protein, that could be modulated with a drug to treat a disease. As the number of potential targets is large, the search space can be reduced using network propagation on a dedicated subgraph that captures the functional relationship between genes. This approach also requires a set of seed genes, defined based on high confidence associations with diseases. Disease preferences are then propagated through the network resulting in a preference distribution for the complete set of genes which is used to reduce the search space. In contrast to adding context to experiments, a considerable amount of training data is available to support target identification. For instance, both successful and failed clinical trials can act as a useful source of data for target identification. Such a setting warrants use of supervised recommendation systems. A supervised approach, however introduces another machine learning hurdle — trust. Since supervised models are typically ”black boxes”, their quality must be ascertained indirectly, for example using train-test split and estimating model’s performance on the test set. Such quantitative performance metrics often are of little value to a biological expert looking for relevant gene targets. Instead, experts instinctively assess model quality by checking if a list of recommendations contains a handful of expected genes [9]. To simultaneously use biologists’ intuitions as training data, while avoiding an overly optimistic trust in model output, we used an ensemble modeling approach. We partitioned training data among multiple models such that each available training gene was omitted from one model’s training data. The model was then permitted to assess this previously unseen gene in constructing its final list of recommendations, while training genes were removed from consideration. Each model therefore produced a list of recommendations based on an incomplete set of genes. A final set of recommendations was then constructed by collating each individual model’s output list. Because these output lists were constructed with biologist input through supervised training, biologists placed a higher degree of trust in the recommendations. This allowed roughly two dozen genes to be fast-tracked for manual assessment and experimental screening. In summary, accumulation of large amounts of biomedical data coupled with a need to comprehend and reason about it makes drug discovery an attractive field to apply recommendation techniques. Specifics of the problem space and complexity of biological systems call for efficient recommendation solutions that could operate in unsupervised or weakly supervised settings. At the same time, a strong emphasis on explainability is essential to gain trust of biomedical experts.",2021,https://doi.org/10.1145/3460231.3474598,10.1145/3460231.3474598,3,top-tier,yes,"recommender systems, human-computer interaction, ai",0.95,"The ACM Recommender Systems conference is a well-established, leading venue for recommender systems research, focusing on advanced and novel research in the field. It is recognized as a top-tier conference with rigorous peer review standards.",acm_venues.csv,Proceedings of the 15th ACM Conference on Recommender Systems,NA,ACM,NA
ACM Conference on Recommender Systems,Explainable Multi-Stakeholder Job Recommender Systems,"Schellingerhout, Roan","Public opinion on recommender systems has become increasingly wary in recent years. In line with this trend, lawmakers have also started to become more critical of such systems, resulting in the introduction of new laws focusing on aspects such as privacy, fairness, and explainability for recommender systems and AI at large. These concepts are especially crucial in high-risk domains such as recruitment. In recruitment specifically, decisions carry substantial weight, as the outcomes can significantly impact individuals’ careers and companies’ success. Additionally, there is a need for a multi-stakeholder approach, as these systems are used by job seekers, recruiters, and companies simultaneously, each with its own requirements and expectations. In this paper, I summarize my current research on the topic of explainable, multi-stakeholder job recommender systems and set out a number of future research directions.",2024,https://doi.org/10.1145/3640457.3688014,10.1145/3640457.3688014,5,top-tier,yes,recommender systems,0.9,"The ACM Conference on Recommender Systems (RecSys) is a leading venue in the area of recommender systems, consistently showcasing groundbreaking research and innovations. It is a well-respected, peer-reviewed conference, attracting top researchers and practitioners.",acm_venues.csv,Proceedings of the 18th ACM Conference on Recommender Systems,NA,ACM,NA
ACM Conference on Recommender Systems,Learning to Collaborate in Multi-Module Recommendation via Multi-Agent Reinforcement Learning without Communication,"HE, Xu; An, Bo; Li, Yanghua; Chen, Haikai; Wang, Rundong; Wang, Xinrun; Yu, Runsheng; Li, Xin; Wang, Zhirong","With the rise of online e-commerce platforms, more and more customers prefer to shop online. To sell more products, online platforms introduce various modules to recommend items with different properties such as huge discounts. A web page often consists of different independent modules. The ranking policies of these modules are decided by different teams and optimized individually without cooperation, which might result in competition between modules. Thus, the global policy of the whole page could be sub-optimal. In this paper, we propose a novel multi-agent cooperative reinforcement learning approach with the restriction that different modules cannot communicate. Our contributions are three-fold. Firstly, inspired by a solution concept in game theory named correlated equilibrium, we design a signal network to promote cooperation of all modules by generating signals (vectors) for different modules. Secondly, an entropy-regularized version of the signal network is proposed to coordinate agents’ exploration of the optimal global policy. Furthermore, experiments based on real-world e-commerce data demonstrate that our algorithm obtains superior performance over baselines.",2020,https://doi.org/10.1145/3383313.3412233,10.1145/3383313.3412233,10,top-tier,yes,recommender systems,0.9,ACM RecSys is recognized as a leading conference in the area of recommender systems. It is highly regarded for its rigorous peer-review process and contributions to both theoretical and practical advancements.,acm_venues.csv,Proceedings of the 14th ACM Conference on Recommender Systems,NA,ACM,NA
ACM Conference on Recommender Systems,Making Neural Networks Interpretable with Attribution: Application to Implicit Signals Prediction,"Afchar, Darius; Hennequin, Romain","Explaining recommendations enables users to understand whether recommended items are relevant to their needs and has been shown to increase their trust in the system. More generally, if designing explainable machine learning models is key to check the sanity and robustness of a decision process and improve their efficiency, it however remains a challenge for complex architectures, especially deep neural networks that are often deemed ”black-box”. In this paper, we propose a novel formulation of interpretable deep neural networks for the attribution task. Differently to popular post-hoc methods, our approach is interpretable by design. Using masked weights, hidden features can be deeply attributed, split into several input-restricted sub-networks and trained as a boosted mixture of experts. Experimental results on synthetic data and real-world recommendation tasks demonstrate that our method enables to build models achieving close predictive performances to their non-interpretable counterparts, while providing informative attribution interpretations.",2020,https://doi.org/10.1145/3383313.3412253,10.1145/3383313.3412253,10,top-tier,yes,recommender systems,0.9,ACM RecSys is recognized as a leading conference in the area of recommender systems. It is highly regarded for its rigorous peer-review process and contributions to both theoretical and practical advancements.,acm_venues.csv,Proceedings of the 14th ACM Conference on Recommender Systems,NA,ACM,NA
ACM International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS),A full-stack search technique for domain optimized deep learning accelerators,"Zhang, Dan; Huda, Safeen; Songhori, Ebrahim; Prabhu, Kartik; Le, Quoc; Goldie, Anna; Mirhoseini, Azalia","The rapidly-changing deep learning landscape presents a unique opportunity for building inference accelerators optimized for specific datacenter-scale workloads. We propose Full-stack Accelerator Search Technique (FAST), a hardware accelerator search framework that defines a broad optimization environment covering key design decisions within the hardware-software stack, including hardware datapath, software scheduling, and compiler passes such as operation fusion and tensor padding. In this paper, we analyze bottlenecks in state-of-the-art vision and natural language processing (NLP) models, including EfficientNet and BERT, and use FAST to design accelerators capable of addressing these bottlenecks. FAST-generated accelerators optimized for single workloads improve Perf/TDP by 3.7× on average across all benchmarks compared to TPU-v3. A FAST-generated accelerator optimized for serving a suite of workloads improves Perf/TDP by 2.4× on average compared to TPU-v3. Our return on investment analysis shows that FAST-generated accelerators can potentially be practical for moderate-sized datacenter deployments.",2022,https://doi.org/10.1145/3503222.3507767,10.1145/3503222.3507767,16,top-tier,yes,"computer architecture, operating systems, programming languages",1,"ASPLOS is widely recognized as a premier conference focusing on computer architecture, operating systems, and programming languages, enjoying high repute and rigorous peer-review standards.",acm_venues.csv,Proceedings of the 27th ACM International Conference on Architectural Support for Programming Languages and Operating Systems,NA,ACM,NA
ACM International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS),ACES: Accelerating Sparse Matrix Multiplication with Adaptive Execution Flow and Concurrency-Aware Cache Optimizations,"Lu, Xiaoyang; Long, Boyu; Chen, Xiaoming; Han, Yinhe; Sun, Xian-He","Sparse matrix-matrix multiplication (SpMM) is a critical computational kernel in numerous scientific and machine learning applications. SpMM involves massive irregular memory accesses and poses great challenges to conventional cache-based computer architectures. Recently dedicated SpMM accelerators have been proposed to enhance SpMM performance. However, current SpMM accelerators still face challenges in adapting to varied sparse patterns, fully exploiting inherent parallelism, and optimizing cache performance. To address these issues, we introduce ACES, a novel SpMM accelerator in this study. First, ACES features an adaptive execution flow that dynamically adjusts to diverse sparse patterns. The adaptive execution flow balances parallel computing efficiency and data reuse. Second, ACES incorporates locality-concurrency co-optimizations within the global cache. ACES utilizes a concurrency-aware cache management policy, which considers data locality and concurrency for optimal replacement decisions. Additionally, the integration of a non-blocking buffer with the global cache enhances concurrency and reduces computational stalls. Third, the hardware architecture of ACES is designed to integrate all innovations. The architecture ensures efficient support across the adaptive execution flow, advanced cache optimizations, and fine-grained parallel processing. Our performance evaluation demonstrates that ACES significantly outperforms existing solutions, providing a 2.1× speedup and marking a substantial advancement in SpMM acceleration.",2024,https://doi.org/10.1145/3620666.3651381,10.1145/3620666.3651381,15,top-tier,yes,"computer architecture, systems, operating systems",1,"ASPLOS is a leading conference in systems and architecture, integrating multiple disciplines and consistently featuring high-impact research, hence it is considered a top-tier venue.",acm_venues.csv,"Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 3",NA,ACM,NA
ACM International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS),DREAM: A Dynamic Scheduler for Dynamic Real-time Multi-model ML Workloads,"Kim, Seah; Kwon, Hyoukjun; Song, Jinook; Jo, Jihyuck; Chen, Yu-Hsin; Lai, Liangzhen; Chandra, Vikas","Emerging real-time multi-model ML (RTMM) workloads such as AR/VR and drone control involve dynamic behaviors in various granularity; task, model, and layers within a model. Such dynamic behaviors introduce new challenges to the system software in an ML system since the overall system load is not completely predictable, unlike traditional ML workloads. In addition, RTMM workloads require real-time processing, involve highly heterogeneous models, and target resource-constrained devices. Under such circumstances, developing an effective scheduler gains more importance to better utilize underlying hardware considering the unique characteristics of RTMM workloads. Therefore, we propose a new scheduler, DREAM, which effectively handles various dynamicity in RTMM workloads targeting multi-accelerator systems. DREAM quantifies the unique requirements for RTMM workloads and utilizes the quantified scores to drive scheduling decisions, considering the current system load and other inference jobs on different models and input frames. DREAM utilizes tunable parameters that provide fast and effective adaptivity to dynamic workload changes. In our evaluation of five scenarios of RTMM workload, DREAM reduces the overall UXCosT, which is an equivalent metric of the energy-delay product (EDP) for RTMM defined in the paper, by 32.2% and 50.0% in the geometric mean (up to 80.8% and 97.6%) compared to state-of-the-art baselines, which shows the efficacy of our scheduling methodology.",2024,https://doi.org/10.1145/3623278.3624753,10.1145/3623278.3624753,14,top-tier,yes,"computer science, computer architecture, operating systems",0.9,"ASPLOS is highly reputable in fields bridging hardware and software, consistently regarded as top-tier. It is peer-reviewed and attracts high-quality submissions.",acm_venues.csv,"Proceedings of the 28th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 4",NA,ACM,NA
ACM International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS),Heet: Accelerating Elastic Training in Heterogeneous Deep Learning Clusters,"Mo, Zizhao; Xu, Huanle; Xu, Chengzhong","Modern GPU clusters inherently exhibit heterogeneity, encompassing various aspects such as computation and communication. This heterogeneity poses a significant challenge for the elastic scheduling of deep learning workloads. Unfortunately, existing elastic schedulers often overlook the impact of heterogeneity on scaling efficiency, resulting in considerably prolonged job completion times.In this paper, we present Heet, a new Heterogeneity-aware system explicitly developed for elastic training in DL clusters. Heet addresses two critical issues. First, it utilizes a 3-D collaborative filtering method to accurately measure the scaling efficiency of all elastic configurations on heterogeneous hosts, substantially reducing profiling overhead. Second, Heet introduces a unique price function to effectively balance scaling efficiency and scheduling efficiency. Building upon this function, Heet incorporates a scalable mechanism that employs minimum-weight full bipartite matching and opportunistic resource trading to generate dynamic scheduling decisions. Evaluations conducted on cloud clusters and large-scale simulations demonstrate that Heet can reduce job completion time by up to 2.46× compared to existing solutions.",2024,https://doi.org/10.1145/3620665.3640375,10.1145/3620665.3640375,15,top-tier,yes,"computer architecture, systems",0.9,"ASPLOS is a highly respected conference covering research in architecture and systems, known for a rigorous peer-review process, and is considered a top-tier venue within the field.",acm_venues.csv,"Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2",NA,ACM,NA
ACM International Conference on Information and Knowledge Management (CIKM),LST2A: Lexical-Syntactic Targeted Adversarial Attack for Texts,"Zhou, Guanghao; Qiu, Panjia; Fan, Mingyuan; Chen, Cen; Li, Yaliang; Zhou, Wenmeng","Textual adversarial attack in black-box scenarios is a challenging task, as only the predicted label is available, and the text space is discrete and non-differentiable. Current research in this area is still in its infancy and mostly focuses on untargeted attack, lacking the capability to control the labels of the generated adversarial examples. Meanwhile, existing textual adversarial attack methods primarily rely on word substitution operations to maintain semantic similarity between the adversarial and original examples, which greatly limits the search space for adversarial examples. To address these issues, we propose a novel &lt;u&gt;L&lt;/u&gt;exical-&lt;u&gt;S&lt;/u&gt;yntactic &lt;u&gt;T&lt;/u&gt;argeted &lt;u&gt;A&lt;/u&gt;dversarial &lt;u&gt;A&lt;/u&gt;ttack method tailored for the black-box settings, referred to as LST2A. Our approach involves adversarial perturbations at different levels of granularities, i.e., word-level with word substitution operations and syntactic-level through rewriting the syntax of the examples. Specifically, we first embed the entire text into the embedding layer of a masked language model, and then optimize perturbations at the word level within the hidden state to generate adversarial examples with the target label. For examples that are difficult to attack successfully with only word-level perturbations at higher semantic similarity thresholds, we leverage Large Language Model (LLM) to introduce syntactic-level perturbations to these examples, making them more vulnerable to the decision boundary of the victim model. Subsequently, we re-optimize the word-level perturbations for these vulnerable examples. Extensive experiments and human evaluations demonstrate that our proposed method consistently outperforms the state-of-the-art baselines, crafting smoother, more grammatically correct adversarial examples.",2024,https://doi.org/10.1145/3627673.3679640,10.1145/3627673.3679640,11,top-tier,yes,information and knowledge management,0.9,"CIKM is a prominent conference in the field of information and knowledge management, with a rigorous peer-review process. It attracts high-quality submissions and is considered top-tier due to its impact and reputable history.",acm_venues.csv,Proceedings of the 33rd ACM International Conference on Information and Knowledge Management,NA,ACM,NA
ACM International Conference on Information and Knowledge Management (CIKM),LTBoost: Boosted Hybrids of Ensemble Linear and Gradient Algorithms for the Long-term Time Series Forecasting,"Truchan, Hubert; Kalfar, Christian; Ahmadi, Zahra","The progress of deep-learning-based forecasting architectures is evident through their expanding parameter configurations. However, the need for rapid online decision making in practical scenarios calls for an alternative strategy, highlighting the necessity for networks that are not only adaptive but also efficient in real-time operations. This shift is critical as we confront three principal challenges in deep-learning-based forecasting frameworks: (i) the inherent limitations of transformers, which, despite their attempts to preserve ordering information, the temporal information loss due to the permutation-invariant nature of self-attention mechanisms is inevitable, (ii) the inefficacy of linear models in capturing the dynamic interactions within swiftly evolving signals; and (iii) the incapacity of tree-based approaches to extrapolating beyond values present in the training set. In response to these challenges, we introduce LTBoost, an innovative boosted hybrid of linear and tree-based ensemble gradient algorithms tailored for long-term time series forecasting (LTSF) tasks, scalable to high data dimensions. LTBoost employs a dual strategy, beginning with a linear regression model to capture trends and extrapolate beyond known data, complemented by a robust nonlinear tree-based model that focuses on the residuals. This boosted hybrid approach not only addresses the challenges posed by existing models but also significantly improves forecast accuracy. The effectiveness of LTBoost is validated through empirical experiments conducted on nine well-established benchmark datasets, demonstrating superior performance and achieving state-of-the-art results in 32 out of 36 cases, measured by mean absolute error (MAE). Our findings also explore the impact of lag features and signal normalization techniques, demonstrating further improvements in predictive accuracy. This hybrid and highly effective approach highlights LTBoost's innovation and its resolution of specific forecasting challenges, setting the stage for its contribution to the field of time series forecasting, paving the way for its application in diverse real-world scenarios.",2024,https://doi.org/10.1145/3627673.3679527,10.1145/3627673.3679527,11,top-tier,yes,information and knowledge management,0.9,"CIKM is a prominent conference in the field of information and knowledge management, with a rigorous peer-review process. It attracts high-quality submissions and is considered top-tier due to its impact and reputable history.",acm_venues.csv,Proceedings of the 33rd ACM International Conference on Information and Knowledge Management,NA,ACM,NA
ACM International Conference on Information and Knowledge Management (CIKM),LuPe: A System for Personalized and Transparent Data-driven Decisions,"Oppold, Sarah; Herschel, Melanie","Machine learning models are commonly used for decision support even though they are far from perfect, e.g., due to bias introduced by imperfect training data or wrong feature selection. While efforts are made and should continue to be put into developing better models, we will likely continue to rely on imperfect models in many applications. In these settings, how could we at least use the ""best"" model for an individual or a group of users and transparently communicate the risks and weaknesses that apply?We demonstrate LuPe, a system that addresses these questions. LuPe allows to optimize the choice of the applied model for subgroups of the population or individuals, thereby personalizing the model choice to best fit users' profiles, which improves fairness. LuPe further captures data to explain the choices made and the results of the model. We showcase how such data enable users to understand the system performance they can expect. This transparency helps users in making informed decisions or providing informed consent when such systems are used. Our demonstration will focus on several real-world applications showcasing the behavior of LuPe, including credit scoring and income prediction.",2019,https://doi.org/10.1145/3357384.3357857,10.1145/3357384.3357857,4,top-tier,yes,"information systems, knowledge management",0.9,"CIKM is considered a leading conference in information and knowledge management, known for its rigorous peer-review process and high-quality contributions in the field.",acm_venues.csv,Proceedings of the 28th ACM International Conference on Information and Knowledge Management,NA,ACM,NA
ACM International Conference on Information and Knowledge Management (CIKM),MArBLE: Hierarchical Multi-Armed Bandits for Human-in-the-Loop Set Expansion,"Wahed, Muntasir; Gruhl, Daniel; Lourentzou, Ismini","The modern-day research community has an embarrassment of riches regarding pre-trained AI models. Even for a simple task such as lexicon set expansion, where an AI model suggests new entities to add to a predefined seed set of entities, thousands of models are available. However, deciding which model to use for a given set expansion task is non-trivial. In hindsight, some models can be 'off topic' for specific set expansion tasks, while others might work well initially but quickly exhaust what they have to offer. Additionally, certain models may require more careful priming in the form of samples or feedback before being finetuned to the task at hand. In this work, we frame this model selection as a sequential non-stationary problem, where there exist a large number of diverse pre-trained models that may or may not fit a task at hand, and an expert is shown one suggestion at a time to include in the set or not, i.e., accept or reject the suggestion. The goal is to expand the list with the most entities as quickly as possible. We introduce MArBLE, a hierarchical multi-armed bandit method for this task, and two strategies designed to address cold-start problems. Experimental results on three set expansion tasks demonstrate MArBLE's effectiveness compared to baselines.",2023,https://doi.org/10.1145/3583780.3615485,10.1145/3583780.3615485,7,top-tier,yes,information and knowledge management,0.95,"CIKM is a well-established conference in the area of information and knowledge management, having high citation rates and reputable publications, indicating its top-tier status and rigorous peer-review process.",acm_venues.csv,Proceedings of the 32nd ACM International Conference on Information and Knowledge Management,NA,ACM,NA
ACM International Conference on Information and Knowledge Management (CIKM),MedRetriever: Target-Driven Interpretable Health Risk Prediction via Retrieving Unstructured Medical Text,"Ye, Muchao; Cui, Suhan; Wang, Yaqing; Luo, Junyu; Xiao, Cao; Ma, Fenglong","The broad adoption of electronic health record (EHR) systems and the advances of deep learning technology have motivated the development of health risk prediction models, which mainly depend on the expressiveness and temporal modeling capacity of deep neural networks (DNNs) to improve prediction performance. Some further augment the prediction by using external knowledge, however, a great deal of EHR information inevitably loses during the knowledge mapping. In addition, prediction made by existing models usually lacks reliable interpretation, which undermines their reliability in guiding clinical decision-making. To solve these challenges, we propose MedRetriever, an effective and flexible framework that leverages unstructured medical text collected from authoritative websites to augment health risk prediction as well as to provide understandable interpretation. Besides, MedRetriever explicitly takes the target disease documents into consideration, which provide key guidance for the model to learn in a target-driven direction, i.e., from the target disease to the input EHR. To specify, MedRetriever can flexibly choose its backbone from major predictive models to learn the EHR embedding for each visit. After that, the EHR embedding and features of target disease documents are aggregated into a query by self-attention to retrieve highly relevant text segments from the medical text pool, which is stored in the dynamically updated text memory. Finally, the comprehensive EHR embedding and the text memory are used for prediction and interpretation. We evaluate MedRetriever against nine state-of-the-art approaches across three real-world EHR datasets, which consistently achieves the best performance in AUC and recall metrics and outperforms the best baseline by at least 4.8% in recall on three test datasets. Furthermore, we conduct case studies to show the easy-to-understand interpretation by MedRetriever.",2021,https://doi.org/10.1145/3459637.3482273,10.1145/3459637.3482273,10,top-tier,yes,information & knowledge management,0.9,"CIKM is recognized for its quality research contributions in databases, information retrieval, and knowledge management, and is considered a prestigious conference in these fields.",acm_venues.csv,Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management,NA,ACM,NA
ACM International Conference on Information and Knowledge Management (CIKM),MetaTrader: An Reinforcement Learning Approach Integrating Diverse Policies for Portfolio Optimization,"Niu, Hui; Li, Siyuan; Li, Jian","Portfolio management is a fundamental problem in finance. It involves periodic reallocations of assets to maximize the expected returns within an appropriate level of risk exposure. Deep reinforcement learning (RL) has been considered a promising approach to solving this problem owing to its strong capability in sequential decision making. However, due to the non-stationary nature of financial markets, applying RL techniques to portfolio optimization remains a challenging problem. Extracting trading knowledge from various expert strategies could be helpful for agents to accommodate the changing markets. In this paper, we propose MetaTrader, a novel two-stage RL-based approach for portfolio management, which learns to integrate diverse trading policies to adapt to various market conditions. In the first stage, MetaTrader incorporates an imitation learning objective into the reinforcement learning framework. Through imitating different expert demonstrations, MetaTrader acquires a set of trading policies with great diversity. In the second stage, MetaTrader learns a meta-policy to recognize the market conditions and decide on the most proper learned policy to follow. We evaluate the proposed approach on three real-world index datasets and compare it to state-of-the-art baselines. The empirical results demonstrate that MetaTrader significantly outperforms those baselines in balancing profits and risks. Furthermore, thorough ablation studies validate the effectiveness of the components in the proposed approach.",2022,https://doi.org/10.1145/3511808.3557363,10.1145/3511808.3557363,11,top-tier,yes,information and knowledge management,0.9,CIKM is a prestigious conference in the fields of information retrieval and knowledge management. It is widely recognized in academia for its high-quality contributions and rigorous peer review process.,acm_venues.csv,Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management,NA,ACM,NA
ACM International Conference on Information and Knowledge Management (CIKM),MGMAE: Molecular Representation Learning by Reconstructing Heterogeneous Graphs with A High Mask Ratio,"Feng, Jinjia; Wang, Zhen; Li, Yaliang; Ding, Bolin; Wei, Zhewei; Xu, Hongteng","Masked autoencoder (MAE), as an effective self-supervised learner for computer vision and natural language processing, has been recently applied to molecule representation learning. In this paper, we identify two issues in applying MAE to pre-train Transformer-based models on molecular graphs that existing works have ignored. (1) As only atoms are abstracted as tokens and then reconstructed, the chemical bonds are not decided in the decoded molecule, making molecules with different arrangements of the same atoms indistinguishable. (2) Although a high mask ratio that corresponds to a challenging reconstruction task has been proved beneficial in the vision domain, it cannot be trivially leveraged on molecular graphs as there is less redundancy of information in graph data. To resolve these issues, we propose a novel framework, Molecular Graph Mask AutoEncoder (MGMAE). As the first step in MGMAE, we transform each molecular graph into a heterogeneous atom-bond graph to fully use the bond attributes and design unidirectional position encoding for such graphs. Then we propose a hybrid masking mechanism that exploits the complementary nature between atoms' attributive and spatial features. Meanwhile, we compensate for the mask embedding by a dynamic aggregation representation that exploits the correlations between topologically adjacent tokens. As a result, MGMAE can reconstruct the masked atoms, the masked bonds, and the relative distance among atoms simultaneously, with a high mask ratio. We compare MGMAE with the state-of-the-art methods on various molecular benchmarks and show the competitiveness of MGMAE in both regression and classification tasks.",2022,https://doi.org/10.1145/3511808.3557395,10.1145/3511808.3557395,11,top-tier,yes,information and knowledge management,0.9,CIKM is a prestigious conference in the fields of information retrieval and knowledge management. It is widely recognized in academia for its high-quality contributions and rigorous peer review process.,acm_venues.csv,Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management,NA,ACM,NA
ACM International Conference on Information and Knowledge Management (CIKM),Modeling Consumer Buying Decision for Recommendation Based on Multi-Task Deep Learning,"Xia, Qiaolin; Jiang, Peng; Sun, Fei; Zhang, Yi; Wang, Xiaobo; Sui, Zhifang","Although marketing researchers and sociologists have recognized the importance of buying decision process and its significant influence on consumer's purchasing behaviors, existing recommender systems do not explicitly model the consumer buying decision process or capture the sequential regularities of what happens before and after each purchase. In this paper, we try to bridge the gap and improve recommendation systems by explicitly modeling consumer buying decision process and corresponding stages. In particular, we propose a multi-task learning model with long short-term memory networks (LSTM) to learn consumer buying decision process. It maps items, users, product categories, and the behavior sequences into real valued vectors, with which the probability of purchasing a product can be estimated. In this way, the model can capture user intentions and preferences, predicts the conversion rate of each candidate product, and makes recommendations accordingly. Experiments on real world data demonstrate the effectiveness of the proposed approach.",2018,https://doi.org/10.1145/3269206.3269285,10.1145/3269206.3269285,4,top-tier,yes,information and knowledge management,0.9,"CIKM is a well-established, high-impact conference in the information and knowledge management field, consistently hosting cutting-edge research and attracting top researchers worldwide, suggesting its high ranking and peer-reviewed status.",acm_venues.csv,Proceedings of the 27th ACM International Conference on Information and Knowledge Management,NA,ACM,NA
ACM International Conference on Information and Knowledge Management (CIKM),MODRL-TA: A Multi-Objective Deep Reinforcement Learning Framework for Traffic Allocation in E-Commerce Search,"Cheng, Peng; Wang, Huimu; Zhao, Jinyuan; Wang, Yihao; Xu, Enqiang; Zhao, Yu; Xiao, Zhuojian; Wang, Songlin; Tang, Guoyu; Liu, Lin; Xu, Sulong","Traffic allocation is a process of redistributing natural traffic to products by adjusting their positions in the post-search phase, aimed at effectively fostering merchant growth, precisely meeting customer demands, and ensuring the maximization of interests across various parties within e-commerce platforms. Existing methods based on learning to rank neglect the long-term value of traffic allocation, whereas approaches of reinforcement learning suffer from balancing multiple objectives and the difficulties of cold starts within real-world data environments. To address the aforementioned issues, this paper propose a multi-objective deep reinforcement learning framework consisting of multi-objective Q-learning (MOQ), a decision fusion algorithm (DFM) based on the cross-entropy method(CEM), and a progressive data augmentation system (PDA). Specifically. MOQ constructs ensemble RL models, each dedicated to an objective, such as click-through rate, conversion rate, etc. These models individually determine the position of items as actions, aiming to estimate the long-term value of multiple objectives from an individual perspective. Then we employ DFM to dynamically adjust weights among objectives to maximize long-term value, addressing temporal dynamics in objective preferences in e-commerce scenarios. Initially, PDA trained MOQ with simulated data from offline logs. As experiments progressed, it strategically integrated real user interaction data, ultimately replacing the simulated dataset to alleviate distributional shifts and the cold start problem. Experimental results on real-world online e-commerce systems demonstrate the significant improvements of MODRL-TA, and we have successfully deployed MODRL-TA on an e-commerce search platform.",2024,https://doi.org/10.1145/3627673.3679964,10.1145/3627673.3679964,5,top-tier,yes,information and knowledge management,0.9,"CIKM is a prominent conference in the field of information and knowledge management, with a rigorous peer-review process. It attracts high-quality submissions and is considered top-tier due to its impact and reputable history.",acm_venues.csv,Proceedings of the 33rd ACM International Conference on Information and Knowledge Management,NA,ACM,NA
ACM International Conference on Information and Knowledge Management (CIKM),Offline Reinforcement Learning for Mobile Notifications,"Yuan, Yiping; Muralidharan, Ajith; Nandy, Preetam; Cheng, Miao; Prabhakar, Prakruthi","Mobile notification systems have taken a major role in driving and maintaining user engagement for online platforms. They are interesting recommender systems to machine learning practitioners with more sequential and long-term feedback considerations. Most machine learning applications in notification systems are built around response-prediction models, trying to attribute both short-term impact and long-term impact to a notification decision. However, a user's experience depends on a sequence of notifications and attributing impact to a single notification is not always accurate, if not impossible. In this paper, we argue that reinforcement learning is a better framework for notification systems in terms of performance and iteration speed. We propose an offline reinforcement learning framework to optimize sequential notification decisions for driving user engagement. We describe a state-marginalized importance sampling policy evaluation approach, which can be used to evaluate the policy offline and tune learning hyperparameters. Through simulations that approximate the notifications ecosystem, we demonstrate the performance and benefits of the offline evaluation approach as a part of the reinforcement learning modeling approach. Finally, we collect data through online exploration in the production system, train an offline Double Deep Q-Network and launch a successful policy online. We also discuss the practical considerations and results obtained by deploying these policies for a large-scale recommendation system use-case.",2022,https://doi.org/10.1145/3511808.3557083,10.1145/3511808.3557083,10,top-tier,yes,information and knowledge management,0.9,CIKM is a prestigious conference in the fields of information retrieval and knowledge management. It is widely recognized in academia for its high-quality contributions and rigorous peer review process.,acm_venues.csv,Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management,NA,ACM,NA
ACM International Conference on Information and Knowledge Management (CIKM),On Causally Disentangled State Representation Learning for Reinforcement Learning based Recommender Systems,"Wang, Siyu; Chen, Xiaocong; Yao, Lina","In Reinforcement Learning-based Recommender Systems (RLRS), the complexity and dynamism of user interactions often result in high-dimensional and noisy state spaces, making it challenging to discern which aspects of the state are truly influential in driving the decision-making process. This issue is exacerbated by the evolving nature of user preferences and behaviors, requiring the recommender system to adaptively focus on the most relevant information for decision-making while preserving generaliability. To tackle this problem, we introduce an innovative causal approach for decomposing the state and extracting Causal-InDispensable State Representations (CIDS) in RLRS. Our method concentrates on identifying the Directly Action-Influenced State Variables (DAIS) and Action-Influence Ancestors (AIA), which are essential for making effective recommendations. By leveraging conditional mutual information, we develop a framework that not only discerns the causal relationships within the generative process but also isolates critical state variables from the typically dense and high-dimensional state representations. We provide theoretical evidence for the identifiability of these variables. Then, by making use of the identified causal relationship, we construct causal-indispensable state representations, enabling the training of policies over a more advantageous subset of the agent's state space. We demonstrate the efficacy of our approach through extensive experiments, showcasing our method outperforms state-of-the-art methods.",2024,https://doi.org/10.1145/3627673.3679674,10.1145/3627673.3679674,10,top-tier,yes,information and knowledge management,0.9,"CIKM is a prominent conference in the field of information and knowledge management, with a rigorous peer-review process. It attracts high-quality submissions and is considered top-tier due to its impact and reputable history.",acm_venues.csv,Proceedings of the 33rd ACM International Conference on Information and Knowledge Management,NA,ACM,NA
ACM International Conference on Information and Knowledge Management (CIKM),On Smoothed Explanations: Quality and Robustness,"Ajalloeian, Ahmad; Moosavi-Dezfooli, Seyed-Mohsen; Vlachos, Michalis; Frossard, Pascal","Explanation methods highlight the importance of the input features in taking a predictive decision, and represent a solution to increase the transparency and trustworthiness in machine learning and deep neural networks (DNNs). However, explanation methods can be easily manipulated generating misleading explanations particularly under visually imperceptible adversarial perturbations. Recent work has identified the decision surface geometry of DNNs as the main cause of this phenomenon. To make explanation methods more robust against adversarially crafted perturbations, recent research has promoted several smoothing approaches. These approaches smooth either the explanation map or the decision surface.In this work, we initiate a very thorough evaluation of the quality and robustness of the explanations offered by smoothing approaches. Different properties are evaluated. We present settings in which the smoothed explanations are both better, and worse, than the explanations derived by the commonly-used (non-smoothed) Gradient explanation method. By making the connection with the literature on adversarial attacks, we demonstrate that such smoothed explanations are robust primarily against additive attacks. However, a combination of additive and non-additive attacks can still manipulate these explanations, revealing important shortcomings in their robustness properties.",2022,https://doi.org/10.1145/3511808.3557409,10.1145/3511808.3557409,11,top-tier,yes,information and knowledge management,0.9,CIKM is a prestigious conference in the fields of information retrieval and knowledge management. It is widely recognized in academia for its high-quality contributions and rigorous peer review process.,acm_venues.csv,Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management,NA,ACM,NA
ACM International Conference on Information and Knowledge Management (CIKM),On the Mining of Time Series Data Counterfactual Explanations using Barycenters,"Filali Boubrahimi, Soukaïna; Hamdi, Shah Muhammad","EXplainable Artificial Intelligence (XAI) methods are increasingly accepted as effective tools to trace complex machine learning models' decision-making processes. There are two underlying XAI paradigms: (1) traditional factual methods and (2) emerging counterfactual models. The first family of methods uses feature attribution techniques that alter the feature space and observe the impact on the decision function. Counterfactual models aim at providing the smallest possible change to the feature vector that can change the prediction outcome. In this paper, we propose TimeX, a new model-agnostic time series counterfactual explanation algorithm that provides sparse, interpretable, and contiguous explanations. We validate our model using real-world time series datasets and show that our approach can generate explanations with up to 20% fewer outliers in comparison with other state-of-the-art competing baselines.",2022,https://doi.org/10.1145/3511808.3557663,10.1145/3511808.3557663,5,top-tier,yes,information and knowledge management,0.9,CIKM is a prestigious conference in the fields of information retrieval and knowledge management. It is widely recognized in academia for its high-quality contributions and rigorous peer review process.,acm_venues.csv,Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management,NA,ACM,NA
ACM International Conference on Intelligent User Interfaces (IUI),Appropriate Reliance on AI Advice: Conceptualization and the Effect of Explanations,"Schemmer, Max; Kuehl, Niklas; Benz, Carina; Bartos, Andrea; Satzger, Gerhard","AI advice is becoming increasingly popular, e.g., in investment and medical treatment decisions. As this advice is typically imperfect, decision-makers have to exert discretion as to whether actually follow that advice: they have to “appropriately” rely on correct and turn down incorrect advice. However, current research on appropriate reliance still lacks a common definition as well as an operational measurement concept. Additionally, no in-depth behavioral experiments have been conducted that help understand the factors influencing this behavior. In this paper, we propose Appropriateness of Reliance (AoR) as an underlying, quantifiable two-dimensional measurement concept. We develop a research model that analyzes the effect of providing explanations for AI advice. In an experiment with 200 participants, we demonstrate how these explanations influence the AoR, and, thus, the effectiveness of AI advice. Our work contributes fundamental concepts for the analysis of reliance behavior and the purposeful design of AI advisors.",2023,https://doi.org/10.1145/3581641.3584066,10.1145/3581641.3584066,13,top-tier,yes,"human-computer interaction, artificial intelligence",0.9,"IUI is a well-regarded conference known for its focus on cutting-edge research at the intersection of AI and HCI, and is organized by ACM SIGCHI and SIGAI, marking it as top-tier.",acm_venues.csv,Proceedings of the 28th International Conference on Intelligent User Interfaces,NA,ACM,NA
ACM International Conference on Intelligent User Interfaces (IUI),AutoDOViz: Human-Centered Automation for Decision Optimization,"Weidele, Daniel Karl I.; Afzal, Shazia; Valente, Abel N.; Makuch, Cole; Cornec, Owen; Vu, Long; Subramanian, Dharmashankar; Geyer, Werner; Nair, Rahul; Vejsbjerg, Inge; Marinescu, Radu; Palmes, Paulito; Daly, Elizabeth M.; Franke, Loraine; Haehn, Daniel","We present AutoDOViz, an interactive user interface for automated decision optimization (AutoDO) using reinforcement learning (RL). Decision optimization (DO) has classically being practiced by dedicated DO researchers [43] where experts need to spend long periods of time fine tuning a solution through trial-and-error. AutoML pipeline search has sought to make it easier for a data scientist to find the best machine learning pipeline by leveraging automation to search and tune the solution. More recently, these advances have been applied to the domain of AutoDO [36], with a similar goal to find the best reinforcement learning pipeline through algorithm selection and parameter tuning. However, Decision Optimization requires significantly more complex problem specification when compared to an ML problem. AutoDOViz seeks to lower the barrier of entry for data scientists in problem specification for reinforcement learning problems, leverage the benefits of AutoDO algorithms for RL pipeline search and finally, create visualizations and policy insights in order to facilitate the typical interactive nature when communicating problem formulation and solution proposals between DO experts and domain experts. In this paper, we report our findings from semi-structured expert interviews with DO practitioners as well as business consultants, leading to design requirements for human-centered automation for DO with RL. We evaluate a system implementation with data scientists and find that they are significantly more open to engage in DO after using our proposed solution. AutoDOViz further increases trust in RL agent models and makes the automated training and evaluation process more comprehensible. As shown for other automation in ML tasks [33, 59], we also conclude automation of RL for DO can benefit from user and vice-versa when the interface promotes human-in-the-loop.",2023,https://doi.org/10.1145/3581641.3584094,10.1145/3581641.3584094,17,top-tier,yes,"human-computer interaction, artificial intelligence",0.9,"IUI is a well-regarded conference known for its focus on cutting-edge research at the intersection of AI and HCI, and is organized by ACM SIGCHI and SIGAI, marking it as top-tier.",acm_venues.csv,Proceedings of the 28th International Conference on Intelligent User Interfaces,NA,ACM,NA
ACM International Conference on Intelligent User Interfaces (IUI),Categorical and Continuous Features in Counterfactual Explanations of AI Systems,"Warren, Greta; Byrne, Ruth M. J.; Keane, Mark T.","Recently, eXplainable AI (XAI) research has focused on the use of counterfactual explanations to address interpretability, algorithmic recourse, and bias in AI system decision-making. The proponents of these algorithms claim they meet users’ requirements for counterfactual explanations. For instance, many claim that the output of their algorithms work as explanations because they prioritise ""plausible"", ""actionable"" or ""causally important"" features in their generated counterfactuals. However, very few of these claims have been tested in controlled psychological studies, and we know very little about which aspects of counterfactual explanations help users to understand AI system decisions. Furthermore, we do not know whether counterfactual explanations are an advance on more traditional causal explanations that have a much longer history in AI (in explaining expert systems and decision trees). Accordingly, we carried out two user studies to (i) test a fundamental distinction in feature-types, between categorical and continuous features, and (ii) compare the relative effectiveness of counterfactual and causal explanations. The studies used a simulated, automated decision-making app that determined safe driving limits after drinking alcohol, based on predicted blood alcohol content, and user responses were measured objectively (users’ predictive accuracy) and subjectively (users’ satisfaction and trust judgments). Study 1 (N=127) showed that users understand explanations referring to categorical features more readily than those referring to continuous features. It also discovered a dissociation between objective and subjective measures: counterfactual explanations elicited higher accuracy of predictions than no-explanation control descriptions but no higher accuracy than causal explanations, yet counterfactual explanations elicited greater satisfaction and trust judgments than causal explanations. Study 2 (N=211) found that users were more accurate for categorically-transformed features compared to continuous ones, and also replicated the results of Study 1. The findings delineate important boundary conditions for current and future counterfactual explanation methods in XAI.",2023,https://doi.org/10.1145/3581641.3584090,10.1145/3581641.3584090,17,top-tier,yes,"human-computer interaction, artificial intelligence",0.9,"IUI is a well-regarded conference known for its focus on cutting-edge research at the intersection of AI and HCI, and is organized by ACM SIGCHI and SIGAI, marking it as top-tier.",acm_venues.csv,Proceedings of the 28th International Conference on Intelligent User Interfaces,NA,ACM,NA
ACM International Conference on Intelligent User Interfaces (IUI),Directive Explanations for Monitoring the Risk of Diabetes Onset: Introducing Directive Data-Centric Explanations and Combinations to Support What-If Explorations,"Bhattacharya, Aditya; Ooge, Jeroen; Stiglic, Gregor; Verbert, Katrien","Explainable artificial intelligence is increasingly used in machine learning (ML) based decision-making systems in healthcare. However, little research has compared the utility of different explanation methods in guiding healthcare experts for patient care. Moreover, it is unclear how useful, understandable, actionable and trustworthy these methods are for healthcare experts, as they often require technical ML knowledge. This paper presents an explanation dashboard that predicts the risk of diabetes onset and explains those predictions with data-centric, feature-importance, and example-based explanations. We designed an interactive dashboard to assist healthcare experts, such as nurses and physicians, in monitoring the risk of diabetes onset and recommending measures to minimize risk. We conducted a qualitative study with 11 healthcare experts and a mixed-methods study with 45 healthcare experts and 51 diabetic patients to compare the different explanation methods in our dashboard in terms of understandability, usefulness, actionability, and trust. Results indicate that our participants preferred our representation of data-centric explanations that provide local explanations with a global overview over other methods. Therefore, this paper highlights the importance of visually directive data-centric explanation method for assisting healthcare experts to gain actionable insights from patient health records. Furthermore, we share our design implications for tailoring the visual representation of different explanation methods for healthcare experts.",2023,https://doi.org/10.1145/3581641.3584075,10.1145/3581641.3584075,16,top-tier,yes,"human-computer interaction, artificial intelligence",0.9,"IUI is a well-regarded conference known for its focus on cutting-edge research at the intersection of AI and HCI, and is organized by ACM SIGCHI and SIGAI, marking it as top-tier.",acm_venues.csv,Proceedings of the 28th International Conference on Intelligent User Interfaces,NA,ACM,NA
ACM International Conference on Intelligent User Interfaces (IUI),Efficient Human-in-the-loop System for Guiding DNNs Attention,"He, Yi; Yang, Xi; Chang, Chia-Ming; Xie, Haoran; Igarashi, Takeo","Attention guidance is used to address dataset bias in deep learning, where the model relies on incorrect features to make decisions. Focusing on image classification tasks, we propose an efficient human-in-the-loop system to interactively direct the attention of classifiers to regions specified by users, thereby reducing the effect of co-occurrence bias and improving the transferability and interpretability of a deep neural network (DNN). Previous approaches for attention guidance require the preparation of pixel-level annotations and are not designed as interactive systems. We herein present a new interactive method that allows users to annotate images via simple clicks. Additionally, we identify a novel active learning strategy that can significantly reduce the number of annotations. We conduct both numerical evaluations and a user study to evaluate the proposed system using multiple datasets. Compared with the existing non-active-learning approach, which typically relies on considerable amounts of polygon-based segmentation masks to fine-tune or train the DNNs, our system can obtain fine-tuned networks on biased datasets in a more time- and cost-efficient manner and offers a more user-friendly experience. Our experimental results show that the proposed system is efficient, reasonable, and reliable. Our code is publicly available at https://github.com/ultratykis/Guiding-DNNs-Attention.",2023,https://doi.org/10.1145/3581641.3584074,10.1145/3581641.3584074,13,top-tier,yes,"human-computer interaction, artificial intelligence",0.9,"IUI is a well-regarded conference known for its focus on cutting-edge research at the intersection of AI and HCI, and is organized by ACM SIGCHI and SIGAI, marking it as top-tier.",acm_venues.csv,Proceedings of the 28th International Conference on Intelligent User Interfaces,NA,ACM,NA
ACM International Conference on Intelligent User Interfaces (IUI),What can AI do for me? evaluating machine learning interpretations in cooperative play,"Feng, Shi; Boyd-Graber, Jordan","Machine learning is an important tool for decision making, but its ethical and responsible application requires rigorous vetting of its interpretability and utility: an understudied problem, particularly for natural language processing models. We propose an evaluation of interpretation on a real task with real human users, where the effectiveness of interpretation is measured by how much it improves human performance. We design a grounded, realistic human-computer cooperative setting using a question answering task, Quizbowl. We recruit both trivia experts and novices to play this game with computer as their teammate, who communicates its prediction via three different interpretations. We also provide design guidance for natural language processing human-in-the-loop settings.",2019,https://doi.org/10.1145/3301275.3302265,10.1145/3301275.3302265,11,top-tier,yes,human-computer interaction (hci),0.9,"The ACM IUI conference is a respected venue focusing on the intersection of HCI and AI, showcasing innovative research in intelligent interfaces. It is well-regarded in the HCI community and involves a rigorous peer-review process.",acm_venues.csv,Proceedings of the 24th International Conference on Intelligent User Interfaces,NA,ACM,NA
ACM International Conference on Multimedia,Context-Aware Visual Policy Network for Sequence-Level Image Captioning,"Liu, Daqing; Zha, Zheng-Jun; Zhang, Hanwang; Zhang, Yongdong; Wu, Feng","Many vision-language tasks can be reduced to the problem of sequence prediction for natural language output. In particular, recent advances in image captioning use deep reinforcement learning (RL) to alleviate the ""exposure bias” during training: ground-truth subsequence is exposed in every step prediction, which introduces bias in test when only predicted subsequence is seen. However, existing RL-based image captioning methods only focus on the language policy while not the visual policy (eg, visual attention), and thus fail to capture the visual context that are crucial for compositional reasoning such as visual relationships (eg, ""man riding horse”) and comparisons (eg. ""smaller cat""). To fill the gap, we propose a Context-Aware Visual Policy network (CAVP) for sequence-level image captioning. At every time step, CAVP explicitly accounts for the previous visual attentions as the context, and then decides whether the context is helpful for the current word generation given the current visual attention. Compared against traditional visual attention that only fixes a single image region at every step, CAVP can attend to complex visual compositions over time. The whole image captioning model — CAVP and its subsequent language policy network — can be efficiently optimized end-to-end by using an actor-critic policy gradient method with respect to any caption evaluation metric. We demonstrate the effectiveness of CAVP by state-of-the-art performances on MS-COCO offline split and online server, using various metrics and sensible visualizations of qualitative visual context. The code is available at urlhttps://github.com/daqingliu/CAVP",2018,https://doi.org/10.1145/3240508.3240632,10.1145/3240508.3240632,9,top-tier,yes,multimedia,1,"ACM Multimedia is a leading conference in multimedia research, known for high-quality peer-reviewed papers and influential work. It covers a wide range of multimedia topics, making it a top-tier venue in its field.",acm_venues.csv,Proceedings of the 26th ACM International Conference on Multimedia,NA,ACM,NA
ACM International Symposium on Mobile Ad Hoc Networking and Computing (MobiHoc),First learn then earn: optimizing mobile crowdsensing campaigns through data-driven user profiling,"Karaliopoulos, Merkourios; Koutsopoulos, Iordanis; Titsias, Michalis","We study the optimal design of mobile crowdsensing campaigns in terms of the aggregate quality of contributions attracted for a set of tasks. The interaction of the campaign with users is realized through a mobile app interface that recommends tasks to users and offers them incentives. The main contribution is a novel perspective on the payment distribution problem faced by the crowdsensing campaign organizer in light of originally unknown individual user preferences. Contrary to common practice, we acknowledge that users exhibit high diversity in decision making because they assess differently attributes related to a task such as their proximity to the place of interest (PoI), the payment made for contributing data, or the task context/theme.We draw on logistic-regression techniques from machine learning to learn users' individual preferences from past data rather than hypothesizing about them. We then formulate non-linear (sigmoid) optimization problems to determine the tasks and incentives (payments) that should be optimally offered to each user. Our mechanism is validated against synthetic but also real data about the way users choose tasks, collected through an online questionnaire. It achieves very good approximations of the optimal solutions and substantially outperforms alternative preference-agnostic policies that do not exercise behavioral user profiling to target the provision of incentives.",2016,https://doi.org/10.1145/2942358.2942369,10.1145/2942358.2942369,10,top-tier,yes,"computer networks, mobile computing",0.9,MobiHoc is a highly respected conference focused on wireless ad hoc networks and has consistently been regarded as a top-tier venue in mobile computing research.,acm_venues.csv,Proceedings of the 17th ACM International Symposium on Mobile Ad Hoc Networking and Computing,NA,ACM,NA
ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE),Black box fairness testing of machine learning models,"Aggarwal, Aniya; Lohia, Pranay; Nagar, Seema; Dey, Kuntal; Saha, Diptikalyan","Any given AI system cannot be accepted unless its trustworthiness is proven. An important characteristic of a trustworthy AI system is the absence of algorithmic bias. 'Individual discrimination' exists when a given individual different from another only in 'protected attributes' (e.g., age, gender, race, etc.) receives a different decision outcome from a given machine learning (ML) model as compared to the other individual. The current work addresses the problem of detecting the presence of individual discrimination in given ML models. Detection of individual discrimination is test-intensive in a black-box setting, which is not feasible for non-trivial systems. We propose a methodology for auto-generation of test inputs, for the task of detecting individual discrimination. Our approach combines two well-established techniques - symbolic execution and local explainability for effective test case generation. We empirically show that our approach to generate test cases is very effective as compared to the best-known benchmark systems that we examine.",2019,https://doi.org/10.1145/3338906.3338937,10.1145/3338906.3338937,11,top-tier,yes,software engineering,1,"ESEC/FSE is a leading conference in software engineering, known for its rigorous peer-review process and high-impact research contributions, making it a top-tier venue in this field.",acm_venues.csv,Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering,NA,ACM,NA
ACM Multimedia Systems Conference (MMSys),Ceasefire Hierarchical Weapon Dataset,"Malon, Thierry; Chambon, Sylvie; Crouzil, Alain; Lechelek, Loubna; Jalabert, Grégory; Brocard, Christian; Bernardeau, Nadia; Abadie, Laurence; Sera, Bruno; Hartmann, Thierry; Bras, Marjorie Le","Given the huge level of firearms trafficking in Europe, governments, and in particular interior ministries, are actively engaged in developing artificial intelligence tools to identify firearms more effectively. Indeed, confronted with the huge number of different possible firearms, when a weapon is seized, police officers are not always able to identify it and in particular its illegal nature or the dangerousness of owning it. Consequently, we aim to develop a recognition approach based on a neural network. To this end, a training database is required. As firearms can be hierarchically classified, we have decided to build a hierarchical database. This article presents the Ceasefire Hierarchical Weapon Dataset, an RGB image dataset of firearms tailored for fine-grained image classification. It contains 260 classes ranging from 25 to hundreds of images per class, with a total of 40,789 images. In addition, a 4-level hierarchy (family, group, type, model) is provided and validated by forensic experts. The dataset was built from more than 23,000 images acquired at the Toulouse forensics laboratory (France) using frames extracted from videos filmed on site, and completed with the existing Firearm 14k dataset enriched with 2,526 downloaded images from the Web. Results of hierarchical classification using the proposed dataset are also reported.",2024,https://doi.org/10.1145/3625468.3653434,10.1145/3625468.3653434,7,top-tier,yes,multimedia systems,0.9,The ACM Multimedia Systems Conference (MMSys) is a well-regarded venue for research on multimedia systems. It features peer-reviewed papers and is considered top-tier in its field.,acm_venues.csv,Proceedings of the 15th ACM Multimedia Systems Conference,NA,ACM,NA
ACM Multimedia Systems Conference (MMSys),Empowering video players in cellular: throughput prediction from radio network measurements,"Raca, Darijo; Zahran, Ahmed H.; Sreenan, Cormac J.; Sinha, Rakesh K.; Halepovic, Emir; Jana, Rittwik; Gopalakrishnan, Vijay; Bathula, Balagangadhar; Varvello, Matteo","Today's HTTP adaptive streaming applications are designed to provide high levels of Quality of Experience (QoE) across a wide range of network conditions. The adaptation logic in these applications typically needs an estimate of the future network bandwidth for quality decisions. This estimation, however, is challenging in cellular networks because of the inherent variability of bandwidth and latency due to factors like signal fading, variable load, and user mobility. In this paper, we exploit machine learning (ML) techniques on a range of radio channel metrics and throughput measurements from a commercial cellular network to improve the estimation accuracy and hence, streaming quality. We propose a novel summarization approach for input raw data samples. This approach reduces the 90th percentile of absolute prediction error from 54% to 13%. We evaluate our prediction engine in a trace-driven controlled lab environment using a popular Android video player (ExoPlayer) running on a stock mobile device and also validate it in the commercial cellular network. Our results show that the three tested adaptation algorithms register improvement across all QoE metrics when using prediction, with stall reduction up to 85% and bitrate switching reduction up to 40%, while maintaining or improving video quality. Finally, prediction improves the video QoE score by up to 33%.",2019,https://doi.org/10.1145/3304109.3306233,10.1145/3304109.3306233,12,top-tier,yes,multimedia systems,1,"MMSys is a well-regarded conference focusing on multimedia systems, recognized for its high-quality contributions and rigorous peer-review process, making it a top-tier venue in its field.",acm_venues.csv,Proceedings of the 10th ACM Multimedia Systems Conference,NA,ACM,NA
ACM Multimedia Systems Conference (MMSys),GreenABR: energy-aware adaptive bitrate streaming with deep reinforcement learning,"Turkkan, Bekir Oguzhan; Dai, Ting; Raman, Adithya; Kosar, Tevfik; Chen, Changyou; Bulut, Muhammed Fatih; Zola, Jaroslaw; Sow, Daby","Adaptive bitrate (ABR) algorithms aim to make optimal bitrate decisions in dynamically changing network conditions to ensure a high quality of experience (QoE) for the users during video streaming. However, most of the existing ABRs share the limitations of predefined rules and incorrect assumptions about streaming parameters. They also come short to consider the perceived quality in their QoE model, target higher bitrates regardless, and ignore the corresponding energy consumption. This joint approach results in additional energy consumption and becomes a burden, especially for mobile device users. This paper proposes GreenABR, a new deep reinforcement learning-based ABR scheme that optimizes the energy consumption during video streaming without sacrificing the user QoE. GreenABR employs a standard perceived quality metric, VMAF, and real power measurements collected through a streaming application. GreenABR's deep reinforcement learning model makes no assumptions about the streaming environment and learns how to adapt to the dynamically changing conditions in a wide range of real network scenarios. GreenABR outperforms the existing state-of-the-art ABR algorithms by saving up to 57% in streaming energy consumption and 60% in data consumption while achieving up to 22% more perceptual QoE due to up to 84% less rebuffering time and near-zero capacity violations.",2022,https://doi.org/10.1145/3524273.3528188,10.1145/3524273.3528188,14,top-tier,yes,multimedia systems,0.9,"ACM MMSys is widely recognized as a leading conference in multimedia and systems research, attracting high-quality submissions and offering rigorous peer review. It covers topics on multimedia and distributed computing systems.",acm_venues.csv,Proceedings of the 13th ACM Multimedia Systems Conference,NA,ACM,NA
ACM Multimedia Systems Conference (MMSys),Machine learning-based strategies for streaming and experiencing 3DoF virtual reality: research proposal,"Guimard, Quentin; Sassatelli, Lucile","This paper contains the research proposal of Quentin Guimard that was presented at the MMSys 2022 doctoral symposium.The development of 360° videos experienced in virtual reality (VR) is hindered by network, cybersickness, and content perception challenges. Many levers have already been proposed to address these challenges, but separately. This PhD thesis intends to jointly address these issues by dynamically controlling levers and making quality decisions, with a view to improving the VR streaming experience.This paper describes the steps necessary to the building of such approach, by separating work that has already been achieved over the course of this PhD from tasks that are still left to do. First results are also presented.",2022,https://doi.org/10.1145/3524273.3533934,10.1145/3524273.3533934,5,top-tier,yes,multimedia systems,0.9,"ACM MMSys is widely recognized as a leading conference in multimedia and systems research, attracting high-quality submissions and offering rigorous peer review. It covers topics on multimedia and distributed computing systems.",acm_venues.csv,Proceedings of the 13th ACM Multimedia Systems Conference,NA,ACM,NA
ACM Multimedia Systems Conference (MMSys),NAORL: Network Feature Aware Offline Reinforcement Learning for Real Time Bandwidth Estimation,"Zhang, Wei; Tao, Xuefeng; Wang, Jianan","Bandwidth Estimation(BWE) is the most important and challenging problem for Real Time Communication(RTC) systems. The rule-based BWE is designed with hand-crafted rules, which mainly depend on human knowledge, and therefore is difficult to generalize to unknown scenarios. Learning-based BWE algorithms, especially online reinforcement learning-based algorithms, are proposed to explore new decisions in complex network environments adaptively. However, these algorithms require frequent interactions with the environment, which would cause catastrophic experience for RTC users.In this paper, we propose NAORL, a Network feature Aware Offline Reinforcement Learning for BWE in RTC applications. First, we devise a network-aware feature pre-training scheme, which extracts network-aware feature representation from both emulated and testbed data. Notably, pre-training is conducted in a self-regressive manner, where no labeled data is required, and its performance would be increased with richer and more diverse data. Second, we adopt an effective offline reinforcement learning algorithm IQL to learn experiences from existing data. Third, we design a multi-expert module to enhance model robustness. Furthermore, we devise a method of curriculum learning to facilitate efficient model learning. Finally, we design a set of metrics to evaluate the accuracy of NAORL and conduct extensive ablation experiments. The evaluation results demonstrate that all building blocks in NAORL improve accuracy significantly. In addition, NAORL achieves superior accuracy compared to the mmsys baseline model. The source code can be found at https://github.com/bytedance/offline-RL-congestion-control.",2024,https://doi.org/10.1145/3625468.3652177,10.1145/3625468.3652177,6,top-tier,yes,multimedia systems,0.9,The ACM Multimedia Systems Conference (MMSys) is a well-regarded venue for research on multimedia systems. It features peer-reviewed papers and is considered top-tier in its field.,acm_venues.csv,Proceedings of the 15th ACM Multimedia Systems Conference,NA,ACM,NA
ACM Multimedia Systems Conference (MMSys),TACDEC: Dataset of Tackle Events in Soccer Game Videos,"Kassab, Evan Jåsund; Solberg, Håkon Maric; Gautam, Sushant; Sabet, Saeed Shafiee; Torjusen, Thomas; Riegler, Michael; Halvorsen, Pål; Midoglu, Cise","This paper introduces TACDEC, a dataset of tackle events in soccer game videos. Recognizing the gap in existing open datasets that predominantly focus on official soccer events such as goals and cards, TACDEC targets a comprehensive analysis of tackles — a critical aspect of soccer that combines technical skills, tactical decision-making, and physical engagement. By leveraging video data from the Norwegian Eliteserien league across multiple seasons, we annotated 425 videos with 4 types of tackle events, categorized into ""tackle-live"", ""tackle-replay"", ""tackle-live-incomplete"", and ""tackle-replay-incomplete"", yielding a total of 836 event annotations. The dataset offers an unprecedented resource for the development and testing of machine learning models aimed at understanding and analyzing soccer game dynamics. A proof-of-concept classification model demonstrates the dataset's utility, achieving promising results in automatic tackle detection, thereby validating TACDEC's potential to support not only advanced game analytics but also to enhance fan engagement and player development initiatives.",2024,https://doi.org/10.1145/3625468.3652166,10.1145/3625468.3652166,7,top-tier,yes,multimedia systems,0.9,The ACM Multimedia Systems Conference (MMSys) is a well-regarded venue for research on multimedia systems. It features peer-reviewed papers and is considered top-tier in its field.,acm_venues.csv,Proceedings of the 15th ACM Multimedia Systems Conference,NA,ACM,NA
ACM SIGCOMM Conference,AuTO: scaling deep reinforcement learning for datacenter-scale automatic traffic optimization,"Chen, Li; Lingys, Justinas; Chen, Kai; Liu, Feng","Traffic optimizations (TO, e.g. flow scheduling, load balancing) in datacenters are difficult online decision-making problems. Previously, they are done with heuristics relying on operators' understanding of the workload and environment. Designing and implementing proper TO algorithms thus take at least weeks. Encouraged by recent successes in applying deep reinforcement learning (DRL) techniques to solve complex online control problems, we study if DRL can be used for automatic TO without human-intervention. However, our experiments show that the latency of current DRL systems cannot handle flow-level TO at the scale of current datacenters, because short flows (which constitute the majority of traffic) are usually gone before decisions can be made.Leveraging the long-tail distribution of datacenter traffic, we develop a two-level DRL system, AuTO, mimicking the Peripheral &amp; Central Nervous Systems in animals, to solve the scalability problem. Peripheral Systems (PS) reside on end-hosts, collect flow information, and make TO decisions locally with minimal delay for short flows. PS's decisions are informed by a Central System (CS), where global traffic information is aggregated and processed. CS further makes individual TO decisions for long flows. With CS&amp;PS, AuTO is an end-to-end automatic TO system that can collect network information, learn from past decisions, and perform actions to achieve operator-defined goals. We implement AuTO with popular machine learning frameworks and commodity servers, and deploy it on a 32-server testbed. Compared to existing approaches, AuTO reduces the TO turn-around time from weeks to 100 milliseconds while achieving superior performance. For example, it demonstrates up to 48.14% reduction in average flow completion time (FCT) over existing solutions.",2018,https://doi.org/10.1145/3230543.3230551,10.1145/3230543.3230551,15,top-tier,yes,computer networks,1,"The ACM SIGCOMM Conference is the flagship conference of the ACM Special Interest Group on Data Communication. It is highly prestigious, known for rigorous peer review, and is considered a top-tier venue in computer networking.",acm_venues.csv,Proceedings of the 2018 Conference of the ACM Special Interest Group on Data Communication,NA,ACM,NA
ACM SIGCOMM Conference,Interpreting Deep Learning-Based Networking Systems,"Meng, Zili; Wang, Minhu; Bai, Jiasong; Xu, Mingwei; Mao, Hongzi; Hu, Hongxin","While many deep learning (DL)-based networking systems have demonstrated superior performance, the underlying Deep Neural Networks (DNNs) remain blackboxes and stay uninterpretable for network operators. The lack of interpretability makes DL-based networking systems prohibitive to deploy in practice. In this paper, we propose Metis, a framework that provides interpretability for two general categories of networking problems spanning local and global control. Accordingly, Metis introduces two different interpretation methods based on decision tree and hypergraph, where it converts DNN policies to interpretable rule-based controllers and highlight critical components based on analysis over hypergraph. We evaluate Metis over two categories of state-of-the-art DL-based networking systems and show that Metis provides human-readable interpretations while preserving nearly no degradation in performance. We further present four concrete use cases of Metis, showcasing how Metis helps network operators to design, debug, deploy, and ad-hoc adjust DL-based networking systems.",2020,https://doi.org/10.1145/3387514.3405859,10.1145/3387514.3405859,18,top-tier,yes,computer networks,1,"ACM SIGCOMM is a leading conference in computer networking and communication, known for its rigorous peer-review process and high impact on the field. It is widely recognized as a top-tier venue.",acm_venues.csv,"Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication",NA,ACM,NA
ACM SIGCOMM Conference,Network planning with deep reinforcement learning,"Zhu, Hang; Gupta, Varun; Ahuja, Satyajeet Singh; Tian, Yuandong; Zhang, Ying; Jin, Xin","Network planning is critical to the performance, reliability and cost of web services. This problem is typically formulated as an Integer Linear Programming (ILP) problem. Today's practice relies on hand-tuned heuristics from human experts to address the scalability challenge of ILP solvers.In this paper, we propose NeuroPlan, a deep reinforcement learning (RL) approach to solve the network planning problem. This problem involves multi-step decision making and cost minimization, which can be naturally cast as a deep RL problem. We develop two important domain-specific techniques. First, we use a graph neural network (GNN) and a novel domain-specific node-link transformation for state encoding, in order to handle the dynamic nature of the evolving network topology during planning decision making. Second, we leverage a two-stage hybrid approach that first uses deep RL to prune the search space and then uses an ILP solver to find the optimal solution. This approach resembles today's practice, but avoids human experts with an RL agent in the first stage. Evaluation on real topologies and setups from large production networks demonstrates that NeuroPlan scales to large topologies beyond the capability of ILP solvers, and reduces the cost by up to 17% compared to hand-tuned heuristics.",2021,https://doi.org/10.1145/3452296.3472902,10.1145/3452296.3472902,14,top-tier,yes,computer networks and communications,1,"ACM SIGCOMM is a leading conference in the field of computer networking, well-regarded for its high-quality research papers and rigorous peer-review process. It is widely recognized as a premier venue in its area.",acm_venues.csv,Proceedings of the 2021 ACM SIGCOMM 2021 Conference,NA,ACM,NA
ACM SIGCOMM Conference,Neural Adaptive Video Streaming with Pensieve,"Mao, Hongzi; Netravali, Ravi; Alizadeh, Mohammad","Client-side video players employ adaptive bitrate (ABR) algorithms to optimize user quality of experience (QoE). Despite the abundance of recently proposed schemes, state-of-the-art ABR algorithms suffer from a key limitation: they use fixed control rules based on simplified or inaccurate models of the deployment environment. As a result, existing schemes inevitably fail to achieve optimal performance across a broad set of network conditions and QoE objectives.We propose Pensieve, a system that generates ABR algorithms using reinforcement learning (RL). Pensieve trains a neural network model that selects bitrates for future video chunks based on observations collected by client video players. Pensieve does not rely on pre-programmed models or assumptions about the environment. Instead, it learns to make ABR decisions solely through observations of the resulting performance of past decisions. As a result, Pensieve automatically learns ABR algorithms that adapt to a wide range of environments and QoE metrics. We compare Pensieve to state-of-the-art ABR algorithms using trace-driven and real world experiments spanning a wide variety of network conditions, QoE metrics, and video properties. In all considered scenarios, Pensieve outperforms the best state-of-the-art scheme, with improvements in average QoE of 12%–25%. Pensieve also generalizes well, outperforming existing schemes even on networks for which it was not explicitly trained.",2017,https://doi.org/10.1145/3098822.3098843,10.1145/3098822.3098843,14,top-tier,yes,computer networks,1,"The ACM SIGCOMM Conference is a prestigious and highly regarded conference in the field of computer networks, known for presenting cutting-edge research. Being a top-tier, peer-reviewed venue, it attracts leading researchers and practitioners.",acm_venues.csv,Proceedings of the Conference of the ACM Special Interest Group on Data Communication,NA,ACM,NA
ACM SIGCOMM Conference,RedTE: Mitigating Subsecond Traffic Bursts with Real-time and Distributed Traffic Engineering,"Gui, Fei; Wang, Songtao; Li, Dan; Chen, Li; Gao, Kaihui; Min, Congcong; Wang, Yi","Internet traffic bursts usually happen within a second, thus conventional burst mitigation methods ignore the potential of Traffic Engineering (TE). However, our experiments indicate that a TE system, with a sub-second control loop latency, can effectively alleviate burst-induced congestion. TE-based methods can leverage network-wide tunnel-level information to make globally informed decisions (e.g., balancing traffic bursts among multiple paths). Our insight in reducing control loop latency is to let each router make local TE decisions, but this introduces the key challenge of minimizing performance loss compared to centralized TE systems.In this paper, we present RedTE, a novel distributed TE system with a control loop latency of &lt; 100ms, while achieving performance comparable to centralized TE systems. RedTE's innovation is the modeling of TE as a distributed cooperative multi-agent problem, and we design a novel multi-agent deep reinforcement learning algorithm to solve it, which enables each agent to make globally informed decisions solely based on local information. We implement real RedTE routers and deploy them on a WAN spanning six city datacenters. Evaluation reveals notable improvements compared to existing solutions: &lt; 100ms of control loop latency, a 37.4% reduction in maximum link utilization, and a 78.9% reduction in average queue length.",2024,https://doi.org/10.1145/3651890.3672231,10.1145/3651890.3672231,15,top-tier,yes,computer networking and communications,1,"ACM SIGCOMM is one of the most prestigious conferences in the field of computer networking. It is known for featuring high-quality research papers and is highly selective, ensuring rigorous peer-review.",acm_venues.csv,Proceedings of the ACM SIGCOMM 2024 Conference,NA,ACM,NA
ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,Aircraft Trajectory Prediction Made Easy with Predictive Analytics,"Ayhan, Samet; Samet, Hanan","At the heart of Air Traffic Management (ATM) lies the Decision Support Systems (DST) that rely upon accurate trajectory prediction to determine how the airspace will look like in the future to make better decisions and advisories. Dealing with airspace that is prone to congestion due to environmental factors still remains the challenge especially when a deterministic approach is used in the trajectory prediction process. In this paper, we describe a novel stochastic trajectory prediction approach for ATM that can be used for more efficient and realistic flight planning and to assist airspace flow management, potentially resulting in higher safety, capacity, and efficiency commensurate with fuel savings thereby reducing emissions for a better environment. Our approach considers airspace as a 3D grid network, where each grid point is a location of a weather observation. We hypothetically build cubes around these grid points, so the entire airspace can be considered as a set of cubes. Each cube is defined by its centroid, the original grid point, and associated weather parameters that remain homogeneous within the cube during a period of time. Then, we align raw trajectories to a set of cube centroids which are basically fixed 3D positions independent of trajectory data. This creates a new form of trajectories which are 4D joint cubes, where each cube is a segment that is associated with not only spatio-temporal attributes but also with weather parameters. Next, we exploit machine learning techniques to train inference models from historical data and apply a stochastic model, a Hidden Markov Model (HMM), to predict trajectories taking environmental uncertainties into account. During the process, we apply time series clustering to generate input observations from an excessive set of weather parameters to feed into the Viterbi algorithm. Our experiments use a real trajectory dataset with pertaining weather observations and demonstrate the effectiveness of our approach to the trajectory prediction process for ATM.",2016,https://doi.org/10.1145/2939672.2939694,10.1145/2939672.2939694,10,top-tier,yes,"data mining, machine learning, artificial intelligence",1,KDD is a premier conference in the field of data mining and knowledge discovery. It features rigorous peer review and is highly respected in the data science community for its contributions to the area.,acm_venues.csv,Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,NA,ACM,NA
ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,Boosted Decision Tree Regression Adjustment for Variance Reduction in Online Controlled Experiments,"Poyarkov, Alexey; Drutsa, Alexey; Khalyavin, Andrey; Gusev, Gleb; Serdyukov, Pavel","Nowadays, the development of most leading web services is controlled by online experiments that qualify and quantify the steady stream of their updates achieving more than a thousand concurrent experiments per day. Despite the increasing need for running more experiments, these services are limited in their user traffic. This situation leads to the problem of finding a new or improving existing key performance metric with a higher sensitivity and lower variance. We focus on the problem of variance reduction for engagement metrics of user loyalty that are widely used in A/B testing of web services. We develop a general framework that is based on evaluation of the mean difference between the actual and the approximated values of the key performance metric (instead of the mean of this metric). On the one hand, it allows us to incorporate the state-of-the-art techniques widely used in randomized experiments of clinical and social research, but limitedly used in online evaluation. On the other hand, we propose a new class of methods based on advanced machine learning algorithms, including ensembles of decision trees, that, to the best of our knowledge, have not been applied earlier to the problem of variance reduction. We validate the variance reduction approaches on a very large set of real large-scale A/B experiments run at Yandex for different engagement metrics of user loyalty. Our best approach demonstrates 63% average variance reduction (which is equivalent to 63% saved user traffic) and detects the treatment effect in 2 times more A/B experiments.",2016,https://doi.org/10.1145/2939672.2939688,10.1145/2939672.2939688,10,top-tier,yes,"data mining, machine learning, artificial intelligence",1,KDD is a premier conference in the field of data mining and knowledge discovery. It features rigorous peer review and is highly respected in the data science community for its contributions to the area.,acm_venues.csv,Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,NA,ACM,NA
ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,Firebird: Predicting Fire Risk and Prioritizing Fire Inspections in Atlanta,"Madaio, Michael; Chen, Shang-Tse; Haimson, Oliver L.; Zhang, Wenwen; Cheng, Xiang; Hinds-Aldrich, Matthew; Chau, Duen Horng; Dilkina, Bistra","The Atlanta Fire Rescue Department (AFRD), like many municipal fire departments, actively works to reduce fire risk by inspecting commercial properties for potential hazards and fire code violations. However, AFRD's fire inspection practices relied on tradition and intuition, with no existing data-driven process for prioritizing fire inspections or identifying new properties requiring inspection. In collaboration with AFRD, we developed the Firebird framework to help municipal fire departments identify and prioritize commercial property fire inspections, using machine learning, geocoding, and information visualization. Firebird computes fire risk scores for over 5,000 buildings in the city, with true positive rates of up to 71% in predicting fires. It has identified 6,096 new potential commercial properties to inspect, based on AFRD's criteria for inspection. Furthermore, through an interactive map, Firebird integrates and visualizes fire incidents, property information and risk scores to help AFRD make informed decisions about fire inspections. Firebird has already begun to make positive impact at both local and national levels. It is improving AFRD's inspection processes and Atlanta residents' safety, and was highlighted by National Fire Protection Association (NFPA) as a best practice for using data to inform fire inspections.",2016,https://doi.org/10.1145/2939672.2939682,10.1145/2939672.2939682,10,top-tier,yes,"data mining, machine learning, artificial intelligence",1,KDD is a premier conference in the field of data mining and knowledge discovery. It features rigorous peer review and is highly respected in the data science community for its contributions to the area.,acm_venues.csv,Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,NA,ACM,NA
ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,Interpretable Decision Sets: A Joint Framework for Description and Prediction,"Lakkaraju, Himabindu; Bach, Stephen H.; Leskovec, Jure","One of the most important obstacles to deploying predictive models is the fact that humans do not understand and trust them. Knowing which variables are important in a model's prediction and how they are combined can be very powerful in helping people understand and trust automatic decision making systems.Here we propose interpretable decision sets, a framework for building predictive models that are highly accurate, yet also highly interpretable. Decision sets are sets of independent if-then rules. Because each rule can be applied independently, decision sets are simple, concise, and easily interpretable. We formalize decision set learning through an objective function that simultaneously optimizes accuracy and interpretability of the rules. In particular, our approach learns short, accurate, and non-overlapping rules that cover the whole feature space and pay attention to small but important classes. Moreover, we prove that our objective is a non-monotone submodular function, which we efficiently optimize to find a near-optimal set of rules.Experiments show that interpretable decision sets are as accurate at classification as state-of-the-art machine learning techniques. They are also three times smaller on average than rule-based models learned by other methods. Finally, results of a user study show that people are able to answer multiple-choice questions about the decision boundaries of interpretable decision sets and write descriptions of classes based on them faster and more accurately than with other rule-based models that were designed for interpretability. Overall, our framework provides a new approach to interpretable machine learning that balances accuracy, interpretability, and computational efficiency.",2016,https://doi.org/10.1145/2939672.2939874,10.1145/2939672.2939874,10,top-tier,yes,"data mining, machine learning, artificial intelligence",1,KDD is a premier conference in the field of data mining and knowledge discovery. It features rigorous peer review and is highly respected in the data science community for its contributions to the area.,acm_venues.csv,Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,NA,ACM,NA
ACM SIGMETRICS Performance Evaluation Review,"A NetAI Manifesto (Part I): Less Explorimentation, More Science","Willinger, Walter; Gupta, Arpit; Jacobs, Arthur S.; Beltiukov, Roman; Ferreira, Ronaldo A.; Granville, Lisandro","The application of the latest techniques from artificial intelligence (AI) and machine learning (ML) to improve and automate the decision-making required for solving realworld network security and performance problems (NetAI, for short) has generated great excitement among networking researchers. However, network operators have remained very reluctant when it comes to deploying NetAI-based solutions in their production networks, mainly because the black-box nature of the underlying learning models forces operators to blindly trust these models without having any understanding of how they work, why they work, or when they don't work (and why not). Paraphrasing [1], we argue that to overcome this roadblock and ensure its future success in practice, NetAI ""has to get past its current stage of explorimentation, or the practice of poking around to see what happens, and has to start employing tools of the scientific method.""",2023,https://doi.org/10.1145/3626570.3626609,10.1145/3626570.3626609,3,top-tier,yes,"computer science, performance evaluation, measurement",0.9,"SIGMETRICS is a leading conference focusing on the performance evaluation of computing systems and networks. It is highly respected in the fields of computer systems and performance measurement. Note that the main conference is peer-reviewed, while the newsletter/formal review part may have distinct practices.",acm_venues.csv,SIGMETRICS Perform. Eval. Rev.,NA,ACM,NA
ACM SIGMETRICS Performance Evaluation Review,"A NetAI Manifesto (Part II): Less Hubris, more Humility","Willinger, Walter; Gupta, Arpit; Beltiukov, Roman; Guo, Wenbo","The application of the latest techniques from artificial intelligence (AI) and machine learning (ML) to improve and automate the decision-making required for solving real-world network security and performance problems (NetAI, for short) has generated great excitement among networking researchers. However, network operators have remained very reluctant when it comes to deploying NetAIbased solutions in their production networks. In Part I of this manifesto, we argue that to gain the operators' trust, researchers will have to pursue a more scientific approach towards NetAI than in the past that endeavors the development of explainable and generalizable learning models. In this paper, we go one step further and posit that this ""opening up of NetAI research"" will require that the largely self-assured hubris about NetAI gives way to a healthy dose humility. Rather than continuing to extol the virtues and ""magic"" of black-box models that largely obfuscate the critical role of the utilized data play in training these models, concerted research efforts will be needed to design NetAI-driven agents or systems that can be expected to perform well when deployed in production settings and are also required to exhibit strong robustness properties when faced with ambiguous situations and real-world uncertainties. We describe one such effort that is aimed at developing a new ML pipeline for generating trained models that strive to meet these expectations and requirements.",2023,https://doi.org/10.1145/3626570.3626610,10.1145/3626570.3626610,3,top-tier,yes,"computer science, performance evaluation, measurement",0.9,"SIGMETRICS is a leading conference focusing on the performance evaluation of computing systems and networks. It is highly respected in the fields of computer systems and performance measurement. Note that the main conference is peer-reviewed, while the newsletter/formal review part may have distinct practices.",acm_venues.csv,SIGMETRICS Perform. Eval. Rev.,NA,ACM,NA
ACM SIGMETRICS Performance Evaluation Review,Fighting Under-price DoS Attack in Ethereum with Machine Learning Techniques,"Eduardo A. Sousa, Jose; Oliveira, Vinicius C.; Almeida Valadares, Julia; Borges Vieira, Alex; Bernardino, Heder S.; Moraes Villela, Saulo; Dias Goncalves, Glauber","Ethereum is one of the most popular cryptocurrency currently and it has been facing security threats and attacks. As a consequence, Ethereum users may experience long periods to validate transactions. Despite the maintenance on the Ethereum mechanisms, there are still indications that it remains susceptible to a sort of attacks. In this work, we analyze the Ethereum network behavior during an under-priced DoS attack, where malicious users try to perform denial-of-service attacks that exploit flaws in the fee mechanism of this cryptocurrency. We propose the application of machine learning techniques and ensemble methods to detect this attack, using the available transaction attributes. The proposals present notable performance as the Decision Tree models, with AUC-ROC, F-score and recall larger than 0.94, 0.82, and 0.98, respectively.",2021,https://doi.org/10.1145/3466826.3466835,10.1145/3466826.3466835,4,top-tier,yes,"computer science, performance evaluation, measurement",0.9,"SIGMETRICS is a leading conference focusing on the performance evaluation of computing systems and networks. It is highly respected in the fields of computer systems and performance measurement. Note that the main conference is peer-reviewed, while the newsletter/formal review part may have distinct practices.",acm_venues.csv,SIGMETRICS Perform. Eval. Rev.,NA,ACM,NA
European Radiology,Inter-operator variability and source of errors in tumour response assessment for hepatocellular carcinoma treated with sorafenib,"Tovoli, Francesco;Renzulli, Matteo;Negrini, Giulia;Brocchi, Stefano;Ferrarini, Alessia;Andreone, Andrea;Benevento, Francesca;Golfieri, Rita;Morselli-Labate, Antonio Maria;Mastroroberto, Marianna;Badea, Radu Ion;Piscaglia, Fabio","Objectives To assess the inter-operator concordance and the potential sources of discordance in defining response to sorafenib in hepatocellular carcinoma( HCC). Methods All patients who received sorafenib between September 2008 and February 2015 were scrutinised for this retrospective study. Images were evaluated separately by three radiologists with different expertise in liver imaging( operator 1, >10 years; operator 2, 5 years; operator 3, no specific training in liver imaging) , according to: response evaluation radiological criteria in solid tumours( RECIST) 1. 1, modified RECIST( mRECIST) and response evaluation criteria in cancer of the liver( RECICL). Results The overall response concordance between the more expert operators was good, irrespective of the criteria( RECIST 1. 1, ĸ = 0. 840; mRECIST, ĸ = 0. 871; RECICL, ĸ = 0. 819). Concordance between the less expert operator and the other colleagues was lower. The most evident discordance was in target lesion response assessment, with expert operators disagreeing mostly on lesion selection and less expert operators on lesion measurement. As a clinical correlate, overall survival was more tightly related with “progressive disease” as assessed by the expert compared to the same assessment performed by operator 3. Conclusions Decision on whether a patient is a responder or progressor under sorafenib may vary among different operators, especially in case of a non-specifically trained radiologist. Regardless of the adopted criteria, patients should be evaluated by experienced radiologists to minimise variability in this critical instance. Key Points • Inter-operator variability in the assessment of response to sorafenib is poorly known. • The concordance between operators with expertise in liver imaging was good. • Target lesions selection was the main source of discordance between expert operators. • Concordance with non-specifically trained operator was lower, independently from the response criteria. • The non-specifically trained operator was mainly discordant in measurements of target lesions.",2018,http://dx.doi.org/10.1007/s00330-018-5393-3,10.1007/s00330-018-5393-3,9,top-tier,yes,radiology and medical imaging,1,European Radiology is a highly respected journal in the field of radiology and medical imaging. It is peer-reviewed and is considered top-tier due to its stringent review process and impact in the medical imaging research community.,springnature_venues.csv,European Radiology,Article,Springer,NA
European Radiology,"Intra-arterial therapy of neuroendocrine tumour liver metastases: comparing conventional TACE, drug-eluting beads TACE and yttrium-90 radioembolisation as treatment options using a propensity score analysis model","Do Minh, Duc;Chapiro, Julius;Gorodetski, Boris;Huang, Qiang;Liu, Cuihong;Smolka, Susanne;Savic, Lynn Jeanette;Wainstejn, David;Lin, MingDe;Schlachter, Todd;Gebauer, Bernhard;Geschwind, Jean-François","Objectives To compare efficacy, survival outcome and prognostic factors of conventional transarterial chemoembolisation( cTACE) , drug-eluting beads TACE( DEB-TACE) and yttrium-90 radioembolisation( Y90) for the treatment of liver metastases from gastroenteropancreatic( GEP) neuroendocrine tumours( NELM). Methods This retrospective analysis included 192 patients( 58. 6 years mean age, 56% men) with NELM treated with cTACE( N = 122) , DEB-TACE( N = 26) or Y90( N = 44) between 2000 and 2014. Radiologic response to therapy was assessed according to Response Evaluation Criteria in Solid Tumours( RECIST) and World Health Organization( WHO) criteria using periprocedural MR imaging. Survival analysis included propensity score analysis( PSA) , median overall survival( MOS) , hepatic progression-free survival, Kaplan–Meier using log-rank test and the uniand multivariate Cox proportional hazards model( MVA). Results MOS of the entire study population was 28. 8 months. As for cTACE, DEB-TACE and Y90, MOS was 33. 8 months, 21. 7 months and 23. 6 months, respectively. According to the MVA, cTACE demonstrated a significantly longer MOS as compared to DEB-TACE( p <. 01) or Y90( p =. 02). The 5-year survival rate after initial cTACE, DEB-TACE and Y90 was 28. 2%, 10. 3% and 18. 5%, respectively. Conclusions Upon PSA, our study suggests significant survival benefits for patients treated with cTACE as compared to DEB-TACE and Y90. This data supports the therapeutic decision for cTACE as the primary intra-arterial therapy option in patients with unresectable NELM until proven otherwise. Key Points • cTACE achieved a significantly longer overall survival in patients with unresectable NELM. • Patients treated with cTACE showed a prolonged hepatic progression-free survival. • cTACE, DEB-TACE and Y90 radioembolisation demonstrated comparable safety and toxicity profiles. • Age >70 years, extrahepatic metastases and tumour burden >50% were identified as negative predictors. • Propensity score analysis suggests the superiority of cTACE over DEB-TACE and Y90.",2017,http://dx.doi.org/10.1007/s00330-017-4856-2,10.1007/s00330-017-4856-2,10,top-tier,yes,radiology and medical imaging,1,European Radiology is a highly respected journal in the field of radiology and medical imaging. It is peer-reviewed and is considered top-tier due to its stringent review process and impact in the medical imaging research community.,springnature_venues.csv,European Radiology,Article,Springer,NA
European Radiology,Intra-individual consistency of spectral detector CT-enabled iodine quantification of the vascular and renal blood pool,"Lennartz, Simon;Abdullayev, Nuran;Zopfs, David;Borggrefe, Jan;Neuhaus, Victor-Frederic;Persigehl, Thorsten;Haneder, Stefan;Große Hokamp, Nils","Objectives The objective of this study was to evaluate the intra-individual, longitudinal consistency of iodine measurements regarding the vascular and renal blood pool in patients that underwent repetitive spectral detector computed tomography( SDCT) examinations to evaluate their utility for oncologic imaging. Methods Seventy-nine patients with two( n = 53) or three( n = 26) clinically indicated biphasic SDCT scans of the abdomen were retrospectively included. ROI-based measurements of Hounsfield unit( HU) attenuation in conventional images and iodine concentration were performed by an experienced radiologist in the following regions( two ROIs each) : abdominal aorta, vena cava inferior, portal vein, and renal cortices. Modified variation coefficients( MVCs) were computed to assess intra-individual longitudinal between the different time points. Results Variation of HU attenuation and iodine concentration measurements was significantly lower in the venous than in the arterial phase images( attenuation/iodine concentration: arterial − 4. 2/− 3. 9, venous 0. 4/1. 0; p ≤ 0. 05). Regarding attenuation in conventional images of the arterial phase, the median MVC was − 1. 8( − 20. 5–21. 3) % within the aorta and − 6. 5( − 44. 0–25. 0) % within the renal cortex while in the portal venous phase, it was 0. 62( − 11. 1–11. 7) % and − 1. 6( − 16. 2–10. 6) %, respectively. Regarding iodine concentration, MVC for arterial phase was − 2. 5( − 22. 9–28. 4) % within the aorta and − 5. 8( − 55. 9–29. 6) % within the renal cortex. The referring MVCs of the portal venous phase were − 0. 7( − 17. 9–16. 9) % and − 2. 6( − 17. 6–12. 5) %. Conclusions Intra-individual iodine quantification of the vascular and cortical renal blood pool at different time points works most accurately in venous phase images whereas measurements conducted in arterial phase images underlay greater variability. Key Points • There is an intra-individual, physiological variation in iodine map measurements from dual-energy computed tomography. • This variation is smaller in venous phase examinations compared with arterial phase and therefore venous phase images should be preferred to minimize this intra-individual variation. • Care has to be taken, when considering iodine measurements for clinical decision-making, particularly in the context of oncologic initial or follow-up imaging.",2019,http://dx.doi.org/10.1007/s00330-019-06266-w,10.1007/s00330-019-06266-w,9,top-tier,yes,radiology and medical imaging,1,European Radiology is a highly respected journal in the field of radiology and medical imaging. It is peer-reviewed and is considered top-tier due to its stringent review process and impact in the medical imaging research community.,springnature_venues.csv,European Radiology,Article,Springer,NA
European Radiology,Intratumoral and peritumoral MRI radiomics nomogram for predicting parametrial invasion in patients with early-stage cervical adenocarcinoma and adenosquamous carcinoma,"Xiao, Mei Ling;Fu, Le;Wei, Yan;Liu, Ai E;Cheng, Jie Jun;Ma, Feng Hua;Li, Hai Ming;Li, Yong Ai;Lin, Zi Jing;Zhang, Guo Fu;Qiang, Jin Wei","Objective To develop a comprehensive nomogram based on MRI intraand peritumoral radiomics signatures and independent risk factors for predicting parametrial invasion( PMI) in patients with early-stage cervical adenocarcinoma( AC) and adenosquamous carcinoma( ASC). Methods A total of 460 patients with IB to IIB cervical AC and ASC who underwent preoperative MRI examination and radical trachelectomy/hysterectomy were retrospectively enrolled and divided into primary, internal validation, and external validation cohorts. The original( Ori) and wavelet( Wav) -transform features were extracted from the volumetric region of interest of the tumour( ROI-T) and 3mmand 5mm-peritumoral rings( ROI-3 and ROI-5) , respectively. Then the Ori and Ori-Wav feature-based radiomics signatures from the tumour( RST) and 3 mmand 5 mm-peritumoral regions( RS3 and RS5) were independently built and their diagnostic performances were compared to select the optimal ones. Finally, the nomogram was developed by integrating optimal intraand peritumoral signatures and clinical independent risk factors based on multivariable logistic regression analysis. Results FIGO stage, disruption of the cervical stromal ring on MRI( DCSRMR) , parametrial invasion on MRI( PMIMR) , and serum CA-125 were identified as independent risk factors. The nomogram constructed by integrating independent risk factors, Ori-Wav feature-based RST, and RS5 yielded AUCs of 0. 874( 0. 810–0. 922) , 0. 885( 0. 834–0. 924) , and 0. 966( 0. 887–0. 995) for predicting PMI in the primary, internal and external validation cohorts, respectively. Furthermore, the nomogram was superior to radiomics signatures and clinical model for predicting PMI in three cohorts. Conclusion The nomogram can preoperatively, accurately, and noninvasively predict PMI in patients with early-stage cervical AC and ASC. Clinical relevance statement The nomogram can preoperatively, accurately, and noninvasively predict PMI and facilitate precise treatment decisions regarding chemoradiotherapy or radical hysterectomy in patients with early-stage cervical AC and ASC. Key Points The accurate preoperative prediction of PMI in early-stage cervical AC and ASC can facilitate precise treatment decisions regarding chemoradiotherapy or radical hysterectomy. The nomogram integrating independent risk factors, Ori-Wav feature-based RST, and RS5 can preoperatively, accurately, and noninvasively predict PMI in early-stage cervical AC and ASC. The nomogram was superior to radiomics signatures and clinical model for predicting PMI in early-stage cervical AC and ASC.",2024,http://dx.doi.org/10.1007/s00330-023-10042-2,10.1007/s00330-023-10042-2,10,top-tier,yes,radiology and medical imaging,1,European Radiology is a highly respected journal in the field of radiology and medical imaging. It is peer-reviewed and is considered top-tier due to its stringent review process and impact in the medical imaging research community.,springnature_venues.csv,European Radiology,Article,Springer,NA
European Radiology,Intratumoral and peritumoral radiomics for preoperative prediction of neoadjuvant chemotherapy effect in breast cancer based on contrast-enhanced spectral mammography,"Mao, Ning;Shi, Yinghong;Lian, Chun;Wang, Zhongyi;Zhang, Kun;Xie, Haizhu;Zhang, Haicheng;Chen, Qianqian;Cheng, Guanxun;Xu, Cong;Dai, Yi","Objective To investigative the performance of intratumoral and peritumoral radiomics based on contrast-enhanced spectral mammography( CESM) to preoperatively predict the effect of the neoadjuvant chemotherapy( NAC) of breast cancers. Materials and methods A total of 118 patients with breast cancer who underwent preoperative CESM and NAC from July 2017 to June 2020 were retrospectively analyzed, and the patients were grouped into training( n = 81) and test sets( n = 37) according to the CESM examination time. NAC effect for each patient was assessed by pathology. Intratumoral and peritumoral radiomics features were extracted from CESM images, and feature selection was performed through the Mann–Whitney U test and least absolute shrinkage and selection operator regression( LASSO). Five radiomics signatures based on intratumoral regions, 5-mm peritumoral regions, 10-mm peritumoral regions, intratumoral regions + 5-mm peritumoral regions, and intratumoral regions + 10-mm peritumoral regions were calculated through a linear combination of selected features weighted by their respective coefficients. The prediction performance of radiomics signatures was assessed by the area under the receiver operator characteristic( ROC) curve, the precision-recall( P-R) curve, the calibration curve, and decision curve analysis( DCA). Results Ten radiomics features were selected to establish the radiomics signature of intratumoral regions + 5-mm peritumoral regions, which yielded a maximum AUC of 0. 85( 95% CI, 0. 72–0. 98) in the test set. The calibration curves, P-R curves, and DCA showed favorable predictive performance of the five radiomics signatures. Conclusion The intratumoral and peritumoral radiomics based on CESM exhibited potential for predicting the NAC effect in breast cancer, which could guide treatment decisions. Key Points • The intratumoral and peritumoral CESM-based radiomics signatures show good performance in predicting the NAC effect in breast cancer.",2022,http://dx.doi.org/10.1007/s00330-021-08414-7,10.1007/s00330-021-08414-7,12,top-tier,yes,radiology and medical imaging,1,European Radiology is a highly respected journal in the field of radiology and medical imaging. It is peer-reviewed and is considered top-tier due to its stringent review process and impact in the medical imaging research community.,springnature_venues.csv,European Radiology,Article,Springer,NA
European Radiology,Is the future of breast imaging with AI?,"Fuchsjäger, Michael",NA,2019,http://dx.doi.org/10.1007/s00330-019-06286-6,10.1007/s00330-019-06286-6,2,top-tier,yes,radiology and medical imaging,1,European Radiology is a highly respected journal in the field of radiology and medical imaging. It is peer-reviewed and is considered top-tier due to its stringent review process and impact in the medical imaging research community.,springnature_venues.csv,European Radiology,Article,Springer,NA
European Radiology,Letter to the Editor: “Percutaneous ultrasound-guided needle tenotomy for treatment of chronic tendinopathy and fasciopathy: a meta-analysis”,"Rhim, Hye Chang;Ha, Jane",NA,2024,http://dx.doi.org/10.1007/s00330-024-10876-4,10.1007/s00330-024-10876-4,1,top-tier,yes,radiology and medical imaging,1,European Radiology is a highly respected journal in the field of radiology and medical imaging. It is peer-reviewed and is considered top-tier due to its stringent review process and impact in the medical imaging research community.,springnature_venues.csv,European Radiology,Article,Springer,NA
European Radiology,Leveraging deep learning for more accurate prediction of lung microwave ablation zones,"Graur, Alexander;Alici, Cagatay;Fintelmann, Florian J.",NA,2024,http://dx.doi.org/10.1007/s00330-024-10995-y,10.1007/s00330-024-10995-y,1,top-tier,yes,radiology and medical imaging,1,European Radiology is a highly respected journal in the field of radiology and medical imaging. It is peer-reviewed and is considered top-tier due to its stringent review process and impact in the medical imaging research community.,springnature_venues.csv,European Radiology,Article,Springer,NA
European Radiology,Limited clinical value of two consecutive post-transplant renal scintigraphy procedures,"Benjamens, Stan;Pol, Robert A.;Berger, Stefan P.;Glaudemans, Andor W. J. M.;Dibbets-Schneider, Petra;Slart, Riemer H. J. A.;Geus-Oei, Lioe-Fee","Objectives Duration of delayed graft function( DGF) and length of hospital stay( LOS) are outcomes of interest in an era that warrants increased efficacy of transplant care whereas renal allografts originate increasingly from marginal donors. While earlier studies investigate the predictive capability of a single renal scintigraphy, this study focuses on the value for both DGF duration and LOS of consecutively performed scintigraphies. Methods From 2011 to 2014, renal transplant recipients referred for a Tc-99m MAG3 renal scintigraphy were included in a single-center retrospective study. Primary endpoints were DGF duration and LOS. Both the first( ≤ 3 days) and second scintigraphies( 3–7 days after transplantation) were analyzed using a 4-grade qualitative scale and quantitative indices( TFS, cTER, MUC10, average upslope). Results We evaluated 200 first and 108( 54%) consecutively performed scintigraphies. The Kaplan-Meier curves for DGF duration and qualitative grading of the first and second scintigraphy showed significant differences between the grades( p < 0. 01). The Kaplan-Meier curve for the delta grades between these procedures( lower, equal, or higher grade) did not show significant differences( p = 0. 18). Multivariate analysis showed a significant association between the qualitative grades, from the first and second scintigraphy, and DGF duration, HR 1. 8( 1. 4–2. 2, p < 0. 01) and 2. 8( 1. 8–4. 3, p < 0. 01) , respectively. Conclusions Qualitative grades of single renal scintigraphies, performed within 7 days after transplantation, can be used to make a reliable image-guided decision on the need for dialysis and to predict LOS. A consecutive renal scintigraphy, however, did not show an additional value in the assessment of DGF. Key Points • Post-transplant renal scintigraphy procedures provide information to predict delayed graft function duration and length of hospital stay. • Performing two consecutive renal scintigraphy procedures within 1 week after transplantation does not strengthen the prediction of delayed graft function duration and length of hospital stay. • Single renal scintigraphy procedures can be used to provide clinicians and patients with a reliable indication of the need for dialysis after transplantation and the expected duration of hospitalization.",2020,http://dx.doi.org/10.1007/s00330-019-06334-1,10.1007/s00330-019-06334-1,8,top-tier,yes,radiology and medical imaging,1,European Radiology is a highly respected journal in the field of radiology and medical imaging. It is peer-reviewed and is considered top-tier due to its stringent review process and impact in the medical imaging research community.,springnature_venues.csv,European Radiology,Article,Springer,NA
European Symposium on Research in Computer Security,Privacy-Preserving Decision Trees Evaluation via Linear Functions,"Tai, Raymond K. H.;Ma, Jack P. K.;Zhao, Yongjun;Chow, Sherman S. M.","The combination of cloud-based computing paradigm and machine learning algorithms has enabled many complex analytic services, such as face recognition in a crowd or valuation of immovable properties. Companies can charge clients who do not have the expertise or resource to build such complex models for the prediction or classification service. In this work, we focus on machine learning classification with decision tree( or random forests) as the analytic model, which is popular for its effectiveness and simplicity. We propose privacy-preserving decision tree evaluation protocols which hide the sensitive inputs( model and query) from the counterparty. Comparing with the state-of-the-art, we made a significant improvement in efficiency by cleverly exploiting the structure of decision trees, which avoids an exponential number of encryptions in the depth of the decision tree. Our experiment results show that our protocols are especially efficient for deep but sparse decision trees, which are typical for classification models trained from real datasets, ranging from cancer diagnosis to spam classification.",2017,http://dx.doi.org/10.1007/978-3-319-66399-9_27,10.1007/978-3-319-66399-9_27,NA,top-tier,yes,"computer security, cryptography",1,"The European Symposium on Research in Computer Security (ESORICS) is a leading conference in the field of information and computer security, known for publishing high-quality peer-reviewed research.",springnature_venues.csv,Computer Security – ESORICS 2017,Chapter ConferencePaper,Springer,NA
European Symposium on Research in Computer Security,Private Decision Tree Evaluation with Malicious Security via Function Secret Sharing,"Fu, Jiaxuan;Cheng, Ke;Xia, Yuheng;Song, Anxiao;Li, Qianxing;Shen, Yulong","Private Decision Tree Evaluation( PDTE) allows the client to use a decision tree classification model on the server to classify their private data, without revealing the data or the classification results to the server. Recent advancements in PDTE have greatly enhanced its effectiveness in scenarios involving semi-honest security, offering a viable and secure alternative to traditional, less secure approaches for decision tree evaluation. However, this model of semi-honest security may not always align well with real-world problems. In this work, we present FSSTree, a malicious-secure three-party PDTE protocol using function secret sharing( FSS). FSSTree achieves its high performance against malicious adversaries via several innovative cryptographic designs. Especially, 1) we transform a comparison operation into a prefix parity query problem, allowing us to implement malicious-secure comparisons rapidly using lightweight and verifiable FSS. 2) Building upon this, we further propose a constant-round protocol for securely evaluating Conditional Oblivious Selection( COS). 3) We utilize these optimized protocols to enhance the PDTE processes, achieving a considerable decrease in both communication costs and the number of rounds. The experimental results show that FSSTree reduces the runtime in a WAN environment by up to $$22. 3\\times $$ 22. 3 × times and saves up to $$4. 1 \\times $$ 4. 1 × the communication cost compared to the state-of-the-art work.",2024,http://dx.doi.org/10.1007/978-3-031-70890-9_16,10.1007/978-3-031-70890-9_16,NA,top-tier,yes,computer security,0.95,"ESORICS is a prominent conference in the field of computer security, commonly recognized as top-tier due to its rigorous peer-review process and high impact on the academic community.",springnature_venues.csv,Computer Security – ESORICS 2024,Chapter ConferencePaper,Springer,NA
European Symposium on Research in Computer Security,ProxyKiller: An Anonymous Proxy Traffic Attack Model Based on Traffic Behavior Graphs,"Xu, Hongbo;Cheng, Zhenyu;Li, Shuhao;Wang, Chenxu;Sun, Peishuai;Xie, Jiang;Liu, Qingyun","As common tools for evading censorship and protecting privacy, anonymous proxies are widely favored for their lightweight and easy deployment. In recent years, anonymous proxies have continually evolved regarding traffic obfuscation and masking strategies. Due to the lack of design targeting the connection behavior features of different proxy flows, current methods for proxy traffic identification often suffer from high false positive rates. Consequently, these methods are insufficient for real-world applications. This masks the deficiencies of existing anonymous proxy technologies in combating detection models based on flow relationship analysis. To address the issues mentioned, we introduce a novel proxy traffic attack model called ProxyKiller based on multi-flow connection behavior features. After obtaining the original PCAP traffic files, ProxyKiller constructs traffic behavior graphs using extracted temporal, spatial, content, and specially designed byte features. Subsequently, ProxyKiller extracts latent topological structure features through graph neural networks, integrates them into a unified graph-level representation vector, and obtains prediction results for each traffic behavior graph through a random forest model. Finally, ProxyKiller implements a global decision-making mechanism from a traffic graph correlation perspective to correct prediction results for related traffic behavior graphs. Experimental results on three real-world datasets demonstrate that ProxyKiller outperforms several state-of-the-art traffic classification methods and shows robustness in various proxy traffic classification tasks. These results indicate that current anonymous proxies exhibit certain vulnerabilities when countering traffic analysis methods based on traffic behavior graph structure.",2024,http://dx.doi.org/10.1007/978-3-031-70890-9_9,10.1007/978-3-031-70890-9_9,NA,top-tier,yes,computer security,0.95,"ESORICS is a prominent conference in the field of computer security, commonly recognized as top-tier due to its rigorous peer-review process and high impact on the academic community.",springnature_venues.csv,Computer Security – ESORICS 2024,Chapter ConferencePaper,Springer,NA
European Symposium on Research in Computer Security,Puncturable Proxy Re-Encryption Supporting to Group Messaging Service,"Phuong, Tran Viet Xuan;Susilo, Willy;Kim, Jongkil;Yang, Guomin;Liu, Dongxi","This work envisions a new encryption primitive for many-to-many paradigms such as group messaging systems. Previously, puncturable encryption( PE) was introduced to provide forward security for asynchronous messaging services. However, existing PE schemes were proposed only for one-to-one communication, and causes a significant overhead for a group messaging system. In fact, the group communication over PE can only be achieved by encrypting a message multiple times for each receiver by the sender’s device, which is usually suitable to restricted resources such as mobile phones or sensor devices. Our new suggested scheme enables to re-encrypt ciphertexts of puncturable encryption by a message server( i. e. , a proxy) so that computationally heavy operations are delegated to the server who has more powerful processors and a constant power source. We then proposed a new Puncturable Proxy Re-Encryption( PPRE) scheme. The scheme is inspired by unidirectional proxy re-encryption( UPRE) , which achieves forward secrecy through fine-grained revocation of decryption capability by integrating the PE scheme. This paper first presents a forward secure PPRE in the group messaging service. Our scheme is IND-CCA secure under 3-weak Decision Bilinear Diffie-Hellman Inversion assumption.",2019,http://dx.doi.org/10.1007/978-3-030-29959-0_11,10.1007/978-3-030-29959-0_11,NA,top-tier,yes,computer security,0.9,"ESORICS (European Symposium on Research in Computer Security) is a well-regarded conference in the field of computer security, considered a top-tier venue. It is peer-reviewed and respected for high-quality research contributions in computer security.",springnature_venues.csv,Computer Security – ESORICS 2019,Chapter ConferencePaper,Springer,NA
Experimental Economics,( Not) alone in the world: Cheating in the presence of a virtual observer,"Mol, Jantsje M.;Heijden, Eline C. M.;Potters, Jan J. M.","We conducted an experiment in a high-immersive virtual reality environment to study the effect of the presence of a virtual observer on cheating behavior. Participants were placed in a virtual room and played 30 rounds of a cheating game without a chance of their cheating being detected. We varied whether or not a virtual observer( an avatar) was present in the room, and, if so, whether the avatar was actively staring at the decision maker or passively seated in a corner watching his smartphone. Results display significantly less cheating with an active than with a passive avatar, but not less cheating than in a control condition without an avatar. This suggests that an active( virtual) observer can intensify reputational concerns, but that the presence of someone passive and uninterested may actually alleviate such concerns.",2020,http://dx.doi.org/10.1007/s10683-020-09644-0,10.1007/s10683-020-09644-0,17,top-tier,yes,economics,0.9,"""Experimental Economics"" is a leading journal in the field of economics that focuses on the use of experimental methods. It is a peer-reviewed publication, indicating high academic standards, and is widely regarded as a top-tier venue in its field.",springnature_venues.csv,Experimental Economics,Article,Springer,NA
Experimental Economics,Ambiguity and enforcement,"Calford, Evan M.;DeAngelo, Gregory","Law enforcement officials face numerous decisions regarding their enforcement choices. One important decision, that is often controversial, is the amount of knowledge that law enforcement distributes to the community regarding their policing strategies. Assuming the goal is to minimize criminal activity( alternatively, maximize citation rates) , our theoretical analysis suggests that agencies should reveal( shroud) their resource allocation if criminals are uncertainty seeking, and shroud( reveal) their allocation if criminals are uncertainty averse. We run a laboratory experiment to test our theoretical framework, and find that enforcement behavior is approximately optimal given the observed non-expected utility uncertainty preferences of criminals.",2023,http://dx.doi.org/10.1007/s10683-022-09755-w,10.1007/s10683-022-09755-w,34,top-tier,yes,economics,0.9,"""Experimental Economics"" is a leading journal in the field of economics that focuses on the use of experimental methods. It is a peer-reviewed publication, indicating high academic standards, and is widely regarded as a top-tier venue in its field.",springnature_venues.csv,Experimental Economics,Article,Springer,NA
Experimental Economics,"Asymmetric firms, technology sharing and R&D investment","Roelofs, Matthew R.;Østbye, Stein E.;Heen, Eirik E.","We use a combination of theory and experiment to study the incentives for firms to share knowledge when they engage in research and development( R&D) in an uncertain environment. We consider both symmetric and asymmetric starting points with regards to the amount of initial knowledge firms have before conducting R&D and look at how differences in starting positions affect the willingness of firms to share knowledge. We investigate when and if firms find R&D cooperation beneficial and how investment in R&D is affected by the outcome of the sharing decisions. The experimental evidence shows that overall subjects tend to behave consistently with theoretical predictions for the sharing of knowledge, although leaders who are not compensated by a side payment from laggards are more willing to share than predicted by the theory, and leaders who are compensated are less willing. The data on investment suggests less investment with sharing than without, consistent with theory. Compared to exact numerical predictions, there is overinvestment or underinvestment except for symmetric firms under no sharing. All cases of overinvestment and underinvestment, regardless of sharing or not and regardless of starting positions, are well explained by smoothed-out best( quantal) responses.",2017,http://dx.doi.org/10.1007/s10683-016-9500-5,10.1007/s10683-016-9500-5,26,top-tier,yes,economics,0.9,"""Experimental Economics"" is a leading journal in the field of economics that focuses on the use of experimental methods. It is a peer-reviewed publication, indicating high academic standards, and is widely regarded as a top-tier venue in its field.",springnature_venues.csv,Experimental Economics,Article,Springer,NA
Experimental Economics,Avoiding the cost of your conscience: belief dependent preferences and information acquisition,"Rimbaud, Claire;Soldà, Alice","Pro-social individuals typically face a trade-off between their monetary incentives and their other-regarding preferences. When this is the case, they may be tempted to exploit the uncertainty in their decision environment to reconcile this trade-off. In this paper, we investigate whether individuals with belief-dependent preferences acquire information about others’ expectations in a self-serving way. We present a model of endogenous information acquisition and test our theoretical predictions in an online experiment based on a modified trust-game in which the trustee is uncertain about the trustor’s expectations. Our experimental design enables us to( 1) identify participants with belief-based preferences and( 2) investigate their information acquisition strategy. Consistent with our predictions for subjective belief-dependent preferences, we find that most individuals classified as belief-dependent strategically select their source of information to avoid the cost of their conscience.",2024,http://dx.doi.org/10.1007/s10683-024-09827-z,10.1007/s10683-024-09827-z,56,top-tier,yes,economics,0.9,"""Experimental Economics"" is a leading journal in the field of economics that focuses on the use of experimental methods. It is a peer-reviewed publication, indicating high academic standards, and is widely regarded as a top-tier venue in its field.",springnature_venues.csv,Experimental Economics,Article,Springer,NA
Formal Methods,Understanding Synthesized Reactive Systems Through Invariants,"Ehlers, Rüdiger","In many applications for which reactive synthesis is attractive, computed implementations need to have understandable behavior. While some existing synthesis approaches compute finite-state machines with a structure that supports their understandability, such approaches do not scale to specifications that can only be realized with a large number of states. Furthermore, asking the engineer to understand the internal structure of the implementation is unnecessary when only the behavior of the implementation is to be understood. In this paper, we present an approach to computing understandable safety invariants that every implementation satisfying a generalized reactivity( 1) specification needs to fulfill. Together with the safety part of the specification, the invariants completely define which transitions between input and output proposition valuations any correct implementation can take. We apply the approach in two case studies and demonstrate that the computed invariants highlight the strategic decisions that implementations for the given specification need to make, which not only helps the system designer with understanding what the specification entails, but also supports specification debugging.",2025,http://dx.doi.org/10.1007/978-3-031-71162-6_9,10.1007/978-3-031-71162-6_9,NA,top-tier,yes,"computer science, software engineering",0.9,"""Formal Methods"" is a respected journal focusing on formal techniques in computer science, with a rigorous peer-review process and known for publishing high-quality research, making it a top-tier venue in its field.",springnature_venues.csv,Formal Methods,Chapter ConferencePaper,Springer,NA
Formal Methods,Verifying Auto-generated C Code from Simulink,"Berger, Philipp;Katoen, Joost-Pieter;Ábrahám, Erika;Waez, Md Tawhid Bin;Rambow, Thomas","This paper presents our experience with formal verification of C code that is automatically generated from Simulink open-loop controller models. We apply the state-of-the-art commercial model checker BTC EmbeddedPlatform to two Ford R&D prototype case studies: a next-gen Driveline State Request and a next-gen E-Clutch Control. These case studies contain various features( decision logic, floating-point arithmetic, rate limiters and state-flow systems) implemented in discrete-time logic. The diverse features and the extensive use of floating-point variables make the formal code verification highly challenging. The paper reports our findings, identifies shortcomings and strengths of formal verification when adopted in an automotive setting. We also provide recommendations to tool developers and requirement engineers so as to integrate formal code verification into the automotive mass product development.",2018,http://dx.doi.org/10.1007/978-3-319-95582-7_18,10.1007/978-3-319-95582-7_18,NA,top-tier,yes,"computer science, software engineering",0.9,"""Formal Methods"" is a respected journal focusing on formal techniques in computer science, with a rigorous peer-review process and known for publishing high-quality research, making it a top-tier venue in its field.",springnature_venues.csv,Formal Methods,Chapter ConferencePaper,Springer,NA
Formal Methods in Computer-Aided Design,Formal Methods for Trused AI,Bettina Könighofer,"The enormous influence of systems deploying AI is contrasted by the growing concerns about their safety and the relative lack of trust by the society. This talk will focus on a few aspects of trustworthy AI: safety, accountability, and explainability. First, we will discuss recent work on evaluating safety for systems deploying deep learning, and correct-by-construction runtime assurance methods to enforce safety during runtime (aka shielding). For accountability, we outline the potential of formal computing tools to analyse the decisions of autonomous agents and to assign responsibility. Finally, we approach explainability from the automata learning perspective. We will discuss recent automata learning approaches which are able to learn compact probabilistic models for high-dimensional environments and outline how learned environmental models can effectively be used to understand and to evaluate the decisions of the agent.",2023,https://ieeexplore.ieee.org/document/10329391,10.34727/2023/isbn.978-3-85448-060-0_3,1,top-tier,yes,"formal methods, computer-aided design",0.9,FM-CAD is a leading conference in the formal methods and computer-aided verification community. It features high-quality research papers and is recognized for its rigorous peer-review process.,ieee_venues.csv,Formal Methods in Computer-Aided Design,NA,IEEE,NA
Formal Methods in Computer-Aided Design,Formal Methods with a Touch of Magic,Par Alizadeh Alamdari;Guy Avni;Thomas A. Henzinger;Anna Lukina,"Machine learning and formal methods have complimentary benefits and drawbacks. In this work, we address the controller-design problem with a combination of techniques from both fields. The use of black-box neural networks in deep reinforcement learning (deep RL) poses a challenge for such a combination. Instead of reasoning formally about the output of deep RL, which we call the wizard, we extract from it a decision-tree based model, which we refer to as the magic book. Using the extracted model as an intermediary, we are able to handle problems that are infeasible for either deep RL or formal methods by themselves. First, we suggest, for the first time, a synthesis procedure that is based on a magic book. We synthesize a stand-alone correct-by-design controller that enjoys the favorable performance of RL. Second, we incorporate a magic book in a bounded model checking (BMC) procedure. BMC allows us to find numerous traces of the plant under the control of the wizard, which a user can use to increase the trustworthiness of the wizard and direct further training.",2020,https://ieeexplore.ieee.org/document/9283628,10.34727/2020/isbn.978-3-85448-042-6_21,10,top-tier,yes,"formal methods, computer-aided design",0.9,FM-CAD is a leading conference in the formal methods and computer-aided verification community. It features high-quality research papers and is recognized for its rigorous peer-review process.,ieee_venues.csv,Formal Methods in Computer-Aided Design,NA,IEEE,NA
Foundations of Computational Mathematics,Polytope Lyapunov Functions for Stable and for Stabilizable LSS,"Guglielmi, Nicola;Laglia, Linda;Protasov, Vladimir","We present a new approach for constructing polytope Lyapunov functions for continuous-time linear switching systems( LSS). This allows us to decide the stability of LSS and to compute the Lyapunov exponent with a good precision in relatively high dimensions. The same technique is also extended for stabilizability of positive systems by evaluating a polytope concave Lyapunov function( “antinorm”) in the cone. The method is based on a suitable discretization of the underlying continuous system and provides both a lower and an upper bound for the Lyapunov exponent. The absolute error in the Lyapunov exponent computation is estimated from above and proved to be linear in the dwell time. The practical efficiency of the new method is demonstrated in several examples and in the list of numerical experiments with randomly generated matrices of dimensions up to 10( for general linear systems) and up to 100( for positive systems). The development of the method is based on several theoretical results proved in the paper: the existence of monotone invariant norms and antinorms for positively irreducible systems, the equivalence of all contractive norms for stable systems and the linear convergence theorem.",2017,http://dx.doi.org/10.1007/s10208-015-9301-9,10.1007/s10208-015-9301-9,56,top-tier,yes,computational mathematics,1,"Foundations of Computational Mathematics is a highly-regarded journal that publishes significant advances in computational mathematics. It is well-known in its field and is peer-reviewed, ensuring high-quality research contributions.",springnature_venues.csv,Foundations of Computational Mathematics,Article,Springer,NA
Foundations of Software Science and Computation Structures,Comparator Automata in Quantitative Verification,"Bansal, Suguman;Chaudhuri, Swarat;Vardi, Moshe Y.","The notion of comparison between system runs is fundamental in formal verification. This concept is implicitly present in the verification of qualitative systems, and is more pronounced in the verification of quantitative systems. In this work, we identify a novel mode of comparison in quantitative systems: the online comparison of the aggregate values of two sequences of quantitative weights. This notion is embodied by comparator automata( comparators, in short) , a new class of automata that read two infinite sequences of weights synchronously and relate their aggregate values. We show that comparators that are finite-state and accept by the Büchi condition lead to generic algorithms for a number of well-studied problems, including the quantitative inclusion and winning strategies in quantitative graph games with incomplete information, as well as related non-decision problems, such as obtaining a finite representation of all counterexamples in the quantitative inclusion problem. We study comparators for two aggregate functions: discounted-sum and limit-average. We prove that the discounted-sum comparator is $$\\omega $$ ω -regular for all integral discount factors. Not every aggregate function, however, has an $$\\omega $$ ω -regular comparator. Specifically, we show that the language of sequence-pairs for which limit-average aggregates exist is neither $$\\omega $$ ω -regular nor $$\\omega $$ ω -context-free. Given this result, we introduce the notion of prefix-average as a relaxation of limit-average aggregation, and show that it admits $$\\omega $$ ω -context-free comparators.",2018,http://dx.doi.org/10.1007/978-3-319-89366-2_23,10.1007/978-3-319-89366-2_23,NA,top-tier,yes,computer science,0.9,"FoSSaCS is a conference part of the European Joint Conferences on Theory and Practice of Software (ETAPS), which is well-regarded in theoretical computer science, particularly in software science and computation structures. The peer-review process is stringent, indicative of top-tier conferences.",springnature_venues.csv,Foundations of Software Science and Computation Structures,Chapter ConferencePaper,Springer,NA
Foundations of Software Science and Computation Structures,Contextual Approximation and Higher-Order Procedures,"Lazić, Ranko;Murawski, Andrzej S.","We investigate the complexity of deciding contextual approximation( refinement) in finitary Idealized Algol, a prototypical language combining higher-order types with state. Earlier work in the area established the borderline between decidable and undecidable cases, and focussed on the complexity of deciding approximation between terms in normal form. In contrast, in this paper we set out to quantify the impact of locally declared higher-order procedures on the complexity of establishing contextual approximation in the decidable cases. We show that the obvious decision procedure based on exhaustive $$\\beta $$ β -reduction can be beaten. Further, by classifying redexes by levels, we give tight bounds on the complexity of contextual approximation for terms that may contain redexes up to level k, namely, $$( k-1) $$( k - 1) -EXPSPACE-completeness. Interestingly, the bound is obtained by selective $$\\beta $$ β -reduction: redexes from level 3 onwards can be reduced without losing optimality, whereas redexes up to order 2 are handled by a dedicated decision procedure based on game semantics and a variant of pushdown automata.",2016,http://dx.doi.org/10.1007/978-3-662-49630-5_10,10.1007/978-3-662-49630-5_10,NA,top-tier,yes,computer science,0.9,"FoSSaCS is a conference part of the European Joint Conferences on Theory and Practice of Software (ETAPS), which is well-regarded in theoretical computer science, particularly in software science and computation structures. The peer-review process is stringent, indicative of top-tier conferences.",springnature_venues.csv,Foundations of Software Science and Computation Structures,Chapter ConferencePaper,Springer,NA
Future Generation Computer Systems,Deep learning for understanding multilabel imbalanced chest x-ray datasets,Helena Liz;Javier Huertas-Tato;Manuel Sánchez-Montañés;Javier {Del Ser};David Camacho,"Over the last few years, convolutional neural networks (CNNs) have dominated the field of computer vision thanks to their ability to extract features and their outstanding performance in classification problems, for example in the automatic analysis of X-rays. Unfortunately, these neural networks are considered black-box algorithms, i.e. it is impossible to understand how the algorithm has achieved the final result. To apply these algorithms in different fields and test how the methodology works, we need to use eXplainable AI techniques. Most of the work in the medical field focuses on binary or multiclass classification problems. However, in many real-life situations, such as chest X-rays, radiological signs of different diseases can appear at the same time. This gives rise to what is known as ”multilabel classification problems”. A disadvantage of these tasks is class imbalance, i.e. different labels do not have the same number of samples. The main contribution of this paper is a Deep Learning methodology for imbalanced, multilabel chest X-ray datasets. It establishes a baseline for the currently underutilised PadChest dataset and a new eXplainable AI technique based on heatmaps. This technique also includes probabilities and inter-model matching. The results of our system are promising, especially considering the number of labels used. Furthermore, the heatmaps match the expected areas, i.e. they mark the areas that an expert would use to make a decision.",2023,https://www.sciencedirect.com/science/article/pii/S0167739X23000821,https://doi.org/10.1016/j.future.2023.03.005,16,top-tier,yes,"computer science, information technology",0.95,"Future Generation Computer Systems is a prominent journal published by Elsevier, focusing on distributed and parallel computing, big data, and cloud computing. Its high impact factor and rigorous peer-review process signify its status as a top-tier journal in the computer science community.",elsevier_venues.csv,Future Generation Computer Systems,NA,Elsevier,NA
Future Generation Computer Systems,Deep reinforcement learning based scheduling strategy for federated learning in sensor-cloud systems,Tinghao Zhang;Kwok-Yan Lam;Jun Zhao,"Sensor-cloud systems (SCSs) aim to provide flexible configurable platforms for monitoring and controlling the IoT-enabled applications. By integrating sensors, wireless networks and cloud for managing sensors, collecting data, and automating decision-making, the collected sensing data are typically used for machine learning purposes. With increasing emphasis in privacy protection, Federated Learning (FL) is widely adopted for enhancing privacy preservation. FL enables sharing of data for machine learning while preserving the privacy of the data owners. In SCSs, FL involves a large number of edge nodes in order to ensure a sufficient amount of data for model training. However, FL inevitably incurs prohibitive overheads if it simply gathers data from all the nodes, hence making it desirable to adopt some scheduling strategy so that data are collected only from a selected subset of nodes. This paper proposes a scheduling strategy based on deep reinforcement learning (DRL) for improving the performance and efficiency of FL in SCSs. The DRL environment, such as state space, action space, and reward function, is carefully designed. Proximal policy optimization is employed to train the DRL agent. Experimental results demonstrated that the proposed method outperforms other baselines on both independent and identically distributed (IID) and non-IID datasets.",2023,https://www.sciencedirect.com/science/article/pii/S0167739X23000870,https://doi.org/10.1016/j.future.2023.03.009,11,top-tier,yes,"computer science, information technology",0.95,"Future Generation Computer Systems is a prominent journal published by Elsevier, focusing on distributed and parallel computing, big data, and cloud computing. Its high impact factor and rigorous peer-review process signify its status as a top-tier journal in the computer science community.",elsevier_venues.csv,Future Generation Computer Systems,NA,Elsevier,NA
Future Generation Computer Systems,"Deep reinforcement learning for traffic signal control under disturbances: a case study on sunway city, malaysia",Faizan Rasheed;Kok-Lim Alvin Yau;Yeh-Ching Low,"In most urban areas, traffic congestion is a vexing, complex and growing issue day by day. Reinforcement learning (RL) enables a single decision maker (or an agent) to learn and make optimal actions in an independent manner, while multi-agent reinforcement learning (MARL) enables multiple agents to exchange knowledge, learn, and make optimal joint actions in a collaborative manner. The integration of the newly emerging deep learning and the traditional RL approach has created an advanced technique called deep Q-network (DQN) that has shown promising results in solving high-dimensional and complex problems, including traffic congestion. In this paper, DQN is embedded in traffic signal control to solve traffic congestion issue, which has been plagued with the curse of dimensionality whereby the representation of the operating environment can be highly dimensional and complex when the traditional RL approach is used. Most importantly, this paper proposes multi-agent DQN (MADQN) and investigates its use to further address the curse of dimensionality under traffic network scenarios with high traffic volume and disturbances. To investigate the effectiveness of our proposed scheme, a case study based on an urban area, namely Sunway city in Malaysia, is conducted. We evaluate our scheme via simulation using a traffic network simulator called simulation of urban mobility (SUMO) and a simulation tool called MATLAB. Simulation results show that our proposed scheme reduces the total travel time of the vehicles.",2020,https://www.sciencedirect.com/science/article/pii/S0167739X19328249,https://doi.org/10.1016/j.future.2020.03.065,15,top-tier,yes,"computer science, information technology",0.95,"Future Generation Computer Systems is a prominent journal published by Elsevier, focusing on distributed and parallel computing, big data, and cloud computing. Its high impact factor and rigorous peer-review process signify its status as a top-tier journal in the computer science community.",elsevier_venues.csv,Future Generation Computer Systems,NA,Elsevier,NA
Future Generation Computer Systems,Deep transfer learning framework for the identification of malicious activities to combat cyberattack,Deepak Singh;Anurag Shukla;Mohit Sajwan,"The people having a perpetrating mind and the facilitation in advanced technologies cause the criminogenic activities in cyberspace, thereby creating societal problems. Darknet is an internet-based technology that builds on an encrypted network. Darknet networks can be accessed using a specific software with a specific network configuration; its content does not index by any search engines. Since its beginning, Darknet has been used for criminogenic tasks and applauded primarily for cybercrime promotion, including arms and drug dealing. Few countries have control over digital media and are ruled by a suppressive government. They have formulated strict policies for freedom fighters and journalism, using the Darknet anonymously. Also, many people use it for illegal purposes. Therefore, we have both positive and negative impacts of the darknet on human society and just cannot be discarded. However, in this paper, our prime concern emanates from the darknet network detection from the network traffic data through the deep transfer learning model. To provide a more accurate result, we transform time-based features into a three-dimensional image and then feed it into a pre-trained model for the extraction of promising features. In this study, we considered the DeepInsight method to transform the numerical features into image data. These features were then used in a proposed bi-level classification system to classify the input data into malicious activities. To identify the optimized pretrained network this paper utilized 10 pre-trained models: AlexNet, ResNet18, ResNet50, ResNet101, DenseNet, GoogLeNet, VGG16, VGG19, Inceptionv3, and SqueezeNet with three different baseline classifiers, namely support vector machine, decision tree, and random forest. In addition to malicious activity prediction, the proposed model could also predict the type of traffic. The experiment results illustrate that the VGG19 based features along with random forest can classify the traffic data with 96% of accuracy.",2021,https://www.sciencedirect.com/science/article/pii/S0167739X21002776,https://doi.org/10.1016/j.future.2021.07.015,11,top-tier,yes,"computer science, information technology",0.95,"Future Generation Computer Systems is a prominent journal published by Elsevier, focusing on distributed and parallel computing, big data, and cloud computing. Its high impact factor and rigorous peer-review process signify its status as a top-tier journal in the computer science community.",elsevier_venues.csv,Future Generation Computer Systems,NA,Elsevier,NA
Future Generation Computer Systems,Dendron : genetic trees driven rule induction for network intrusion detection systems,Dimitrios Papamartzivanos;Félix {Gómez Mármol};Georgios Kambourakis,"Intrusion detection systems (IDSs) are essential entities in a network topology aiming to safeguard the integrity and availability of sensitive assets in the protected systems. In misuse detection systems, which is the topic of the paper at hand, the detection process relies on specific attack signatures (rules) in an effort to distinguish between legitimate and malicious network traffic. Generally, three major challenges are associated with any IDS of this category: identifying patterns of new attacks with high accuracy, ameliorating the human-readability of the detection rules, and rightly designating the category these attacks belong to. To this end, we propose Dendron, a methodology for generating new detection rules which are able to classify both common and rare types of attacks. Our methodology takes advantage of both Decision Trees and Genetic Algorithms for the sake of evolving linguistically interpretable and accurate detection rules. It also integrates heuristic methods in the evolutionary process aiming to deal with the challenging nature of the network traffic, which generally biases machine learning techniques to neglect the minority classes of a dataset. The experimental results, using KDDCup’99, NSL-KDD and UNSW-NB15 datasets, reveal that Dendron is able to achieve superior results over other state-of-the-art and legacy techniques under several classification metrics, while at the same time is able to significantly detect rare intrusive incidents.",2018,https://www.sciencedirect.com/science/article/pii/S0167739X16305465,https://doi.org/10.1016/j.future.2017.09.056,17,top-tier,yes,"computer science, information technology",0.95,"Future Generation Computer Systems is a prominent journal published by Elsevier, focusing on distributed and parallel computing, big data, and cloud computing. Its high impact factor and rigorous peer-review process signify its status as a top-tier journal in the computer science community.",elsevier_venues.csv,Future Generation Computer Systems,NA,Elsevier,NA
Gastrointestinal Endoscopy,Whole-slide images using artificial intelligence can decide the need for secondary surgery after endoscopic resection of t1 colorectal cancer,Yuki Takashina;Shin-ei Kudo;Yuta Kouyama;Hideyuki Miyachi;Katsuro Ichimasa;Kenichi Mochizuki;Yushi Ogawa;Maeda Yasuharu;Yuichi Mori;Toyoki Kudo;Yusuke Takehara;Shunpei Mukai;Takemasa Hayashi;Kunihiko Wakamura;Yuta Enami;Naruhiko Sawada;Toshiyuki Baba;Tetsuo Nemoto;Fumio Ishida;Masashi Misawa,NA,2023,https://www.sciencedirect.com/science/article/pii/S0016510723016127,https://doi.org/10.1016/j.gie.2023.04.1226,NA,top-tier,yes,medicine/gastroenterology,0.9,"Gastrointestinal Endoscopy is a highly respected journal in the field of gastroenterology, focusing on endoscopic research. It is peer-reviewed and known for publishing influential studies, placing it among top-tier journals in its area.",elsevier_venues.csv,Gastrointestinal Endoscopy,NA,Elsevier,NA
Genetic and Evolutionary Computation Conference (GECCO),A robot to shape your natural plant: the machine learning approach to model and control bio-hybrid systems,"Wahby, Mostafa; Heinrich, Mary Katherine; Hofstadler, Daniel Nicolas; Zahadat, Payam; Risi, Sebastian; Ayres, Phil; Schmickl, Thomas; Hamann, Heiko","Bio-hybrid systems-close couplings of natural organisms with technology-are high potential and still underexplored. In existing work, robots have mostly influenced group behaviors of animals. We explore the possibilities of mixing robots with natural plants, merging useful attributes. Significant synergies arise by combining the plants' ability to efficiently produce shaped material and the robots' ability to extend sensing and decision-making behaviors. However, programming robots to control plant motion and shape requires good knowledge of complex plant behaviors. Therefore, we use machine learning to create a holistic plant model and evolve robot controllers. As a benchmark task we choose obstacle avoidance. We use computer vision to construct a model of plant stem stiffening and motion dynamics by training an LSTM network. The LSTM network acts as a forward model predicting change in the plant, driving the evolution of neural network robot controllers. The evolved controllers augment the plants' natural light-finding and tissue-stiffening behaviors to avoid obstacles and grow desired shapes. We successfully verify the robot controllers and bio-hybrid behavior in reality, with a physical setup and actual plants.",2018,https://doi.org/10.1145/3205455.3205516,10.1145/3205455.3205516,8,top-tier,yes,"evolutionary computation, artificial intelligence",0.95,"The Genetic and Evolutionary Computation Conference (GECCO) is recognized as a leading conference in genetic and evolutionary computation, featuring rigorously peer-reviewed research. It's organized by ACM SIGEVO, contributing significantly to AI and computational intelligence fields.",acm_venues.csv,Proceedings of the Genetic and Evolutionary Computation Conference,NA,ACM,NA
Genetic and Evolutionary Computation Conference (GECCO),Accelerated evolutionary induction of heterogeneous decision trees for gene expression-based classification,"Czajkowski, Marcin; Jurczuk, Krzysztof; Kretowski, Marek","Decision trees (DTs) are popular techniques in the field of eXplainable Artificial Intelligence. Despite their effectiveness in solving various classification problems, they are not compatible with modern biological data generated with high-throughput technologies. This work aims to combine evolutionary induced DT with a recently developed concept designed directly for gene expression data, called Relative eXpression Analysis (RXA). We propose a new solution, termed Evolutionary Heterogeneous Decision Tree (EvoHDTree), which uses both classical univariate and bivariate tests that focus on the relative ordering and weight relationships between the genes in the splitting nodes. The search for the decision tree structure, node representation, and splits is performed globally by the evolutionary algorithm.To meet the huge computational demands, we enriched our solution with more than a dozen specialized variants of recombination operators, GPU-computed local search components, OpenMP parallelization, and built-in gene ranking to improve evolutionary convergence. Experiments performed on cancer-related gene expression-based data show that the proposed solution finds accurate and much simpler interactions between genes. Importantly, the patterns discovered by EvoHDTree are easy to understand and to some extent supported by biological evidence in the literature.",2021,https://doi.org/10.1145/3449639.3459376,10.1145/3449639.3459376,9,top-tier,yes,"evolutionary computation, artificial intelligence",0.95,"The Genetic and Evolutionary Computation Conference (GECCO) is recognized as a leading conference in genetic and evolutionary computation, featuring rigorously peer-reviewed research. It's organized by ACM SIGEVO, contributing significantly to AI and computational intelligence fields.",acm_venues.csv,Proceedings of the Genetic and Evolutionary Computation Conference,NA,ACM,NA
Genetic and Evolutionary Computation Conference (GECCO),An efficient computational approach for automatic itinerary planning on web servers,"Ma, Zeyuan; Guo, Hongshu; Gui, Yinxuan; Gong, Yue-Jiao","The automatic itinerary planning service requires to generate multiple-day schedules automatically under user-specified POIs and constraints. Knowing as an NP-Hard optimization problem, the task is commonly solved by (meta-)heuristic algorithms such as the genetic algorithms (GAs). However, considering the concurrent requests received by a web server in practice, the time efficiency of the existing itinerary planners can be rather unsatisfactory. To address the issue, this paper proposes a computational approach that hybridizing a GA with the reinforcement learning (RL) technology. The benefit is that we no longer need to re-execute the GA for each new request arrived. Instead, the approach keeps the historical solutions in track and maintains a RL agent to sequentially decide how to handle each new request. Experimental results show that the proposed approach is able to stably provide high-quality solutions, while greatly reducing the average time overhead of the web server.",2021,https://doi.org/10.1145/3449639.3459301,10.1145/3449639.3459301,9,top-tier,yes,"evolutionary computation, artificial intelligence",0.95,"The Genetic and Evolutionary Computation Conference (GECCO) is recognized as a leading conference in genetic and evolutionary computation, featuring rigorously peer-reviewed research. It's organized by ACM SIGEVO, contributing significantly to AI and computational intelligence fields.",acm_venues.csv,Proceedings of the Genetic and Evolutionary Computation Conference,NA,ACM,NA
Genetic and Evolutionary Computation Conference (GECCO),Augmented evolutionary intelligence: combining human and evolutionary design for water distribution network optimisation,"Johns, Matthew B.; Mahmoud, Herman A.; Walker, David J.; Ross, Nicholas D. F.; Keedwell, Edward C.; Savic, Dragan A.","Evolutionary Algorithms (EAs) have been employed for the optimisation of both theoretical and real-world problems for decades. These methods although capable of producing near-optimal solutions, often fail to meet real-world application requirements due to considerations which are hard to define in an objective function. One solution is to employ an Interactive Evolutionary Algorithm (IEA), involving an expert human practitioner in the optimisation process to help guide the algorithm to a solution more suited to real-world implementation. This approach requires the practitioner to make thousands of decisions during an optimisation, potentially leading to user fatigue and diminishing the algorithm's search ability. This work proposes a method for capturing engineering expertise through machine learning techniques and integrating the resultant heuristic into an EA through its mutation operator. The human-derived heuristic based mutation is assessed on a range of water distribution network design problems from the literature and shown to often outperform traditional EA approaches. These developments open up the potential for more effective interaction between human expert and evolutionary techniques and with potential application to a much larger and diverse set of problems beyond the field of water systems engineering.",2019,https://doi.org/10.1145/3321707.3321814,10.1145/3321707.3321814,9,top-tier,yes,"evolutionary computation, artificial intelligence",0.95,"The Genetic and Evolutionary Computation Conference (GECCO) is recognized as a leading conference in genetic and evolutionary computation, featuring rigorously peer-reviewed research. It's organized by ACM SIGEVO, contributing significantly to AI and computational intelligence fields.",acm_venues.csv,Proceedings of the Genetic and Evolutionary Computation Conference,NA,ACM,NA
Genetics in Medicine,BOADICEA: a comprehensive breast cancer risk prediction model incorporating genetic and nongenetic risk factors,"Lee, Andrew;Mavaddat, Nasim;Wilcox, Amber N.;Cunningham, Alex P.;Carver, Tim;Hartley, Simon;Babb de Villiers, Chantal;Izquierdo, Angel;Simard, Jacques;Schmidt, Marjanka K.;Walter, Fiona M.;Chatterjee, Nilanjan;Garcia-Closas, Montserrat;Tischkowitz, Marc;Pharoah, Paul;Easton, Douglas F.;Antoniou, Antonis C.","Purpose Breast cancer( BC) risk prediction allows systematic identification of individuals at highest and lowest risk. We extend the Breast and Ovarian Analysis of Disease Incidence and Carrier Estimation Algorithm( BOADICEA) risk model to incorporate the effects of polygenic risk scores( PRS) and other risk factors( RFs). Methods BOADICEA incorporates the effects of truncating variants in BRCA1, BRCA2, PALB2, CHEK2, and ATM ; a PRS based on 313 single-nucleotide polymorphisms( SNPs) explaining 20% of BC polygenic variance; a residual polygenic component accounting for other genetic/familial effects; known lifestyle/hormonal/reproductive RFs; and mammographic density, while allowing for missing information. Results Among all factors considered, the predicted UK BC risk distribution is widest for the PRS, followed by mammographic density. The highest BC risk stratification is achieved when all genetic and lifestyle/hormonal/reproductive/anthropomorphic factors are considered jointly. With all factors, the predicted lifetime risks for women in the UK population vary from 2. 8% for the 1st percentile to 30. 6% for the 99th percentile, with 14. 7% of women predicted to have a lifetime risk of ≥17–<30%( moderate risk according to National Institute for Health and Care Excellence [NICE] guidelines) and 1. 1% a lifetime risk of ≥30%( high risk). Conclusion This comprehensive model should enable high levels of BC risk stratification in the general population and women with family history, and facilitate individualized, informed decision-making on prevention therapies and screening.",2019,http://dx.doi.org/10.1038/s41436-018-0406-9,10.1038/s41436-018-0406-9,10,top-tier,yes,"medicine, genetics",0.95,"Genetics in Medicine is a highly respected journal published by Elsevier, focusing on research in genetics and medicine. It is considered top-tier due to its high impact factor and reputation in the field, and it is well-known for its rigorous peer-review process.",elsevier_venues.csv,Genetics in Medicine,Article,Springer,NA
Genetics in Medicine,Broad consent for health care–embedded biobanking: understanding and reasons to donate in a large patient sample,"Richter, Gesine;Krawczak, Michael;Lieb, Wolfgang;Wolff, Lena;Schreiber, Stefan;Buyx, Alena","Purpose To facilitate ethically acceptable and practically successful health care–embedded biobanking, the attitudes and understanding of patients and their motivation to participate need to be explored. Methods A questionnaire study was conducted among 760 outpatients of a northern German university hospital to assess their awareness of, and motivation for giving broad consent to health care–embedded biobanking, also addressing the issue of feedback on individual-level research findings. Results The overall willingness to give broad consent was high( 86. 9%) in our study, even though the subjective and objective understanding of patients was found to be only modest. Most participants who consented did so for prosocial reasons( altruism, solidarity, reciprocity, gratitude) , whereas self-interest or worries about disadvantages played only a marginal role. Better objective understanding was associated with both a greater demand for feedback on individual research findings and a higher willingness to consent. Intermittent modification of the information material provided by the hospital led to significantly improved objective understanding. Conclusion Patient willingness to give broad consent to health care–embedded biobanking is high, with prosocial reasons driving decision making more than factual knowledge and approval or disapproval of specific consent elements. Future efforts to improve the information material used in health care–embedded biobanking should therefore emphasize prosocial reasons to consent.",2018,http://dx.doi.org/10.1038/gim.2017.82,10.1038/gim.2017.82,6,top-tier,yes,"medicine, genetics",0.95,"Genetics in Medicine is a highly respected journal published by Elsevier, focusing on research in genetics and medicine. It is considered top-tier due to its high impact factor and reputation in the field, and it is well-known for its rigorous peer-review process.",elsevier_venues.csv,Genetics in Medicine,Article,Springer,NA
Genetics in Medicine,Cancer communication research in the era of genomics and precision medicine: a scoping review,"Kaphingst, Kimberly A.;Peterson, Emily;Zhao, Jingsong;Gaysynsky, Anna;Elrick, Ashley;Hong, Soo Jung;Krakow, Melinda;Pokharel, Manusheela;Ratcliff, Chelsea L.;Klein, William M. P.;Khoury, Muin J.;Chou, Wen-Ying Sylvia","Effective use of genetic and genomic data in cancer prevention and treatment depends on adequate communication with patients and the public. Although relevant empirical work has emerged, the scope and outcomes of this communication research have not been characterized. We conducted a comprehensive scoping review of recent published research( 2010–2017) on communication of cancer-related genetic and genomic testing( CGT) information. Searches in six databases revealed 9243 unique records; 513 papers were included. Most papers utilized an observational quantitative design; fewer utilized an experimental design. More attention has been paid to outcomes of CGT results disclosure than to decision making regarding CGT uptake or the process of results disclosure. Psychosocial outcomes were most common across studies. This literature has a strong focus on BRCA1/2, with few papers focused on Lynch syndrome or next-generation technologies. Women, Caucasians, older adults, and those of higher socioeconomic status were overrepresented. Research gaps identified include the need for studies on the process of CGT communication; examining behavioral, decision making, and communication outcomes; and inclusion of diverse populations. Addressing these gaps can help improve the use of genomics in cancer control and reduce disparities in access to and use of CGT.",2019,http://dx.doi.org/10.1038/s41436-018-0402-0,10.1038/s41436-018-0402-0,7,top-tier,yes,"medicine, genetics",0.95,"Genetics in Medicine is a highly respected journal published by Elsevier, focusing on research in genetics and medicine. It is considered top-tier due to its high impact factor and reputation in the field, and it is well-known for its rigorous peer-review process.",elsevier_venues.csv,Genetics in Medicine,Article,Springer,NA
Genetics in Medicine,Challenges and lessons learned from clinical pharmacogenetic implementation of multiple gene–drug pairs across ambulatory care settings,"Cicali, Emily J.;Weitzel, Kristin Wiisanen;Elsey, Amanda R.;Orlando, Frank A.;Vinson, Michelle;Mosley, Scott;Smith, D. Max;Davis, Richard;Drum, Lori;Estores, David;Franciosi, James P.;Hagen, Melanie Gross;Jerkins, Gabriel J.;Mercado, Elvira S.;Nainaparampil, Jaison;Padron, Adaixa;Rosenberg, Eric I.;Wright, Ashleigh;Schmidt, Siegfried O.;Mathews, Carol A.;Cavallari, Larisa H.;Johnson, Julie A.","Purpose Incorporating a patient’s genotype into the clinical decision-making process is one approach to precision medicine. The University of Florida( UF) Health Precision Medicine Program is a pharmacist-led multidisciplinary effort that has led the clinical implementation of six gene–drug( s) pairs to date. This study focuses on the challenges encountered and lessons learned with implementing pharmacogenetic testing for three of these: CYP2D6 -opioids, CYP2D6 / CYP2C19 -selective serotonin reuptake inhibitors, and CYP2C19 -proton pump inhibitors within six pragmatic clinical trials at UF Health and partners. Methods We compared common measures collected within each of the pharmacogenetic implementations as well as solicited feedback from stakeholders to identify challenges, successes, and lessons learned. Results We identified several challenges related to trial design and implementation, and learned valuable lessons. Most notably, case discussions are effective for prescriber education, prescribers need clear concise guidance on genotype-based actions, having genotype results available at the time of the patient–prescriber encounter helps optimize the ability to act on them, children prefer noninvasive sample collection, and study participants are willing to answer patient-reported outcomes questionnaires if they are not overly burdensome, among others. Conclusion The lessons learned from implementing three gene–drug pairs in ambulatory care settings will help shape future pharmacogenetic clinical trials and clinical implementations.",2019,http://dx.doi.org/10.1038/s41436-019-0500-7,10.1038/s41436-019-0500-7,10,top-tier,yes,"medicine, genetics",0.95,"Genetics in Medicine is a highly respected journal published by Elsevier, focusing on research in genetics and medicine. It is considered top-tier due to its high impact factor and reputation in the field, and it is well-known for its rigorous peer-review process.",elsevier_venues.csv,Genetics in Medicine,Article,Springer,NA
Genetics in Medicine,ClinGen expert clinical validity curation of 164 hearing loss gene–disease pairs,"DiStefano, Marina T.;Hemphill, Sarah E.;Oza, Andrea M.;Siegert, Rebecca K.;Grant, Andrew R.;Hughes, Madeline Y.;Cushman, Brandon J.;Azaiez, Hela;Booth, Kevin T.;Chapin, Alex;Duzkale, Hatice;Matsunaga, Tatsuo;Shen, Jun;Zhang, Wenying;Kenna, Margaret;Schimmenti, Lisa A.;Tekin, Mustafa;Rehm, Heidi L.;Tayoun, Ahmad N. Abou;Amr, Sami S.;on behalf of the ClinGen Hearing Loss Clinical Domain Working Group","Purpose Proper interpretation of genomic variants is critical to successful medical decision making based on genetic testing results. A fundamental prerequisite to accurate variant interpretation is the clear understanding of the clinical validity of gene–disease relationships. The Clinical Genome Resource( ClinGen) has developed a semiquantitative framework to assign clinical validity to gene–disease relationships. Methods The ClinGen Hearing Loss Gene Curation Expert Panel( HL GCEP) uses this framework to perform evidence-based curations of genes present on testing panels from 17 clinical laboratories in the Genetic Testing Registry. The HL GCEP curated and reviewed 142 genes and 164 gene–disease pairs, including 105 nonsyndromic and 59 syndromic forms of hearing loss. Results The final outcome included 82 Definitive( 50%) , 12 Strong( 7%) , 25 Moderate( 15%) , 32 Limited( 20%) , 10 Disputed( 6%) , and 3 Refuted( 2%) classifications. The summary of each curation is date stamped with the HL GCEP approval, is live, and will be kept up-to-date on the ClinGen website( https://search. clinicalgenome. org/kb/gene-validity). Conclusion This gene curation approach serves to optimize the clinical sensitivity of genetic testing while reducing the rate of uncertain or ambiguous test results caused by the interrogation of genes with insufficient evidence of a disease link.",2019,http://dx.doi.org/10.1038/s41436-019-0487-0,10.1038/s41436-019-0487-0,8,top-tier,yes,"medicine, genetics",0.95,"Genetics in Medicine is a highly respected journal published by Elsevier, focusing on research in genetics and medicine. It is considered top-tier due to its high impact factor and reputation in the field, and it is well-known for its rigorous peer-review process.",elsevier_venues.csv,Genetics in Medicine,Article,Springer,NA
Genetics in Medicine,"Clinical whole-genome sequencing from routine formalin-fixed, paraffin-embedded specimens: pilot study for the 100, 000 Genomes Project","Robbe, Pauline;Popitsch, Niko;Knight, Samantha J L;Antoniou, Pavlos;Becq, Jennifer;He, Miao;Kanapin, Alexander;Samsonova, Anastasia;Vavoulis, Dimitrios V;Ross, Mark T;Kingsbury, Zoya;Cabes, Maite;Ramos, Sara D C;Page, Suzanne;Dreau, Helene;Ridout, Kate;Jones, Louise J;Tuff-Lacey, Alice;Henderson, Shirley;Mason, Joanne;Buffa, Francesca M;Verrill, Clare;Maldonado-Perez, David;Roxanis, Ioannis;Collantes, Elena;Browning, Lisa;Dhar, Sunanda;Damato, Stephen;Davies, Susan;Caulfield, Mark;Bentley, David R;Taylor, Jenny C;Turnbull, Clare;Schuh, Anna;on behalf of the 100,000 Genomes Project","Purpose Fresh-frozen( FF) tissue is the optimal source of DNA for whole-genome sequencing( WGS) of cancer patients. However, it is not always available, limiting the widespread application of WGS in clinical practice. We explored the viability of using formalin-fixed, paraffin-embedded( FFPE) tissues, available routinely for cancer patients, as a source of DNA for clinical WGS. Methods We conducted a prospective study using DNAs from matched FF, FFPE, and peripheral blood germ-line specimens collected from 52 cancer patients( 156 samples) following routine diagnostic protocols. We compared somatic variants detected in FFPE and matching FF samples. Results We found the single-nucleotide variant agreement reached 71% across the genome and somatic copy-number alterations( CNAs) detection from FFPE samples was suboptimal( 0. 44 median correlation with FF) due to nonuniform coverage. CNA detection was improved significantly with lower reverse crosslinking temperature in FFPE DNA extraction( 80 °C or 65 °C depending on the methods). Our final data showed somatic variant detection from FFPE for clinical decision making is possible. We detected 98% of clinically actionable variants( including 30/31 CNAs). Conclusion We present the first prospective WGS study of cancer patients using FFPE specimens collected in a routine clinical environment proving WGS can be applied in the clinic.",2018,http://dx.doi.org/10.1038/gim.2017.241,10.1038/gim.2017.241,9,top-tier,yes,"medicine, genetics",0.95,"Genetics in Medicine is a highly respected journal published by Elsevier, focusing on research in genetics and medicine. It is considered top-tier due to its high impact factor and reputation in the field, and it is well-known for its rigorous peer-review process.",elsevier_venues.csv,Genetics in Medicine,Article,Springer,NA
Hawaii International Conference on System Sciences,A stressful explanation: the dual effect of explainable artificial intelligence in personal health management,"Gr{\""u}ning, Maximilian;Wolf, Tobias;Trenz, Manuel","Artificial intelligence (AI) is increasingly incorporated into innovative personal health apps to improve the decision-making of its users. To facilitate the understanding and to increase usage of such AI-based personal health apps, firms are progressively turning to explainable artificial intelligence (XAI) designs. However, we argue that explanations of the AI-based recommendations have not only positive but also negative consequences. Based on a socio-technical lens, we develop a model that relates XAI to technostress - both eustress and distress - and its downstream consequences. To test our model, we conducted an online experiment, in which participants interact with XAI or black-box AI. Our results show that (1) XAI causes both eu- and distress, and (2) simultaneously exerts differential influence on objective performance, satisfaction, and intention to use. Our findings contribute to information systems research and practice by uncovering the dual effect of XAI on decision processes in the health context.",2024,https://aisel.aisnet.org/hicss-57/hc/wellness_management/2,NA,NA,top-tier,yes,"information systems, computer science, management, decision sciences",0.9,"HICSS is known for its interdisciplinary approach, covering various aspects of information systems and technology. It is respected within its niche but is generally considered mid-tier compared to top conferences like ICIS or SIGMOD.",ieee_venues.csv,Hawaii International Conference on System Sciences,Hawaii International Conference on System Sciences 2024 (HICSS-57),AISEL,NA
Hawaii International Conference on System Sciences,Acceptance of ai for delegating emotional intelligence: results from an experiment,"Aysolmaz, Banu;Leyer, Michael;Iren, Deniz","Detecting emotions of other humans is challenging for us humans. It is however important in many social contexts so that many individuals seek help in this regard. As technology is evolving, more and more AI-based options emerge that promise to detect human emotions and support decision making. We focus on the full delegation of detecting emotions to AI to contribute to our understanding how such AI is perceived and why it is accepted. For this, we conduct an online scenario-based experiment in which participants have the choice to delegate emotion detection to another human in one group and to an AI tool in the other group. Our results show that the delegation rates are higher for a human, but surprisingly high for AI. The results provide insights that should be considered when designing AI-based emotion-detection tools to build trustworthy and accepted designs.",2021,https://aisel.aisnet.org/hicss-54/os/promises_and_perils_of_ai/2,NA,NA,top-tier,yes,"information systems, computer science, management, decision sciences",0.9,"HICSS is known for its interdisciplinary approach, covering various aspects of information systems and technology. It is respected within its niche but is generally considered mid-tier compared to top conferences like ICIS or SIGMOD.",ieee_venues.csv,Hawaii International Conference on System Sciences,Hawaii International Conference on System Sciences 2021 (HICSS-54),AISEL,NA
Hawaii International Conference on System Sciences,Achieving decisional fit with ai-aided group decisions: the role of intuitive decision-making style in predicting perceived fairness and decision acceptance,"Askay, David;Dhillon, Anuraj;Metcalf, Lynn","As organizations integrate AI decision tools into their decision-making processes, there is a need to understand factors that promote acceptance of decisions made with AI tools. This study draws from the theory of decisional fit and design features of an AI platform to examine the relationship between decision-making styles, procedural fairness, and decision acceptance when teams collaborate with AI decision aid to reach a decision. The results confirm the mediating relationship of procedural fairness between an intuitive decision-making style and decision acceptance. These results extend theory related to decision-making styles by identifying individual differences that predict procedural fairness and decision acceptance. Moreover, it offers guidance to managers and organizations seeking to adopt and design AI decision aids.",2024,https://aisel.aisnet.org/hicss-57/cl/machines_as_teammates/3,NA,NA,top-tier,yes,"information systems, computer science, management, decision sciences",0.9,"HICSS is known for its interdisciplinary approach, covering various aspects of information systems and technology. It is respected within its niche but is generally considered mid-tier compared to top conferences like ICIS or SIGMOD.",ieee_venues.csv,Hawaii International Conference on System Sciences,Hawaii International Conference on System Sciences 2024 (HICSS-57),AISEL,NA
Hawaii International Conference on System Sciences,Adversarial cognitive engineering (ace) and defensive cybersecurity: leveraging attacker decision-making heuristics in a cybersecurity task,"Johnson, Chelsea;Van Tassel, Richard W.;Shade, Temmie;Rogers, Andrew;Ferguson-Walter, Kimberly","The role of cyberspace continues to expand, touching nearly every aspect in our lives. Critical information, when stolen, can be devastating to a nation's people, economy, and security. To defend against this threat, it is essential to understand the human behind the attack. A first step in developing new defenses where human attackers are involved is obtaining valid and reliable human performance and decision-making data. These data can be procured through rigorous human science research that experimentally evaluates foundational theory and measures human performance. Taking the key concepts from behavioral economics, the game-based testbed, CYPHER, was specifically designed to test the occurrence of the Sunk Cost Fallacy across multiple decisions in an abstract cyber environment. Evaluating decisions made over a series of actions to catch a fictitious cyber thief, we analyze the effects of two antecedents (uncertainty and project completion) and resource expenditure. Our results show that irrespective of condition, significantly more participants unnecessarily wasted resources, demonstrating behavior consistent with the Sunk Cost Fallacy. These data provide a baseline upon which to build artificial intelligence algorithms for automated cyber defense.",2024,https://aisel.aisnet.org/hicss-57/da/cyber_deception/6,NA,NA,top-tier,yes,"information systems, computer science, management, decision sciences",0.9,"HICSS is known for its interdisciplinary approach, covering various aspects of information systems and technology. It is respected within its niche but is generally considered mid-tier compared to top conferences like ICIS or SIGMOD.",ieee_venues.csv,Hawaii International Conference on System Sciences,Hawaii International Conference on System Sciences 2024 (HICSS-57),AISEL,NA
Hawaii International Conference on System Sciences,Ai implementation and capability development in manufacturing: an action research case,"Eklof, Jon;Snis, Ulrika;Hamelryck, Thomas;Grima, Alexander;Ronning, Ola","This action research article presents a case study of a global manufacturing company deploying artificial intelligence (AI) to develop capabilities and enhance decision-making. This study explores considerations and trade-offs involved in introducing AI into daily operations, leading up to the decision to develop AI capabilities in-house or outsource them. The case study offers in-depth technical descriptions of model selection, dataset creation, model adoption, model training and evaluation while addressing organizational obstacles and decision-making processes. The study's findings highlight the importance of collaboration between technical experts, business leaders, and end-users, as well as the interaction and collaboration between AI systems and human employees in the workplace. The article contributes a practical perspective on AI implementation in manufacturing, emphasizing the need to balance in-house capability development with external acquisition. Although the case study company managed to create an in-house model, factors such as implementation, debugging, data requirements, training time, and performance led to outsourcing the capabilities. However, making this informed decision required capabilities and insights that were acquired through practical work. Consequently, although in-house development can be challenging, it can also enhance organizational capabilities and provide the necessary knowledge to make informed decisions about future development or outsourcing.",2024,https://aisel.aisnet.org/hicss-57/os/ai_and_organizing/3,NA,NA,top-tier,yes,"information systems, computer science, management, decision sciences",0.9,"HICSS is known for its interdisciplinary approach, covering various aspects of information systems and technology. It is respected within its niche but is generally considered mid-tier compared to top conferences like ICIS or SIGMOD.",ieee_venues.csv,Hawaii International Conference on System Sciences,Hawaii International Conference on System Sciences 2024 (HICSS-57),AISEL,NA
Hawaii International Conference on System Sciences,Ai suffrage: a four-country survey on the acceptance of an automated voting system,"Suter, Viktor;Meckel, Miriam;Shahrezaye, Morteza;Steinacker, L{\'e}a","Governments have begun to employ technological systems that use massive amounts of data and artificial intelligence (AI) in the domains of law enforcement, public health, or social welfare. In some areas, shifts in public opinion increasingly favor technology-aided public decision-making. This development presents an opportunity to explore novel approaches to how technology could be used to reinvigorate democratic governance and how the public perceives such changes. The study therefore posits a hypothetical AI voting system that mediates political decision-making between citizens and the state. We conducted a four-country online survey (N=6043) in Greece, Singapore, Switzerland, and the US to find out what factors affect the public's acceptance of such a system. The data show that Singaporeans are most likely and Greeks least likely to accept the system. Considerations of the technology's utility have a large effect on acceptance rates across cultures whereas attitudes towards political norms and political performance have partial effects.",2022,https://aisel.aisnet.org/hicss-55/dg/ai/2,NA,NA,top-tier,yes,"information systems, computer science, management, decision sciences",0.9,"HICSS is known for its interdisciplinary approach, covering various aspects of information systems and technology. It is respected within its niche but is generally considered mid-tier compared to top conferences like ICIS or SIGMOD.",ieee_venues.csv,Hawaii International Conference on System Sciences,Hawaii International Conference on System Sciences 2022 (HICSS-55),AISEL,NA
Health Policy and Planning,The political economy of health financing reform in malaysia,Kevin Croke;Mariana Binti Mohd Yusoff;Zalilah Abdullah;Ainul Nadziha Mohd Hanafiah;Khairiah Mokhtaruddin;Emira Soleha Ramli;Nor Filzatun Borhan;Yadira Almodovar-Diaz;Rifat Atun;Amrit Kaur Virk,"There is growing evidence that political economy factors are central to whether or not proposed health financing reforms are adopted, but there is little consensus about which political and institutional factors determine the fate of reform proposals. One set of scholars see the relative strength of interest groups in favour of and opposed to reform as the determining factor. An alternative literature identifies aspects of a country’s political institutions–specifically the number and strength of formal ‘veto gates’ in the political decision-making process—as a key predictor of reform’s prospects. A third group of scholars highlight path dependence and ‘policy feedback’ effects, stressing that the sequence in which health policies are implemented determines the set of feasible reform paths, since successive policy regimes bring into existence patterns of public opinion and interest group mobilization which can lock in the status quo. We examine these theories in the context of Malaysia, a successful health system which has experienced several instances of proposed, but ultimately blocked, health financing reforms. We argue that policy feedback effects on public opinion were the most important factor inhibiting changes to Malaysia’s health financing system. Interest group opposition was a closely related factor; this opposition was particularly powerful because political leaders perceived that it had strong public support. Institutional veto gates, by contrast, played a minimal role in preventing health financing reform in Malaysia. Malaysia’s dramatic early success at achieving near-universal access to public sector healthcare at low cost created public opinion resistant to any change which could threaten the status quo. We conclude by analysing the implications of these dynamics for future attempts at health financing reform in Malaysia.",2019,http://www.jstor.org/stable/48545921,10.2307/48545921,8,top-tier,yes,"public health, health policy",0.9,"Health Policy and Planning is a well-regarded journal focusing on public health and health policy, often cited and respected in the academic community, indicating its top-tier status. It is peer-reviewed, ensuring credibility and relevance in its field.",jstor_venues.csv,Health Policy and Planning,Research-article,JSTOR,NA
Health Policy and Planning,Valuing the work of unpaid community health workers and exploring the incentives to volunteering in rural africa,Frida Kasteng;Stella Settumba;Karin Källander;Anna Vassall;the inSCALE Study Group,"Community health worker (CHW) programmes are currently being scaled-up in sub-Saharan Africa to improve access to healthcare. CHWs are often volunteers; from an economic perspective, this raises considerations whether reliance on an unpaid workforce is sustainable and how to appropriately cost and value the work of CHWs. Both these questions can be informed by an understanding of CHWs’ workload, their opportunity costs of time and the perceived benefits of being a CHW. However, to date few studies have fully explored the methodological challenges in valuing CHW time. We examined the costs and benefits of volunteering in a sample of 45 CHWs providing integrated community case management of common childhood illnesses in rural Uganda in February 2012 using different methods. We assessed the value of CHW time using the minimum public sector salary rate and a CHW-elicited replacement wage, as well as the opportunity cost of time based on CHW-estimated annual income and alternative work opportunities, respectively. Reported monthly CHW workload, a median of 19.3 h (range 2.5–57), was valued at USD 6.9 (range 0.9–20.4) per month from the perspective of the healthcare system (applicable replacement wage) and at a median of USD 4.1 (range 0.4–169) from the perspective of the CHWs (individual opportunity cost of time). In a discrete choice experiment on preferred work characteristics, remuneration and community appreciation dominated. We find that volunteering CHWs value the opportunity to make a social contribution, but the decision to volunteer is also influenced by anticipated future rewards. Care must be taken by those costing and designing CHW programmes to acknowledge the opportunity cost of CHWs at the margin and over the long term. Failure to properly consider these issues may lead to cost estimations below the amount necessary to scale up and sustain programmes. Les programmes des agents de santé communautaires (ASC) sont actuellement mis à l’échelle en Afrique subsaharienne afin d’améliorer l’accès aux soins de santé. Les ASC sont souvent des bénévoles; du point de vue économique, on se pose la question de savoir si le recours à une main-d’œuvre non rémunérée est une solution viable et comment estimer de manière appropriée le coût et la valeur du travail des agents de santé communautaires. On peut mieux cerner ces deux questions en appréhendant la charge de travail des ASC, les coûts d’opportunité du temps consacré à faire ce travail et les avantages à jouer le rôle d’agent de santé communautaire. A ce jour cependant, peu d’études ont exploré les défis méthodologiques de l’évaluation du temps des ASC. Nous avons examiné les coûts et les avantages du bénévolat dans un échantillon de 45 agents de santé communautaires oeuvrant dans la prise en charge intégrée des cas de maladies infantiles courantes au sein de la communauté rurale de l’Ouganda au courant du mois de février 2012, en utilisant différentes méthodes. Nous avons estimé la valeur du temps des ASC en utilisant respectivement le taux du salaire minimum du secteur public et un salaire de remplacement induit pour les ASC, le coût d’opportunité du temps consacré en fonction du revenu annuel estimé d’un ASC ainsi que les opportunités alternatives de travail. La charge de travail mensuelle déclarée des ASC, une médiane de 19,3 h (intervalle de variations de 2,5 à 57), a été évalué à 6,9 USD (intervalle de 0,9 à 20,4) par mois dans la perspective du système de santé (salaire de remplacement applicable) et à une médiane de 4,1 USD (intervalle de 0,4 à 169) du point de vue des agents de santé communautaires (coût d’opportunité du temps individuel). Dans une expérience avec choix discrets sur les caractéristiques de travail préférées, la rémunération et la communauté étaient les caractéristiques les plus appréciées. Nous trouvons que les ASC bénévoles apprécient l’occasion d’apporter une contribution sociale, mais la décision de faire du bénévolat est également influencée par l’éventualité de récompenses futures. Des précautions doivent être prises par ceux qui évaluent les coûts et la conception des programmes des ASC, afin qu’ils reconnaîssent le coût d’opportunité des ASC à la marge et sur le long terme. Si l’on ne tient pas judicieusement compte de ces questions, on peut aboutir à des estimations de coûts inférieures au montant nécessaire pour élaborer et perpétuer ces programmes. Los programas de los trabajadores comunitarios de salud (TCSs) se están ampliando actualmente en África subsahariana para mejorar el acceso al cuidado de la salud. Los TCSs son a menudo voluntarios; desde una perspectiva económica, esto plantea consideraciones de si la dependencia de una fuerza de trabajo no remunerado es sostenible y cómo costear y valorar apropiadamente el trabajo de los TCSs. Estas preguntas pueden ser informadas por una comprensión de la carga de trabajo de los TCSs, de sus costos de oportunidad en cuanto a tiempo y de los beneficios percibidos de ser un TCS. Sin embargo, hasta la fecha pocos estudios han explorado plenamente los desafíos metodológicos en la valoración de tiempo de los TCS. Examinamos los costos y beneficios del voluntariado en una muestra de 45 TCSs suministrando el manejo integrado comunitario de casos de las enfermedades comunes de la infancia en zonas rurales de Uganda en febrero de 2012 usando diferentes métodos. Se evaluó el valor del tiempo de los TCSs utilizando la tasa salarial mínima del sector público y un salario de reemplazo obtenido de los TCSs, así como el costo de oportunidad del tiempo basado en el ingreso anual estimado de los TCS y las oportunidades de trabajo alternativas, respectivamente. La carga de trabajo mensual reportada de los TCSs, una mediana de 19.3 h (rango 2.5-57), fue valorada en USD 6.9 (rango 0.9 a 20.4) por mes desde la perspectiva del sistema de salud (salario de sustitución aplicable) y en una mediana de USD 4.1 (rango de 0.4 a 169) desde la perspectiva de los TCSs (costo de oportunidad individual de tiempo). En un experimento de selección discreta sobre las características preferidas del trabajo, la remuneración y el agradecimiento de la comunidad dominaron. Encontramos que los TCSs voluntarios valoran la oportunidad de hacer una contribución social, pero la decisión de ofrecerse como voluntario también está influida por recompensas anticipadas futuras. Deben tener cuidado aquellos que costean y diseñan los programas de los TCSs para reconocer el costo de oportunidad marginal y en el largo plazo de los TCSs. No considerar adecuadamente estas cuestiones puede dar lugar a estimaciones de costos por debajo de la cantidad necesaria para ampliar y sostener programas. 社区医疗エ作者 (CHW) 项目目前在撒哈拉以南的非洲正不 断扩大以更好地普及医疗服务。社区医疗エ作者通常是志愿 服务；从经济学的角度看，依靠不支付薪酬的劳动カ是否能够 持续，以及如何合适地衡量成本和他们的工作价值是值得考虑 的。这些问题可以从他们的工作量、机会成本以及成为ー个 社区医疗エ作者的益处来理解。然而，现在很少有研宄来解決 评估社区医疗エ作者时间的方法论的挑战。2012年2月，我们 在乌干达的乡村采用了不同的方法研宄了 45个社区医疗工作 者的成本和收益，这些エ作者为常见儿童疾病提供整合的社区 病例管理。我们分别通过最低公共领域薪资水平，社区医疗エ 作者替换エ资，社区医疗エ作者一年的收入估计和其他可能的 工作机会的工资的机会成本来估值他们的工作时间。 社区医 疗エ作者一个月的工作量，中位数19.3小时 （范围2.5-57), 从 医疗体系 (适用替换工作) 的角度估值为每月6.9美元 (范围 0.9-20.4), 从社区医疗エ作者的角度 (个人时间的机会成本) 估值中位数为4.1美元 (范围0.4-169) 。在关于工作倾向特点 的离散选择试验研宄中，薪酬和社区的认可处于支配地位。我 们发现社区医疗エ作者认为为社会做贡献有价值，但是从事志 愿工作也受未来回报的影响。在设计提供医疗服务的社区エ 作者项目时应该意识到这些エ作者的边际机会成本并从长远 来计划。如果没有考虑到这些因素，可能会导致在扩大和维持 这些项目的时候预算低于实际需要的。",2016,http://www.jstor.org/stable/48507580,10.2307/48507580,12,top-tier,yes,"public health, health policy",0.9,"Health Policy and Planning is a well-regarded journal focusing on public health and health policy, often cited and respected in the academic community, indicating its top-tier status. It is peer-reviewed, ensuring credibility and relevance in its field.",jstor_venues.csv,Health Policy and Planning,Research-article,JSTOR,NA
Health Psychology,"A preliminary experimental examination of worldview verification, perceived racism, and stress reactivity in african americans.","Lucas, Todd;Lumley, Mark A.;Flack, John M.;Wegner, Rhiana;Pierce, Jennifer;Goetz, Stefan","Objective: According to worldview verification theory, inconsistencies between lived experiences and worldviews are psychologically threatening. These inconsistencies may be key determinants of stress processes that influence cardiovascular health disparities. This preliminary examination considers how experiencing injustice can affect perceived racism and biological stress reactivity among African Americans. Guided by worldview verification theory, it was hypothesized that responses to receiving an unfair outcome would be moderated by fairness of the accompanying decision process, and that this effect would further depend on the consistency of the decision process with preexisting justice beliefs. Method: A sample of 118 healthy African American adults completed baseline measures of justice beliefs, followed by a laboratory-based social-evaluative stressor task. Two randomized fairness manipulations were implemented during the task: participants were given either high or low levels of distributive (outcome) and procedural (decision process) justice. Glucocorticoid (cortisol) and inflammatory (C-reactive protein) biological responses were measured in oral fluids, and attributions of racism were also measured. Results: The hypothesized 3-way interaction was generally obtained. Among African Americans with a strong belief in justice, perceived racism, cortisol, and C-reactive protein responses to low distributive justice were higher when procedural justice was low. Among African Americans with a weak belief in justice however, these responses were higher when a low level of distributive justice was coupled with high procedural justice. Conclusions: Biological and psychological processes that contribute to cardiovascular health disparities are affected by consistency between individual-level and contextual justice factors. (PsycInfo Database Record (c) 2024 APA, all rights reserved)",2016,https://doi.org/10.1037/hea0000284,10.1037/hea0000284,NA,top-tier,yes,"health psychology, behavioral medicine",0.9,"Health Psychology is a well-established, peer-reviewed journal published by the American Psychological Association, focusing on psychological aspects of health and illness. It is considered a top-tier journal in the fields of health psychology and behavioral medicine.",apa_venues.csv,Health Psychology,Journal Article,American Psychological Association,NA
Health Psychology,Affective forecasting and medication decision making in breast-cancer prevention.,"Hoerger, Michael;Scherer, Laura D.;Fagerlin, Angela","Objective: Over 2 million American women at elevated risk for breast cancer are eligible to take chemoprevention medications such as tamoxifen and raloxifene, which can cut in half the risk of developing breast cancer, but which also have a number of side effects. Historically, very few at-risk women have opted to use chemoprevention medications. Affective forecasting theory suggests that people may avoid these medications if they expect taking them to increase their health-related stress. Method: After receiving an individually tailored decision aid that provided personalized information about the risks and benefits of these medications, 661 women at elevated risk of breast cancer were asked to make 3 affective forecasts, predicting what their level of health-related stress would be if they took tamoxifen, raloxifene, or neither medication. They also completed measures of decisional preferences and intentions, and at a 3-month follow-up, reported on whether or not they had decided to use either medication. Results: On the affective forecasting items, very few women (<10%) expected the medications to reduce their health-related stress, relative to no medication at all. Participants with more negative affective forecasts about taking a chemoprevention medication expressed lower preferences and intentions for using the medications (Cohen’s ds from 0.74 to 0.79) and were more likely to have opted against using medication at follow-up (OR range = 1.34–2.66). Conclusion: These findings suggest that affective forecasting may explain avoidance of breast-cancer chemoprevention medications. They also highlight the need for more research aimed at integrating emotional content into decision aids. (PsycInfo Database Record (c) 2020 APA, all rights reserved)",2016,https://doi.org/10.1037/hea0000324,10.1037/hea0000324,NA,top-tier,yes,"health psychology, behavioral medicine",0.9,"Health Psychology is a well-established, peer-reviewed journal published by the American Psychological Association, focusing on psychological aspects of health and illness. It is considered a top-tier journal in the fields of health psychology and behavioral medicine.",apa_venues.csv,Health Psychology,Journal Article,American Psychological Association,NA
Health Psychology,Associations of perceived norms with intentions to learn genomic sequencing results: roles for attitudes and ambivalence.,"Reid, Allecia E.;Taber, Jennifer M.;Ferrer, Rebecca A.;Biesecker, Barbara B.;Lewis, Katie L.;Biesecker, Leslie G.;Klein, William M. P.","Objective: Genomic sequencing is becoming increasingly accessible, highlighting the need to understand the social and psychological factors that drive interest in receiving testing results. These decisions may depend on perceived descriptive norms (how most others behave) and injunctive norms (what is approved of by others). We predicted that descriptive norms would be directly associated with intentions to learn genomic sequencing results, whereas injunctive norms would be associated indirectly, via attitudes. These differential associations with intentions versus attitudes were hypothesized to be strongest when individuals held ambivalent attitudes toward obtaining results. Method: Participants enrolled in a genomic sequencing trial (n = 372) reported intentions to learn medically actionable, nonmedically actionable, and carrier sequencing results. Descriptive norms items referenced other study participants. Injunctive norms were analyzed separately for close friends and family members. Attitudes, attitudinal ambivalence, and sociodemographic covariates were also assessed. Results: In structural equation models, both descriptive norms and friend injunctive norms were associated with intentions to receive all sequencing results (ps < .004). Attitudes consistently mediated all friend injunctive norms-intentions associations, but not the descriptive norms–intentions associations. Attitudinal ambivalence moderated the association between friend injunctive norms (p ≤ .001), but not descriptive norms (p = .16), and attitudes. Injunctive norms were significantly associated with attitudes when ambivalence was high, but were unrelated when ambivalence was low. Results replicated for family injunctive norms. Conclusions: Descriptive and injunctive norms play roles in genomic sequencing decisions. Considering mediators and moderators of these processes enhances ability to optimize use of normative information to support informed decision making. (PsycINFO Database Record (c) 2019 APA, all rights reserved)",2018,https://doi.org/10.1037/hea0000579,10.1037/hea0000579,NA,top-tier,yes,"health psychology, behavioral medicine",0.9,"Health Psychology is a well-established, peer-reviewed journal published by the American Psychological Association, focusing on psychological aspects of health and illness. It is considered a top-tier journal in the fields of health psychology and behavioral medicine.",apa_venues.csv,Health Psychology,Journal Article,American Psychological Association,NA
Human Rights Quarterly,The prosecution of sexual and gender crimes in the national courts of argentina,Paloma Soria Montañez;Viviana Waisman;Keina Yoshida,"This article provides an analysis of a number of judgments which feature sexual and gender crimes in domestic prosecutions in Argentina. The authors analyze eleven decisions where individuals have been convicted of these crimes and argue that two major lines of jurisprudence have emerged tackling gender violence perpetrated in clandestine detention centers during the military dictatorship. The judgments illustrate the domestication of international criminal legal principles and their influence on national proceedings. While these judgments are welcome and important, the authors also draw attention to some of the on-going silences in the jurisprudence and the challenges which remain.",2017,http://www.jstor.org/stable/26802123,10.2307/26802123,27,top-tier,yes,"law, human rights",0.9,"Human Rights Quarterly is a respected, peer-reviewed journal in the field of human rights and law, well-regarded for its scholarly contributions and frequently cited in academic and legal references.",jstor_venues.csv,Human Rights Quarterly,Research-article,JSTOR,NA
Human Rights Quarterly,The united nations working group on arbitrary detention: procedures and summary of jurisprudence,David S. Weissbrodt;Brittany Mitchell,"For nearly twenty-five years, the United Nations Working Group on Arbitrary Detention has provided a well-respected jurisprudence on fundamental human rights, such as: freedom of expression and religion; limits on administrative detention; restrictions on discrimination in detention; and violations of the right to fair trial. The Working Group has amassed a unique collection of legal principles applicable to individuals detained by the United States, including asylum seekers, immigrants, and refugees. The decisions of the Working Group have also applied to non-state actors.",2016,http://www.jstor.org/stable/24738039,10.2307/24738039,51,top-tier,yes,"law, human rights",0.9,"Human Rights Quarterly is a respected, peer-reviewed journal in the field of human rights and law, well-regarded for its scholarly contributions and frequently cited in academic and legal references.",jstor_venues.csv,Human Rights Quarterly,Research-article,JSTOR,NA
Human-Computer Interaction,A Reformation Proposal of the Process Phase in the Computer-Supported Collaborative Learning,"Agredo-Delgado, Vanessa;Ruiz, Pablo H.;Collazos, Cesar A.;Fardoun, Habib M.","One of the important needs of the companies is form interdisciplinary expert groups on specific topics that contribute to a decision-making process and the solution of complex problems, more efficiently, which has led to seeking the challenge of achieving an adequate collaboration and better productivity, allowing common objectives to be achieved through interaction with the rest of the group. The education has not been foreign to this need, since it is intended to support students to be more prepared in their collaborative skills and to form collaborative citizens who, together, can solve key problems of society. This is where the definition of computer-supported collaborative learning( CSCL) appears, which focuses mainly on the study of how people can learn together with the help of computers. The CSCL is divided into three phases according to its temporal execution: Pre-Process, Process and Post-Process. The Process phase is carried out mainly by the students, where the interactions of the learning process and collaboration are materialized. In this paper, we propose an elements refinement of the Process stage, in addition to its validation through the usefulness, applicability, and ease of use. Obtaining as a result that, our proposal is useful and applicable, but despite this, due to the amount of information necessary for its ap-plication it does not ease of use. Thus, we have contributed to the enrichment of the learning process elements in the Process stage which can be used in the execution of the collaborative activities.",2019,http://dx.doi.org/10.1007/978-3-030-37386-3_2,10.1007/978-3-030-37386-3_2,NA,top-tier,yes,human-computer interaction,0.9,"The journal ""Human-Computer Interaction"" is a well-regarded and established publication venue within the HCI community, known for publishing high-quality research. It is peer-reviewed, contributing significantly to the field, and is considered top-tier based on its reputation and impact.",springnature_venues.csv,Human-Computer Interaction,Chapter ConferencePaper,Springer,NA
Human-Computer Interaction Conference (INTERACT),A Systematic Review of Thermal and Cognitive Stress Indicators: Implications for Use Scenarios on Sensor-Based Stress Detection,"Carrizosa-Botero, Susana;Rendón-Vélez, Elizabeth;Roldán-Rojo, Tatiana A.","A systematic literature review aiming to identify the characteristics of physiological signals on two types of stress states - single moderate thermal stress state and moderate thermal stress combined with cognitive stress state – was conducted. Results of the review serve as a backdrop to envision different scenarios on the detection of these stress states in everyday situations, such as in schools, workplaces and residential settings, where the use of interactive technologies is commonplace. Stress detection is one of the most studied areas of affective computing. However, current models developed for stress detection only focus on recognizing whether a person is stressed, but not on identifying stress states. It is essential to differentiate them in order to implement strategies to minimize the source of stress by designing different interactive technologies. Wearables are commonly used to acquire physiological signals, such as heart rate and respiratory rate. Analysis results of these signals can support a user to make a decision for taking actions or to make an automatic system undertake certain strategies to counteract the sources of stress. These technologies can be designed for educational, work or medical environments. Our future work is to validate these use scenarios systematically to enhance the design of the technologies.",2021,http://dx.doi.org/10.1007/978-3-030-85623-6_7,10.1007/978-3-030-85623-6_7,NA,top-tier,yes,human-computer interaction,0.9,"INTERACT is a reputable conference in Human-Computer Interaction, organized by the International Federation for Information Processing (IFIP). Being a notable conference, it is peer-reviewed and is considered top-tier in its research community.",springnature_venues.csv,Human-Computer Interaction – INTERACT 2021,Chapter ConferencePaper,Springer,NA
Human-Computer Interaction Conference (INTERACT),Acceptance of an AR-Based In-Store Shopping Advisor - the Impact of Psychological User Characteristics,"Álvarez Márquez, Jesús Omar;Ziegler, Jürgen","We present a study on the acceptance of augmented reality-based product comparison and recommending in a physical store context. An online study was performed, in which a working prototype for head-mounted displays, developed in previous research, was used to showcase the concept. The survey included questionnaires to assess shopping behaviour, decision styles and propensity to adopt new technologies of the participants. A cluster analysis of these psychological traits reveals the existence of different types of customers, who also differ on their assessment of the system. While the technology adoption propensity index is the better predictor of the acceptance of an augmented reality shopping advisor, the results suggest that factors such as the user’s previous experience, a high experiential chronic shopping orientation, or an intuitive decision style have a significant impact on it as well. Thus, predicting user acceptance solely based on one of the investigated psychological traits may be unreliable, and studying them in conjunction can provide a more accurate estimation.",2021,http://dx.doi.org/10.1007/978-3-030-85623-6_28,10.1007/978-3-030-85623-6_28,NA,top-tier,yes,human-computer interaction,0.9,"INTERACT is a reputable conference in Human-Computer Interaction, organized by the International Federation for Information Processing (IFIP). Being a notable conference, it is peer-reviewed and is considered top-tier in its research community.",springnature_venues.csv,Human-Computer Interaction – INTERACT 2021,Chapter ConferencePaper,Springer,NA
Human-Computer Interaction Conference (INTERACT),AI-Based Clinical Decision Support Tool on Mobile Devices for Neurodegenerative Diseases,"Loiotile, Annamaria Demarinis;Dentamaro, Vincenzo;Giglio, Paolo;Impedovo, Donato","Recently, the role of AI in the development of eHealth is becoming increasingly ambitious since AI is allowing the development of whole new healthcare areas. In many cases, AI offers the possibility to support patient screening and monitoring through low-cost, non-invasive tests. One of the most relevant sectors in which a great contribution from AI is expected is that of neurodegenerative diseases, which represent one of the most important pathologies in Western countries with very serious follow up not only clinical, but also social and economic. In this context, AI certainly represents an indispensable tool for effectively addressing aspects related to early diagnosis but also to monitoring patients suffering from various neurodegenerative diseases. To achieve these results, AI tools must be made available in test applications on mobile devices that are also easy to use by a large part of the population. In this sense, the aspects related to human-machine interaction are of paramount relevance for the diffusion of these solutions. This article presents a mobile device application based on artificial intelligence tools for the early diagnosis and monitoring of patients suffering from neurodegenerative diseases and illustrates the results of specific usability tests that highlight the strengths but also the limitations in the iteration with application users. Some concluding remarks are highlighted to face the actual limitations of the proposed solution.",2021,http://dx.doi.org/10.1007/978-3-030-85623-6_10,10.1007/978-3-030-85623-6_10,NA,top-tier,yes,human-computer interaction,0.9,"INTERACT is a reputable conference in Human-Computer Interaction, organized by the International Federation for Information Processing (IFIP). Being a notable conference, it is peer-reviewed and is considered top-tier in its research community.",springnature_venues.csv,Human-Computer Interaction – INTERACT 2021,Chapter ConferencePaper,Springer,NA
Human-Computer Interaction Conference (INTERACT),Co-designing Tangible Break Reminders with People with Repetitive Strain Injury,"Singh, Aditi;Nabil, Sara;Roudaut, Anne;Girouard, Audrey","People with Repetitive Strain Injury( RSI) performing computer work for 4+ hours/day should take microbreaks every hour to reduce their symptoms. Unlike apps and notifications, tangible user interfaces offer the opportunity to provide non-focus-demanding and calm break-reminders in users’ periphery. This paper explores this design space to identify the design parameters of break-reminders as everyday things. First, we discuss and analyze our initial co-designing study, where 11 participants with RSI created 9 low-fidelity prototypes. Then, we present our results-led high-fidelity prototypes and demonstrate the use of the findings in directing the design decisions of the technical implementation. Finally, we take our designs back to users in a second study to gain deeper insight on their reflection on physical break reminders. Results show how users designed for calmness and ubiquity in their everyday environment, playful user engagement and emotional shape-shifting among other design qualities.",2021,http://dx.doi.org/10.1007/978-3-030-85623-6_18,10.1007/978-3-030-85623-6_18,NA,top-tier,yes,human-computer interaction,0.9,"INTERACT is a reputable conference in Human-Computer Interaction, organized by the International Federation for Information Processing (IFIP). Being a notable conference, it is peer-reviewed and is considered top-tier in its research community.",springnature_venues.csv,Human-Computer Interaction – INTERACT 2021,Chapter ConferencePaper,Springer,NA
Human-Computer Interaction Conference (INTERACT),Cognitive Limitations of Older E-Commerce Customers in Product Comparison Tasks,"Rydzewska, Klara;Pawłowska, Justyna;Nielek, Radosław;Wierzbicki, Adam;Sedek, Grzegorz","The number of older consumers making e-commerce purchasing decisions is constantly rising. We examined the impact of age-related cognitive limitations on older adults’ choices in a series of multi-attribute choice tasks designed to mimic the process of products comparison and selection on e-commerce platforms. 135 older, middle-aged and younger adults were asked to participate in an on-line experiment. We found significant age-related limitations in solving simple and moderately difficult tasks, especially in the older adults group. The mediational model indicated an interplay between the age-related limitation and the role of additional variables( Helplessness of Contracting an Infectious Disease and Numeracy) in explaining the relationship between aging and performance in the multi-attribute choice task.",2021,http://dx.doi.org/10.1007/978-3-030-85613-7_41,10.1007/978-3-030-85613-7_41,NA,top-tier,yes,human-computer interaction,0.9,"INTERACT is a reputable conference in Human-Computer Interaction, organized by the International Federation for Information Processing (IFIP). Being a notable conference, it is peer-reviewed and is considered top-tier in its research community.",springnature_venues.csv,Human-Computer Interaction – INTERACT 2021,Chapter ConferencePaper,Springer,NA
Icarus: International Journal of Solar System Studies,A comparative analysis of machine learning classifiers in the classification of resonant asteroids,Evgeny Smirnov,"This study explores how well various machine learning classifiers can identify mean-motion resonances in the main belt using supervised learning. The most popular classifiers are assessed: k-Nearest Neighbours, Decision Tree, Gradient Boosting, AdaBoost, Random Forest, and Naïve Bayes. In contrast to previous studies that often relied on default ML configurations, this research conducts a detailed investigation, fine-tuning, and testing of each classifier across various parameters. The results show that simpler models, especially k-Nearest Neighbours and Decision Tree, perform better than more complex ones, particularly in terms of F1 scores. The paper provides guides on selecting features, parameters, and training set sizes for optimal classifier performance and outlines a method for developing effective machine-learning models for asteroid classification.",2024,https://www.sciencedirect.com/science/article/pii/S0019103524001180,https://doi.org/10.1016/j.icarus.2024.116058,NA,top-tier,yes,planetary science,0.9,"Icarus is a well-respected journal in the field of planetary science, frequently publishing influential research. It is widely regarded as a leading venue for work related to the study of the solar system.",elsevier_venues.csv,Icarus,NA,Elsevier,NA
IEEE Annual International Symposium on Field-Programmable Custom Computing Machines,Decision Forest Training Accelerator Based on Binary Feature Decomposition,Thiem Van Chu;Yu Mizutani;Yuta Nagahara;Shungo Kumazawa;Kazushi Kawamura;Jaehoon Yu;Masato Motomura,"In recent years, while Deep Neural Networks (DNNs) have revolutionized various fields, it is widely acknowledged that they are not always the optimal solution, and complementary Machine Learning (ML) tools are necessary. For instance, developing DNN models that can effectively handle tabular data with rows and columns remains a challenging open question. Additionally, the difficulty of interpreting DNN models poses a significant obstacle that hinders their use in many practical applications where the interpretability of the inference results and the ability to offer advice on how to modify input for desired output are required. In such cases, Decision Forests (DFs) have been widely considered a promising solution.",2023,https://ieeexplore.ieee.org/document/10171586,10.1109/FCCM57271.2023.00043,1,top-tier,yes,"computer engineering, reconfigurable computing",0.9,"Known as FCCM, this conference focuses on field-programmable technology and custom computing, areas critical to advancements in hardware design. Being IEEE sponsored, peer-reviewed, and widely respected, it is considered a top-tier venue.",ieee_venues.csv,IEEE Annual International Symposium on Field-Programmable Custom Computing Machines,NA,IEEE,NA
"IEEE Annual International Symposium on Personal, Indoor, and Mobile Radio Communications",A Deep Reinforcement Learning Approach for Dependency-Aware Task Offloading in Cooperative Vehicular Networks,Yixin Fan;Xuelian Cai;Wenwei Yue;Jing Zheng;Changle Li,"To investigate the diversified applications in vehicular networks, artificial intelligence, intelligent edge computing, and vehicular networks are combined. By offloading computation tasks to devices close to vehicles, Vehicular Edge Computing (VEC) has emerged as a new computing paradigm to tackle the problem. Most existing VEC methods simply slice the application into subtasks for offloading purposes without considering the dependencies between subtasks. In practice, the dependency information is critical to the efficiency of offloading strategies. If a subtask requires the computation result of another subtask, the latter has to be processed before the former is finished. In this paper, we propose a deep reinforcement learning based offloading strategy for multi-vehicle collaboration VEC, with task dependency taken into account. With the proposed strategy, we formulate the offloading problem as an Markov Decision Process (MDP) and use the Sequence-to-Sequence (S2S) neural network to represent the policy/value function of the MDP. Furthermore, we train the S2S neural network to obtain the appropriate offloading policy using the Proximal Policy Optimization (PPO) technique. Our simulation results indicate that, by considering task dependencies during offloading, the proposed strategy outperforms existing methods in effectively reducing task offloading latencies.",2023,https://ieeexplore.ieee.org/document/10294053,10.1109/PIMRC56721.2023.10294053,6,top-tier,yes,"wireless communications, mobile networks",0.9,"This symposium is a leading venue for presenting advanced research in wireless communications and mobile networking, attracting a large number of high-quality submissions and attendees from academia and industry.",ieee_venues.csv,"IEEE Annual International Symposium on Personal, Indoor, and Mobile Radio Communications",NA,IEEE,NA
"IEEE Annual International Symposium on Personal, Indoor, and Mobile Radio Communications",A Deep Reinforcement Learning Approach for Federated Learning Optimization with UAV Trajectory Planning,Chunyu Zhang;Yiming Liu;Zhi Zhang,"Federated learning (FL) provides an efficient distributed learning framework for computing-constrained Unmanned aerial vehicles (UAVs) swarms. However, due to the dynamic channel condition and limited resources in UAV swarm, the efficiency of FL requires to be further improved. In this paper, by leveraging the motion characteristics of UAVs, we propose an energy-efficient FL framework based on trajectory planning to train machine learning (ML) models. In the proposed framework, a two-level UAV swarm is established, consisting of a high-level UAV (H-UAV) and a group of low-level UAVs (L-UAVs). Considering the limited energy resources of the UAVs, our primary objective is to minimize the flight energy consumption of the H-UAV as it is much higher than the communication and computation energy consumption. To achieve this goal, we formulate the optimization problem jointly considering the adjustment of FL training parameters and the trajectory planning of H-UAV. Then, we reformulate the problem as a Markov decision process (MDP) and employ soft actor-critic (SAC) and deep deterministic policy gradient (DDPG) algorithms to tackle it. Simulation results show that the proposed approach and the proposed algorithms have good performance.",2023,https://ieeexplore.ieee.org/document/10293884,10.1109/PIMRC56721.2023.10293884,7,top-tier,yes,"wireless communications, mobile networks",0.9,"This symposium is a leading venue for presenting advanced research in wireless communications and mobile networking, attracting a large number of high-quality submissions and attendees from academia and industry.",ieee_venues.csv,"IEEE Annual International Symposium on Personal, Indoor, and Mobile Radio Communications",NA,IEEE,NA
"IEEE Annual International Symposium on Personal, Indoor, and Mobile Radio Communications",A Novel Conditional Handover Scheme based on Deep Reinforcement Learning for mmWave Systems,Juhyoung Sung;Wongi Jeon;Sungyoon Cho;Kiwon Kwon,"For the future wireless communication systems, millimeter wave (mmWave) frequency bands have been considered as an attractive candidate since the bands can meet high data rate requirements by utilizing a broadband spectrum. However, transmitting signals over the long distances is difficult in the bands compared to typical microwave bands due to the property of mmWave’s intense straightness, which leads densely deployed mmWave base stations (BSs). The probability that user equipments (UEs) experience frequent handover (HO) also increases as the number of BSs increases. Therefore, an elaborate HO strategy is required since inadequate HO leads frequent ping-pong or radio link failure (RLF) which is critical for the communication link quality. Meanwhile, 3GPP introduced conditional handover (CHO) in Release 16. Since CHO allows UEs to decide whether to carry out HO or not, CHO is different from the legacy HO method. By focusing on this potential of CHO, we propose a novel CHO management scheme based on a deep reinforcement learning (DRL) for mmWave systems to balance HO rates and a spectral efficiency in this paper. The simulation results show that the proposed DRL based-CHO scheme has superior performance compared to the conventional hysteresis-based HO decision.",2023,https://ieeexplore.ieee.org/document/10293873,10.1109/PIMRC56721.2023.10293873,7,top-tier,yes,"wireless communications, mobile networks",0.9,"This symposium is a leading venue for presenting advanced research in wireless communications and mobile networking, attracting a large number of high-quality submissions and attendees from academia and industry.",ieee_venues.csv,"IEEE Annual International Symposium on Personal, Indoor, and Mobile Radio Communications",NA,IEEE,NA
IEEE Communications Magazine,The Matrix: Quantum AI for Interacting Two Worlds in Prioritized Metaverse Spaces,Soohyun Park;Hankyul Baek;Joongheon Kim,"In modern network applications, the concept of metaverse is an emerging technology, and one of its key characteristics is the separation between the physical-space of the users and the virtual meta-space of the avatars. Based on this, a novel quantum multi-agent reinforcement learning (QMARL)-based scheduler, prioritizing the improvement of the performance of meta-space rendering is proposed in this article. The increase in performance can be achieved by controlling the number of utilized point cloud segments depending on avatar-popularity under the consideration of physical-space constraints. During this process, QMARL-centered quantum artificial intelligence (AI) algorithms are utilized for sequential scheduling action decision-making over time. By utilizing this QMARL, our proposed scheduler is designed to reduce the number of scheduling action dimensions into logarithmic scales. This is beneficial in the noisy intermediate-scale quantum (NISQ) era as the number of usable qubits is inherently limited. After this QMARL-based scheduling, the scheduled regions will be re-constructed over meta-space with prioritized point cloud registration. Finally, our performance evaluation results show that our proposed scheduler outperforms classical multi-agent reinforcement learning (MARL)-based scheduling in terms of utility between 12.6 and 20.7 percent, under various avatar distributions.",2024,https://ieeexplore.ieee.org/document/10707052,10.1109/MCOM.001.2300457,NA,top-tier,yes,telecommunications,0.9,"IEEE Communications Magazine is highly regarded within the telecommunications field, known for publishing cutting-edge research and surveys. It is recognized as a top-tier journal due to its high impact factor and widespread readership within the academic and industry communities.",ieee_venues.csv,IEEE Communications Magazine,NA,IEEE,NA
IEEE Communications Surveys & Tutorials,A Survey on Artificial Intelligence Techniques for Improved Rich Media Content Delivery in a 5G and Beyond Network Slicing Context,Fazal E Subhan;Abid Yaqoob;Cristina Hava Muntean;Gabriel-Miro Muntean,"Network slicing is an emerging paradigm driven by an objective to provide support for personalized services in the highly evolving and dynamic 5G and beyond network environment. The management of network functions and resources under network slicing architecture for rich media content delivery is a challenging task that requires an efficient decision at all network levels to maintain the required Quality of Service (QoS) and Quality of Experience (QoE). Integrating Artificial Intelligence (AI) in the network slice architecture for taking efficient network decision is one of the potential solutions to the problem. In this paper, we summarize the network slicing enabling technologies such as Software Defined Network (SDN), Network Function Virtualization (NFV), Multi-access Edge Computing (MEC) in the context of AI for improving the rich media content delivery. In addition, we present a comprehensive survey on content-centric networking and delivery solutions based on network slicing technologies i.e., MPEG-DASH-enabled Information Centric Networking (ICN) and Content Delivery Network (CDN) for intelligent rich media content caching and prefetching, predictive analysis, content preference optimization, secure resource allocation, and dynamic traffic steering. Several standardization and orchestration mechanisms of 5G network slicing proposed by 3GPP are then presented. Finally, the challenges of AI-enabled 5G network slicing for immersive content delivery are outlined with potential solutions and future research opportunities.",2024,https://ieeexplore.ieee.org/document/10636754,10.1109/COMST.2024.3442149,NA,top-tier,yes,communications,1,"IEEE Communications Surveys & Tutorials is a highly respected journal known for comprehensive, scholarly review articles in the field of communications, indicating its top-tier status, with rigorous peer-review as standard for IEEE publications.",ieee_venues.csv,IEEE Communications Surveys & Tutorials,NA,IEEE,NA
IEEE Communications Surveys & Tutorials,"A Survey on XAI for 5G and Beyond Security: Technical Aspects, Challenges and Research Directions",Thulitha Senevirathna;Vinh Hoa La;Samuel Marchal;Bartlomiej Siniarski;Madhusanka Liyanage;Shen Wang,"With the advent of 5G commercialization, the need for more reliable, faster, and intelligent telecommunication systems is envisaged for the next generation beyond 5G (B5G) radio access technologies. Artificial Intelligence (AI) and Machine Learning (ML) are immensely popular in service layer applications and have been proposed as essential enablers in many aspects of 5G and beyond networks, from IoT devices and edge computing to cloud-based infrastructures. However, existing 5G ML-based security surveys tend to emphasize AI/ML model performance and accuracy more than the models’ accountability and trustworthiness. In contrast, this paper explores the potential of Explainable AI (XAI) methods, which would allow stakeholders in 5G and beyond to inspect intelligent black-box systems used to secure next-generation networks. The goal of using XAI in the security domain of 5G and beyond is to allow the decision-making processes of ML-based security systems to be transparent and comprehensible to 5G and beyond stakeholders, making the systems accountable for automated actions. In every facet of the forthcoming B5G era, including B5G technologies such as ORAN, zero-touch network management, and end-to-end slicing, this survey emphasizes the role of XAI in them that the general users would ultimately enjoy. Furthermore, we presented the lessons from recent efforts and future research directions on top of the currently conducted projects involving XAI.",2024,https://ieeexplore.ieee.org/document/10620685,10.1109/COMST.2024.3437248,NA,top-tier,yes,communications,1,"IEEE Communications Surveys & Tutorials is a highly respected journal known for comprehensive, scholarly review articles in the field of communications, indicating its top-tier status, with rigorous peer-review as standard for IEEE publications.",ieee_venues.csv,IEEE Communications Surveys & Tutorials,NA,IEEE,NA
IEEE Communications Surveys & Tutorials,"AI-Empowered Fog/Edge Resource Management for IoT Applications: A Comprehensive Review, Research Challenges, and Future Perspectives",Guneet Kaur Walia;Mohit Kumar;Sukhpal Singh Gill,"The proliferation of ubiquitous Internet of Things (IoT) sensors and smart devices in several domains embracing healthcare, Industry 4.0, transportation and agriculture are giving rise to a prodigious amount of data requiring ever-increasing computations and services from cloud to the edge of the network. Fog/Edge computing is a promising and distributed computing paradigm that has drawn extensive attention from both industry and academia. The infrastructural efficiency of these computing paradigms necessitates adaptive resource management mechanisms for offloading decisions and efficient scheduling. Resource Management (RM) is a non-trivial issue whose complexity is the result of heterogeneous resources, incoming transactional workload, edge node discovery, and Quality of Service (QoS) parameters at the same time, which makes the efficacy of resources even more challenging. Hence, the researchers have adopted Artificial Intelligence (AI)-based techniques to resolve the above-mentioned issues. This paper offers a comprehensive review of resource management issues and challenges in Fog/Edge paradigm by categorizing them into provisioning of computing resources, task offloading, resource scheduling, service placement, and load balancing. In addition, existing AI and non-AI based state-of-the-art solutions have been discussed, along with their QoS metrics, datasets analysed, limitations and challenges. The survey provides mathematical formulation corresponding to each categorized resource management issue. Our work sheds light on promising research directions on cutting-edge technologies such as Serverless computing, 5G, Industrial IoT (IIoT), blockchain, digital twins, quantum computing, and Software-Defined Networking (SDN), which can be integrated with the existing frameworks of fog/edge-of-things paradigms to improve business intelligence and analytics amongst IoT-based applications.",2024,https://ieeexplore.ieee.org/document/10335918,10.1109/COMST.2023.3338015,51,top-tier,yes,communications,1,"IEEE Communications Surveys & Tutorials is a highly respected journal known for comprehensive, scholarly review articles in the field of communications, indicating its top-tier status, with rigorous peer-review as standard for IEEE publications.",ieee_venues.csv,IEEE Communications Surveys & Tutorials,NA,IEEE,NA
IEEE Communications Surveys & Tutorials,"AI-Enhanced Cloud-Edge-Terminal Collaborative Network: Survey, Applications, and Future Directions",Huixian Gu;Liqiang Zhao;Zhu Han;Gan Zheng;Shenghui Song,"The cloud-edge-terminal collaborative network (CETCN) is considered as a novel paradigm for emerging applications owing to its huge potential in providing low-latency and ultra-reliable computing services. However, achieving such benefits is very challenging due to the heterogeneous computing power of terminal devices and the complex environment faced by the CETCN. In particular, the high-dimensional and dynamic environment states cause difficulties for the CETCN to make efficient decisions in terms of task offloading, collaborative caching and mobility management. To this end, artificial intelligence (AI), especially deep reinforcement learning (DRL) has been proven effective in solving sequential decision-making problems in various domains, and offers a promising solution for the above-mentioned issues due to several reasons. Firstly, accurate modelling of the CETCN, which is difficult to obtain for real-world applications, is not required for the DRL-based method. Secondly, DRL can effectively respond to high-dimensional and dynamic tasks through iterative interactions with the environment. Thirdly, due to the complexity of tasks and the differences in resource supply among different vendors, collaboration is required between different vendors to complete tasks. The multi-agent DRL (MADRL) methods are very effective in solving collaborative tasks, where the collaborative tasks can be jointly completed by cloud, edge and terminal devices which provided by different vendors. This survey provides a comprehensive overview regarding the applications of DRL and MADRL in the context of CETCN. The first part of this survey provides a depth overview of the key concepts of the CETCN and the mathematical underpinnings of both DRL and MADRL. Then, we highlight the applications of RL algorithms in solving various challenges within CETCN, such as task offloading, resource allocation, caching and mobility management. In addition, we extend discussion to explore how DRL and MADR...",2024,https://ieeexplore.ieee.org/document/10336879,10.1109/COMST.2023.3338153,64,top-tier,yes,communications,1,"IEEE Communications Surveys & Tutorials is a highly respected journal known for comprehensive, scholarly review articles in the field of communications, indicating its top-tier status, with rigorous peer-review as standard for IEEE publications.",ieee_venues.csv,IEEE Communications Surveys & Tutorials,NA,IEEE,NA
IEEE Conference on Automation Science and Engineering,Comparison study of two reinforcement learning based real-time control policies for two-machine-one-buffer production system,Wei Zheng;Yong Lei;Qing Chang,"Real-time control policy of production system is attractive to reduce the total cost that is mainly composed of the production cost, the penalty of the permanent production loss, and the Work-In-Process(WIP) inventory level cost. Because of the starved and blocked phenomena, the random failures and the maintenances, it is difficult to analyze production system, let alone to find a good control policy. Two reinforcement learning based control decision policies are proposed based on the actions of switching the machines on or off at the start of each time slot. Samples collected from a simulated model are used to obtain two sub-optimal policies named LSPI and T H. TH policy is a simplified form of LSPI, while LSPI performs better in reducing total production cost.",2017,https://ieeexplore.ieee.org/document/8256260,10.1109/COASE.2017.8256260,6,top-tier,yes,"automation, engineering",0.9,"The IEEE Conference on Automation Science and Engineering (CASE) is a well-regarded event within the automation and engineering fields, focusing on emerging technologies and methodologies. It is peer-reviewed and attracts leading researchers, thus recognized as top-tier.",ieee_venues.csv,IEEE Conference on Automation Science and Engineering,NA,IEEE,NA
IEEE Conference on Automation Science and Engineering,Complexity analysis of reinforcement learning and its application to robotics,Bocheng Li;Li Xia;Qianchuan Zhao,"Reinforcement learning (RL) is a widely adopted theory in machine learning, which aims to handle the optimal decision of intelligent agent interacting with the stochastic dynamic environment. Its origin may come from the motivation of phycological observations since 1960's [1]. It blooms recently as the emerging of large sample data and powerful computation facility, especially the AlphaGo's beat over the human top Go player in 2016 [2].",2017,https://ieeexplore.ieee.org/document/8256303,10.1109/COASE.2017.8256303,2,top-tier,yes,"automation, engineering",0.9,"The IEEE Conference on Automation Science and Engineering (CASE) is a well-regarded event within the automation and engineering fields, focusing on emerging technologies and methodologies. It is peer-reviewed and attracts leading researchers, thus recognized as top-tier.",ieee_venues.csv,IEEE Conference on Automation Science and Engineering,NA,IEEE,NA
IEEE Conference on Automation Science and Engineering,Dynamic dispatching for re-entrant production lines — A deep learning approach,Fang-Yi Zhou;Cheng-Hung Wu;Cheng-Juei Yu,"This study presents a dynamic dispatching method for re-entrant production systems by combing dynamic programming (DP) with deep learning. First, we use DP to derive optimal value functions and optimal dispatching policies in a small number of numerical cases. The optimal value functions are then applied to train a deep neural network (DNN). The DNN builds an efficient estimation engine for optimal value functions. Since optimal dispatching decisions can be considered a compressed feature of the optimal value function, the value function estimated by DNN can be quickly mapped to dynamic dispatching policies. The accuracy of DNN dispatching policies is validated by the k-fold cross-validation (k-cv) test in a wide variety of re-entrant systems. Our preliminary investigation shows the potential of DNN in instantaneously generating accurate dynamic dispatching policies.",2017,https://ieeexplore.ieee.org/document/8256238,10.1109/COASE.2017.8256238,6,top-tier,yes,"automation, engineering",0.9,"The IEEE Conference on Automation Science and Engineering (CASE) is a well-regarded event within the automation and engineering fields, focusing on emerging technologies and methodologies. It is peer-reviewed and attracts leading researchers, thus recognized as top-tier.",ieee_venues.csv,IEEE Conference on Automation Science and Engineering,NA,IEEE,NA
IEEE Conference on Automation Science and Engineering,Nonlinear programming for multi-vehicle motion planning with homotopy initialization strategies,Bai Li;Zhijiang Shao;Youmin Zhang;Pu Li,"Multi-vehicle motion planning (MVMP) is a critical decision-making module in intelligent transportation systems. Compared to the decentralized MVMP methods, centralized MVMP methods are beneficial in being generic and complete, because information of all the vehicles is simultaneously considered. This study formulates the MVMP problems as centralized optimal control problems. These problems are parameterized into nonlinear programming (NLP) problems for the convenience of numerical solution. In solving those NLPs, the main challenges lie in the large scale of collision-avoidance constraints, and the high nonlinearity of vehicle kinematics. The typical NLP solvers are inefficient in directly handling such difficulties. It is widely known that the initialization has a significant influence on the NLP solving behavior. Therefore, homotopy initialization strategies are developed in this work to generate the initial guess. The main idea of homotopy is that simplified subproblems are solved in a sequence such that each subproblem is closer to the original problem; the solution to each subproblem serves as the initial guess to facilitate the solving process of the next subproblem. This process continues until the original problem is solved. The efficiency of the proposed initialization strategies is verified via numerical experimentation and theoretical analysis.",2017,https://ieeexplore.ieee.org/document/8256090,10.1109/COASE.2017.8256090,6,top-tier,yes,"automation, engineering",0.9,"The IEEE Conference on Automation Science and Engineering (CASE) is a well-regarded event within the automation and engineering fields, focusing on emerging technologies and methodologies. It is peer-reviewed and attracts leading researchers, thus recognized as top-tier.",ieee_venues.csv,IEEE Conference on Automation Science and Engineering,NA,IEEE,NA
IEEE Conference on Communications and Network Security,A Machine Learning-based Approach for Automated Vulnerability Remediation Analysis,Fengli Zhang;Philip Huff;Kylie McClanahan;Qinghua Li,"Security vulnerabilities in firmware/software pose an important threat ton power grid security, and thus electric utility companies should quickly decide how to remediate vulnerabilities after they are discovered. Making remediation decisions is a challenging task in the electric industry due to the many factors to consider, the balance to maintain between patching and service reliability, and the large amount of vulnerabilities to deal with. Unfortunately, remediation decisions are current manually made which take a long time. This increases security risks and incurs high cost of vulnerability management. In this paper, we propose a machine learning-based automation framework to automate remediation decision analysis for electric utilities. We apply it to an electric utility and conduct extensive experiments over two real operation datasets obtained from the utility. Results show the high effectiveness of the solution.",2020,https://ieeexplore.ieee.org/document/9162309,10.1109/CNS48642.2020.9162309,9,top-tier,yes,"computer science, cybersecurity",0.9,"The IEEE CNS is a well-regarded conference focusing on communications and network security topics, drawing high-quality research papers and experts in the cybersecurity domain. IEEE's reputation in engineering and technology strengthens its standing.",ieee_venues.csv,IEEE Conference on Communications and Network Security,NA,IEEE,NA
IEEE Conference on Communications and Network Security,ACADIA: Efficient and Robust Adversarial Attacks Against Deep Reinforcement Learning,Haider Ali;Mohannad Al Ameedi;Ananthram Swami;Rui Ning;Jiang Li;Hongyi Wu;Jin-Hee Cho,"Existing adversarial algorithms for Deep Reinforcement Learning (DRL) have largely focused on identifying an optimal time to attack a DRL agent. However, little work has been explored in injecting efficient adversarial perturbations in DRL environments. We propose a suite of novel DRL adversarial attacks, called ACADIA, representing AttaCks Against Deep reInforcement leArning. ACADIA provides a set of efficient and robust perturbation-based adversarial attacks to disturb the DRL agent's decision-making based on novel combinations of techniques utilizing momentum, ADAM optimizer (i.e., Root Mean Square Propagation, or RMSProp), and initial randomization. These kinds of DRL attacks with novel integration of such techniques have not been studied in the existing Deep Neural Networks (DNNs) and DRL research. We consider two well-known DRL algorithms, Deep-Q Learning Network (DQN) and Proximal Policy Optimization (PPO), under Atari games and MuJoCo where both targeted and non-targeted attacks are considered with or without the state-of-the-art defenses in DRL (i.e., RADIAL and ATLA). Our results demonstrate that the proposed ACADIA outperforms existing gradient-based counterparts under a wide range of experimental settings. ACADIA is nine times faster than the state-of-the-art Carlini & Wagner (CW) method with better performance under defenses of DRL.",2022,https://ieeexplore.ieee.org/document/9947234,10.1109/CNS56114.2022.9947234,9,top-tier,yes,"computer science, cybersecurity",0.9,"The IEEE CNS is a well-regarded conference focusing on communications and network security topics, drawing high-quality research papers and experts in the cybersecurity domain. IEEE's reputation in engineering and technology strengthens its standing.",ieee_venues.csv,IEEE Conference on Communications and Network Security,NA,IEEE,NA
IEEE Conference on Decision and Control,A Policy Gradient Approach for Finite Horizon Constrained Markov Decision Processes,Soumyajit Guin;Shalabh Bhatnagar,"The infinite horizon setting is widely adopted for problems of reinforcement learning (RL). These invariably result in stationary policies that are optimal. In many situations, finite horizon control problems are of interest and for such problems, the optimal policies are time-varying in general. Another setting that has become popular in recent times is of Constrained Reinforcement Learning, where the agent maximizes its rewards while it also aims to satisfy some given constraint criteria. However, this setting has only been studied in the context of infinite horizon MDPs where stationary policies are optimal. We present an algorithm for constrained RL in the Finite Horizon Setting where the horizon terminates after a fixed (finite) time. We use function approximation in our algorithm which is essential when the state and action spaces are large or continuous and use the policy gradient method to find the optimal policy. The optimal policy that we obtain depends on the stage and so is non-stationary in general. To the best of our knowledge, our paper presents the first policy gradient algorithm for the finite horizon setting with constraints. We show the convergence of our algorithm to a constrained optimal policy. We also compare and analyze the performance of our algorithm through experiments and show that our algorithm performs better than some other well known algorithms.",2023,https://ieeexplore.ieee.org/document/10383413,10.1109/CDC49753.2023.10383413,7,top-tier,yes,"control systems, automation",0.95,"The IEEE Conference on Decision and Control is a prestigious conference known for its high-quality papers in control systems and automation. It is peer-reviewed, attracting top researchers and practitioners in the area.",ieee_venues.csv,IEEE Conference on Decision and Control,NA,IEEE,NA
IEEE Conference on Decision and Control,A Reinforcement Learning Approach to Sensing Design in Resource-Constrained Wireless Networked Control Systems,Luca Ballotta;Giovanni Peserico;Francesco Zanini,"In this paper, we consider a wireless network of smart sensors (agents) that monitor a dynamical process and send measurements to a base station that performs global monitoring and decision-making. Smart sensors are equipped with both sensing and computation, and can either send raw measurements or process them prior to transmission. Constrained agent resources raise a fundamental latency-accuracy trade-off. On the one hand, raw measurements are inaccurate but fast to produce. On the other hand, data processing on resource-constrained platforms generates accurate measurements at the cost of non-negligible computation latency. Further, if processed data are also compressed, latency caused by wireless communication might be higher for raw measurements. Hence, it is challenging to decide when and where sensors in the network should transmit raw measurements or leverage time-consuming local processing. To tackle this design problem, we propose a Reinforcement Learning approach to learn an efficient policy that dynamically decides when measurements are to be processed at each sensor. Effectiveness of our proposed approach is validated through a numerical simulation with case study on smart sensing motivated by the Internet of Drones.",2022,https://ieeexplore.ieee.org/document/9993151,10.1109/CDC51059.2022.9993151,6,top-tier,yes,"control systems, automation",0.95,"The IEEE Conference on Decision and Control is a prestigious conference known for its high-quality papers in control systems and automation. It is peer-reviewed, attracting top researchers and practitioners in the area.",ieee_venues.csv,IEEE Conference on Decision and Control,NA,IEEE,NA
IEEE Conference on Decision and Control,A Scale-Independent Multi-Objective Reinforcement Learning with Convergence Analysis,Mohsen Amidzadeh,"Many sequential decision-making problems need optimization of different objectives which possibly conflict with each other. The conventional way to deal with a multitask problem is to establish a scalar objective function based on a linear combination of different objectives. However, for the case where we have conflicting objectives with different scales, this method needs a trial-and-error approach to properly find proper weights for the combination. As such, in most cases, this approach cannot guarantee an optimal Pareto solution. In this paper, we develop a single-agent scale-independent multi-objective reinforcement learning on the basis of the Advantage Actor-Critic (A2C) algorithm. A convergence analysis is then done for the devised multi-objective algorithm providing a convergence-in-mean guarantee. We then perform some experiments over a multitask problem to evaluate the performance of the proposed algorithm. Simulation results show the superiority of developed multi-objective A2C approach against the single-objective algorithm.",2023,https://ieeexplore.ieee.org/document/10383419,10.1109/CDC49753.2023.10383419,8,top-tier,yes,"control systems, automation",0.95,"The IEEE Conference on Decision and Control is a prestigious conference known for its high-quality papers in control systems and automation. It is peer-reviewed, attracting top researchers and practitioners in the area.",ieee_venues.csv,IEEE Conference on Decision and Control,NA,IEEE,NA
IEEE Conference on Decision and Control,Active Task-Inference-Guided Deep Inverse Reinforcement Learning,Farzan Memarian;Zhe Xu;Bo Wu;Min Wen;Ufuk Topcu,"We consider the problem of reward learning for temporally extended tasks. For reward learning, inverse reinforcement learning (IRL) is a widely used paradigm. Given a Markov decision process (MDP) and a set of demonstrations for a task, IRL learns a reward function that assigns a real-valued reward to each state of the MDP. However, for temporally extended tasks, the underlying reward function may not be expressible as a function of individual states of the MDP. Instead, the history of visited states may need to be considered to determine the reward at the current state. To address this issue, we propose an iterative algorithm to learn a reward function for temporally extended tasks. At each iteration, the algorithm alternates between two modules, a task inference module that infers the underlying task structure and a reward learning module that uses the inferred task structure to learn a reward function. The task inference module produces a series of queries, where each query is a sequence of subgoals. The demonstrator provides a binary response to each query by attempting to execute it in the environment and observing the environment's feedback. After the queries are answered, the task inference module returns an automaton encoding its current hypothesis of the task structure. The reward learning module augments the state space of the MDP with the states of the automaton. The module then proceeds to learn a reward function over the augmented state space using a novel deep maximum entropy IRL algorithm. This iterative process continues until it learns a reward function with satisfactory performance. The experiments show that the proposed algorithm significantly outperforms several IRL baselines on temporally extended tasks.",2020,https://ieeexplore.ieee.org/document/9304190,10.1109/CDC42340.2020.9304190,7,top-tier,yes,"control systems, automation",0.95,"The IEEE Conference on Decision and Control is a prestigious conference known for its high-quality papers in control systems and automation. It is peer-reviewed, attracting top researchers and practitioners in the area.",ieee_venues.csv,IEEE Conference on Decision and Control,NA,IEEE,NA
IEEE Conference on Decision and Control,Adversarial Attacks on Computation of the Modified Policy Iteration Method,Ali Yekkehkhany;Han Feng;Javad Lavaei,"Adversarial attacks on Markov decision processes (MDPs) and reinforcement learning (RL) have been studied in the literature in the context of robust learning and adversarial game theory. In this paper, we introduce a new notion of adversarial attacks on MDP and RL computation that is motivated by the emergence of edge computing. The large-scale computation of MDP and RL models in the form of value/policy iteration and Q-learning is being offloaded from agents to distributed servers, giving rise to edge reinforcement learning. By the inherently distributed nature of edge RL, the MDP/RL computation can be prone to adversarial attacks in different forms. We analyze a probabilistic model of adversarial attacks on the computation of the modified policy iteration method in which the principal contraction property of the Bellman operator is undermined with a certain probability in iterations of the policy evaluation step of the aforementioned method. This can result in luring the agent to search among suboptimal policies without improving the true values of policies. We prove that under certain conditions, the attacked modified policy iteration method can still converge to the vicinity of the optimal policy with high probability if the number of policy evaluation iterations is larger than a threshold that is logarithmic in the inverse of a desired precision. We also provide an upper bound on the number of iterations needed for the attacked modified policy iteration method to terminate, which holds with an associated confidence level.",2021,https://ieeexplore.ieee.org/document/9683559,10.1109/CDC45484.2021.9683559,8,top-tier,yes,"control systems, automation",0.95,"The IEEE Conference on Decision and Control is a prestigious conference known for its high-quality papers in control systems and automation. It is peer-reviewed, attracting top researchers and practitioners in the area.",ieee_venues.csv,IEEE Conference on Decision and Control,NA,IEEE,NA
IEEE Global Communications Conference,Utility Optimization for Resource Allocation in Edge Network Slicing Using DRL,Zhaoying Wang;Yifei Wei;F. Richard Yu;Zhu Han,"Network slicing and Multi-access Edge Computing (MEC) have been envisioned as promising technique in the fifth generation mobile communication (5G). In this work, we study joint optimization of radio and computation resource in network slicing with MEC to maximize utility of Mobile Virtual Network Operator (MVNO), while meeting slice Quality of Service (QoS) requirements. On account of the dynamic change of slice demands and environment information, it is hard to solve resource allocation problems with conventional methods. Inspired by the superiority of deep reinforcement learning (DRL) in decision-making problems with the high state space and continuous action space. We formulate the utility maximization problem as a markov decision process (MDP). With an MVNO controller, the problem can be solved utilizing deep deterministic policy gradient (DDPG) algorithm to execute the dynamic resource allocation scheme. Simulation results show that utility performance of the proposed algorithm outperforms than the benchmark algorithms and enables dynamic resource allocation scheme.",2020,https://ieeexplore.ieee.org/document/9322481,10.1109/GLOBECOM42002.2020.9322481,6,top-tier,yes,"communications, networking",0.95,"The IEEE Global Communications Conference (GLOBECOM) is a major annual international event organized by IEEE, focusing on communications and networking. It is considered a leading conference in the field, with a rigorous peer-review process, making it a top-tier venue.",ieee_venues.csv,IEEE Global Communications Conference,NA,IEEE,NA
IEEE Global Communications Conference,Video Service-Oriented Vehicular Collaboration: A Multi-Agent Proximal Policy Optimization Approach,Zhidu Li;Xue Jiang;Dapeng Wu;Honggang Wang;Tong Tang;Ruyan Wang,"To guarantee heterogeneous performance requirements of diverse vehicular services, it is necessary to design a full cooperative policy for both vehicle to infrastructure (V2I) links and vehicle to vehicle (V2V) links. This paper investigates how to improve the quality of experience (QoE) of the V2I users for video services while satisfying the delay requirements of both V2I and V2V links. In specific, a QoE maximization problem is formulated with consideration of vehicular collaboration where task offloading decision, channel reuse decision and power allocation of V2V users are all included. A multi-agent reinforcement learning (MARL) framework is then designed, where a new reward function is proposed to evaluate the utility of the considered network. Thereafter, a proximal policy optimization approach is proposed to enable each V2V user to learn policy individually with the shared global network reward. The effectiveness of the proposed approach is finally validated with comparison of other baseline approaches through extensive simulation experiments.",2021,https://ieeexplore.ieee.org/document/9685857,10.1109/GLOBECOM46510.2021.9685857,6,top-tier,yes,"communications, networking",0.95,"The IEEE Global Communications Conference (GLOBECOM) is a major annual international event organized by IEEE, focusing on communications and networking. It is considered a leading conference in the field, with a rigorous peer-review process, making it a top-tier venue.",ieee_venues.csv,IEEE Global Communications Conference,NA,IEEE,NA
IEEE Intelligent Vehicles Symposium,Adaptive Behavior Generation for Autonomous Driving using Deep Reinforcement Learning with Compact Semantic States,Peter Wolf;Karl Kurzer;Tobias Wingert;Florian Kuhnt;J. Marius Zollner,"Making the right decision in traffic is a challenging task that is highly dependent on individual preferences as well as the surrounding environment. Therefore it is hard to model solely based on expert knowledge. In this work we use Deep Reinforcement Learning to learn maneuver decisions based on a compact semantic state representation. This ensures a consistent model of the environment across scenarios as well as a behavior adaptation function, enabling on-line changes of desired behaviors without re-training. The input for the neural network is a simulated object list similar to that of Radar or Lidar sensors, superimposed by a relational semantic scene description. The state as well as the reward are extended by a behavior adaptation function and a parameterization respectively. With little expert knowledge and a set of mid-level actions, it can be seen that the agent is capable to adhere to traffic rules and learns to drive safely in a variety of situations.",2018,https://ieeexplore.ieee.org/document/8500427,10.1109/IVS.2018.8500427,8,top-tier,yes,"intelligent vehicles, autonomous systems",0.9,"The IEEE Intelligent Vehicles Symposium is a leading conference in the field of intelligent and autonomous vehicles, frequently featuring cutting-edge research. As an IEEE-sponsored event, it is peer-reviewed, drawing high-quality contributions and significant participation from academia and industry, indicating its top-tier status.",ieee_venues.csv,IEEE Intelligent Vehicles Symposium,NA,IEEE,NA
IEEE Intelligent Vehicles Symposium,Adaptive learning based on guided exploration for decision making at roundabouts,Franz Gritschneder;Patrick Hatzelmann;Markus Thom;Felix Kunz;Klaus Dietmayer,"This paper proposes a learning-based behavior generation approach for automated vehicles which is adapted sequentially. Instead of engineering behavioral policies for a variety of individual traffic situations by hand, our approach concentrates on a general problem description which is adjusted using a learning algorithm that successively derives safe actions as an outcome. Recent approaches apply Reinforcement Learning techniques for this problem using Markov Decision Processes (MDP). Our approach benefits from a trajectory planning module that uses an optimal control approach and generates realistic trajectories. Further, the trajectory planning module is exploited for the exploration in solving the adaption of the action selection problem. The task of action selection for merging into a roundabout as an exemplary traffic situation is examined. The contributions of this paper are the usage of an underlying optimization-based trajectory generation module and the evaluation of convergence of the adapted behavior, also for real-world data.",2016,https://ieeexplore.ieee.org/document/7535422,10.1109/IVS.2016.7535422,8,top-tier,yes,"intelligent vehicles, autonomous systems",0.9,"The IEEE Intelligent Vehicles Symposium is a leading conference in the field of intelligent and autonomous vehicles, frequently featuring cutting-edge research. As an IEEE-sponsored event, it is peer-reviewed, drawing high-quality contributions and significant participation from academia and industry, indicating its top-tier status.",ieee_venues.csv,IEEE Intelligent Vehicles Symposium,NA,IEEE,NA
IEEE Intelligent Vehicles Symposium,Adaptive Stress Testing for Autonomous Vehicles,Mark Koren;Saud Alsaif;Ritchie Lee;Mykel J. Kochenderfer,"This paper presents a method for testing the decision making systems of autonomous vehicles. Our approach involves perturbing stochastic elements in the vehicle's environment until the vehicle is involved in a collision. Instead of applying direct Monte Carlo sampling to find collision scenarios, we formulate the problem as a Markov decision process and use reinforcement learning algorithms to find the most likely failure scenarios. This paper presents Monte Carlo Tree Search (MCTS) and Deep Reinforcement Learning (DRL) solutions that can scale to large environments. We show that DRL can find more likely failure scenarios than MCTS with fewer calls to the simulator. A simulation scenario involving a vehicle approaching a crosswalk is used to validate the framework. Our proposed approach is very general and can be easily applied to other scenarios given the appropriate models of the vehicle and the environment.",2018,https://ieeexplore.ieee.org/document/8500400,10.1109/IVS.2018.8500400,7,top-tier,yes,"intelligent vehicles, autonomous systems",0.9,"The IEEE Intelligent Vehicles Symposium is a leading conference in the field of intelligent and autonomous vehicles, frequently featuring cutting-edge research. As an IEEE-sponsored event, it is peer-reviewed, drawing high-quality contributions and significant participation from academia and industry, indicating its top-tier status.",ieee_venues.csv,IEEE Intelligent Vehicles Symposium,NA,IEEE,NA
"IEEE International Conference on Acoustics, Speech and Signal Processing",A Controllable Lifestyle Simulator for Use in Deep Reinforcement Learning Algorithms,Libio Gonçalves Braz;Allmin Susaiyah,"Deep learning, especially deep reinforcement learning (DRL), has become one of the most useful tools for solving sequential decision-making problems. This is particularly relevant to recommender systems and drug administration in healthcare. This approach has the main drawback of requiring a lot of training, usually several millions of examples before it can learn an interesting policy. Therefore, in healthcare, it is crucial for training the neural network to use reliable and realistic simulations of users. These simulations can be measurements of the user’s vital signals throughout the day or the occurrence of lifestyle events such as sleeping, eating, etc. In this paper, we present a novel and highly generalizable simulation system based on state machines associated with probabilistic transitions to simulate the user’s lifestyle. Thanks to its random nature, the proposed approach can generate infinite yet realistic data from the simulation. It can also be controlled based on the simulation constraints, which is an important requirement for DRL algorithms. We demonstrate its usefulness and relevance in two simple cases of user behavior simulation using different types of input data. We also show its application for a DRL scenario involving behavior change interventions.",2023,https://ieeexplore.ieee.org/document/10095924,10.1109/ICASSP49357.2023.10095924,5,top-tier,yes,signal processing,1,"ICASSP is a premier conference in the fields of signal processing, acoustics, and speech. Organized by IEEE, it is highly regarded for its rigorous peer-review process and significant contributions to advancements in these areas.",ieee_venues.csv,"ICASSP - IEEE International Conference on Acoustics, Speech and Signal Processing",NA,IEEE,NA
IEEE International Conference on Automation Science and Engineering,USV Path Planning Under Marine Environment Simulation Using DWA and Safe Reinforcement Learning,Tianci Qu;Gang Xiong;Hub Ali;Xisong Dong;Yunjun Han;Zhen Shen,"It is a challenge for USV navigation due to uncertainties and disturbances in the complex marine environment, which may lead to tilting or collision. However, current path planning methods for USVs lack dynamic environment adaptivity and timeliness. We formulate this problem as a Markov Decision Process (MDP) and combine the advantages of Dynamic Window Approach (DWA) and Safe Reinforcement Learning (RL) to solve it. First, the state encoding output by DWA is employed as observation to reduce the state dimension. Second, a safety-ensured reward function is designed to avoid collision areas. Then, the actor-critic network based on RL algorithm is used. Along with the RL training, the parameters in DWA is adaptively adjusted. Simulation experiments with dynamic waves and ocean currents demonstrate the adaptivity of our method, with avg. trajectory length decreased by 10%, avg. time cost decreased by 17%, and avg. speed increased by 18%, compared to the case using only DWA.",2023,https://ieeexplore.ieee.org/document/10260584,10.1109/CASE56687.2023.10260584,6,top-tier,yes,automation and control systems,0.9,"The IEEE CASE is a premier conference known for high-quality papers in automation and control science, making it a top-tier venue. It is rigorously peer-reviewed and attracts significant contributions from academia and industry.",ieee_venues.csv,IEEE International Conference on Automation Science and Engineering,NA,IEEE,NA
IEEE International Conference on Cloud Engineering,RLSK: A Job Scheduler for Federated Kubernetes Clusters based on Reinforcement Learning,Jiaming Huang;Chuming Xiao;Weigang Wu,"Job scheduling in cluster is often considered as a difficult online decision-making problem, and its solution depends largely on the understanding of the workload and environment. People usually first propose a simple heuristic scheduling algorithm, and then perform repeated and tedious manual tests and adjustments based on the characteristics of the workload to gradually improve the algorithm. In this work, focusing on multi-cluster environments, load balancing and efficient scheduling, we present RLSK, a deep reinforcement learning based job scheduler for scheduling independent batch jobs among multiple federated cloud computing clusters adaptively. By directly specifying high-level scheduling targets, RLSK interacts with the system environment and automatically learns scheduling strategies from experience without any prior knowledge assumed over the underlying multi-cluster environment and human instructions, which avoids people's tedious testing and tuning work. We implement our scheduler based on Kubernetes, and conduct simulations to evaluate the performance of our design. The results show that, RLSK can outperform traditional scheduling algorithms.",2020,https://ieeexplore.ieee.org/document/9096488,10.1109/IC2E48712.2020.00019,8,top-tier,yes,cloud computing,0.9,"The IEEE International Conference on Cloud Engineering (IC2E) is a highly-regarded forum for cloud computing research and practice, hence it is considered top-tier. Being an IEEE conference, it is peer-reviewed and focuses on key topics in cloud engineering.",ieee_venues.csv,IEEE International Conference on Cloud Engineering,NA,IEEE,NA
IEEE International Conference on Computer Vision,Attention-Aware Deep Reinforcement Learning for Video Face Recognition,Yongming Rao;Jiwen Lu;Jie Zhou,"In this paper, we propose an attention-aware deep reinforcement learning (ADRL) method for video face recognition, which aims to discard the misleading and confounding frames and find the focuses of attentions in face videos for person recognition. We formulate the process of finding the attentions of videos as a Markov decision process and train the attention model through a deep reinforcement learning framework without using extra labels. Unlike existing attention models, our method takes information from both the image space and the feature space as the input to make better use of face information that is discarded in the feature learning process. Besides, our approach is attention-aware, which seeks different attentions of videos for the recognition of different pairs of videos. Our approach achieves very competitive video face recognition performance on three widely used video face datasets.",2017,https://ieeexplore.ieee.org/document/8237686,10.1109/ICCV.2017.424,10,top-tier,yes,computer vision,0.95,"The IEEE International Conference on Computer Vision (ICCV) is a highly regarded and prestigious conference in the field of computer vision, attracting top researchers and practitioners globally. It is known for its rigorous peer-review process and influential research presentations.",ieee_venues.csv,IEEE International Conference on Computer Vision,NA,IEEE,NA
IEEE International Conference on Data Engineering,A Model-Agnostic Approach for Learning with Noisy Labels of Arbitrary Distributions,Shuang Hao;Peng Li;Renzhi Wu;Xu Chu,"Most real-world datasets contain label noise, which can negatively affect downstream ML models trained on them. To deal with this problem, one can clean the mislabeled data before training, which is not only time-consuming and expensive but also requires domain expertise. Another approach is to use a noise-robust ML training algorithm. However, existing methods have some prerequisites that may not be practical in many applications( e. g. , they are tied to specific downstream model architecture or they are applicable to specific noise distributions). In this paper, we propose a model-agnostic approach for learning with noisy labels of arbitrary distributions. In particular, our approach can work with any gradient descent optimization based machine learning model and deal with any label noise distribution. We achieve them by proposing two theoretically grounded noise-robust loss functions( for different noise distributions) , and we are able to automatically decide which loss function to use based on a novel noise setting detection module. We directly learn the required hyper-parameters in the loss functions via meta-learning technique to minimize the loss on a given small clean validation set, and propose several strategies to improve the efficiency of training. Experiments on multiple datasets with both real-world and injected label noise show that our method performs better than state-of-the-art approaches.",2022,https://ieeexplore.ieee.org/document/9835412,10.1109/ICDE53745.2022.00096,13,top-tier,yes,data engineering,0.95,"The IEEE International Conference on Data Engineering (ICDE) is a leading conference in the field of data engineering. It is recognized for its rigorous peer-review process and high-quality publications, making it a top-tier venue.",ieee_venues.csv,IEEE International Conference on Data Engineering,NA,IEEE,NA
IEEE International Conference on Data Science and Advanced Analytics,CAUSALYSIS: Causal Machine Learning for Real-Estate Investment Decisions,Rodrigo Rivera-Castro;Evgeny Burnaev,"As a company, proper financial planning is challenging. The knowledge is specific and competent experts are scarce. Poor financial management has a high cost. It results in penalty fees, missed opportunities, and return on investment. CAUSALYSIS empowers small and medium businesses with financial scenario planning powered by Causal Machine Learning. We describe a use case for causal machine learning on the ROI of property rentals.",2021,https://ieeexplore.ieee.org/document/9564210,10.1109/DSAA53316.2021.9564210,3,top-tier,yes,"data science, analytics",0.9,"The IEEE International Conference on Data Science and Advanced Analytics is a well-regarded conference, drawing high-quality submissions in the field of data science, and features peer-reviewed research. It is recognized as a top venue within the data science community.",ieee_venues.csv,IEEE International Conference on Data Science and Advanced Analytics,NA,IEEE,NA
IEEE International Conference on Distributed Computing Systems,A Hierarchical Framework of Cloud Resource Allocation and Power Management Using Deep Reinforcement Learning,Ning Liu;Zhe Li;Jielong Xu;Zhiyuan Xu;Sheng Lin;Qinru Qiu;Jian Tang;Yanzhi Wang,"Automatic decision-making approaches, such as reinforcement learning (RL), have been applied to (partially) solve the resource allocation problem adaptively in the cloud computing system. However, a complete cloud resource allocation framework exhibits high dimensions in state and action spaces, which prohibit the usefulness of traditional RL techniques. In addition, high power consumption has become one of the critical concerns in design and control of cloud computing systems, which degrades system reliability and increases cooling cost. An effective dynamic power management (DPM) policy should minimize power consumption while maintaining performance degradation within an acceptable level. Thus, a joint virtual machine (VM) resource allocation and power management framework is critical to the overall cloud computing system. Moreover, novel solution framework is necessary to address the even higher dimensions in state and action spaces. In this paper, we propose a novel hierarchical framework for solving the overall resource allocation and power management problem in cloud computing systems. The proposed hierarchical framework comprises a global tier for VM resource allocation to the servers and a local tier for distributed power management of local servers. The emerging deep reinforcement learning (DRL) technique, which can deal with complicated control problems with large state space, is adopted to solve the global tier problem. Furthermore, an autoencoder and a novel weight sharing structure are adopted to handle the high-dimensional state space and accelerate the convergence speed. On the other hand, the local tier of distributed server power managements comprises an LSTM based workload predictor and a model-free RL based power manager, operating in a distributed manner. Experiment results using actual Google cluster traces show that our proposed hierarchical framework significantly saves the power consumption and energy usage than the baseline while achieving n...",2017,https://ieeexplore.ieee.org/document/7979983,10.1109/ICDCS.2017.123,11,top-tier,yes,"distributed computing, computer science",0.95,"The IEEE International Conference on Distributed Computing Systems (ICDCS) is a well-respected venue in distributed computing, known for its rigorous peer-review process and strong impact in academia, indicating a top-tier status.",ieee_venues.csv,IEEE International Conference on Distributed Computing Systems,NA,IEEE,NA
IEEE Internet of Things Journal,A Deep Reinforcement Learning Model for a Two-Layer Scheduling Policy in Urban Public Resources,Cong Zhang;Fan Wu;He Wang;Hegeng Zhang;Huadong Ma;Yuanan Liu,"The issue of efficient scheduling and deployment of urban public resources has become increasingly important with the development of technological innovations and the mobility of societies. The arbitrary usage behavior of users causes the unbalanced distribution of resources and makes it difficult for users to get adequate resources in some places but redundant resources in others. Therefore, designing an efficient scheduling policy for public resources becomes crucial to promoting resource utilization and customer satisfaction. In this article, we propose a novel scheduling system for public resources that aligns with the actual value-driven scheduling strategy and take the bike-sharing system as an example. Then, we design a deep reinforcement learning algorithm named two action layer proximal policy optimization (TALPPO) to generate an effective sharing-bike scheduling strategy under realistic constraints, which could help enterprises to make better management and operation decisions. Finally, we compare the proposed algorithm with the other ten baseline models and provide extensive experimental results on two data sets called Mobike (dockless) and Citi Bike (docked) to evaluate the performance of our proposed approach.",2024,https://ieeexplore.ieee.org/document/10183782,10.1109/JIOT.2023.3292903,16,top-tier,yes,"internet of things, computer science, engineering",1,"The IEEE Internet of Things Journal is a well-regarded publication in the field of IoT. It is peer-reviewed and recognized for high-quality research, contributing significantly to the domain. Its association with IEEE further solidifies its reputation as a top-tier journal.",ieee_venues.csv,IEEE Internet of Things Journal,NA,IEEE,NA
IEEE Transactions on Power Systems,Joint Energy and Carbon Trading for Multi-Microgrid System Based on Multi-Agent Deep Reinforcement Learning,Yanting Zhou;Zhongjing Ma;Tianyu Wang;Jinhui Zhang;Xingyu Shi;Suli Zou,"Carbon trading has emerged as an effective way to promote the renewable generation and sustainable energy development. Since carbon emissions are closely coupled to energy system, it is a challenge to design a market mechanism for joint energy and carbon trading to achieve better strategies. In this study, the energy management problem with a specific focus on joint trading in multi-microgrid system is investigated by utilizing a multi-agent deep reinforcement learning approach. Initially, a joint energy and carbon trading market is established and the dispatch optimization problem is formulated as a Markov decision process without modeling uncertainties accurately. This mechanism enables direct one-to-one energy transactions among all areas, avoiding the market clearing in traditional multi-party local energy trading markets. To enhance the learning efficiency and maintain agent privacy, an enhanced multi-agent proximal policy optimization (MAPPO) algorithm that incorporates a parameter sharing mechanism is introduced. Moreover, the recurrent neural networks (RNN) structure is leveraged to perform feature encoding for individual agents, which improves the overall feature extraction capability. Through comprehensive experiments involving various algorithms, the proposed approach reduce operating costs 14.86 \n%\\%\n and carbon emissions 19.04 \n%\\%\n compared with traditional MAPPO, which validates the effectiveness and performance benefits.",2024,https://ieeexplore.ieee.org/document/10477548,10.1109/TPWRS.2024.3380070,13,top-tier,yes,"electrical engineering, power systems",1,"IEEE Transactions on Power Systems is a leading journal in the field of electrical engineering, specifically focusing on power systems. It is highly respected, peer-reviewed, and widely regarded as a top-tier publication within the electrical engineering community.",ieee_venues.csv,IEEE Transactions on Power Systems,NA,IEEE,NA